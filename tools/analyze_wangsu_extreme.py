#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç½‘å®¿ç§‘æŠ€æè‡´æ‹†åˆ†åˆ†æå™¨ (Phase 0)
CTOæŒ‡ä»¤ï¼šæŠŠç½‘å®¿1-26/2-13æ‹†åˆ°æè‡´ï¼Œäº§å‡ºæ ‡æ†æŠ¥å‘Š

åˆ†æç»´åº¦ï¼š
1. äº‹ä»¶ç”Ÿå‘½å‘¨æœŸï¼ˆT_fake/T_up/T_downã€Î”p_fake/Î”p_up/Î”p_downã€èµ„é‡‘ratioè·¯å¾„ï¼‰
2. å¯äº¤æ˜“çª—å£ï¼šäººå¯ä¸Šè½¦èŠ‚ç‚¹çš„æ”¶ç›Š/å›æ’¤åˆ†å¸ƒ
3. ç¯å¢ƒæ¡ä»¶ï¼šresonance_scoreã€market_sentimentã€risk_score
4. äº‹ä»¶åT+1/T+2/T+3èµ°åŠ¿ç»“æœ
"""

import sys
from pathlib import Path
from datetime import datetime, timedelta
import json
import pandas as pd
import numpy as np

PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from logic.services.data_service import data_service
from logic.qmt_historical_provider import QMTHistoricalProvider
from logic.rolling_metrics import RollingFlowCalculator
from logic.event_lifecycle_analyzer import EventLifecycleAnalyzer


class WangsuExtremeAnalyzer:
    """ç½‘å®¿ç§‘æŠ€æè‡´æ‹†åˆ†åˆ†æå™¨"""
    
    def __init__(self):
        self.code = "300017"
        self.name = "ç½‘å®¿ç§‘æŠ€"
        self.true_date = "2026-01-26"
        self.trap_date = "2026-02-13"
        
    def analyze_case(self, date: str, label: str) -> dict:
        """åˆ†æå•ä¸ªæ¡ˆä¾‹"""
        print(f"\n{'='*80}")
        print(f"åˆ†æ {self.name} {date} ({label})")
        print(f"{'='*80}")
        
        result = {
            'code': self.code,
            'name': self.name,
            'date': date,
            'label': label,
        }
        
        # 1. åŠ è½½Tickæ•°æ®
        df_ticks = self._load_tick_data(date)
        if df_ticks is None:
            return result
        
        result['tick_count'] = len(df_ticks)
        result['pre_close'] = df_ticks['pre_close'].iloc[0]
        
        # 2. äº‹ä»¶ç”Ÿå‘½å‘¨æœŸåˆ†æ
        lifecycle = self._analyze_lifecycle(df_ticks, result['pre_close'])
        result['lifecycle'] = lifecycle
        
        # 3. å¯äº¤æ˜“çª—å£åˆ†æ
        tradable = self._analyze_tradable_windows(df_ticks, lifecycle)
        result['tradable_windows'] = tradable
        
        # 4. ç¯å¢ƒæ¡ä»¶åˆ†æ
        environment = self._analyze_environment(date)
        result['environment'] = environment
        
        # 5. ç»´æŒèƒ½åŠ›åˆ†æ (Phase 1æ ¸å¿ƒ)
        sustain_ability = self._analyze_sustain_ability(df_ticks, lifecycle)
        result['sustain_ability'] = sustain_ability
        
        # 6. äº‹ä»¶åèµ°åŠ¿åˆ†æ
        post_event = self._analyze_post_event(date)
        result['post_event'] = post_event
        
        return result
    
    def _load_tick_data(self, date: str) -> pd.DataFrame:
        """åŠ è½½Tickæ•°æ®"""
        formatted_code = data_service._format_code(self.code)
        pre_close = data_service.get_pre_close(self.code, date)
        
        if pre_close <= 0:
            print(f"âŒ æ— æ³•è·å–æ˜¨æ”¶ä»·")
            return None
        
        start_time = date.replace('-', '') + '093000'
        end_time = date.replace('-', '') + '150000'
        
        provider = QMTHistoricalProvider(
            stock_code=formatted_code,
            start_time=start_time,
            end_time=end_time,
            period='tick'
        )
        
        tick_count = provider.get_tick_count()
        if tick_count == 0:
            print(f"âŒ æ— Tickæ•°æ®")
            return None
        
        print(f"âœ… åŠ è½½ {tick_count} æ¡Tickæ•°æ®ï¼Œæ˜¨æ”¶: {pre_close}")
        
        # è®¡ç®—èµ„é‡‘æµ
        calc = RollingFlowCalculator(windows=[1, 5, 15])
        results = []
        last_tick = None
        
        for tick in provider.iter_ticks():
            metrics = calc.add_tick(tick, last_tick)
            true_change = (tick['lastPrice'] - pre_close) / pre_close * 100
            
            results.append({
                'time': datetime.fromtimestamp(int(tick['time']) / 1000),
                'price': tick['lastPrice'],
                'true_change_pct': true_change,
                'flow_1min': metrics.flow_1min.total_flow,
                'flow_5min': metrics.flow_5min.total_flow,
                'flow_15min': metrics.flow_15min.total_flow,
                'pre_close': pre_close,
            })
            last_tick = tick
        
        return pd.DataFrame(results)
    
    def _analyze_lifecycle(self, df: pd.DataFrame, pre_close: float) -> dict:
        """åˆ†æäº‹ä»¶ç”Ÿå‘½å‘¨æœŸ"""
        analyzer = EventLifecycleAnalyzer(
            breakout_threshold=5.0,
            trap_reversal_threshold=3.0,
            max_drawdown_threshold=5.0
        )
        
        events = analyzer.analyze_day(df, pre_close)
        
        lifecycle = {
            'max_change_pct': df['true_change_pct'].max(),
            'min_change_pct': df['true_change_pct'].min(),
            'final_change_pct': df['true_change_pct'].iloc[-1],
            'total_inflow_yi': df['flow_5min'].sum() / 1e8,  # å•ä½ï¼šäº¿å…ƒ
        }
        
        # çœŸèµ·çˆ†äº‹ä»¶
        if events['breakouts']:
            evt = events['breakouts'][0]
            if evt.push_phase:
                # èµ„é‡‘å•ä½è½¬æ¢ä¸ºäº¿å…ƒï¼ˆ1äº¿å…ƒ = 1e8å…ƒï¼‰
                total_inflow_yi = evt.push_phase.total_inflow / 1e8
                max_flow_yi = evt.push_phase.max_flow_5min / 1e8
                
                lifecycle['breakout'] = {
                    't_start': evt.push_phase.t_start,
                    't_end': evt.push_phase.t_end,
                    'warmup_duration': evt.push_phase.duration_minutes,  # çœŸèµ·çˆ†ç”¨warmup_duration
                    'change_start_pct': evt.push_phase.change_start_pct,
                    'change_end_pct': evt.push_phase.change_end_pct,
                    'change_peak_pct': evt.push_phase.change_peak_pct,
                    'max_drawdown_pct': evt.push_phase.max_drawdown_pct,
                    'total_inflow_yi': total_inflow_yi,  # å•ä½ï¼šäº¿å…ƒ
                    'max_flow_5min_yi': max_flow_yi,  # å•ä½ï¼šäº¿å…ƒ
                    'sustain_ratio': evt.push_phase.sustain_ratio,
                    'efficiency': evt.push_phase.price_efficiency,
                    'is_gradual_push': evt.is_gradual_push,
                }
                print(f"\nğŸ“ˆ çœŸèµ·çˆ†æ¨å‡é˜¶æ®µ:")
                print(f"   æ—¶é—´: {evt.push_phase.t_start} -> {evt.push_phase.t_end}")
                print(f"   æ¨å‡æ—¶é•¿: {evt.push_phase.duration_minutes:.1f}åˆ†é’Ÿ")
                print(f"   æ¶¨å¹…: {evt.push_phase.change_start_pct:.2f}% -> {evt.push_phase.change_end_pct:.2f}%")
                print(f"   èµ„é‡‘æµå…¥: {total_inflow_yi:.2f}äº¿å…ƒ")
        
        # éª—ç‚®äº‹ä»¶
        if events['traps']:
            evt = events['traps'][0]
            if evt.fake_phase:
                lifecycle['trap'] = {
                    't_fake': evt.t_fake,
                    't_peak': evt.t_peak,
                    't_fail': evt.t_fail,
                    'fake_duration': evt.fake_duration,  # éª—ç‚®ç”¨fake_duration
                    'fake_change_pct': evt.fake_change_pct,
                    'fall_duration': evt.fall_duration,
                    'fall_change_pct': evt.fall_change_pct,
                }
                print(f"\nğŸ“‰ éª—ç‚®æ¬ºéª—é˜¶æ®µ:")
                print(f"   èµ·ç‚¹: {evt.t_fake}, é«˜ç‚¹: {evt.t_peak}, å¤±è´¥: {evt.t_fail}")
                print(f"   æ¬ºéª—æ—¶é•¿: {evt.fake_duration:.1f}åˆ†é’Ÿ, å¹…åº¦: {evt.fake_change_pct:.2f}%")
                print(f"   å è½æ—¶é•¿: {evt.fall_duration:.1f}åˆ†é’Ÿ, å¹…åº¦: {evt.fall_change_pct:.2f}%")
        
        return lifecycle
    
    def _analyze_tradable_windows(self, df: pd.DataFrame, lifecycle: dict) -> dict:
        """åˆ†æå¯äº¤æ˜“çª—å£"""
        print(f"\nğŸ¯ å¯äº¤æ˜“çª—å£åˆ†æ:")
        
        tradable = {
            'entry_points': [],
            'pnl_distribution': {}
        }
        
        # æ¨¡æ‹Ÿä¸åŒå…¥åœºæ—¶æœºçš„æ”¶ç›Š
        # ä»¥çªç ´5%ä¸ºä¿¡å·èµ·ç‚¹
        signal_points = df[df['true_change_pct'] >= 5.0].index.tolist()
        
        if not signal_points:
            return tradable
        
        signal_idx = signal_points[0]
        signal_price = df.loc[signal_idx, 'price']
        
        # æ¨¡æ‹Ÿåœ¨ä¿¡å·å1min/3min/5min/10minå…¥åœº
        entry_delays = [1, 3, 5, 10]  # åˆ†é’Ÿ
        
        for delay in entry_delays:
            entry_idx = signal_idx + delay * 20  # çº¦20ä¸ªtick/åˆ†é’Ÿ
            if entry_idx >= len(df):
                continue
            
            entry_price = df.loc[entry_idx, 'price']
            entry_time = df.loc[entry_idx, 'time'].strftime('%H:%M:%S')
            
            # è®¡ç®—æŒæœ‰åˆ°æ”¶ç›˜çš„æ”¶ç›Š
            exit_price = df['price'].iloc[-1]
            pnl_pct = (exit_price - entry_price) / entry_price * 100
            
            # è®¡ç®—æœŸé—´æœ€å¤§å›æ’¤
            hold_df = df.iloc[entry_idx:]
            cummax = hold_df['price'].cummax()
            drawdowns = (cummax - hold_df['price']) / cummax * 100
            max_drawdown = drawdowns.max()
            
            tradable['entry_points'].append({
                'delay_minutes': delay,
                'entry_time': entry_time,
                'entry_price': entry_price,
                'pnl_pct': pnl_pct,
                'max_drawdown_pct': max_drawdown,
            })
            
            print(f"   ä¿¡å·å{delay}åˆ†é’Ÿå…¥åœº ({entry_time}):")
            print(f"      å…¥åœºä»·: {entry_price:.2f}, æ”¶ç›˜æ”¶ç›Š: {pnl_pct:+.2f}%, æœ€å¤§å›æ’¤: {max_drawdown:.2f}%")
        
        # æ”¶ç›Šåˆ†å¸ƒç»Ÿè®¡
        if tradable['entry_points']:
            pnls = [e['pnl_pct'] for e in tradable['entry_points']]
            tradable['pnl_distribution'] = {
                'min': min(pnls),
                'max': max(pnls),
                'mean': np.mean(pnls),
            }
        
        return tradable
    
    def _analyze_environment(self, date: str) -> dict:
        """åˆ†æç¯å¢ƒæ¡ä»¶ - Phase 1å¢å¼ºç‰ˆ"""
        print(f"\nğŸŒ ç¯å¢ƒæ¡ä»¶åˆ†æ (Phase 1å¢å¼ºç‰ˆ):")
        
        environment = {
            'date': date,
            'resonance_score': None,
            'market_sentiment': None,
            'risk_score': None,
            'environment_score': 0.0,  # ç»¼åˆç¯å¢ƒè¯„åˆ†
        }
        
        # 1. åŠ è½½å¸‚åœºæƒ…ç»ªæ•°æ®ï¼ˆæ”¯æŒå¤šç§æ—¥æœŸæ ¼å¼ï¼‰
        sentiment_loaded = False
        sentiment_path = PROJECT_ROOT / "config" / "market_sentiment.json"
        if sentiment_path.exists():
            try:
                with open(sentiment_path, 'r', encoding='utf-8') as f:
                    sentiment_data = json.load(f)
                
                # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼åŒ¹é…
                date_formats = [date, date.replace('-', ''), f"{date.replace('-', '')[:8]}"]
                
                for date_fmt in date_formats:
                    if date_fmt in sentiment_data:
                        environment['market_sentiment'] = sentiment_data[date_fmt]
                        sentiment_info = sentiment_data[date_fmt]
                        sentiment_score = sentiment_info.get('sentiment_score', 0)
                        limit_up = sentiment_info.get('limit_up_count', 0)
                        limit_down = sentiment_info.get('limit_down_count', 0)
                        
                        print(f"   å¸‚åœºæƒ…ç»ª: {sentiment_score:.2f} [æ¶¨åœ={limit_up}, è·Œåœ={limit_down}]")
                        sentiment_loaded = True
                        break
                
                if not sentiment_loaded:
                    # ä½¿ç”¨æœ€è¿‘æ—¥æœŸçš„æƒ…ç»ªæ•°æ®ä½œä¸ºå›é€€
                    available_dates = list(sentiment_data.keys())
                    if available_dates:
                        latest_date = max(available_dates)
                        environment['market_sentiment'] = sentiment_data[latest_date]
                        print(f"   å¸‚åœºæƒ…ç»ª(æœ€è¿‘): {sentiment_data[latest_date].get('sentiment_score', 0):.2f} (æ—¥æœŸ: {latest_date})")
                        sentiment_loaded = True
                        
            except Exception as e:
                print(f"   âš ï¸ å¸‚åœºæƒ…ç»ªåŠ è½½å¤±è´¥: {e}")
        
        if not sentiment_loaded:
            print(f"   å¸‚åœºæƒ…ç»ª: [æ•°æ®ç¼ºå¤±]")
        
        # 2. é›†æˆWindFilterè·å–æ¿å—å…±æŒ¯åˆ†æ•°
        resonance_loaded = False
        try:
            # å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…å¾ªç¯ä¾èµ–
            from logic.strategies.wind_filter import WindFilter
            
            wind_filter = WindFilter()
            resonance_result = wind_filter.check_sector_resonance(self.code)
            
            environment['resonance_score'] = resonance_result.get('resonance_score', 0)
            environment['resonance_details'] = {
                'is_resonance': resonance_result.get('is_resonance', False),
                'limit_up_count': resonance_result.get('limit_up_count', 0),
                'breadth': resonance_result.get('breadth', 0),
                'passed_conditions': resonance_result.get('passed_conditions', [])
            }
            
            resonance_score = environment['resonance_score']
            limit_up_count = environment['resonance_details']['limit_up_count']
            breadth_pct = environment['resonance_details']['breadth'] * 100
            passed_conditions = environment['resonance_details']['passed_conditions']
            
            print(f"   æ¿å—å…±æŒ¯: {resonance_score:.2f} [æ¶¨åœ={limit_up_count}, ä¸Šæ¶¨={breadth_pct:.1f}%, æ¡ä»¶={','.join(passed_conditions) if passed_conditions else 'æ— '}]")
            resonance_loaded = True
            
        except ImportError as e:
            print(f"   âš ï¸ WindFilterå¯¼å…¥å¤±è´¥: {e}")
        except Exception as e:
            print(f"   âš ï¸ WindFilterè®¡ç®—å¤±è´¥: {e}")
        
        if not resonance_loaded:
            print(f"   æ¿å—å…±æŒ¯: [è®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨å ä½å€¼0.5]")
            environment['resonance_score'] = 0.5
        
        # 3. é£é™©è¯„åˆ†ï¼ˆå ä½å®ç°ï¼‰
        # TODO: é›†æˆRiskServiceæˆ–TrapDetector
        environment['risk_score'] = 0.5  # é»˜è®¤ä¸­ç­‰é£é™©
        print(f"   é£é™©è¯„åˆ†: {environment['risk_score']:.2f} [å ä½å®ç°]")
        
        # 4. è®¡ç®—ç»¼åˆç¯å¢ƒè¯„åˆ†ï¼ˆ0-1ï¼‰
        # æƒé‡ï¼šå…±æŒ¯åˆ†æ•°40%ï¼Œå¸‚åœºæƒ…ç»ª40%ï¼Œé£é™©è¯„åˆ†20%ï¼ˆé£é™©è¶Šé«˜åˆ†æ•°è¶Šä½ï¼‰
        sentiment_score = 0
        if environment['market_sentiment'] and 'sentiment_score' in environment['market_sentiment']:
            sentiment_score = environment['market_sentiment']['sentiment_score']
        elif environment['market_sentiment'] and isinstance(environment['market_sentiment'], dict):
            # å°è¯•å…¶ä»–å¯èƒ½çš„é”®å
            for key in ['score', 'value', 'rating']:
                if key in environment['market_sentiment']:
                    sentiment_score = environment['market_sentiment'][key]
                    break
        
        resonance_score = environment['resonance_score'] or 0.5
        risk_score = environment['risk_score'] or 0.5
        
        # é£é™©åˆ†æ•°éœ€è¦åè½¬ï¼šé£é™©è¶Šé«˜ï¼Œç¯å¢ƒåˆ†è¶Šä½
        risk_adjusted = 1.0 - abs(risk_score - 0.5) * 2  # 0.5é£é™©å¾—1åˆ†ï¼Œ0æˆ–1é£é™©å¾—0åˆ†
        
        environment['environment_score'] = (
            resonance_score * 0.4 + 
            sentiment_score * 0.4 + 
            risk_adjusted * 0.2
        )
        
        print(f"   ç»¼åˆç¯å¢ƒåˆ†: {environment['environment_score']:.2f}")
        
        return environment
    
    def _analyze_sustain_ability(self, df: pd.DataFrame, lifecycle: dict) -> dict:
        """
        åˆ†æç»´æŒèƒ½åŠ›æŒ‡æ ‡ - Phase 1æ ¸å¿ƒåŠŸèƒ½
        
        æ ¸å¿ƒæŒ‡æ ‡ï¼š
        1. æ—¶é—´ç»´åº¦ï¼šé«˜ä½ç»´æŒæ—¶é•¿ï¼ˆä»·æ ¼ä¿æŒåœ¨æ¨å‡ç»“æŸä»·-2%ä»¥ä¸Šçš„æ—¶é—´ï¼‰
        2. å¼ºåº¦ç»´åº¦ï¼šç»´æŒæœŸé—´å¹³å‡èµ„é‡‘æµå…¥ï¼ˆäº¿å…ƒ/5minï¼‰
        3. ç¨³å®šæ€§ç»´åº¦ï¼šä»·æ ¼æ³¢åŠ¨ç‡ï¼ˆç»´æŒæœŸé—´ä»·æ ¼æ ‡å‡†å·®ï¼‰
        4. ç»¼åˆå¾—åˆ†ï¼šåŠ æƒç»´æŒèƒ½åŠ›è¯„åˆ†ï¼ˆ0-1ï¼‰
        
        Args:
            df: Tickæ•°æ®DataFrame
            lifecycle: äº‹ä»¶ç”Ÿå‘½å‘¨æœŸåˆ†æç»“æœ
        
        Returns:
            dict: ç»´æŒèƒ½åŠ›åˆ†æç»“æœ
        """
        print(f"\nğŸ“Š ç»´æŒèƒ½åŠ›åˆ†æ (Phase 1æ ¸å¿ƒ):")
        
        sustain = {
            'high_level_duration_minutes': 0,  # é«˜ä½ç»´æŒæ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰
            'sustain_strength': 0,  # ç»´æŒå¼ºåº¦ï¼ˆäº¿å…ƒ/5minï¼‰
            'price_volatility': 0,  # ä»·æ ¼æ³¢åŠ¨ç‡ï¼ˆ%ï¼‰
            'composite_score': 0,  # ç»¼åˆç»´æŒå¾—åˆ†ï¼ˆ0-1ï¼‰
            'sustain_grade': 'Unknown',  # ç»´æŒç­‰çº§
            'details': {},  # è¯¦ç»†åˆ†ææ•°æ®
        }
        
        # 1. è¯†åˆ«äº‹ä»¶ç±»å‹å¹¶è®¡ç®—ç»´æŒèƒ½åŠ›
        t_breakout = lifecycle.get('breakout', {})
        t_trap = lifecycle.get('trap', {})
        
        if t_breakout:
            # çœŸèµ·çˆ†ï¼šåŸºäºæ¨å‡ç»“æŸç‚¹è®¡ç®—ç»´æŒèƒ½åŠ›
            sustain_result = self._calculate_true_breakout_sustain(df, t_breakout)
            sustain.update(sustain_result)
            sustain['sustain_type'] = 'TrueBreakout'
            
        elif t_trap:
            # éª—ç‚®ï¼šåŸºäºæ¬ºéª—é«˜ç‚¹è®¡ç®—ç»´æŒèƒ½åŠ›ï¼ˆé€šå¸¸å¾ˆçŸ­ï¼‰
            sustain_result = self._calculate_trap_sustain(df, t_trap)
            sustain.update(sustain_result)
            sustain['sustain_type'] = 'Trap'
        else:
            print(f"   âš ï¸ æœªè¯†åˆ«åˆ°æ˜ç¡®äº‹ä»¶ç±»å‹")
            sustain['sustain_type'] = 'Unknown'
        
        # 2. è¾“å‡ºåˆ†æç»“æœ
        if sustain['high_level_duration_minutes'] > 0:
            print(f"   é«˜ä½ç»´æŒæ—¶é•¿: {sustain['high_level_duration_minutes']:.1f}åˆ†é’Ÿ")
            print(f"   ç»´æŒå¼ºåº¦: {sustain['sustain_strength']:.3f}äº¿å…ƒ/5min")
            print(f"   ä»·æ ¼æ³¢åŠ¨ç‡: {sustain['price_volatility']:.2f}%")
            print(f"   ç»¼åˆç»´æŒå¾—åˆ†: {sustain['composite_score']:.2f}")
            print(f"   ç»´æŒç­‰çº§: {sustain['sustain_grade']}")
        else:
            print(f"   âš ï¸ ç»´æŒèƒ½åŠ›åˆ†æå¤±è´¥æˆ–æ— ç»´æŒé˜¶æ®µ")
        
        return sustain
    
    def _calculate_true_breakout_sustain(self, df: pd.DataFrame, breakout_info: dict) -> dict:
        """è®¡ç®—çœŸèµ·çˆ†ç»´æŒèƒ½åŠ›"""
        sustain = {
            'high_level_duration_minutes': 0,
            'sustain_strength': 0,
            'price_volatility': 0,
            'composite_score': 0,
            'sustain_grade': 'Poor',
        }
        
        # è·å–æ¨å‡ç»“æŸæ—¶é—´ç‚¹
        push_end_time = breakout_info.get('t_end', '')
        if not push_end_time:
            return sustain
        
        # æ‰¾åˆ°æ¨å‡ç»“æŸç‚¹åœ¨dfä¸­çš„ç´¢å¼•
        push_end_idx = self._find_time_index(df, push_end_time)
        if push_end_idx >= len(df) - 1:
            return sustain
        
        # æ¨å‡ç»“æŸä»·æ ¼ï¼ˆä½œä¸ºç»´æŒèµ·ç‚¹ï¼‰
        push_end_price = df.loc[push_end_idx, 'price']
        sustain_threshold = push_end_price * 0.98  # -2%é˜ˆå€¼
        
        # æå–ç»´æŒé˜¶æ®µæ•°æ®ï¼ˆæ¨å‡ç»“æŸåï¼‰
        sustain_df = df.iloc[push_end_idx:]
        
        # è®¡ç®—é«˜ä½ç»´æŒæ—¶é•¿ï¼šä»·æ ¼ä¿æŒåœ¨é˜ˆå€¼ä»¥ä¸Šçš„æ—¶é•¿
        above_threshold = sustain_df[sustain_df['price'] >= sustain_threshold]
        if len(above_threshold) == 0:
            return sustain
        
        # æ—¶é—´ç»´åº¦ï¼šé«˜ä½ç»´æŒæ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰
        # å‡è®¾Tickæ•°æ®çº¦3ç§’ä¸€æ¡ï¼ˆå®é™…å¯èƒ½ä¸åŒï¼‰
        tick_interval_seconds = 3  # ä¿å®ˆä¼°è®¡
        sustain_minutes = len(above_threshold) * tick_interval_seconds / 60
        
        # å¼ºåº¦ç»´åº¦ï¼šç»´æŒæœŸé—´å¹³å‡èµ„é‡‘æµå…¥ï¼ˆäº¿å…ƒ/5minï¼‰
        avg_flow = above_threshold['flow_5min'].mean() / 1e8  # è½¬æ¢ä¸ºäº¿å…ƒ
        
        # ç¨³å®šæ€§ç»´åº¦ï¼šä»·æ ¼æ³¢åŠ¨ç‡ï¼ˆç»´æŒæœŸé—´ä»·æ ¼æ ‡å‡†å·®ï¼Œ%ï¼‰
        price_volatility = above_threshold['price'].std() / above_threshold['price'].mean() * 100
        
        # è®¡ç®—ç»¼åˆå¾—åˆ†ï¼ˆ0-1ï¼‰
        # æƒé‡ï¼šæ—¶é•¿50%ï¼Œå¼ºåº¦30%ï¼Œç¨³å®šæ€§20%
        duration_score = min(sustain_minutes / 60, 1.0)  # 60åˆ†é’Ÿä¸ºæ»¡åˆ†
        strength_score = min(avg_flow / 0.5, 1.0)  # 0.5äº¿å…ƒ/5minä¸ºæ»¡åˆ†
        stability_score = 1.0 - min(price_volatility / 10.0, 1.0)  # æ³¢åŠ¨ç‡<10%ä¸ºæ»¡åˆ†
        
        composite_score = (
            duration_score * 0.5 + 
            strength_score * 0.3 + 
            stability_score * 0.2
        )
        
        # ç¡®å®šç»´æŒç­‰çº§
        if composite_score >= 0.8:
            sustain_grade = 'Excellent'
        elif composite_score >= 0.6:
            sustain_grade = 'Good'
        elif composite_score >= 0.4:
            sustain_grade = 'Fair'
        else:
            sustain_grade = 'Poor'
        
        sustain.update({
            'high_level_duration_minutes': sustain_minutes,
            'sustain_strength': avg_flow,
            'price_volatility': price_volatility,
            'composite_score': composite_score,
            'sustain_grade': sustain_grade,
            'details': {
                'push_end_price': push_end_price,
                'sustain_threshold': sustain_threshold,
                'sustain_start_time': df.loc[push_end_idx, 'time'].strftime('%H:%M:%S'),
                'sustain_end_time': df.loc[above_threshold.index[-1], 'time'].strftime('%H:%M:%S'),
                'duration_score': duration_score,
                'strength_score': strength_score,
                'stability_score': stability_score,
            }
        })
        
        return sustain
    
    def _calculate_trap_sustain(self, df: pd.DataFrame, trap_info: dict) -> dict:
        """è®¡ç®—éª—ç‚®ç»´æŒèƒ½åŠ›ï¼ˆé€šå¸¸å¾ˆçŸ­ï¼‰"""
        sustain = {
            'high_level_duration_minutes': 0,
            'sustain_strength': 0,
            'price_volatility': 0,
            'composite_score': 0,
            'sustain_grade': 'Poor',
        }
        
        # éª—ç‚®é€šå¸¸æ²¡æœ‰çœŸæ­£çš„ç»´æŒé˜¶æ®µï¼Œä½†æˆ‘ä»¬å¯ä»¥è®¡ç®—"è™šå‡ç»´æŒ"
        # æ‰¾åˆ°ä»·æ ¼é«˜ç‚¹
        peak_price = df['price'].max()
        peak_idx = df[df['price'] == peak_price].index[0]
        
        if peak_idx >= len(df) - 1:
            return sustain
        
        # é«˜ç‚¹å-2%é˜ˆå€¼
        sustain_threshold = peak_price * 0.98
        
        # é«˜ç‚¹åçš„æ•°æ®
        after_peak_df = df.iloc[peak_idx:]
        
        # è®¡ç®—"è™šå‡ç»´æŒ"æ—¶é•¿
        above_threshold = after_peak_df[after_peak_df['price'] >= sustain_threshold]
        if len(above_threshold) == 0:
            return sustain
        
        tick_interval_seconds = 3
        sustain_minutes = len(above_threshold) * tick_interval_seconds / 60
        
        # éª—ç‚®çš„ç»´æŒé€šå¸¸å¾ˆçŸ­ï¼Œå¼ºåº¦ä½ï¼Œæ³¢åŠ¨å¤§
        avg_flow = above_threshold['flow_5min'].mean() / 1e8
        price_volatility = above_threshold['price'].std() / above_threshold['price'].mean() * 100
        
        # éª—ç‚®çš„ç»¼åˆå¾—åˆ†é€šå¸¸å¾ˆä½
        duration_score = min(sustain_minutes / 30, 1.0)  # 30åˆ†é’Ÿä¸ºæ»¡åˆ†ï¼ˆå¯¹éª—ç‚®æ›´å®½æ¾ï¼‰
        strength_score = min(avg_flow / 0.2, 1.0)  # 0.2äº¿å…ƒ/5minä¸ºæ»¡åˆ†
        stability_score = 1.0 - min(price_volatility / 15.0, 1.0)  # æ³¢åŠ¨ç‡<15%ä¸ºæ»¡åˆ†
        
        composite_score = (
            duration_score * 0.4 + 
            strength_score * 0.3 + 
            stability_score * 0.3
        )
        
        # éª—ç‚®çš„ç»´æŒç­‰çº§é€šå¸¸ä¸ºPoor
        if composite_score >= 0.5:
            sustain_grade = 'Fair'  # ç½•è§çš„"å¼ºéª—ç‚®"
        elif composite_score >= 0.3:
            sustain_grade = 'Weak'
        else:
            sustain_grade = 'Poor'
        
        sustain.update({
            'high_level_duration_minutes': sustain_minutes,
            'sustain_strength': avg_flow,
            'price_volatility': price_volatility,
            'composite_score': composite_score,
            'sustain_grade': sustain_grade,
            'details': {
                'peak_price': peak_price,
                'sustain_threshold': sustain_threshold,
                'peak_time': df.loc[peak_idx, 'time'].strftime('%H:%M:%S'),
                'sustain_end_time': df.loc[above_threshold.index[-1], 'time'].strftime('%H:%M:%S'),
                'is_trap': True,
            }
        })
        
        return sustain
    
    def _find_time_index(self, df: pd.DataFrame, target_time: str) -> int:
        """åœ¨DataFrameä¸­æŸ¥æ‰¾æ—¶é—´ç‚¹ç´¢å¼•"""
        if not target_time or 'time' not in df.columns:
            return 0
        
        # æ ‡å‡†åŒ–æ—¶é—´æ ¼å¼
        if ':' in target_time:
            # å·²ç»æ˜¯HH:MM:SSæ ¼å¼
            time_str = target_time
        else:
            # å¯èƒ½æ˜¯å…¶ä»–æ ¼å¼ï¼Œå°è¯•è½¬æ¢
            try:
                time_obj = datetime.strptime(target_time, '%H%M%S')
                time_str = time_obj.strftime('%H:%M:%S')
            except:
                return 0
        
        # åœ¨dfä¸­æŸ¥æ‰¾
        for idx, row in df.iterrows():
            if row['time'].strftime('%H:%M:%S') == time_str:
                return idx
        
        # å¦‚æœæ‰¾ä¸åˆ°ç²¾ç¡®åŒ¹é…ï¼Œæ‰¾æœ€æ¥è¿‘çš„æ—¶é—´
        for idx, row in df.iterrows():
            df_time_str = row['time'].strftime('%H:%M:%S')
            if df_time_str >= time_str:
                return idx
        
        return 0
    
    def _analyze_post_event(self, date: str) -> dict:
        """åˆ†æäº‹ä»¶åT+1/T+2/T+3èµ°åŠ¿"""
        print(f"\nğŸ“Š äº‹ä»¶åèµ°åŠ¿åˆ†æ:")
        
        post_event = {
            'event_date': date,
            't1': None,
            't2': None,
            't3': None,
        }
        
        # ä½¿ç”¨data_serviceè·å–äº‹ä»¶æ—¥æ”¶ç›˜ä»·
        try:
            formatted_code = data_service._format_code(self.code)
            
            # å…ˆè·å–äº‹ä»¶æ—¥æ•°æ®
            df_event = data_service.get_daily_data(self.code, date)
            if df_event is None or len(df_event) == 0:
                print(f"   âš ï¸ æ— æ³•è·å–äº‹ä»¶æ—¥æ•°æ®")
                return post_event
            
            event_close = df_event['close'].iloc[0]
            event_date = datetime.strptime(date, '%Y-%m-%d')
            
            # T+1
            t1_date = (event_date + timedelta(days=1)).strftime('%Y-%m-%d')
            df_t1 = data_service.get_daily_data(self.code, t1_date)
            if df_t1 is not None and len(df_t1) > 0:
                post_event['t1'] = {
                    'date': t1_date,
                    'open_gap': (df_t1['open'].iloc[0] - event_close) / event_close * 100,
                    'high_change': (df_t1['high'].iloc[0] - event_close) / event_close * 100,
                    'low_change': (df_t1['low'].iloc[0] - event_close) / event_close * 100,
                    'close_change': (df_t1['close'].iloc[0] - event_close) / event_close * 100,
                }
                print(f"   T+1 ({t1_date}):")
                print(f"      å¼€ç›˜è·³ç©º: {post_event['t1']['open_gap']:+.2f}%")
                print(f"      æ”¶ç›˜æ¶¨è·Œ: {post_event['t1']['close_change']:+.2f}%")
            
            # T+2
            t2_date = (event_date + timedelta(days=2)).strftime('%Y-%m-%d')
            df_t2 = data_service.get_daily_data(self.code, t2_date)
            if df_t2 is not None and len(df_t2) > 0:
                post_event['t2'] = {
                    'date': t2_date,
                    'close_change': (df_t2['close'].iloc[0] - event_close) / event_close * 100,
                }
                print(f"   T+2 ({t2_date}): æ”¶ç›˜æ¶¨è·Œ {post_event['t2']['close_change']:+.2f}%")
            
            # T+3
            t3_date = (event_date + timedelta(days=3)).strftime('%Y-%m-%d')
            df_t3 = data_service.get_daily_data(self.code, t3_date)
            if df_t3 is not None and len(df_t3) > 0:
                post_event['t3'] = {
                    'date': t3_date,
                    'close_change': (df_t3['close'].iloc[0] - event_close) / event_close * 100,
                }
                print(f"   T+3 ({t3_date}): æ”¶ç›˜æ¶¨è·Œ {post_event['t3']['close_change']:+.2f}%")
        
        except Exception as e:
            print(f"   âš ï¸ è·å–æ—¥çº¿æ•°æ®å¤±è´¥: {e}")
        
        return post_event
    
    def generate_report(self, true_result: dict, trap_result: dict):
        """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
        print(f"\n\n{'='*80}")
        print(f"ç½‘å®¿ç§‘æŠ€æè‡´æ‹†åˆ†æŠ¥å‘Š")
        print(f"çœŸèµ·çˆ† ({self.true_date}) vs éª—ç‚® ({self.trap_date})")
        print(f"{'='*80}\n")
        
        # å¯¹æ¯”è¡¨
        print("ã€æ ¸å¿ƒæŒ‡æ ‡å¯¹æ¯”ã€‘")
        print("-" * 80)
        print(f"{'æŒ‡æ ‡':<30} {'çœŸèµ·çˆ† (1-26)':<25} {'éª—ç‚® (2-13)':<25}")
        print("-" * 80)
        
        t_life = true_result.get('lifecycle', {})
        p_life = trap_result.get('lifecycle', {})
        
        print(f"{'å½“æ—¥æœ€é«˜æ¶¨å¹…':<30} {t_life.get('max_change_pct', 0):>+.2f}%{'':<18} {p_life.get('max_change_pct', 0):>+.2f}%")
        print(f"{'å½“æ—¥æ”¶ç›˜æ¶¨å¹…':<30} {t_life.get('final_change_pct', 0):>+.2f}%{'':<18} {p_life.get('final_change_pct', 0):>+.2f}%")
        
        # æ¨å‡é˜¶æ®µå¯¹æ¯”ï¼ˆçœŸèµ·çˆ†ç”¨warmup_durationï¼Œéª—ç‚®ç”¨fake_durationï¼‰
        t_breakout = t_life.get('breakout', {})
        p_trap = p_life.get('trap', {})
        
        # çœŸèµ·çˆ†ç‰¹å¾
        if t_breakout:
            print(f"{'æ¨å‡æ—¶é•¿ T_warmup':<30} {t_breakout.get('warmup_duration', 0):>.1f}åˆ†é’Ÿ{'':<15} {'-':<25}")
            print(f"{'æ¨å‡æ®µæ¶¨å¹… Î”p_push':<30} {t_breakout.get('change_end_pct', 0) - t_breakout.get('change_start_pct', 0):>+.2f}%{'':<17} {'-':<25}")
            print(f"{'æ¨å‡æ®µèµ„é‡‘æµå…¥':<30} {t_breakout.get('total_inflow_yi', 0):>.2f}äº¿å…ƒ{'':<16} {'-':<25}")
        
        # éª—ç‚®ç‰¹å¾
        if p_trap:
            print(f"{'æ¬ºéª—æ—¶é•¿ T_fake':<30} {'-':<25} {p_trap.get('fake_duration', 0):>.1f}åˆ†é’Ÿ")
            print(f"{'æ¬ºéª—å¹…åº¦ Î”p_fake':<30} {'-':<25} {p_trap.get('fake_change_pct', 0):>+.2f}%")
            print(f"{'å è½æ—¶é•¿ T_down':<30} {'-':<25} {p_trap.get('fall_duration', 0):>.1f}åˆ†é’Ÿ")
            print(f"{'å è½å¹…åº¦ Î”p_down':<30} {'-':<25} {p_trap.get('fall_change_pct', 0):>+.2f}%")
        
        print("-" * 80)
        
        # å¯äº¤æ˜“çª—å£å¯¹æ¯”
        print("\nã€å¯äº¤æ˜“çª—å£å¯¹æ¯”ã€‘")
        t_tradable = true_result.get('tradable_windows', {})
        p_tradable = trap_result.get('tradable_windows', {})
        
        t_entries = t_tradable.get('entry_points', [])
        p_entries = p_tradable.get('entry_points', [])
        
        if t_entries and p_entries:
            print(f"{'å…¥åœºæ—¶æœº':<15} {'çœŸèµ·çˆ†æ”¶ç›Š':<15} {'çœŸèµ·çˆ†å›æ’¤':<15} {'éª—ç‚®æ”¶ç›Š':<15} {'éª—ç‚®å›æ’¤':<15}")
            print("-" * 80)
            for t_e, p_e in zip(t_entries, p_entries):
                print(f"ä¿¡å·å{t_e['delay_minutes']}åˆ†é’Ÿ{t_e['entry_time']:<6} "
                      f"{t_e['pnl_pct']:>+.2f}%{'':<8} {t_e['max_drawdown_pct']:>.2f}%{'':<8} "
                      f"{p_e['pnl_pct']:>+.2f}%{'':<8} {p_e['max_drawdown_pct']:>.2f}%")
        
        print("\n" + "="*80)


def main():
    """ä¸»å‡½æ•°"""
    analyzer = WangsuExtremeAnalyzer()
    
    # åˆ†æçœŸèµ·çˆ†
    true_result = analyzer.analyze_case(analyzer.true_date, "çœŸèµ·çˆ†")
    
    # åˆ†æéª—ç‚®
    trap_result = analyzer.analyze_case(analyzer.trap_date, "éª—ç‚®")
    
    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    analyzer.generate_report(true_result, trap_result)
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    output_dir = PROJECT_ROOT / "data" / "wanzhu_data" / "wangsu_analysis"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_file = output_dir / f"wangsu_extreme_analysis_{timestamp}.json"
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'true_breakout': true_result,
            'trap': trap_result,
            'generated_at': datetime.now().isoformat()
        }, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"\nğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜: {output_file}")


if __name__ == "__main__":
    main()
