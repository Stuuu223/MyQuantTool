#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç½‘å®¿ç§‘æŠ€æè‡´æ‹†åˆ†åˆ†æå™¨ (Phase 0)
CTOæŒ‡ä»¤ï¼šæŠŠç½‘å®¿1-26/2-13æ‹†åˆ°æè‡´ï¼Œäº§å‡ºæ ‡æ†æŠ¥å‘Š

åˆ†æç»´åº¦ï¼š
1. äº‹ä»¶ç”Ÿå‘½å‘¨æœŸï¼ˆT_fake/T_up/T_downã€Î”p_fake/Î”p_up/Î”p_downã€èµ„é‡‘ratioè·¯å¾„ï¼‰
2. å¯äº¤æ˜“çª—å£ï¼šäººå¯ä¸Šè½¦èŠ‚ç‚¹çš„æ”¶ç›Š/å›æ’¤åˆ†å¸ƒ
3. ç¯å¢ƒæ¡ä»¶ï¼šresonance_scoreã€market_sentimentã€risk_score
4. äº‹ä»¶åT+1/T+2/T+3èµ°åŠ¿ç»“æœ
"""

import sys
from pathlib import Path
from datetime import datetime, timedelta
import json
import pandas as pd
import numpy as np

PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from logic.services.data_service import data_service
from logic.qmt_historical_provider import QMTHistoricalProvider
from logic.rolling_metrics import RollingFlowCalculator
from logic.event_lifecycle_analyzer import EventLifecycleAnalyzer


class WangsuExtremeAnalyzer:
    """ç½‘å®¿ç§‘æŠ€æè‡´æ‹†åˆ†åˆ†æå™¨"""
    
    def __init__(self):
        self.code = "300017"
        self.name = "ç½‘å®¿ç§‘æŠ€"
        self.true_date = "2026-01-26"
        self.trap_date = "2026-02-13"
        
    def analyze_case(self, date: str, label: str) -> dict:
        """åˆ†æå•ä¸ªæ¡ˆä¾‹"""
        print(f"\n{'='*80}")
        print(f"åˆ†æ {self.name} {date} ({label})")
        print(f"{'='*80}")
        
        result = {
            'code': self.code,
            'name': self.name,
            'date': date,
            'label': label,
        }
        
        # 1. åŠ è½½Tickæ•°æ®
        df_ticks = self._load_tick_data(date)
        if df_ticks is None:
            return result
        
        result['tick_count'] = len(df_ticks)
        result['pre_close'] = df_ticks['pre_close'].iloc[0]
        
        # 2. äº‹ä»¶ç”Ÿå‘½å‘¨æœŸåˆ†æ
        lifecycle = self._analyze_lifecycle(df_ticks, result['pre_close'])
        result['lifecycle'] = lifecycle
        
        # 3. å¯äº¤æ˜“çª—å£åˆ†æ
        tradable = self._analyze_tradable_windows(df_ticks, lifecycle)
        result['tradable_windows'] = tradable
        
        # 4. ç¯å¢ƒæ¡ä»¶åˆ†æ
        environment = self._analyze_environment(date)
        result['environment'] = environment
        
        # 5. äº‹ä»¶åèµ°åŠ¿åˆ†æ
        post_event = self._analyze_post_event(date)
        result['post_event'] = post_event
        
        return result
    
    def _load_tick_data(self, date: str) -> pd.DataFrame:
        """åŠ è½½Tickæ•°æ®"""
        formatted_code = data_service._format_code(self.code)
        pre_close = data_service.get_pre_close(self.code, date)
        
        if pre_close <= 0:
            print(f"âŒ æ— æ³•è·å–æ˜¨æ”¶ä»·")
            return None
        
        start_time = date.replace('-', '') + '093000'
        end_time = date.replace('-', '') + '150000'
        
        provider = QMTHistoricalProvider(
            stock_code=formatted_code,
            start_time=start_time,
            end_time=end_time,
            period='tick'
        )
        
        tick_count = provider.get_tick_count()
        if tick_count == 0:
            print(f"âŒ æ— Tickæ•°æ®")
            return None
        
        print(f"âœ… åŠ è½½ {tick_count} æ¡Tickæ•°æ®ï¼Œæ˜¨æ”¶: {pre_close}")
        
        # è®¡ç®—èµ„é‡‘æµ
        calc = RollingFlowCalculator(windows=[1, 5, 15])
        results = []
        last_tick = None
        
        for tick in provider.iter_ticks():
            metrics = calc.add_tick(tick, last_tick)
            true_change = (tick['lastPrice'] - pre_close) / pre_close * 100
            
            results.append({
                'time': datetime.fromtimestamp(int(tick['time']) / 1000),
                'price': tick['lastPrice'],
                'true_change_pct': true_change,
                'flow_1min': metrics.flow_1min.total_flow,
                'flow_5min': metrics.flow_5min.total_flow,
                'flow_15min': metrics.flow_15min.total_flow,
                'pre_close': pre_close,
            })
            last_tick = tick
        
        return pd.DataFrame(results)
    
    def _analyze_lifecycle(self, df: pd.DataFrame, pre_close: float) -> dict:
        """åˆ†æäº‹ä»¶ç”Ÿå‘½å‘¨æœŸ"""
        analyzer = EventLifecycleAnalyzer(
            breakout_threshold=5.0,
            trap_reversal_threshold=3.0,
            max_drawdown_threshold=5.0
        )
        
        events = analyzer.analyze_day(df, pre_close)
        
        lifecycle = {
            'max_change_pct': df['true_change_pct'].max(),
            'min_change_pct': df['true_change_pct'].min(),
            'final_change_pct': df['true_change_pct'].iloc[-1],
            'total_inflow_yi': df['flow_5min'].sum() / 1e8,  # å•ä½ï¼šäº¿å…ƒ
        }
        
        # çœŸèµ·çˆ†äº‹ä»¶
        if events['breakouts']:
            evt = events['breakouts'][0]
            if evt.push_phase:
                # èµ„é‡‘å•ä½è½¬æ¢ä¸ºäº¿å…ƒï¼ˆ1äº¿å…ƒ = 1e8å…ƒï¼‰
                total_inflow_yi = evt.push_phase.total_inflow / 1e8
                max_flow_yi = evt.push_phase.max_flow_5min / 1e8
                
                lifecycle['breakout'] = {
                    't_start': evt.push_phase.t_start,
                    't_end': evt.push_phase.t_end,
                    'warmup_duration': evt.push_phase.duration_minutes,  # çœŸèµ·çˆ†ç”¨warmup_duration
                    'change_start_pct': evt.push_phase.change_start_pct,
                    'change_end_pct': evt.push_phase.change_end_pct,
                    'change_peak_pct': evt.push_phase.change_peak_pct,
                    'max_drawdown_pct': evt.push_phase.max_drawdown_pct,
                    'total_inflow_yi': total_inflow_yi,  # å•ä½ï¼šäº¿å…ƒ
                    'max_flow_5min_yi': max_flow_yi,  # å•ä½ï¼šäº¿å…ƒ
                    'sustain_ratio': evt.push_phase.sustain_ratio,
                    'efficiency': evt.push_phase.price_efficiency,
                    'is_gradual_push': evt.is_gradual_push,
                }
                print(f"\nğŸ“ˆ çœŸèµ·çˆ†æ¨å‡é˜¶æ®µ:")
                print(f"   æ—¶é—´: {evt.push_phase.t_start} -> {evt.push_phase.t_end}")
                print(f"   æ¨å‡æ—¶é•¿: {evt.push_phase.duration_minutes:.1f}åˆ†é’Ÿ")
                print(f"   æ¶¨å¹…: {evt.push_phase.change_start_pct:.2f}% -> {evt.push_phase.change_end_pct:.2f}%")
                print(f"   èµ„é‡‘æµå…¥: {total_inflow_yi:.2f}äº¿å…ƒ")
        
        # éª—ç‚®äº‹ä»¶
        if events['traps']:
            evt = events['traps'][0]
            if evt.fake_phase:
                lifecycle['trap'] = {
                    't_fake': evt.t_fake,
                    't_peak': evt.t_peak,
                    't_fail': evt.t_fail,
                    'fake_duration': evt.fake_duration,  # éª—ç‚®ç”¨fake_duration
                    'fake_change_pct': evt.fake_change_pct,
                    'fall_duration': evt.fall_duration,
                    'fall_change_pct': evt.fall_change_pct,
                }
                print(f"\nğŸ“‰ éª—ç‚®æ¬ºéª—é˜¶æ®µ:")
                print(f"   èµ·ç‚¹: {evt.t_fake}, é«˜ç‚¹: {evt.t_peak}, å¤±è´¥: {evt.t_fail}")
                print(f"   æ¬ºéª—æ—¶é•¿: {evt.fake_duration:.1f}åˆ†é’Ÿ, å¹…åº¦: {evt.fake_change_pct:.2f}%")
                print(f"   å è½æ—¶é•¿: {evt.fall_duration:.1f}åˆ†é’Ÿ, å¹…åº¦: {evt.fall_change_pct:.2f}%")
        
        return lifecycle
    
    def _analyze_tradable_windows(self, df: pd.DataFrame, lifecycle: dict) -> dict:
        """åˆ†æå¯äº¤æ˜“çª—å£"""
        print(f"\nğŸ¯ å¯äº¤æ˜“çª—å£åˆ†æ:")
        
        tradable = {
            'entry_points': [],
            'pnl_distribution': {}
        }
        
        # æ¨¡æ‹Ÿä¸åŒå…¥åœºæ—¶æœºçš„æ”¶ç›Š
        # ä»¥çªç ´5%ä¸ºä¿¡å·èµ·ç‚¹
        signal_points = df[df['true_change_pct'] >= 5.0].index.tolist()
        
        if not signal_points:
            return tradable
        
        signal_idx = signal_points[0]
        signal_price = df.loc[signal_idx, 'price']
        
        # æ¨¡æ‹Ÿåœ¨ä¿¡å·å1min/3min/5min/10minå…¥åœº
        entry_delays = [1, 3, 5, 10]  # åˆ†é’Ÿ
        
        for delay in entry_delays:
            entry_idx = signal_idx + delay * 20  # çº¦20ä¸ªtick/åˆ†é’Ÿ
            if entry_idx >= len(df):
                continue
            
            entry_price = df.loc[entry_idx, 'price']
            entry_time = df.loc[entry_idx, 'time'].strftime('%H:%M:%S')
            
            # è®¡ç®—æŒæœ‰åˆ°æ”¶ç›˜çš„æ”¶ç›Š
            exit_price = df['price'].iloc[-1]
            pnl_pct = (exit_price - entry_price) / entry_price * 100
            
            # è®¡ç®—æœŸé—´æœ€å¤§å›æ’¤
            hold_df = df.iloc[entry_idx:]
            cummax = hold_df['price'].cummax()
            drawdowns = (cummax - hold_df['price']) / cummax * 100
            max_drawdown = drawdowns.max()
            
            tradable['entry_points'].append({
                'delay_minutes': delay,
                'entry_time': entry_time,
                'entry_price': entry_price,
                'pnl_pct': pnl_pct,
                'max_drawdown_pct': max_drawdown,
            })
            
            print(f"   ä¿¡å·å{delay}åˆ†é’Ÿå…¥åœº ({entry_time}):")
            print(f"      å…¥åœºä»·: {entry_price:.2f}, æ”¶ç›˜æ”¶ç›Š: {pnl_pct:+.2f}%, æœ€å¤§å›æ’¤: {max_drawdown:.2f}%")
        
        # æ”¶ç›Šåˆ†å¸ƒç»Ÿè®¡
        if tradable['entry_points']:
            pnls = [e['pnl_pct'] for e in tradable['entry_points']]
            tradable['pnl_distribution'] = {
                'min': min(pnls),
                'max': max(pnls),
                'mean': np.mean(pnls),
            }
        
        return tradable
    
    def _analyze_environment(self, date: str) -> dict:
        """åˆ†æç¯å¢ƒæ¡ä»¶"""
        print(f"\nğŸŒ ç¯å¢ƒæ¡ä»¶åˆ†æ:")
        
        environment = {
            'date': date,
            'resonance_score': None,
            'market_sentiment': None,
            'risk_score': None,
        }
        
        # å°è¯•åŠ è½½market_sentiment
        sentiment_path = PROJECT_ROOT / "config" / "market_sentiment.json"
        if sentiment_path.exists():
            try:
                with open(sentiment_path, 'r', encoding='utf-8') as f:
                    sentiment_data = json.load(f)
                # æŸ¥æ‰¾å¯¹åº”æ—¥æœŸçš„æƒ…ç»ªæ•°æ®
                if date in sentiment_data:
                    environment['market_sentiment'] = sentiment_data[date]
                    print(f"   å¸‚åœºæƒ…ç»ª: {sentiment_data[date]}")
            except:
                pass
        
        # è¿™é‡Œå¯ä»¥æ‰©å±•åŠ è½½WindFilterçš„resonance_score
        # ç›®å‰å…ˆå ä½
        print(f"   æ¿å—å…±æŒ¯: [å¾…ä»WindFilterè·å–]")
        print(f"   é£é™©è¯„åˆ†: [å¾…ä»TrapDetectorè·å–]")
        
        return environment
    
    def _analyze_post_event(self, date: str) -> dict:
        """åˆ†æäº‹ä»¶åT+1/T+2/T+3èµ°åŠ¿"""
        print(f"\nğŸ“Š äº‹ä»¶åèµ°åŠ¿åˆ†æ:")
        
        post_event = {
            'event_date': date,
            't1': None,
            't2': None,
            't3': None,
        }
        
        # ä½¿ç”¨data_serviceè·å–äº‹ä»¶æ—¥æ”¶ç›˜ä»·
        try:
            formatted_code = data_service._format_code(self.code)
            
            # å…ˆè·å–äº‹ä»¶æ—¥æ•°æ®
            df_event = data_service.get_daily_data(self.code, date)
            if df_event is None or len(df_event) == 0:
                print(f"   âš ï¸ æ— æ³•è·å–äº‹ä»¶æ—¥æ•°æ®")
                return post_event
            
            event_close = df_event['close'].iloc[0]
            event_date = datetime.strptime(date, '%Y-%m-%d')
            
            # T+1
            t1_date = (event_date + timedelta(days=1)).strftime('%Y-%m-%d')
            df_t1 = data_service.get_daily_data(self.code, t1_date)
            if df_t1 is not None and len(df_t1) > 0:
                post_event['t1'] = {
                    'date': t1_date,
                    'open_gap': (df_t1['open'].iloc[0] - event_close) / event_close * 100,
                    'high_change': (df_t1['high'].iloc[0] - event_close) / event_close * 100,
                    'low_change': (df_t1['low'].iloc[0] - event_close) / event_close * 100,
                    'close_change': (df_t1['close'].iloc[0] - event_close) / event_close * 100,
                }
                print(f"   T+1 ({t1_date}):")
                print(f"      å¼€ç›˜è·³ç©º: {post_event['t1']['open_gap']:+.2f}%")
                print(f"      æ”¶ç›˜æ¶¨è·Œ: {post_event['t1']['close_change']:+.2f}%")
            
            # T+2
            t2_date = (event_date + timedelta(days=2)).strftime('%Y-%m-%d')
            df_t2 = data_service.get_daily_data(self.code, t2_date)
            if df_t2 is not None and len(df_t2) > 0:
                post_event['t2'] = {
                    'date': t2_date,
                    'close_change': (df_t2['close'].iloc[0] - event_close) / event_close * 100,
                }
                print(f"   T+2 ({t2_date}): æ”¶ç›˜æ¶¨è·Œ {post_event['t2']['close_change']:+.2f}%")
            
            # T+3
            t3_date = (event_date + timedelta(days=3)).strftime('%Y-%m-%d')
            df_t3 = data_service.get_daily_data(self.code, t3_date)
            if df_t3 is not None and len(df_t3) > 0:
                post_event['t3'] = {
                    'date': t3_date,
                    'close_change': (df_t3['close'].iloc[0] - event_close) / event_close * 100,
                }
                print(f"   T+3 ({t3_date}): æ”¶ç›˜æ¶¨è·Œ {post_event['t3']['close_change']:+.2f}%")
        
        except Exception as e:
            print(f"   âš ï¸ è·å–æ—¥çº¿æ•°æ®å¤±è´¥: {e}")
        
        return post_event
    
    def generate_report(self, true_result: dict, trap_result: dict):
        """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
        print(f"\n\n{'='*80}")
        print(f"ç½‘å®¿ç§‘æŠ€æè‡´æ‹†åˆ†æŠ¥å‘Š")
        print(f"çœŸèµ·çˆ† ({self.true_date}) vs éª—ç‚® ({self.trap_date})")
        print(f"{'='*80}\n")
        
        # å¯¹æ¯”è¡¨
        print("ã€æ ¸å¿ƒæŒ‡æ ‡å¯¹æ¯”ã€‘")
        print("-" * 80)
        print(f"{'æŒ‡æ ‡':<30} {'çœŸèµ·çˆ† (1-26)':<25} {'éª—ç‚® (2-13)':<25}")
        print("-" * 80)
        
        t_life = true_result.get('lifecycle', {})
        p_life = trap_result.get('lifecycle', {})
        
        print(f"{'å½“æ—¥æœ€é«˜æ¶¨å¹…':<30} {t_life.get('max_change_pct', 0):>+.2f}%{'':<18} {p_life.get('max_change_pct', 0):>+.2f}%")
        print(f"{'å½“æ—¥æ”¶ç›˜æ¶¨å¹…':<30} {t_life.get('final_change_pct', 0):>+.2f}%{'':<18} {p_life.get('final_change_pct', 0):>+.2f}%")
        
        # æ¨å‡é˜¶æ®µå¯¹æ¯”ï¼ˆçœŸèµ·çˆ†ç”¨warmup_durationï¼Œéª—ç‚®ç”¨fake_durationï¼‰
        t_breakout = t_life.get('breakout', {})
        p_trap = p_life.get('trap', {})
        
        # çœŸèµ·çˆ†ç‰¹å¾
        if t_breakout:
            print(f"{'æ¨å‡æ—¶é•¿ T_warmup':<30} {t_breakout.get('warmup_duration', 0):>.1f}åˆ†é’Ÿ{'':<15} {'-':<25}")
            print(f"{'æ¨å‡æ®µæ¶¨å¹… Î”p_push':<30} {t_breakout.get('change_end_pct', 0) - t_breakout.get('change_start_pct', 0):>+.2f}%{'':<17} {'-':<25}")
            print(f"{'æ¨å‡æ®µèµ„é‡‘æµå…¥':<30} {t_breakout.get('total_inflow_yi', 0):>.2f}äº¿å…ƒ{'':<16} {'-':<25}")
        
        # éª—ç‚®ç‰¹å¾
        if p_trap:
            print(f"{'æ¬ºéª—æ—¶é•¿ T_fake':<30} {'-':<25} {p_trap.get('fake_duration', 0):>.1f}åˆ†é’Ÿ")
            print(f"{'æ¬ºéª—å¹…åº¦ Î”p_fake':<30} {'-':<25} {p_trap.get('fake_change_pct', 0):>+.2f}%")
            print(f"{'å è½æ—¶é•¿ T_down':<30} {'-':<25} {p_trap.get('fall_duration', 0):>.1f}åˆ†é’Ÿ")
            print(f"{'å è½å¹…åº¦ Î”p_down':<30} {'-':<25} {p_trap.get('fall_change_pct', 0):>+.2f}%")
        
        print("-" * 80)
        
        # å¯äº¤æ˜“çª—å£å¯¹æ¯”
        print("\nã€å¯äº¤æ˜“çª—å£å¯¹æ¯”ã€‘")
        t_tradable = true_result.get('tradable_windows', {})
        p_tradable = trap_result.get('tradable_windows', {})
        
        t_entries = t_tradable.get('entry_points', [])
        p_entries = p_tradable.get('entry_points', [])
        
        if t_entries and p_entries:
            print(f"{'å…¥åœºæ—¶æœº':<15} {'çœŸèµ·çˆ†æ”¶ç›Š':<15} {'çœŸèµ·çˆ†å›æ’¤':<15} {'éª—ç‚®æ”¶ç›Š':<15} {'éª—ç‚®å›æ’¤':<15}")
            print("-" * 80)
            for t_e, p_e in zip(t_entries, p_entries):
                print(f"ä¿¡å·å{t_e['delay_minutes']}åˆ†é’Ÿ{t_e['entry_time']:<6} "
                      f"{t_e['pnl_pct']:>+.2f}%{'':<8} {t_e['max_drawdown_pct']:>.2f}%{'':<8} "
                      f"{p_e['pnl_pct']:>+.2f}%{'':<8} {p_e['max_drawdown_pct']:>.2f}%")
        
        print("\n" + "="*80)


def main():
    """ä¸»å‡½æ•°"""
    analyzer = WangsuExtremeAnalyzer()
    
    # åˆ†æçœŸèµ·çˆ†
    true_result = analyzer.analyze_case(analyzer.true_date, "çœŸèµ·çˆ†")
    
    # åˆ†æéª—ç‚®
    trap_result = analyzer.analyze_case(analyzer.trap_date, "éª—ç‚®")
    
    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    analyzer.generate_report(true_result, trap_result)
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    output_dir = PROJECT_ROOT / "data" / "wanzhu_data" / "wangsu_analysis"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_file = output_dir / f"wangsu_extreme_analysis_{timestamp}.json"
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'true_breakout': true_result,
            'trap': trap_result,
            'generated_at': datetime.now().isoformat()
        }, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"\nğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜: {output_file}")


if __name__ == "__main__":
    main()
