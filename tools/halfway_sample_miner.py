#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŠè·¯çªç ´æ ·æœ¬å¼€é‡‡å™¨ (Halfway Sample Miner)

åŠŸèƒ½ï¼š
1. ä»532åªçƒ­é—¨è‚¡ä¸­è‡ªåŠ¨æŒ–æ˜ç–‘ä¼¼åŠè·¯çªç ´çš„å€™é€‰ç‰‡æ®µ
2. ç”Ÿæˆå¸¦ä»·é‡åºåˆ—çš„å€™é€‰æ ·æœ¬æ–‡ä»¶ï¼ˆJSONæ ¼å¼ï¼‰
3. æ”¯æŒäººå·¥å¤æ ¸æ ‡æ³¨

ä½¿ç”¨æµç¨‹ï¼š
1. è¿è¡Œå¼€é‡‡ï¼špython tools/halfway_sample_miner.py --mode mine --days 10
2. äººå·¥å¤æ ¸ï¼šæŸ¥çœ‹ç”Ÿæˆçš„å€™é€‰æ ·æœ¬ï¼Œæ‰‹å·¥æ ‡æ³¨æ­£/è´Ÿæ ·æœ¬
3. å¯¼å…¥æµ‹è¯•ï¼šå°†æ ‡æ³¨åçš„æ ·æœ¬å¤åˆ¶åˆ° tests/real_samples/ ç›®å½•

Author: AI Project Director
Version: V1.0
Date: 2026-02-17
"""

import sys
import json
import argparse
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import pandas as pd

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from logic.strategies.unified_warfare_core import get_unified_warfare_core
from logic.data_providers.qmt_historical_provider import QMTHistoricalProvider
from logic.utils.logger import get_logger

logger = get_logger(__name__)


class HalfwaySampleMiner:
    """åŠè·¯çªç ´æ ·æœ¬å¼€é‡‡å™¨"""
    
    def __init__(self, output_dir: str = "data/samples/halfway_candidates"):
        """
        åˆå§‹åŒ–å¼€é‡‡å™¨
        
        Args:
            output_dir: å€™é€‰æ ·æœ¬è¾“å‡ºç›®å½•
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # è·å–ç»Ÿä¸€æˆ˜æ³•æ ¸å¿ƒï¼ˆç”¨äºåˆæ­¥ç­›é€‰ï¼‰
        self.warfare_core = get_unified_warfare_core()
        
        logger.info(f"âœ… [æ ·æœ¬å¼€é‡‡å™¨] åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   - è¾“å‡ºç›®å½•: {self.output_dir}")
        logger.info(f"   - æˆ˜æ³•æ ¸å¿ƒ: {type(self.warfare_core).__name__}")
    
    def mine_candidates(
        self,
        stock_codes: List[str],
        start_date: str,
        end_date: str,
        min_confidence: float = 0.3
    ) -> List[Dict]:
        """
        å¼€é‡‡å€™é€‰æ ·æœ¬
        
        Args:
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            min_confidence: æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼
            
        Returns:
            å€™é€‰æ ·æœ¬åˆ—è¡¨
        """
        candidates = []
        
        # è§£ææ—¥æœŸèŒƒå›´
        start_dt = datetime.strptime(start_date, "%Y-%m-%d")
        end_dt = datetime.strptime(end_date, "%Y-%m-%d")
        
        total_days = (end_dt - start_dt).days + 1
        logger.info(f"ğŸ¯ [æ ·æœ¬å¼€é‡‡] å¼€å§‹å¼€é‡‡")
        logger.info(f"   - è‚¡ç¥¨æ•°é‡: {len(stock_codes)}")
        logger.info(f"   - æ—¥æœŸèŒƒå›´: {start_date} è‡³ {end_date} ({total_days}å¤©)")
        logger.info(f"   - ç½®ä¿¡åº¦é˜ˆå€¼: {min_confidence}")
        
        # éå†æ¯åªè‚¡ç¥¨ã€æ¯å¤©
        for stock_code in stock_codes:
            logger.info(f"\nğŸ“Š å¤„ç†è‚¡ç¥¨: {stock_code}")
            
            current_dt = start_dt
            while current_dt <= end_dt:
                date_str = current_dt.strftime("%Y-%m-%d")
                
                try:
                    # å¼€é‡‡å•æ—¥å€™é€‰
                    daily_candidates = self._mine_single_day(
                        stock_code, date_str, min_confidence
                    )
                    candidates.extend(daily_candidates)
                    
                    if daily_candidates:
                        logger.info(f"   {date_str}: å‘ç° {len(daily_candidates)} ä¸ªå€™é€‰")
                    
                except Exception as e:
                    logger.error(f"   {date_str}: å¼€é‡‡å¤±è´¥ - {e}")
                
                current_dt += timedelta(days=1)
        
        logger.info(f"\nâœ… [æ ·æœ¬å¼€é‡‡] å®Œæˆ")
        logger.info(f"   - æ€»å€™é€‰æ•°: {len(candidates)}")
        
        return candidates
    
    def _mine_single_day(
        self,
        stock_code: str,
        date_str: str,
        min_confidence: float
    ) -> List[Dict]:
        """
        å¼€é‡‡å•æ—¥å€™é€‰æ ·æœ¬
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            date_str: æ—¥æœŸ (YYYY-MM-DD)
            min_confidence: æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼
            
        Returns:
            å½“æ—¥å€™é€‰æ ·æœ¬åˆ—è¡¨
        """
        candidates = []
        
        # ä½¿ç”¨QMTè·å–å½“æ—¥Tickæ•°æ®
        try:
            provider = QMTHistoricalProvider(
                stock_code=stock_code,
                start_time=f"{date_str.replace('-', '')}093000",
                end_time=f"{date_str.replace('-', '')}150000",
                period="tick"
            )
            
            # æ”¶é›†å½“æ—¥æ‰€æœ‰Tick
            ticks = []
            for tick in provider.iter_ticks():
                ticks.append(tick)
            
            if len(ticks) < 20:  # æ•°æ®ä¸è¶³
                return candidates
            
            # æ»‘åŠ¨çª—å£æ£€æµ‹ï¼ˆæ¯5åˆ†é’Ÿä¸€ä¸ªçª—å£ï¼‰
            window_size = 20  # 20ä¸ªtickç‚¹
            step_size = 10    # æ­¥é•¿10ä¸ªç‚¹
            
            for i in range(0, len(ticks) - window_size, step_size):
                window_ticks = ticks[i:i+window_size]
                
                # æ„å»ºå½“å‰tickæ•°æ®
                current_tick = window_ticks[-1]
                tick_data = {
                    'stock_code': stock_code,
                    'datetime': datetime.fromtimestamp(current_tick['time'] / 1000),
                    'price': current_tick['last_price'],
                    'volume': current_tick['volume'],
                    'amount': current_tick.get('amount', 0),
                }
                
                # æ„å»ºä¸Šä¸‹æ–‡ï¼ˆä»·æ ¼/æˆäº¤é‡å†å²ï¼‰
                price_history = [t['last_price'] for t in window_ticks]
                volume_history = [t['volume'] for t in window_ticks]
                
                context = {
                    'price_history': price_history,
                    'volume_history': volume_history,
                    'ma5': sum(price_history[-5:]) / 5 if len(price_history) >= 5 else price_history[-1],
                    'ma20': sum(price_history) / len(price_history),
                }
                
                # ä½¿ç”¨ç»Ÿä¸€æˆ˜æ³•æ ¸å¿ƒæ£€æµ‹
                events = self.warfare_core.process_tick(tick_data, context)
                
                # ç­›é€‰Halfway Breakoutäº‹ä»¶
                halfway_events = [e for e in events if e['event_type'] == 'halfway_breakout']
                
                for event in halfway_events:
                    if event['confidence'] >= min_confidence:
                        # è®°å½•å€™é€‰æ ·æœ¬
                        candidate = {
                            'stock_code': stock_code,
                            'date': date_str,
                            'time': datetime.fromtimestamp(current_tick['time'] / 1000).strftime("%H:%M:%S"),
                            'price_series': price_history,
                            'volume_series': volume_history,
                            'trigger_price': current_tick['last_price'],
                            'confidence': event['confidence'],
                            'description': event['description'],
                            'detected_by': 'unified_warfare_core',
                            'label': None,  # å¾…äººå·¥æ ‡æ³¨
                            'label_reason': None,  # æ ‡æ³¨ç†ç”±
                            'mined_at': datetime.now().isoformat(),
                        }
                        candidates.append(candidate)
            
        except Exception as e:
            logger.error(f"è·å–{stock_code} {date_str}æ•°æ®å¤±è´¥: {e}")
        
        return candidates
    
    def save_candidates(self, candidates: List[Dict], filename: str = None):
        """
        ä¿å­˜å€™é€‰æ ·æœ¬åˆ°æ–‡ä»¶
        
        Args:
            candidates: å€™é€‰æ ·æœ¬åˆ—è¡¨
            filename: æ–‡ä»¶åï¼ˆé»˜è®¤ä¸ºæ—¶é—´æˆ³ï¼‰
        """
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"halfway_candidates_{timestamp}.json"
        
        filepath = self.output_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(candidates, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ’¾ å€™é€‰æ ·æœ¬å·²ä¿å­˜: {filepath}")
        logger.info(f"   - æ ·æœ¬æ•°é‡: {len(candidates)}")
    
    def load_candidates(self, filename: str) -> List[Dict]:
        """
        ä»æ–‡ä»¶åŠ è½½å€™é€‰æ ·æœ¬
        
        Args:
            filename: æ–‡ä»¶å
            
        Returns:
            å€™é€‰æ ·æœ¬åˆ—è¡¨
        """
        filepath = self.output_dir / filename
        
        with open(filepath, 'r', encoding='utf-8') as f:
            candidates = json.load(f)
        
        logger.info(f"ğŸ“‚ å·²åŠ è½½å€™é€‰æ ·æœ¬: {filepath}")
        logger.info(f"   - æ ·æœ¬æ•°é‡: {len(candidates)}")
        
        return candidates
    
    def annotate_sample(
        self,
        candidate: Dict,
        label: str,  # 'positive', 'negative', 'uncertain'
        reason: str
    ) -> Dict:
        """
        äººå·¥æ ‡æ³¨å•ä¸ªæ ·æœ¬
        
        Args:
            candidate: å€™é€‰æ ·æœ¬
            label: æ ‡ç­¾ ('positive', 'negative', 'uncertain')
            reason: æ ‡æ³¨ç†ç”±
            
        Returns:
            æ ‡æ³¨åçš„æ ·æœ¬
        """
        candidate['label'] = label
        candidate['label_reason'] = reason
        candidate['annotated_at'] = datetime.now().isoformat()
        
        return candidate
    
    def export_labeled_samples(
        self,
        candidates: List[Dict],
        output_file: str = "tests/real_samples/halfway_labeled_samples.json"
    ):
        """
        å¯¼å‡ºå·²æ ‡æ³¨æ ·æœ¬åˆ°æµ‹è¯•ç›®å½•
        
        Args:
            candidates: å€™é€‰æ ·æœ¬åˆ—è¡¨ï¼ˆå«æ ‡æ³¨ï¼‰
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        # ç­›é€‰å·²æ ‡æ³¨çš„æ ·æœ¬
        labeled = [c for c in candidates if c.get('label') is not None]
        
        if not labeled:
            logger.warning("âš ï¸ æ²¡æœ‰å·²æ ‡æ³¨çš„æ ·æœ¬å¯å¯¼å‡º")
            return
        
        output_path = PROJECT_ROOT / output_file
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(labeled, f, ensure_ascii=False, indent=2)
        
        # ç»Ÿè®¡
        positive = len([c for c in labeled if c['label'] == 'positive'])
        negative = len([c for c in labeled if c['label'] == 'negative'])
        uncertain = len([c for c in labeled if c['label'] == 'uncertain'])
        
        logger.info(f"âœ… å·²å¯¼å‡ºæ ‡æ³¨æ ·æœ¬: {output_path}")
        logger.info(f"   - æ­£æ ·æœ¬: {positive}")
        logger.info(f"   - è´Ÿæ ·æœ¬: {negative}")
        logger.info(f"   - ä¸ç¡®å®š: {uncertain}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='åŠè·¯çªç ´æ ·æœ¬å¼€é‡‡å™¨')
    parser.add_argument('--mode', choices=['mine', 'annotate', 'export'], 
                       default='mine', help='è¿è¡Œæ¨¡å¼')
    parser.add_argument('--stocks', type=str, help='è‚¡ç¥¨ä»£ç æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--start-date', type=str, 
                       default=(datetime.now() - timedelta(days=10)).strftime("%Y-%m-%d"),
                       help='å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)')
    parser.add_argument('--end-date', type=str,
                       default=datetime.now().strftime("%Y-%m-%d"),
                       help='ç»“æŸæ—¥æœŸ (YYYY-MM-DD)')
    parser.add_argument('--min-confidence', type=float, default=0.3,
                       help='æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼')
    parser.add_argument('--input', type=str, help='è¾“å…¥æ–‡ä»¶ï¼ˆç”¨äºannotate/exportæ¨¡å¼ï¼‰')
    parser.add_argument('--output', type=str, help='è¾“å‡ºæ–‡ä»¶')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–å¼€é‡‡å™¨
    miner = HalfwaySampleMiner()
    
    if args.mode == 'mine':
        # åŠ è½½è‚¡ç¥¨åˆ—è¡¨
        if args.stocks:
            with open(args.stocks, 'r') as f:
                stock_codes = [line.strip() for line in f if line.strip()]
        else:
            # é»˜è®¤ä½¿ç”¨çƒ­é—¨è‚¡åˆ—è¡¨
            hot_stocks_path = PROJECT_ROOT / "config" / "hot_stocks.json"
            with open(hot_stocks_path, 'r') as f:
                stock_codes = json.load(f)
            # åªå–å‰20åªåšè¯•ç‚¹
            stock_codes = stock_codes[:20]
        
        logger.info(f"ğŸ¯ å¼€å§‹å¼€é‡‡æ¨¡å¼")
        logger.info(f"   - è‚¡ç¥¨æ•°: {len(stock_codes)}")
        logger.info(f"   - æ—¥æœŸ: {args.start_date} è‡³ {args.end_date}")
        
        # æ‰§è¡Œå¼€é‡‡
        candidates = miner.mine_candidates(
            stock_codes=stock_codes,
            start_date=args.start_date,
            end_date=args.end_date,
            min_confidence=args.min_confidence
        )
        
        # ä¿å­˜å€™é€‰
        if candidates:
            miner.save_candidates(candidates, args.output)
            logger.info(f"\nğŸ’¡ ä¸‹ä¸€æ­¥: äººå·¥å¤æ ¸å€™é€‰æ ·æœ¬å¹¶æ ‡æ³¨")
            logger.info(f"   å€™é€‰æ–‡ä»¶ä½ç½®: {miner.output_dir}/")
        else:
            logger.warning("âš ï¸ æœªå‘ç°å€™é€‰æ ·æœ¬ï¼Œå°è¯•é™ä½ç½®ä¿¡åº¦é˜ˆå€¼æˆ–æ‰©å¤§æ—¥æœŸèŒƒå›´")
    
    elif args.mode == 'annotate':
        # æ ‡æ³¨æ¨¡å¼ï¼ˆç®€åŒ–ç‰ˆï¼Œå®é™…åº”å¼€å‘Webç•Œé¢æˆ–CLIäº¤äº’å·¥å…·ï¼‰
        logger.info("ğŸ“ æ ‡æ³¨æ¨¡å¼")
        logger.info("   æç¤ºï¼šå½“å‰ä¸ºç®€åŒ–CLIç‰ˆæœ¬ï¼Œå»ºè®®å¼€å‘Webæ ‡æ³¨å·¥å…·æå‡æ•ˆç‡")
        
        if not args.input:
            logger.error("âŒ è¯·æŒ‡å®šè¾“å…¥æ–‡ä»¶: --input <å€™é€‰æ–‡ä»¶.json>")
            return
        
        candidates = miner.load_candidates(args.input)
        
        # äº¤äº’å¼æ ‡æ³¨
        for i, candidate in enumerate(candidates):
            if candidate.get('label') is not None:
                continue  # å·²æ ‡æ³¨ï¼Œè·³è¿‡
            
            print(f"\n{'='*80}")
            print(f"æ ·æœ¬ {i+1}/{len(candidates)}: {candidate['stock_code']} {candidate['date']} {candidate['time']}")
            print(f"ç½®ä¿¡åº¦: {candidate['confidence']:.2f}")
            print(f"æè¿°: {candidate['description']}")
            print(f"ä»·æ ¼åºåˆ—(å‰5): {candidate['price_series'][:5]}")
            print(f"ä»·æ ¼åºåˆ—(å5): {candidate['price_series'][-5:]}")
            print(f"\né€‰é¡¹: 1=æ­£æ ·æœ¬(positive) 2=è´Ÿæ ·æœ¬(negative) 3=ä¸ç¡®å®š(uncertain) s=è·³è¿‡ q=é€€å‡º")
            
            choice = input("é€‰æ‹©: ").strip().lower()
            
            if choice == 'q':
                break
            elif choice == 's':
                continue
            elif choice in ['1', 'positive']:
                reason = input("æ ‡æ³¨ç†ç”±: ").strip()
                miner.annotate_sample(candidate, 'positive', reason)
            elif choice in ['2', 'negative']:
                reason = input("æ ‡æ³¨ç†ç”±(å¦‚'å‡çªç ´'/'æ— é‡ä¸Šæ¶¨'ç­‰): ").strip()
                miner.annotate_sample(candidate, 'negative', reason)
            elif choice in ['3', 'uncertain']:
                reason = input("ä¸ç¡®å®šç†ç”±: ").strip()
                miner.annotate_sample(candidate, 'uncertain', reason)
        
        # ä¿å­˜æ ‡æ³¨ç»“æœ
        output_file = args.input.replace('.json', '_labeled.json')
        miner.save_candidates(candidates, output_file)
    
    elif args.mode == 'export':
        # å¯¼å‡ºå·²æ ‡æ³¨æ ·æœ¬åˆ°æµ‹è¯•ç›®å½•
        if not args.input:
            logger.error("âŒ è¯·æŒ‡å®šè¾“å…¥æ–‡ä»¶: --input <å·²æ ‡æ³¨æ–‡ä»¶.json>")
            return
        
        candidates = miner.load_candidates(args.input)
        miner.export_labeled_samples(candidates, args.output)


if __name__ == "__main__":
    main()