#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çŸ­çº¿æ´»è·ƒè‚¡ç”Ÿæˆè„šæœ¬

åŸºäºå·²ä¸‹è½½çš„ 1åˆ†é’Ÿ Kçº¿æ•°æ®ï¼Œç­›é€‰å‡º 500 åªçŸ­çº¿æœ€æ´»è·ƒçš„è‚¡ç¥¨

ç­›é€‰æ¡ä»¶ï¼š
- æ—¥å‡æ¢æ‰‹ç‡ > 3% (æ´»è·ƒ)
- è¿‘ 60 å¤©æœ‰æ¶¨åœ (æœ‰å¦–æ°”)
- æ—¥å‡æˆäº¤é¢ < 50äº¿ (å‰”é™¤è¶…çº§å¤§è±¡)
- å‰”é™¤åœç‰Œè‚¡ç¥¨
"""

import sys
import os
import json
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).resolve().parent.parent
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from logic.utils.logger import get_logger

logger = get_logger("generate_active_pool")

# VIP Token
VIP_TOKEN = '6b1446e317ed67596f13d2e808291a01e0dd9839'


def start_token_service():
    """å¯åŠ¨ xtdatacenter è¡Œæƒ…æœåŠ¡ (Token æ¨¡å¼)"""
    try:
        from xtquant import xtdatacenter as xtdc
    except ImportError:
        logger.error("âŒ æ— æ³•å¯¼å…¥ xtquantï¼Œè¯·æ£€æŸ¥ç¯å¢ƒ")
        return None

    data_dir = PROJECT_ROOT / 'data' / 'qmt_data'
    data_dir.mkdir(parents=True, exist_ok=True)
    xtdc.set_data_home_dir(str(data_dir))
    xtdc.set_token(VIP_TOKEN)
    xtdc.init()
    listen_port = xtdc.listen(port=(58621, 58625))
    logger.info(f"ğŸš€ è¡Œæƒ…æœåŠ¡å·²å¯åŠ¨ï¼Œç›‘å¬ç«¯å£: {listen_port}")
    return listen_port


def generate_active_pool():
    """
    åŸºäºå·²ä¸‹è½½çš„ 1åˆ†é’Ÿ Kçº¿æ•°æ®ï¼Œç­›é€‰å‡º 500 åªçŸ­çº¿æœ€æ´»è·ƒçš„è‚¡ç¥¨
    """
    logger.info("=" * 80)
    logger.info("ğŸ” å¼€å§‹ç”ŸæˆçŸ­çº¿æ´»è·ƒè‚¡åå•")
    logger.info("=" * 80)
    
    # å¯åŠ¨ Token æœåŠ¡
    port = start_token_service()
    if not port:
        logger.error("âŒ Token æœåŠ¡å¯åŠ¨å¤±è´¥")
        return []
    
    # è¿æ¥è¡Œæƒ…æœåŠ¡
    from xtquant import xtdata
    ip, port_num = port
    xtdata.connect(ip='127.0.0.1', port=port_num, remember_if_success=False)
    time.sleep(2)
    
    # è·å–å…¨å¸‚åœºè‚¡ç¥¨
    all_stocks = xtdata.get_stock_list_in_sector('æ²ªæ·±Aè‚¡')
    logger.info(f"   å…¨å¸‚åœºè‚¡ç¥¨æ•°: {len(all_stocks)}")
    
    # è®¡ç®—æ—¶é—´èŒƒå›´ï¼ˆè¿‘ 60 å¤©ï¼‰
    end_date = datetime.now()
    start_date = end_date - timedelta(days=70)  # å¤šå– 10 å¤©ç¡®ä¿æœ‰è¶³å¤Ÿäº¤æ˜“æ—¥
    start_time = start_date.strftime('%Y%m%d%H%M%S')
    
    logger.info(f"   æ—¶é—´èŒƒå›´: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}")
    
    # ä¸‹è½½è¿‘ 60 å¤©æ—¥çº¿æ•°æ®
    logger.info("   ğŸ“¥ ä¸‹è½½è¿‘ 60 å¤©æ—¥çº¿æ•°æ®ç”¨äºç­›é€‰...")
    try:
        xtdata.download_history_data2(all_stocks, period='1d', start_time=start_time)
    except Exception as e:
        logger.error(f"âŒ æ—¥çº¿æ•°æ®ä¸‹è½½å¤±è´¥: {e}")
        return []
    
    # è¯»å–æ•°æ®
    logger.info("   ğŸ“Š è®¡ç®—æŒ‡æ ‡...")
    data = xtdata.get_market_data_ex(
        field_list=['close', 'amount', 'turn'],  # turn æ˜¯æ¢æ‰‹ç‡
        stock_list=all_stocks, 
        period='1d', 
        count=60
    )
    
    valid_stocks = []
    skipped_reasons = {
        'åœç‰Œ': 0,
        'æ¢æ‰‹ç‡ä½': 0,
        'æ— æ¶¨åœ': 0,
        'æˆäº¤é¢è¿‡å¤§': 0,
        'æ•°æ®ä¸è¶³': 0
    }
    
    for code, df in data.items():
        if df.empty or len(df) < 20:
            skipped_reasons['æ•°æ®ä¸è¶³'] += 1
            continue
        
        # 1. å‰”é™¤åœç‰Œ (æœ€è¿‘ä¸€å¤©æˆäº¤é¢ä¸º0)
        last_amount = df['amount'].iloc[-1]
        if last_amount < 100000:  # å°äº10ä¸‡æˆäº¤
            skipped_reasons['åœç‰Œ'] += 1
            continue
        
        # 2. è®¡ç®—æ—¥å‡æ¢æ‰‹ç‡ (æœ€è¿‘ 20 å¤©)
        if 'turn' not in df.columns or df['turn'].isna().all():
            skipped_reasons['æ•°æ®ä¸è¶³'] += 1
            continue
        
        avg_turn = df['turn'].tail(20).mean()
        
        # 3. è®¡ç®—æ˜¯å¦æœ‰æ¶¨åœ (High limit)
        # ç®€å•åˆ¤æ–­ï¼šå•æ—¥æ¶¨å¹… > 9.5% (åŒ…æ‹¬ 10% å’Œ 20%)
        closes = df['close']
        pct_chg = closes.pct_change()
        has_limit = (pct_chg > 0.095).any()
        
        # 4. å‰”é™¤å¤§å¸‚å€¼ (ç”¨æˆäº¤é¢åæ¨)
        avg_amount = df['amount'].tail(20).mean()
        
        # ç­›é€‰é€»è¾‘ï¼š
        # - æ¢æ‰‹ç‡ > 3% (æ´»è·ƒ)
        # - è¿‘ 60 å¤©æœ‰æ¶¨åœ (æœ‰å¦–æ°”)
        # - æ—¥å‡æˆäº¤é¢ < 50äº¿ (å‰”é™¤è¶…çº§å¤§è±¡)
        
        if avg_turn > 3.0 and has_limit and avg_amount < 50e8:
            valid_stocks.append({
                'code': code,
                'avg_turn': round(avg_turn, 2),
                'has_limit': has_limit,
                'avg_amount': round(avg_amount / 1e8, 2),  # äº¿å…ƒ
                'last_price': round(closes.iloc[-1], 2),
                'pct_change_1d': round(pct_chg.iloc[-1] * 100, 2) if len(pct_chg) > 1 else 0
            })
        else:
            # è®°å½•è·³è¿‡åŸå› 
            if avg_turn <= 3.0:
                skipped_reasons['æ¢æ‰‹ç‡ä½'] += 1
            elif not has_limit:
                skipped_reasons['æ— æ¶¨åœ'] += 1
            elif avg_amount >= 50e8:
                skipped_reasons['æˆäº¤é¢è¿‡å¤§'] += 1
    
    # æ’åºï¼šæŒ‰æ¢æ‰‹ç‡å€’åº (è¶Šæ´»è·ƒè¶Šå¥½)
    valid_stocks.sort(key=lambda x: x['avg_turn'], reverse=True)
    
    # å– Top 500
    top_500 = valid_stocks[:500]
    
    logger.info("=" * 80)
    logger.info(f"âœ… ç­›é€‰å®Œæˆï¼å…¥é€‰ {len(top_500)} åª")
    logger.info("=" * 80)
    logger.info(f"è·³è¿‡åŸå› ç»Ÿè®¡:")
    for reason, count in skipped_reasons.items():
        logger.info(f"   - {reason}: {count} åª")
    
    logger.info(f"\næ¦œå–¾ç¤ºä¾‹ (Top 10):")
    for i, stock in enumerate(top_500[:10]):
        logger.info(f"   {i+1}. {stock['code']} | æ¢æ‰‹ç‡: {stock['avg_turn']}% | æ¶¨åœ: {'æ˜¯' if stock['has_limit'] else 'å¦'} | æˆäº¤é¢: {stock['avg_amount']}äº¿")
    
    # ä¿å­˜ä¸º JSON (ä¸¤ç§æ ¼å¼)
    output_dir = PROJECT_ROOT / 'config'
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # æ ¼å¼ 1ï¼šä»…ä»£ç åˆ—è¡¨
    code_list_file = output_dir / 'active_stocks.json'
    code_list = [stock['code'] for stock in top_500]
    with open(code_list_file, 'w', encoding='utf-8') as f:
        json.dump(code_list, f, ensure_ascii=False, indent=2)
    logger.info(f"ğŸ’¾ ä»£ç åˆ—è¡¨å·²ä¿å­˜è‡³: {code_list_file}")
    
    # æ ¼å¼ 2ï¼šè¯¦ç»†ä¿¡æ¯
    detail_file = output_dir / 'active_stocks_detail.json'
    with open(detail_file, 'w', encoding='utf-8') as f:
        json.dump(top_500, f, ensure_ascii=False, indent=2)
    logger.info(f"ğŸ’¾ è¯¦ç»†ä¿¡æ¯å·²ä¿å­˜è‡³: {detail_file}")
    
    return code_list


if __name__ == "__main__":
    import time
    
    result = generate_active_pool()
    
    if result:
        logger.info("=" * 80)
        logger.info(f"ğŸ‰ æˆåŠŸç”Ÿæˆ {len(result)} åªçŸ­çº¿æ´»è·ƒè‚¡ï¼")
        logger.info("=" * 80)
        logger.info("è¯·æŸ¥çœ‹ä»¥ä¸‹æ–‡ä»¶:")
        logger.info("  - config/active_stocks.json (ä»£ç åˆ—è¡¨)")
        logger.info("  - config/active_stocks_detail.json (è¯¦ç»†ä¿¡æ¯)")
    else:
        logger.error("âŒ ç”Ÿæˆå¤±è´¥")