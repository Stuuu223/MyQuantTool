#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†é’ŸKçº¿æ•°æ®æ‹‰å–å·¥å…· - TickProviderç‰ˆï¼ˆT4è¿ç§»ï¼‰

åŠŸèƒ½ï¼š
1. ä»QMTæœåŠ¡å™¨ä¸‹è½½1åˆ†é’ŸKçº¿æ•°æ®åˆ°æœ¬åœ°ç¼“å­˜
2. è¯»å–æœ¬åœ°ç¼“å­˜æ•°æ®è¿›è¡Œç­–ç•¥å›æµ‹
3. æ•°æ®å®Œæ•´æ€§éªŒè¯

ä¼˜åŠ¿ï¼š
- æ— éœ€L2æƒé™ï¼ˆæ‰€æœ‰QMTç”¨æˆ·å…è´¹ï¼‰
- æ•°æ®å¯è¡¥å…¨ï¼ˆä¸ä¼šæ°¸ä¹…ä¸¢å¤±ï¼‰
- æ•°æ®é‡å°ï¼ˆ5000åªè‚¡ç¥¨/å¤©çº¦20MBï¼‰
- é€‚åˆè¯±å¤šæ£€æµ‹å’Œè¶‹åŠ¿åˆ†æ

ä½¿ç”¨TickProviderç»Ÿä¸€å°è£…ç±»ï¼Œä¸å†ç›´æ¥å¯¼å…¥xtdata

Author: iFlow CLI (T4è¿ç§»)
Date: 2026-02-19
"""

import time
import sys
import os
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict
import pandas as pd

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# ğŸ”¥ T4è¿ç§»ï¼šä¸å†ç›´æ¥å¯¼å…¥xtdataï¼Œæ”¹ç”¨TickProvider
# ä¿ç•™DLLè·¯å¾„é…ç½®ä»¥å¤‡éœ€è¦
POSSIBLE_QMT_PATHS = [
    r"D:\å›½é‡‘QMTäº¤æ˜“ç«¯\bin.x64",
    r"C:\å›½é‡‘QMTäº¤æ˜“ç«¯\bin.x64",
    r"D:\å›½é‡‘QMTäº¤æ˜“ç«¯\userdata_mini",
    r"C:\å›½é‡‘QMTäº¤æ˜“ç«¯\userdata_mini",
    project_root / 'xtquant',
]

# å°è¯•æ·»åŠ DLLè·¯å¾„ï¼ˆå¦‚æœéœ€è¦ï¼‰
for path in POSSIBLE_QMT_PATHS:
    path_str = str(path) if isinstance(path, Path) else path
    if os.path.exists(path_str) and path_str not in sys.path:
        sys.path.append(path_str)
        if hasattr(os, 'add_dll_directory'):
            try:
                os.add_dll_directory(path_str)
            except:
                pass

from logic.data_providers.tick_provider import TickProvider, DownloadStatus

# æ£€æŸ¥xtquantå¯ç”¨æ€§ï¼ˆé€šè¿‡TickProvideré—´æ¥ä½¿ç”¨ï¼‰
QMT_AVAILABLE = True  # ç”±TickProviderå†…éƒ¨å¤„ç†


def fetch_minute_data(
    code_list: List[str],
    start_date: str = None,
    end_date: str = None,
    verbose: bool = True
) -> Dict[str, pd.DataFrame]:
    """
    æ‹‰å–1åˆ†é’ŸKçº¿æ•°æ®ï¼ˆä½¿ç”¨TickProviderï¼‰
    
    Args:
        code_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œå¦‚ ['600519.SH', '000001.SZ']
        start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'ï¼Œé»˜è®¤ä¸º7å¤©å‰
        end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'ï¼Œé»˜è®¤ä¸ºä»Šå¤©
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
    
    Returns:
        å­—å…¸ï¼Œkeyä¸ºè‚¡ç¥¨ä»£ç ï¼Œvalueä¸ºDataFrame
    """
    # é»˜è®¤æ—¥æœŸèŒƒå›´ï¼šè¿‡å»7å¤©
    if start_date is None:
        start_date = (datetime.now() - timedelta(days=7)).strftime('%Y%m%d')
    if end_date is None:
        end_date = datetime.now().strftime('%Y%m%d')
    
    if verbose:
        print("=" * 80)
        print("ğŸš€ å¼€å§‹æ‹‰å–1åˆ†é’ŸKçº¿æ•°æ® (TickProviderç‰ˆ)")
        print("=" * 80)
        print(f"ğŸ“… æ—¶é—´èŒƒå›´: {start_date} ~ {end_date}")
        print(f"ğŸ“Š è‚¡ç¥¨æ•°é‡: {len(code_list)}")
        print()
    
    result = {}
    
    # ğŸ”¥ T4è¿ç§»ï¼šä½¿ç”¨TickProvider
    with TickProvider() as provider:
        if not provider.is_connected():
            print("âŒ QMTè¿æ¥å¤±è´¥")
            return {}
        
        if verbose:
            print("âœ… QMTè¿æ¥æˆåŠŸ")
            print()
        
        # ç¬¬1æ­¥ï¼šä¸‹è½½æ•°æ®
        if verbose:
            print("ğŸ“¥ ç¬¬1æ­¥ï¼šä»QMTæœåŠ¡å™¨ä¸‹è½½æ•°æ®åˆ°æœ¬åœ°ç¼“å­˜...")
        
        download_result = provider.download_minute_data(
            stock_codes=code_list,
            start_date=start_date,
            end_date=end_date,
            period='1m'
        )
        
        if verbose:
            print(f"âœ… ä¸‹è½½å®Œæˆ: {download_result.success}/{download_result.total}")
        
        # ç¬¬2æ­¥ï¼šä»æœ¬åœ°ç¼“å­˜è¯»å–æ•°æ®
        if verbose:
            print()
            print("ğŸ“– ç¬¬2æ­¥ï¼šä»æœ¬åœ°ç¼“å­˜è¯»å–æ•°æ®...")
        
        try:
            # ä½¿ç”¨providerå†…éƒ¨çš„xtdataè¯»å–æ•°æ®
            data = provider._xtdata.get_market_data(
                field_list=['time', 'open', 'high', 'low', 'close', 'volume', 'amount'],
                stock_list=code_list,
                period='1m',
                start_time=start_date,
                end_time=end_date,
                count=-1,
                dividend_type='none',
                fill_data=True
            )
        except Exception as e:
            print(f"âŒ è¯»å–å¤±è´¥: {e}")
            return {}
        
        # ç¬¬3æ­¥ï¼šè½¬æ¢å’ŒéªŒè¯æ•°æ®
        if not data or 'time' not in data:
            print("âŒ æ•°æ®ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯")
            return {}
        
        # éå†æ¯ä¸ªè‚¡ç¥¨ä»£ç 
        for code in code_list:
            try:
                # ä¸ºæ¯åªè‚¡ç¥¨æ„å»º DataFrame
                df_dict = {}
                for field in ['time', 'open', 'high', 'low', 'close', 'volume', 'amount']:
                    if field in data and code in data[field].index:
                        df_dict[field] = data[field].loc[code]
                    else:
                        if verbose:
                            print(f"âš ï¸  {code}: å­—æ®µ '{field}' ç¼ºå¤±")
                        break
                else:
                    # æ‰€æœ‰å­—æ®µéƒ½å­˜åœ¨ï¼Œæ„å»º DataFrame
                    df = pd.DataFrame(df_dict)
                    
                    if not df.empty:
                        # è½¬æ¢æ—¶é—´æˆ³ä¸ºå¯è¯»æ—¶é—´
                        df['time_str'] = pd.to_datetime(df['time'], unit='ms') + pd.Timedelta(hours=8)
                        result[code] = df

                        if verbose:
                            print(f"âœ… {code}: è·å–åˆ° {len(df)} æ ¹åˆ†é’ŸKçº¿")
                    else:
                        if verbose:
                            print(f"âš ï¸  {code}: æ•°æ®ä¸ºç©º")
            except Exception as e:
                if verbose:
                    print(f"âŒ {code}: æ•°æ®å¤„ç†å¤±è´¥ - {e}")
    
    if verbose:
        print()
        print("=" * 80)
        print("ğŸ“Š æ•°æ®æ‹‰å–å®Œæˆ")
        print(f"æˆåŠŸ: {len(result)}/{len(code_list)} åªè‚¡ç¥¨")
        print("=" * 80)
    
    return result


def verify_data_integrity(
    data_dict: Dict[str, pd.DataFrame],
    expected_days: int = 7
) -> Dict[str, any]:
    """
    éªŒè¯æ•°æ®å®Œæ•´æ€§
    
    Args:
        data_dict: è‚¡ç¥¨æ•°æ®å­—å…¸
        expected_days: é¢„æœŸå¤©æ•°ï¼ˆç”¨äºè®¡ç®—é¢„æœŸçš„Kçº¿æ•°é‡ï¼‰
    
    Returns:
        éªŒè¯ç»“æœå­—å…¸
    """
    print()
    print("=" * 80)
    print("ğŸ” æ•°æ®å®Œæ•´æ€§éªŒè¯")
    print("=" * 80)
    
    # äº¤æ˜“æ—¥çº¦5å¤©/å‘¨ï¼Œæ¯å¤©çº¦240æ ¹Kçº¿ï¼ˆ4å°æ—¶äº¤æ˜“ï¼‰
    expected_bars = expected_days * 240
    
    results = {
        'total_stocks': len(data_dict),
        'valid_stocks': 0,
        'incomplete_stocks': 0,
        'missing_stocks': 0,
        'details': []
    }
    
    for code, df in data_dict.items():
        actual_bars = len(df)
        completeness = actual_bars / expected_bars * 100
        
        status = 'âœ… å®Œæ•´' if completeness >= 80 else 'âš ï¸ ä¸å®Œæ•´'
        
        result_detail = {
            'code': code,
            'actual_bars': actual_bars,
            'expected_bars': expected_bars,
            'completeness': completeness,
            'status': status
        }
        
        results['details'].append(result_detail)
        
        if completeness >= 80:
            results['valid_stocks'] += 1
        elif completeness > 0:
            results['incomplete_stocks'] += 1
        else:
            results['missing_stocks'] += 1
        
        print(f"{code}: {actual_bars:4d} æ ¹Kçº¿ ({completeness:5.1f}%) {status}")
    
    print()
    print(f"âœ… å®Œæ•´: {results['valid_stocks']}/{results['total_stocks']}")
    print(f"âš ï¸  ä¸å®Œæ•´: {results['incomplete_stocks']}/{results['total_stocks']}")
    print(f"âŒ ç¼ºå¤±: {results['missing_stocks']}/{results['total_stocks']}")
    print("=" * 80)
    
    return results


def save_data_to_csv(
    data_dict: Dict[str, pd.DataFrame],
    output_dir: str = 'data/minute_data'
):
    """
    ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶
    
    Args:
        data_dict: è‚¡ç¥¨æ•°æ®å­—å…¸
        output_dir: è¾“å‡ºç›®å½•
    """
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    print()
    print("=" * 80)
    print("ğŸ’¾ ä¿å­˜æ•°æ®åˆ°CSV")
    print("=" * 80)
    
    for code, df in data_dict.items():
        file_path = output_path / f"{code}_1m.csv"
        df.to_csv(file_path, index=False, encoding='utf-8-sig')
        print(f"âœ… {code} â†’ {file_path}")
    
    print("=" * 80)


def load_data_from_csv(
    input_dir: str = 'data/minute_data'
) -> Dict[str, pd.DataFrame]:
    """
    ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®
    
    Args:
        input_dir: è¾“å…¥ç›®å½•
    
    Returns:
        å­—å…¸ï¼Œkeyä¸ºè‚¡ç¥¨ä»£ç ï¼Œvalueä¸ºDataFrame
    """
    input_path = Path(input_dir)
    
    if not input_path.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {input_path}")
        return {}
    
    print()
    print("=" * 80)
    print("ğŸ“‚ ä»CSVåŠ è½½æ•°æ®")
    print("=" * 80)
    
    result = {}
    
    for file_path in input_path.glob('*_1m.csv'):
        code = file_path.stem.replace('_1m', '')
        try:
            df = pd.read_csv(file_path, encoding='utf-8-sig')
            result[code] = df
            print(f"âœ… {code}: {len(df)} æ ¹Kçº¿")
        except Exception as e:
            print(f"âŒ {code}: åŠ è½½å¤±è´¥ - {e}")
    
    print("=" * 80)
    return result


def analyze_first_stock(data_dict: Dict[str, pd.DataFrame]):
    """
    åˆ†æç¬¬ä¸€åªè‚¡ç¥¨çš„æ•°æ®
    
    Args:
        data_dict: è‚¡ç¥¨æ•°æ®å­—å…¸
    """
    if not data_dict:
        print("âŒ æ²¡æœ‰æ•°æ®å¯åˆ†æ")
        return
    
    first_code = list(data_dict.keys())[0]
    df = data_dict[first_code]
    
    print()
    print("=" * 80)
    print(f"ğŸ“Š {first_code} æ•°æ®åˆ†æ")
    print("=" * 80)
    print()
    
    # åŸºæœ¬ç»Ÿè®¡
    print("ğŸ“Œ åŸºæœ¬ä¿¡æ¯:")
    print(f"   è‚¡ç¥¨ä»£ç : {first_code}")
    print(f"   Kçº¿æ•°é‡: {len(df)}")
    print(f"   æ—¶é—´èŒƒå›´: {df['time_str'].min()} ~ {df['time_str'].max()}")
    print()
    
    # å‰5æ ¹å’Œå5æ ¹
    print("ğŸ“ˆ å‰5æ ¹Kçº¿:")
    print(df[['time_str', 'open', 'high', 'low', 'close', 'volume']].head())
    print()
    
    print("ğŸ“‰ å5æ ¹Kçº¿:")
    print(df[['time_str', 'open', 'high', 'low', 'close', 'volume']].tail())
    print()
    
    # ç»Ÿè®¡ä¿¡æ¯
    print("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   å¹³å‡æˆäº¤é‡: {df['volume'].mean():.0f}")
    print(f"   æœ€å¤§æˆäº¤é‡: {df['volume'].max():.0f}")
    print(f"   å¹³å‡æŒ¯å¹…: {((df['high'] - df['low']) / df['close'] * 100).mean():.2f}%")
    print("=" * 80)


def main():
    """ä¸»å‡½æ•°"""
    print()
    print("=" * 80)
    print("ğŸ”§ MyQuantTool - åˆ†é’ŸKçº¿æ•°æ®æ‹‰å–å·¥å…· (TickProviderç‰ˆ)")
    print("=" * 80)
    print()
    print("âœ… æ— éœ€L2æƒé™ï¼ˆæ‰€æœ‰QMTç”¨æˆ·å…è´¹ï¼‰")
    print("âœ… æ•°æ®å¯è¡¥å…¨ï¼ˆè§£å†³æ ·æœ¬ä¸¢å¤±é—®é¢˜ï¼‰")
    print("âœ… æ•°æ®é‡å°ï¼ˆ5000åªè‚¡ç¥¨/å¤©çº¦20MBï¼‰")
    print("âœ… ä½¿ç”¨TickProviderç»Ÿä¸€å°è£…")
    print()
    
    # ğŸ”¥ åŠ¨æ€æ—¥æœŸï¼šè¿‡å»30å¤©
    end_date = datetime.now()
    start_date = end_date - timedelta(days=30)
    
    start_date_str = start_date.strftime('%Y%m%d')
    end_date_str = end_date.strftime('%Y%m%d')
    
    print(f"ğŸ“… æ—¶é—´èŒƒå›´: {start_date_str} ~ {end_date_str} (è¿‡å»30å¤©)")
    print()
    
    # æµ‹è¯•è‚¡ç¥¨åˆ—è¡¨ï¼ˆå¯æ›¿æ¢ä¸ºä½ çš„è‚¡ç¥¨æ± ï¼‰
    test_stocks = [
        '600519.SH',  # è´µå·èŒ…å°
        '000001.SZ',  # å¹³å®‰é“¶è¡Œ
        '300997.SZ',  # æ¬¢ä¹å®¶
        '002099.SZ',  # æµ·ç¿”è¯ä¸š
        '301150.SZ',  # ä¸­èˆ¹æ±‰å…‰
    ]
    
    # æ‹‰å–æ•°æ®
    data = fetch_minute_data(
        code_list=test_stocks,
        start_date=start_date_str,
        end_date=end_date_str,
        verbose=True
    )
    
    if not data:
        print("âŒ æ²¡æœ‰è·å–åˆ°æ•°æ®ï¼Œè¯·æ£€æŸ¥QMTè¿æ¥")
        return
    
    # éªŒè¯æ•°æ®å®Œæ•´æ€§ï¼ˆ30å¤©ï¼‰
    verify_data_integrity(data, expected_days=30)
    
    # åˆ†æç¬¬ä¸€åªè‚¡ç¥¨
    analyze_first_stock(data)
    
    # ä¿å­˜åˆ°CSV
    save_data_to_csv(data, 'data/minute_data')
    
    print()
    print("âœ… æ•°æ®æ‹‰å–å®Œæˆï¼")
    print()
    print("ğŸ“ ä¸‹ä¸€æ­¥:")
    print("   1. ä½¿ç”¨è¿™äº›æ•°æ®è¿›è¡Œç­–ç•¥å›æµ‹")
    print("   2. å¯¹æ¯”Tickæ•°æ®ï¼ŒéªŒè¯æ•°æ®å®Œæ•´æ€§")
    print("   3. é›†æˆåˆ°ä½ çš„æ‰«æå™¨ä¸­")


if __name__ == "__main__":
    main()