#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†é’ŸKçº¿æ•°æ®æ‹‰å–å·¥å…· - è§£å†³æ ·æœ¬ä¸¢å¤±é—®é¢˜

åŠŸèƒ½ï¼š
1. ä»QMTæœåŠ¡å™¨ä¸‹è½½1åˆ†é’ŸKçº¿æ•°æ®åˆ°æœ¬åœ°ç¼“å­˜
2. è¯»å–æœ¬åœ°ç¼“å­˜æ•°æ®è¿›è¡Œç­–ç•¥å›æµ‹
3. æ•°æ®å®Œæ•´æ€§éªŒè¯

ä¼˜åŠ¿ï¼š
- æ— éœ€L2æƒé™ï¼ˆæ‰€æœ‰QMTç”¨æˆ·å…è´¹ï¼‰
- æ•°æ®å¯è¡¥å…¨ï¼ˆä¸ä¼šæ°¸ä¹…ä¸¢å¤±ï¼‰
- æ•°æ®é‡å°ï¼ˆ5000åªè‚¡ç¥¨/å¤©çº¦20MBï¼‰
- é€‚åˆè¯±å¤šæ£€æµ‹å’Œè¶‹åŠ¿åˆ†æ

Author: iFlow CLI
Date: 2026-02-09
"""

import time
import sys
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict
import pandas as pd

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
    from xtquant import xtdata
    QMT_AVAILABLE = True
except ImportError:
    print("âŒ xtquant æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨ QMT æ•°æ®æº")
    print("   è¯·å®‰è£…ï¼špip install xtquant")
    QMT_AVAILABLE = False
    sys.exit(1)


def fetch_minute_data(
    code_list: List[str],
    start_date: str = None,
    end_date: str = None,
    verbose: bool = True
) -> Dict[str, pd.DataFrame]:
    """
    æ‹‰å–1åˆ†é’ŸKçº¿æ•°æ®
    
    Args:
        code_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œå¦‚ ['600519.SH', '000001.SZ']
        start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'ï¼Œé»˜è®¤ä¸º7å¤©å‰
        end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'ï¼Œé»˜è®¤ä¸ºä»Šå¤©
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
    
    Returns:
        å­—å…¸ï¼Œkeyä¸ºè‚¡ç¥¨ä»£ç ï¼Œvalueä¸ºDataFrame
    """
    if not QMT_AVAILABLE:
        return {}
    
    # é»˜è®¤æ—¥æœŸèŒƒå›´ï¼šè¿‡å»7å¤©
    if start_date is None:
        start_date = (datetime.now() - timedelta(days=7)).strftime('%Y%m%d')
    if end_date is None:
        end_date = datetime.now().strftime('%Y%m%d')
    
    if verbose:
        print("=" * 80)
        print("ğŸš€ å¼€å§‹æ‹‰å–1åˆ†é’ŸKçº¿æ•°æ®")
        print("=" * 80)
        print(f"ğŸ“… æ—¶é—´èŒƒå›´: {start_date} ~ {end_date}")
        print(f"ğŸ“Š è‚¡ç¥¨æ•°é‡: {len(code_list)}")
        print()
    
    # ç¬¬1æ­¥ï¼šå¼ºåˆ¶ä¸‹è½½æ•°æ®åˆ°æœ¬åœ°ç¼“å­˜
    if verbose:
        print("ğŸ“¥ ç¬¬1æ­¥ï¼šä»QMTæœåŠ¡å™¨ä¸‹è½½æ•°æ®åˆ°æœ¬åœ°ç¼“å­˜...")
    
    try:
        xtdata.download_history_data(
            stock_list=code_list,
            period='1m',
            start_time=start_date,
            end_time=end_date
        )
        if verbose:
            print("âœ… ä¸‹è½½å®Œæˆ")
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        return {}
    
    # ç¬¬2æ­¥ï¼šä»æœ¬åœ°ç¼“å­˜è¯»å–æ•°æ®
    if verbose:
        print()
        print("ğŸ“– ç¬¬2æ­¥ï¼šä»æœ¬åœ°ç¼“å­˜è¯»å–æ•°æ®...")
    
    try:
        data = xtdata.get_market_data(
            field_list=['time', 'open', 'high', 'low', 'close', 'volume', 'amount'],
            stock_list=code_list,
            period='1m',
            start_time=start_date,
            end_time=end_date,
            count=-1,  # -1 è¡¨ç¤ºå–æ—¶é—´æ®µå†…æ‰€æœ‰æ•°æ®
            dividend_type='none',  # ä¸å¤æƒï¼ˆå›æµ‹é€šå¸¸ç”¨å‰å¤æƒ 'front'ï¼‰
            fill_data=True  # å¡«å……åœç‰Œæ•°æ®
        )
    except Exception as e:
        print(f"âŒ è¯»å–å¤±è´¥: {e}")
        return {}
    
    # ç¬¬3æ­¥ï¼šè½¬æ¢å’ŒéªŒè¯æ•°æ®
    result = {}
    
    for code in code_list:
        if code in data and data[code] is not None:
            df = data[code]
            
            if not df.empty:
                # è½¬æ¢æ—¶é—´æˆ³ä¸ºå¯è¯»æ—¶é—´
                df['time_str'] = pd.to_datetime(df['time'], unit='ms') + pd.Timedelta(hours=8)
                result[code] = df
                
                if verbose:
                    print(f"âœ… {code}: è·å–åˆ° {len(df)} æ ¹åˆ†é’ŸKçº¿")
            else:
                if verbose:
                    print(f"âš ï¸  {code}: æ•°æ®ä¸ºç©º")
        else:
            if verbose:
                print(f"âŒ {code}: æ•°æ®è·å–å¤±è´¥")
    
    if verbose:
        print()
        print("=" * 80)
        print("ğŸ“Š æ•°æ®æ‹‰å–å®Œæˆ")
        print(f"æˆåŠŸ: {len(result)}/{len(code_list)} åªè‚¡ç¥¨")
        print("=" * 80)
    
    return result


def verify_data_integrity(
    data_dict: Dict[str, pd.DataFrame],
    expected_days: int = 7
) -> Dict[str, any]:
    """
    éªŒè¯æ•°æ®å®Œæ•´æ€§
    
    Args:
        data_dict: è‚¡ç¥¨æ•°æ®å­—å…¸
        expected_days: é¢„æœŸå¤©æ•°ï¼ˆç”¨äºè®¡ç®—é¢„æœŸçš„Kçº¿æ•°é‡ï¼‰
    
    Returns:
        éªŒè¯ç»“æœå­—å…¸
    """
    print()
    print("=" * 80)
    print("ğŸ” æ•°æ®å®Œæ•´æ€§éªŒè¯")
    print("=" * 80)
    
    # äº¤æ˜“æ—¥çº¦5å¤©/å‘¨ï¼Œæ¯å¤©çº¦240æ ¹Kçº¿ï¼ˆ4å°æ—¶äº¤æ˜“ï¼‰
    expected_bars = expected_days * 240
    
    results = {
        'total_stocks': len(data_dict),
        'valid_stocks': 0,
        'incomplete_stocks': 0,
        'missing_stocks': 0,
        'details': []
    }
    
    for code, df in data_dict.items():
        actual_bars = len(df)
        completeness = actual_bars / expected_bars * 100
        
        status = 'âœ… å®Œæ•´' if completeness >= 80 else 'âš ï¸ ä¸å®Œæ•´'
        
        result_detail = {
            'code': code,
            'actual_bars': actual_bars,
            'expected_bars': expected_bars,
            'completeness': completeness,
            'status': status
        }
        
        results['details'].append(result_detail)
        
        if completeness >= 80:
            results['valid_stocks'] += 1
        elif completeness > 0:
            results['incomplete_stocks'] += 1
        else:
            results['missing_stocks'] += 1
        
        print(f"{code}: {actual_bars:4d} æ ¹Kçº¿ ({completeness:5.1f}%) {status}")
    
    print()
    print(f"âœ… å®Œæ•´: {results['valid_stocks']}/{results['total_stocks']}")
    print(f"âš ï¸  ä¸å®Œæ•´: {results['incomplete_stocks']}/{results['total_stocks']}")
    print(f"âŒ ç¼ºå¤±: {results['missing_stocks']}/{results['total_stocks']}")
    print("=" * 80)
    
    return results


def save_data_to_csv(
    data_dict: Dict[str, pd.DataFrame],
    output_dir: str = 'data/minute_data'
):
    """
    ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶
    
    Args:
        data_dict: è‚¡ç¥¨æ•°æ®å­—å…¸
        output_dir: è¾“å‡ºç›®å½•
    """
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    print()
    print("=" * 80)
    print("ğŸ’¾ ä¿å­˜æ•°æ®åˆ°CSV")
    print("=" * 80)
    
    for code, df in data_dict.items():
        file_path = output_path / f"{code}_1m.csv"
        df.to_csv(file_path, index=False, encoding='utf-8-sig')
        print(f"âœ… {code} â†’ {file_path}")
    
    print("=" * 80)


def load_data_from_csv(
    input_dir: str = 'data/minute_data'
) -> Dict[str, pd.DataFrame]:
    """
    ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®
    
    Args:
        input_dir: è¾“å…¥ç›®å½•
    
    Returns:
        å­—å…¸ï¼Œkeyä¸ºè‚¡ç¥¨ä»£ç ï¼Œvalueä¸ºDataFrame
    """
    input_path = Path(input_dir)
    
    if not input_path.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {input_path}")
        return {}
    
    print()
    print("=" * 80)
    print("ğŸ“‚ ä»CSVåŠ è½½æ•°æ®")
    print("=" * 80)
    
    result = {}
    
    for file_path in input_path.glob('*_1m.csv'):
        code = file_path.stem.replace('_1m', '')
        try:
            df = pd.read_csv(file_path, encoding='utf-8-sig')
            result[code] = df
            print(f"âœ… {code}: {len(df)} æ ¹Kçº¿")
        except Exception as e:
            print(f"âŒ {code}: åŠ è½½å¤±è´¥ - {e}")
    
    print("=" * 80)
    return result


def analyze_first_stock(data_dict: Dict[str, pd.DataFrame]):
    """
    åˆ†æç¬¬ä¸€åªè‚¡ç¥¨çš„æ•°æ®
    
    Args:
        data_dict: è‚¡ç¥¨æ•°æ®å­—å…¸
    """
    if not data_dict:
        print("âŒ æ²¡æœ‰æ•°æ®å¯åˆ†æ")
        return
    
    first_code = list(data_dict.keys())[0]
    df = data_dict[first_code]
    
    print()
    print("=" * 80)
    print(f"ğŸ“Š {first_code} æ•°æ®åˆ†æ")
    print("=" * 80)
    print()
    
    # åŸºæœ¬ç»Ÿè®¡
    print("ğŸ“Œ åŸºæœ¬ä¿¡æ¯:")
    print(f"   è‚¡ç¥¨ä»£ç : {first_code}")
    print(f"   Kçº¿æ•°é‡: {len(df)}")
    print(f"   æ—¶é—´èŒƒå›´: {df['time_str'].min()} ~ {df['time_str'].max()}")
    print()
    
    # å‰5æ ¹å’Œå5æ ¹
    print("ğŸ“ˆ å‰5æ ¹Kçº¿:")
    print(df[['time_str', 'open', 'high', 'low', 'close', 'volume']].head())
    print()
    
    print("ğŸ“‰ å5æ ¹Kçº¿:")
    print(df[['time_str', 'open', 'high', 'low', 'close', 'volume']].tail())
    print()
    
    # ç»Ÿè®¡ä¿¡æ¯
    print("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   å¹³å‡æˆäº¤é‡: {df['volume'].mean():.0f}")
    print(f"   æœ€å¤§æˆäº¤é‡: {df['volume'].max():.0f}")
    print(f"   å¹³å‡æŒ¯å¹…: {((df['high'] - df['low']) / df['close'] * 100).mean():.2f}%")
    print("=" * 80)


def main():
    """ä¸»å‡½æ•°"""
    print()
    print("=" * 80)
    print("ğŸ”§ MyQuantTool - åˆ†é’ŸKçº¿æ•°æ®æ‹‰å–å·¥å…·")
    print("=" * 80)
    print()
    print("âœ… æ— éœ€L2æƒé™ï¼ˆæ‰€æœ‰QMTç”¨æˆ·å…è´¹ï¼‰")
    print("âœ… æ•°æ®å¯è¡¥å…¨ï¼ˆè§£å†³æ ·æœ¬ä¸¢å¤±é—®é¢˜ï¼‰")
    print("âœ… æ•°æ®é‡å°ï¼ˆ5000åªè‚¡ç¥¨/å¤©çº¦20MBï¼‰")
    print()
    
    # æµ‹è¯•è‚¡ç¥¨åˆ—è¡¨ï¼ˆå¯æ›¿æ¢ä¸ºä½ çš„è‚¡ç¥¨æ± ï¼‰
    test_stocks = [
        '600519.SH',  # è´µå·èŒ…å°
        '000001.SZ',  # å¹³å®‰é“¶è¡Œ
        '300997.SZ',  # æ¬¢ä¹å®¶
        '002099.SZ',  # æµ·ç¿”è¯ä¸š
        '301150.SZ',  # ä¸­èˆ¹æ±‰å…‰
    ]
    
    # æ‹‰å–æ•°æ®
    data = fetch_minute_data(
        code_list=test_stocks,
        start_date='20260201',  # 2æœˆ1æ—¥
        end_date='20260209',    # 2æœˆ9æ—¥
        verbose=True
    )
    
    if not data:
        print("âŒ æ²¡æœ‰è·å–åˆ°æ•°æ®ï¼Œè¯·æ£€æŸ¥QMTè¿æ¥")
        return
    
    # éªŒè¯æ•°æ®å®Œæ•´æ€§
    verify_data_integrity(data, expected_days=7)
    
    # åˆ†æç¬¬ä¸€åªè‚¡ç¥¨
    analyze_first_stock(data)
    
    # ä¿å­˜åˆ°CSV
    save_data_to_csv(data, 'data/minute_data')
    
    print()
    print("âœ… æ•°æ®æ‹‰å–å®Œæˆï¼")
    print()
    print("ğŸ“ ä¸‹ä¸€æ­¥:")
    print("   1. ä½¿ç”¨è¿™äº›æ•°æ®è¿›è¡Œç­–ç•¥å›æµ‹")
    print("   2. å¯¹æ¯”Tickæ•°æ®ï¼ŒéªŒè¯æ•°æ®å®Œæ•´æ€§")
    print("   3. é›†æˆåˆ°ä½ çš„æ‰«æå™¨ä¸­")


if __name__ == "__main__":
    main()