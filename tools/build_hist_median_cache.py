#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æç®€ç‰ˆhist_medianç¼“å­˜æ„å»ºè„šæœ¬ - CTOæ¶æ„å®šè°ƒç‰ˆ
ç»Ÿä¸€ä½¿ç”¨xtdata.get_local_dataè¯»å–QMTæ ‡å‡†è·¯å¾„ï¼Œä¸æå¤æ‚è·¯å¾„æ˜ å°„

æ¶æ„åŸåˆ™ï¼š
1. æ‰€æœ‰å†å²Tické€šè¿‡xtdata.get_local_dataè¯»å–ï¼ˆQMTå®¢æˆ·ç«¯æ ‡å‡†è·¯å¾„ï¼‰
2. ä¸å†å°è¯•è¯»é¡¹ç›®ç›®å½•æˆ–å…¶ä»–è‡ªå®šä¹‰è·¯å¾„
3. åªç”¨QMTå®¢æˆ·ç«¯ç›®å½•ï¼šE:/qmt/userdata_mini/datadir
"""

import sys
import json
from pathlib import Path
from datetime import datetime, timedelta
import pandas as pd

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# å°è¯•å¯¼å…¥xtdata
try:
    from xtquant import xtdata
    print("âœ… xtdataå¯¼å…¥æˆåŠŸ")
except ImportError:
    print("âŒ æ— æ³•å¯¼å…¥xtdataï¼Œè¯·ç¡®ä¿QMTå®¢æˆ·ç«¯å·²å®‰è£…å¹¶æ¿€æ´»")
    sys.exit(1)

def get_last_n_trading_days(n: int) -> list[str]:
    """
    è·å–æœ€è¿‘nä¸ªäº¤æ˜“æ—¥åˆ—è¡¨ï¼ˆæ ¼å¼YYYYMMDDï¼‰
    ä¸ºç®€åŒ–ï¼Œè¿™é‡Œç”¨å½“å‰æ—¥æœŸå€’æ¨ä¼°ç®—
    """
    days = []
    current_date = datetime.now()
    while len(days) < n * 2:  # å¤šç”Ÿæˆä¸€äº›ï¼Œæ’é™¤å‘¨æœ«
        if current_date.weekday() < 5:  # 0-4 æ˜¯å‘¨ä¸€åˆ°å‘¨äº”
            days.append(current_date.strftime('%Y%m%d'))
        current_date -= timedelta(days=1)
    return days[:n]

def get_turnover_5min_series(tick_df: pd.DataFrame, float_volume: float) -> list[float]:
    """
    è®¡ç®—è‚¡ç¥¨æ¯5åˆ†é’Ÿçš„æ¢æ‰‹ç‡åºåˆ—
    
    Args:
        tick_df: Tickæ•°æ®DataFrame
        float_volume: æµé€šè‚¡æœ¬ï¼ˆè‚¡ï¼‰
    
    Returns:
        list[float]: æ¯ä¸ª5åˆ†é’Ÿçª—å£çš„æ¢æ‰‹ç‡
    """
    if 'volume' not in tick_df.columns or float_volume <= 0:
        return []
    
    # ç¡®ä¿æŒ‰ç…§æ—¶é—´æ’åº
    if 'time' in tick_df.columns:
        tick_df = tick_df.sort_values('time').reset_index(drop=True)
    
    # è®¡ç®—volumeDeltaï¼ˆé€ç¬”æˆäº¤é‡ï¼‰
    tick_df = tick_df.copy()
    tick_df['vol_delta'] = tick_df['volume'].diff().fillna(tick_df['volume'].iloc[0])
    tick_df['vol_delta'] = tick_df['vol_delta'].clip(lower=0)  # æ’é™¤å¼‚å¸¸è´Ÿå€¼
    
    # è½¬æ¢æ—¶é—´æˆ³ä¸ºdatetime
    if 'time' in tick_df.columns:
        if tick_df['time'].dtype in ['int64', 'float64']:
            # å‡è®¾æ˜¯æ¯«ç§’æ—¶é—´æˆ³
            tick_df['dt'] = pd.to_datetime(tick_df['time'], unit='ms')
        else:
            tick_df['dt'] = pd.to_datetime(tick_df['time'])
    else:
        return []
    
    # æŒ‰5åˆ†é’Ÿåˆ†ç»„æ±‚å’Œ
    tick_df.set_index('dt', inplace=True)
    vol_5min = tick_df['vol_delta'].resample('5min').sum()
    
    # æ¢æ‰‹ç‡åºåˆ—
    turnover_series = (vol_5min / float_volume).tolist()
    return [t for t in turnover_series if t > 0]  # è¿‡æ»¤é›¶å€¼çª—å£

def get_float_volume(stock_code: str) -> float | None:
    """
    é€šè¿‡xtdataè·å–æµé€šè‚¡æœ¬ï¼ˆè‚¡ï¼‰
    
    Args:
        stock_code: å¸¦åç¼€çš„è‚¡ç¥¨ä»£ç ï¼Œå¦‚"000547.SZ"
    
    Returns:
        float: æµé€šè‚¡æœ¬ï¼ˆè‚¡ï¼‰
        None:  è·å–å¤±è´¥
    """
    try:
        detail = xtdata.get_instrument_detail(stock_code)
        if not detail:
            return None
        fv = detail.get('FloatVolume')
        if fv is None:
            return None
        # FloatVolumeæ˜¯å­—ç¬¦ä¸²ï¼Œå¿…é¡»å¼ºåˆ¶è½¬æ¢
        # ğŸ”§ ä¿®æ­£ï¼šxtdataè¿”å›çš„FloatVolumeå·²ç»æ˜¯"è‚¡"å•ä½ï¼Œä¸éœ€è¦å†è½¬
        float_vol = float(fv)
        if float_vol <= 0:
            return None
        return float_vol  # ç›´æ¥è¿”å›è‚¡å•ä½
    except Exception as e:
        print(f"  [WARN] get_float_volume {stock_code} å¤±è´¥: {e}")
        return None

def build_hist_median_cache(
    stock_codes: list[str],
    lookback_days: int = 60
) -> dict:
    """
    æ„å»ºhist_medianç¼“å­˜
    
    Args:
        stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆå¸¦åç¼€æ ¼å¼ï¼Œå¦‚["000547.SZ", "300017.SZ"]ï¼‰
        lookback_days: å›æº¯å¤©æ•°ï¼Œé»˜è®¤60
    
    Returns:
        dict: ç¼“å­˜æ•°æ®
    """
    cache = {}
    candidate_dates = get_last_n_trading_days(lookback_days)

    for i, code in enumerate(stock_codes):
        print(f"\n[{i+1}/{len(stock_codes)}] {code}")

        # 1. è·å–æµé€šè‚¡æœ¬
        float_vol = get_float_volume(code)
        if float_vol is None:
            print(f"  âš ï¸ æµé€šè‚¡æœ¬è·å–å¤±è´¥ï¼Œè·³è¿‡")
            continue
        print(f"  æµé€šè‚¡æœ¬: {float_vol/1e8:.2f}äº¿è‚¡")

        # 2. éå†å†å²æ—¥æœŸï¼Œè®¡ç®—æ¯æ—¥å³°å€¼æ¢æ‰‹
        daily_peaks = []
        valid_days = 0

        for date in candidate_dates:
            if valid_days >= lookback_days:
                break

            # ç›´æ¥ä½¿ç”¨xtdata.get_local_dataè¯»å–QMTæ ‡å‡†è·¯å¾„æ•°æ®
            try:
                result = xtdata.get_local_data(
                    field_list=['time', 'volume'],
                    stock_list=[code],
                    period='tick',
                    start_time=date,
                    end_time=date
                )
                
                if result is None or code not in result:
                    continue  # è¯¥æ—¥æ— æ•°æ®ï¼ˆèŠ‚å‡æ—¥/åœç‰Œï¼‰ï¼Œæ­£å¸¸è·³è¿‡
                
                tick_df = result[code]
                if tick_df is None or tick_df.empty:
                    continue
                
                # è®¡ç®—è¯¥æ—¥æ¢æ‰‹ç‡å³°å€¼
                turnover_series = get_turnover_5min_series(tick_df, float_vol)
                if not turnover_series:
                    continue

                # ç”¨å½“æ—¥å³°å€¼ä»£è¡¨"å½“æ—¥æœ€æ´»è·ƒ5åˆ†é’Ÿæ¢æ‰‹æ°´å¹³"
                daily_peaks.append(max(turnover_series))
                valid_days += 1
            except Exception as e:
                # é™é»˜è·³è¿‡ï¼Œå¯èƒ½æ˜¯è¯¥æ—¥æ— æ•°æ®æˆ–æƒé™é—®é¢˜
                continue

        if valid_days < 5:  # å°‘äº5æ—¥æœ‰æ•ˆæ•°æ®ï¼Œä¸å¯é 
            print(f"  âš ï¸ æœ‰æ•ˆæ•°æ®ä¸è¶³ {valid_days} æ—¥ï¼ˆéœ€>=5ï¼‰ï¼Œè·³è¿‡")
            continue

        hist_median = float(pd.Series(daily_peaks).median())
        print(f"  âœ… hist_median={hist_median:.6f}ï¼Œæœ‰æ•ˆ={valid_days}æ—¥")
        print(f"     (è§£è¯»ï¼šæ—¥å³°å€¼æ¢æ‰‹ç‡ä¸­ä½={hist_median*100:.4f}%/5min)")

        cache[code] = {
            "hist_median": hist_median,
            "float_volume": float_vol,
            "valid_days": valid_days,
            "updated_at": datetime.now().strftime('%Y-%m-%d')
        }

    # 3. å†™å…¥ç¼“å­˜æ–‡ä»¶
    cache_dir = PROJECT_ROOT / "data" / "cache"
    cache_dir.mkdir(parents=True, exist_ok=True)
    
    cache_file = cache_dir / "hist_median_cache.json"
    with open(cache_file, 'w', encoding='utf-8') as f:
        json.dump(cache, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… ç¼“å­˜å†™å…¥å®Œæˆ: {len(cache)}/{len(stock_codes)} åª â†’ {cache_file}")
    return cache


if __name__ == "__main__":
    print("="*60)
    print("æç®€ç‰ˆhist_medianç¼“å­˜æ„å»ºè„šæœ¬ - CTOæ¶æ„å®šè°ƒç‰ˆ")
    print("="*60)
    
    # éªŒè¯ç”¨çš„è‚¡ç¥¨æ± ï¼ˆä»é¡½ä¸»ç ”ç©¶ä¸­æå–çš„ï¼‰
    VERIFY_CODES = [
        "300017.SZ",   # ç½‘å®¿ç§‘æŠ€ï¼ˆABå¯¹ç…§æ ¸å¿ƒï¼‰
        "000547.SZ",   # èˆªå¤©å‘å±•
        "300058.SZ",   # è“è‰²å…‰æ ‡
        "000592.SZ",   # å¹³æ½­å‘å±•
        "002792.SZ",   # é€šå®‡é€šè®¯
        "603778.SH",   # å›½æ™Ÿç§‘æŠ€
        "301005.SZ",   # è¶…æ·è‚¡ä»½
        "603516.SH",   # æ·³ä¸­ç§‘æŠ€
    ]

    print(f"å¼€å§‹æ„å»ºç¼“å­˜ï¼Œè‚¡ç¥¨æ•°é‡: {len(VERIFY_CODES)}")
    print(f"å›æº¯å¤©æ•°: 60æ—¥")
    print(f"æ•°æ®æº: QMTå®¢æˆ·ç«¯æ ‡å‡†è·¯å¾„ (E:/qmt/userdata_mini/datadir)")
    
    result = build_hist_median_cache(VERIFY_CODES, lookback_days=60)
    
    # å¿«é€ŸéªŒè¯ï¼šæ‰“å°300017.SZç»“æœä¾›äººå·¥æ ¸å¯¹
    entry = result.get("300017.SZ")
    if entry:
        print(f"\n--- éªŒè¯ 300017.SZ ---")
        print(f"  hist_median  = {entry['hist_median']:.6f}")
        print(f"  float_volume = {entry['float_volume']/1e8:.2f}äº¿è‚¡")
        print(f"  valid_days   = {entry['valid_days']}")
        print(f"  é¢„æœŸ ratio_stock é‡çº§:")
        print(f"    1-26 é«˜å³°æ—¶ flow_5minâ‰ˆ587Mï¼Œpriceâ‰ˆ13.78")
        vol_est = 587e6 / 13.78          # çº¦ 4259ä¸‡è‚¡
        t5_est  = vol_est / entry['float_volume']
        ratio_est = t5_est / entry['hist_median']
        print(f"    vol_5minâ‰ˆ{vol_est/1e4:.0f}ä¸‡è‚¡ â†’ turnoverâ‰ˆ{t5_est:.4f}")
        print(f"    ratio_stockâ‰ˆ{ratio_est:.1f}ï¼ˆç›®æ ‡>15ï¼‰")
    
    print(f"\nç¼“å­˜æ–‡ä»¶ä½ç½®: {PROJECT_ROOT / 'data' / 'cache' / 'hist_median_cache.json'}")
    print("="*60)