"""
ç«ä»·æ•°æ®è´¨é‡ä¸è¯±å¤šæ£€å‡ºç‡æ—¥æŠ¥è‡ªåŠ¨ç”Ÿæˆè„šæœ¬

åŠŸèƒ½ï¼š
1. è¯»å–æŒ‡å®šæ—¥æœŸçš„ç«ä»·å¿«ç…§æ•°æ®
2. è®¡ç®—æ•°æ®è´¨é‡æŒ‡æ ‡ï¼ˆæœ‰æ•ˆç‡ã€åˆ†å¸ƒç­‰ï¼‰
3. ç»Ÿè®¡è¯±å¤šæ£€å‡ºæƒ…å†µ
4. ç”ŸæˆMarkdownæ ¼å¼æ—¥æŠ¥
5. å¯é€‰ç”ŸæˆJSONæ ¼å¼æ•°æ®
"""

import sqlite3
import argparse
import json
from datetime import datetime
from typing import Dict, List, Any
from pathlib import Path


class AuctionDailyReportGenerator:
    """ç«ä»·æ—¥æŠ¥ç”Ÿæˆå™¨"""

    def __init__(self, db_path: str = "data/auction_snapshots.db"):
        self.db_path = db_path

    def get_data(self, date: str) -> Dict[str, Any]:
        """è·å–æŒ‡å®šæ—¥æœŸçš„æ•°æ®"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # åŸºç¡€ç»Ÿè®¡
        cursor.execute('''
            SELECT
                COUNT(*) as total,
                SUM(CASE WHEN volume_ratio_valid = 1 THEN 1 ELSE 0 END) as valid,
                SUM(CASE WHEN data_source = 'production' THEN 1 ELSE 0 END) as production,
                SUM(CASE WHEN data_source = 'simulated' THEN 1 ELSE 0 END) as simulated
            FROM auction_snapshots
            WHERE date = ?
        ''', (date,))
        basic_stats = cursor.fetchone()

        # é‡æ¯”åˆ†å¸ƒ
        cursor.execute('''
            SELECT
                CASE
                    WHEN volume_ratio < 0.5 THEN '0-0.5'
                    WHEN volume_ratio < 1.0 THEN '0.5-1.0'
                    WHEN volume_ratio < 2.0 THEN '1.0-2.0'
                    WHEN volume_ratio < 5.0 THEN '2.0-5.0'
                    WHEN volume_ratio < 10.0 THEN '5.0-10.0'
                    ELSE '>10.0'
                END as bucket,
                COUNT(*) as count
            FROM auction_snapshots
            WHERE date = ? AND volume_ratio_valid = 1
            GROUP BY bucket
            ORDER BY bucket
        ''', (date,))
        volume_distribution = cursor.fetchall()

        # æ¶¨è·Œå¹…åˆ†å¸ƒ
        cursor.execute('''
            SELECT
                CASE
                    WHEN auction_change < -0.10 THEN '<-10%'
                    WHEN auction_change < -0.05 THEN '-10%~-5%'
                    WHEN auction_change < -0.02 THEN '-5%~-2%'
                    WHEN auction_change < 0.02 THEN '-2%~+2%'
                    WHEN auction_change < 0.05 THEN '+2%~+5%'
                    WHEN auction_change < 0.10 THEN '+5%~+10%'
                    ELSE '>+10%'
                END as bucket,
                COUNT(*) as count
            FROM auction_snapshots
            WHERE date = ?
            GROUP BY bucket
            ORDER BY bucket
        ''', (date,))
        change_distribution = cursor.fetchall()

        # è¯±å¤šæ£€å‡ºï¼ˆé«˜å¼€+ä½é‡æ¯”ï¼‰
        cursor.execute('''
            SELECT
                COUNT(*) as trap_count
            FROM auction_snapshots
            WHERE date = ?
              AND auction_change > 0.05
              AND volume_ratio_valid = 1
              AND volume_ratio < 2.0
        ''', (date,))
        trap_stats = cursor.fetchone()

        # é«˜å¼€è¯±å¤šå€™é€‰Top 20
        cursor.execute('''
            SELECT
                code, name, auction_price,
                ROUND(auction_change * 100, 2) as change_pct,
                ROUND(volume_ratio, 2) as volume_ratio,
                CASE
                    WHEN auction_change > 0.05 AND volume_ratio < 2.0 THEN 'è¯±å¤šå€™é€‰'
                    WHEN auction_change > 0.05 AND volume_ratio >= 2.0 THEN 'å¼ºåŠ¿'
                    WHEN auction_change < -0.05 THEN 'ä½å¼€'
                    ELSE 'æ™®é€š'
                END as type
            FROM auction_snapshots
            WHERE date = ?
              AND ABS(auction_change) > 0.03
            ORDER BY auction_change DESC, volume_ratio ASC
            LIMIT 20
        ''', (date,))
        top_stocks = cursor.fetchall()

        # æ¶¨è·Œå¹…ä¸­ä½æ•°
        cursor.execute('''
            SELECT auction_change
            FROM auction_snapshots
            WHERE date = ?
            ORDER BY auction_change
            LIMIT 1
            OFFSET (SELECT COUNT(*) FROM auction_snapshots WHERE date = ?) / 2
        ''', (date, date))
        median_result = cursor.fetchone()
        median_change = median_result[0] * 100 if median_result else 0

        conn.close()

        return {
            'date': date,
            'basic_stats': {
                'total': basic_stats[0],
                'valid': basic_stats[1],
                'production': basic_stats[2],
                'simulated': basic_stats[3],
                'valid_rate': basic_stats[1] / basic_stats[0] * 100 if basic_stats[0] > 0 else 0,
                'data_source': 'production' if basic_stats[2] > basic_stats[3] else 'simulated'
            },
            'volume_distribution': volume_distribution,
            'change_distribution': change_distribution,
            'trap_stats': {
                'trap_count': trap_stats[0],
                'trap_rate': trap_stats[0] / basic_stats[0] * 100 if basic_stats[0] > 0 else 0
            },
            'top_stocks': top_stocks,
            'median_change': median_change
        }

    def generate_markdown(self, data: Dict[str, Any]) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼æŠ¥å‘Š"""
        md = []
        md.append(f"# ç«ä»·è¯±å¤šç³»ç»ŸéªŒè¯æŠ¥å‘Š - {data['date']}")
        md.append("")
        md.append("## ğŸ“Š æ•°æ®è´¨é‡")
        md.append("")
        md.append("### åŸºç¡€ç»Ÿè®¡")
        md.append("")
        md.append("| æŒ‡æ ‡ | æ•°å€¼ |")
        md.append("|------|------|")
        md.append(f"| æ ·æœ¬æ€»æ•° | {data['basic_stats']['total']} |")
        md.append(f"| æœ‰æ•ˆæ•°æ®æ•° | {data['basic_stats']['valid']} |")
        md.append(f"| æ•°æ®æœ‰æ•ˆç‡ | {data['basic_stats']['valid_rate']:.2f}% |")
        md.append(f"| æ•°æ®æ¥æº | {data['basic_stats']['data_source']} |")
        md.append("")
        md.append("### é‡æ¯”åˆ†å¸ƒ")
        md.append("")
        md.append("| åŒºé—´ | æ•°é‡ | å æ¯” |")
        md.append("|------|------|------|")
        for bucket, count in data['volume_distribution']:
            pct = count / data['basic_stats']['total'] * 100 if data['basic_stats']['total'] > 0 else 0
            md.append(f"| {bucket} | {count} | {pct:.2f}% |")
        md.append("")
        md.append("### ç«ä»·æ¶¨è·Œå¹…åˆ†å¸ƒ")
        md.append("")
        md.append("| åŒºé—´ | æ•°é‡ | å æ¯” |")
        md.append("|------|------|------|")
        for bucket, count in data['change_distribution']:
            pct = count / data['basic_stats']['total'] * 100 if data['basic_stats']['total'] > 0 else 0
            md.append(f"| {bucket} | {count} | {pct:.2f}% |")
        md.append("")
        md.append(f"**ä¸­ä½æ•°**ï¼š{data['median_change']:.2f}%")
        md.append("")
        md.append("## ğŸ¯ è¯±å¤šæ£€å‡º")
        md.append("")
        md.append("### æ£€å‡ºç»Ÿè®¡")
        md.append("")
        md.append("| æŒ‡æ ‡ | æ•°å€¼ |")
        md.append("|------|------|")
        md.append(f"| è¯±å¤šå€™é€‰æ•° | {data['trap_stats']['trap_count']} |")
        md.append(f"| æ£€å‡ºç‡ | {data['trap_stats']['trap_rate']:.2f}% |")
        md.append("")
        md.append("### è¯±å¤šå€™é€‰åˆ—è¡¨ï¼ˆTop 20ï¼‰")
        md.append("")
        md.append("| ä»£ç  | åç§° | ç«ä»·ä»· | æ¶¨è·Œå¹…% | é‡æ¯” | ç±»å‹ |")
        md.append("|------|------|--------|---------|------|------|")
        for stock in data['top_stocks']:
            code, name, price, change_pct, volume_ratio, stock_type = stock
            md.append(f"| {code} | {name} | {price:.2f} | {change_pct} | {volume_ratio} | {stock_type} |")
        md.append("")
        md.append("## âœ… éªŒæ”¶ç»“è®º")
        md.append("")
        md.append(f"**å·¥ç¨‹é—­ç¯**ï¼š{'âœ… é€šè¿‡' if data['basic_stats']['data_source'] == 'production' else 'âš ï¸ æ¨¡æ‹Ÿç¯å¢ƒ'}")
        md.append(f"**æ•°æ®è´¨é‡**ï¼š{'âœ… åˆæ ¼' if data['basic_stats']['valid_rate'] > 80 else 'âš ï¸ éœ€å…³æ³¨'}")
        md.append(f"**è¯±å¤šæ£€å‡º**ï¼š{'âœ… æ­£å¸¸' if 1 <= data['trap_stats']['trap_rate'] <= 10 else 'âš ï¸ å¼‚å¸¸'}")
        md.append("")
        md.append("---")
        md.append(f"*ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*")

        return "\n".join(md)

    def save_report(self, date: str, content: str, format: str = "markdown"):
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        report_dir = Path("docs/auction_validation")
        report_dir.mkdir(parents=True, exist_ok=True)

        if format == "markdown":
            file_path = report_dir / f"{date.replace('-', '')}.md"
        elif format == "json":
            file_path = report_dir / f"{date.replace('-', '')}.json"
        else:
            raise ValueError(f"Unsupported format: {format}")

        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)

        print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜ï¼š{file_path}")
        return file_path


def main():
    parser = argparse.ArgumentParser(description="ç”Ÿæˆç«ä»·æ—¥æŠ¥")
    parser.add_argument("--date", type=str, default=datetime.now().strftime("%Y-%m-%d"),
                        help="æ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰")
    parser.add_argument("--format", type=str, default="markdown", choices=["markdown", "json"],
                        help="è¾“å‡ºæ ¼å¼")
    parser.add_argument("--output", action="store_true", help="ä¿å­˜åˆ°æ–‡ä»¶")

    args = parser.parse_args()

    generator = AuctionDailyReportGenerator()

    print(f"ğŸ“Š æ­£åœ¨ç”Ÿæˆ {args.date} çš„ç«ä»·æ—¥æŠ¥...")
    data = generator.get_data(args.date)

    if args.format == "markdown":
        content = generator.generate_markdown(data)
    else:
        content = json.dumps(data, ensure_ascii=False, indent=2)

    print(content)

    if args.output:
        generator.save_report(args.date, content, args.format)


if __name__ == "__main__":
    main()
