# -*- coding: utf-8 -*-
"""
å…¨æ¯æ—¶é—´æœºå™¨æ•°æ®ä¸‹è½½å™¨
æ‰¹é‡ä¸‹è½½å…¨æ¯å›æ¼”æ‰€éœ€Tickæ•°æ®

Author: é¡¹ç›®æ€»ç›‘
Date: 2026-02-23
"""
import os
import sys
import time
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from dotenv import load_dotenv

load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler(
            PROJECT_ROOT / "logs" / "download_holographic.log", encoding="utf-8"
        ),
        logging.StreamHandler(),
    ],
)
logger = logging.getLogger(__name__)


def get_universe_for_dates(dates: List[str]) -> List[str]:
    """
    è·å–å¤šä¸ªæ—¥æœŸçš„ç²—ç­›è‚¡ç¥¨æ± å¹¶åˆå¹¶å»é‡

    CTOè§„èŒƒ: ç¬¬ä¸€å±‚ç²—ç­›å·²æ”¹ç”¨QMTçš„snapshotè¿›è¡Œå®æ—¶å¿«ç…§è¿‡æ»¤
    ä½†ä¸ºäº†æ•°æ®ä¸‹è½½å™¨çš„å…¼å®¹æ€§ï¼Œä¿æŒä½¿ç”¨Tushare daily_basicä½œä¸ºä¸»è¦ç²—ç­›æ–¹æ³•
    å› ä¸ºä¸‹è½½å™¨éœ€è¦åœ¨éäº¤æ˜“æ—¶é—´ä¹Ÿèƒ½è·å–å†å²è‚¡ç¥¨æ± ï¼ŒQMTå†å²æ•°æ®å¯èƒ½ä¸å¯ç”¨

    Args:
        dates: æ—¥æœŸåˆ—è¡¨ ['YYYYMMDD', ...]

    Returns:
        å»é‡åçš„è‚¡ç¥¨ä»£ç åˆ—è¡¨
    """
    from logic.data_providers.universe_builder import UniverseBuilder
    import random

    builder = UniverseBuilder()
    all_stocks = set()

    for date in dates:
        try:
            logger.info(f"ã€ç²—ç­›-å…¼å®¹æ¨¡å¼ã€‘{date} å¼€å§‹...")

            # ä½¿ç”¨Tushareä½œä¸ºä¸»è¦æ–¹æ³•ï¼Œå› ä¸ºå®ƒå¯ä»¥åœ¨éäº¤æ˜“æ—¶é—´è·å–å†å²æ•°æ®
            stocks = builder.get_daily_universe(date)

            # å¦‚æœTushareæ–¹æ³•å¤±è´¥æˆ–è¿”å›ç©ºåˆ—è¡¨ï¼Œä½œä¸ºå¤‡é€‰ä»QMTè·å–å…¨å¸‚åœºè‚¡ç¥¨çš„å­é›†
            if not stocks:
                logger.warning(
                    f"ã€ç²—ç­›-å…¼å®¹æ¨¡å¼ã€‘{date} Tushareæ–¹æ³•è¿”å›ç©ºåˆ—è¡¨ï¼Œä½¿ç”¨QMTå¤‡é€‰æ–¹æ¡ˆ"
                )
                from xtquant import xtdata

                all_stocks_list = xtdata.get_stock_list_in_sector("æ²ªæ·±Aè‚¡")
                if all_stocks_list:
                    # éšæœºé€‰æ‹©ä¸€éƒ¨åˆ†è‚¡ç¥¨ä½œä¸ºå¤‡é€‰ï¼Œç¡®ä¿æœ‰æ•°æ®å¯ä¸‹è½½
                    sample_size = min(100, len(all_stocks_list))
                    stocks = random.sample(all_stocks_list, sample_size)
                    logger.info(
                        f"ã€ç²—ç­›-å…¼å®¹æ¨¡å¼ã€‘{date} QMTå¤‡é€‰æ–¹æ¡ˆè·å–åˆ° {len(stocks)} åªè‚¡ç¥¨"
                    )
                else:
                    logger.error(f"ã€ç²—ç­›-å…¼å®¹æ¨¡å¼ã€‘{date} QMTä¹Ÿæ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
                    continue

            all_stocks.update(stocks)
            logger.info(
                f"ã€ç²—ç­›-å…¼å®¹æ¨¡å¼ã€‘{date} è·å–åˆ° {len(stocks)} åªï¼Œç´¯è®¡ {len(all_stocks)} åª"
            )

        except Exception as e:
            logger.error(f"ã€ç²—ç­›-å…¼å®¹æ¨¡å¼ã€‘{date} å¤±è´¥: {e}")
            import traceback

            traceback.print_exc()
            continue

    return list(all_stocks)


def download_tick_batch(
    stock_list: List[str], dates: List[str], timeout: int = 3600, progress_callback=None
) -> Dict:
    """
    æ‰¹é‡ä¸‹è½½Tickæ•°æ®

    Args:
        stock_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        dates: æ—¥æœŸåˆ—è¡¨
        timeout: æ€»ä½“è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•°

    Returns:
        ä¸‹è½½ç»“æœç»Ÿè®¡
    """
    try:
        from xtquant import xtdata
    except ImportError:
        logger.error("xtquantæœªå®‰è£…")
        return {"error": "xtquantæœªå®‰è£…"}

    results = {
        "total": len(stock_list) * len(dates),
        "success": 0,
        "failed": 0,
        "skipped": 0,
        "errors": [],
    }

    # å¯åŠ¨VIPæœåŠ¡
    try:
        from xtquant import xtdatacenter as xtdc
        from logic.core.path_resolver import PathResolver

        vip_token = os.getenv("QMT_VIP_TOKEN", "")
        # ä»ç¯å¢ƒå˜é‡è·å–QMTè·¯å¾„
        data_dir = os.getenv("QMT_PATH", "")

        if not data_dir:
            # å¦‚æœç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œä½¿ç”¨PathResolverè·å–è·¯å¾„
            data_dir = str(PathResolver.get_qmt_data_dir())

        if vip_token:
            xtdc.set_data_home_dir(data_dir)
            xtdc.set_token(vip_token)
            xtdc.init()
            port = xtdc.listen(port=(58620, 58630))
            logger.info(f"ã€VIPæœåŠ¡ã€‘å·²å¯åŠ¨ï¼Œç«¯å£: {port}")
    except Exception as e:
        logger.warning(f"ã€VIPæœåŠ¡ã€‘å¯åŠ¨å¤±è´¥: {e}ï¼Œä½¿ç”¨æ™®é€šæ¨¡å¼")

    logger.info(
        f"ã€ä¸‹è½½ä»»åŠ¡ã€‘è‚¡ç¥¨: {len(stock_list)} åªï¼Œæ—¥æœŸ: {len(dates)} å¤©ï¼Œæ€»è®¡: {results['total']} ä¸ªä»»åŠ¡"
    )
    logger.info(f"ã€ä¸‹è½½ä»»åŠ¡ã€‘è¶…æ—¶è®¾ç½®: {timeout} ç§’")

    start_date = dates[0]
    end_date = dates[-1]

    import signal
    import sys

    def timeout_handler(signum, frame):
        logger.info(f"ã€ä¸‹è½½ä»»åŠ¡ã€‘è¶…æ—¶ {timeout} ç§’ï¼Œä¿å­˜å½“å‰è¿›åº¦å¹¶é€€å‡º")
        raise TimeoutError(f"ä¸‹è½½ä»»åŠ¡è¶…æ—¶ {timeout} ç§’")

    # è®¾ç½®è¶…æ—¶ä¿¡å·ï¼ˆä»…åœ¨æ”¯æŒçš„ç³»ç»Ÿä¸Šï¼‰
    timeout_set = False
    try:
        signal.signal(signal.SIGALRM, timeout_handler)
        signal.alarm(timeout)
        timeout_set = True
    except AttributeError:
        # Windowsä¸æ”¯æŒSIGALRMï¼Œä½¿ç”¨æ—¶é—´è·Ÿè¸ª
        logger.warning("ã€ä¸‹è½½ä»»åŠ¡ã€‘ç³»ç»Ÿä¸æ”¯æŒSIGALRMï¼Œä½¿ç”¨æ—¶é—´è·Ÿè¸ª")
        import time

        start_time = time.time()

    try:
        from rich.progress import (
            Progress,
            BarColumn,
            TextColumn,
            TimeRemainingColumn,
            TaskID,
        )
        from rich.console import Console

        console = Console()
        with Progress(
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
            TimeRemainingColumn(),
            console=console,
        ) as progress:
            # åˆ›å»ºæ€»è¿›åº¦æ¡
            overall_task = progress.add_task(
                f"[cyan]ä¸‹è½½è¿›åº¦ ({len(stock_list)} åªè‚¡ç¥¨ Ã— {len(dates)} å¤©)",
                total=results["total"],
            )

            for i, stock in enumerate(stock_list, 1):
                try:
                    # æ£€æŸ¥æ˜¯å¦è¶…æ—¶ï¼ˆWindowsï¼‰
                    if not timeout_set:
                        elapsed = time.time() - start_time
                        if elapsed > timeout:
                            logger.info(
                                f"ã€ä¸‹è½½ä»»åŠ¡ã€‘è¶…æ—¶ {timeout} ç§’ï¼Œä¿å­˜å½“å‰è¿›åº¦å¹¶é€€å‡º"
                            )
                            break

                    # æ ‡å‡†åŒ–ä»£ç 
                    if "." not in stock:
                        if stock.startswith("6"):
                            stock = f"{stock}.SH"
                        else:
                            stock = f"{stock}.SZ"

                    # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ®
                    try:
                        existing = xtdata.get_local_data(
                            field_list=["time"],
                            stock_list=[stock],
                            period="tick",
                            start_time=start_date,
                            end_time=end_date,
                        )

                        if (
                            existing
                            and stock in existing
                            and len(existing[stock]) > 1000
                        ):
                            results["skipped"] += len(dates)
                            logger.debug(
                                f"[{i}/{len(stock_list)}] {stock} å·²æœ‰æ•°æ®ï¼Œè·³è¿‡"
                            )
                            progress.update(overall_task, advance=len(dates))
                            continue
                    except:
                        pass

                    # ä¸‹è½½
                    try:
                        xtdata.download_history_data(
                            stock_code=stock,
                            period="tick",
                            start_time=start_date,
                            end_time=end_date,
                        )

                        # éªŒè¯
                        data = xtdata.get_local_data(
                            field_list=["time"],
                            stock_list=[stock],
                            period="tick",
                            start_time=start_date,
                            end_time=end_date,
                        )

                        if data and stock in data and len(data[stock]) > 100:
                            results["success"] += len(dates)
                            logger.info(
                                f"[{i}/{len(stock_list)}] {stock} âœ… ({len(data[stock])} ticks)"
                            )
                        else:
                            results["failed"] += len(dates)
                            logger.warning(
                                f"[{i}/{len(stock_list)}] {stock} âŒ æ•°æ®ä¸è¶³"
                            )

                    except Exception as e:
                        # å¦‚æœä¸‹è½½å¤±è´¥ï¼Œå°è¯•é‡è¯•
                        logger.warning(
                            f"[{i}/{len(stock_list)}] {stock} ä¸‹è½½å¤±è´¥ï¼Œå°è¯•é‡è¯•..."
                        )
                        try:
                            time.sleep(1)  # ç­‰å¾…1ç§’åé‡è¯•
                            xtdata.download_history_data(
                                stock_code=stock,
                                period="tick",
                                start_time=start_date,
                                end_time=end_date,
                            )

                            # éªŒè¯
                            data = xtdata.get_local_data(
                                field_list=["time"],
                                stock_list=[stock],
                                period="tick",
                                start_time=start_date,
                                end_time=end_date,
                            )

                            if data and stock in data and len(data[stock]) > 100:
                                results["success"] += len(dates)
                                logger.info(
                                    f"[{i}/{len(stock_list)}] {stock} âœ… ({len(data[stock])} ticks) [é‡è¯•æˆåŠŸ]"
                                )
                            else:
                                results["failed"] += len(dates)
                                logger.warning(
                                    f"[{i}/{len(stock_list)}] {stock} âŒ æ•°æ®ä¸è¶³ [é‡è¯•å¤±è´¥]"
                                )
                        except Exception as retry_e:
                            results["failed"] += len(dates)
                            error_msg = f"{stock}: {str(retry_e)}"
                            results["errors"].append(error_msg)
                            logger.error(
                                f"[{i}/{len(stock_list)}] {stock} âŒ {retry_e}"
                            )

                except Exception as e:
                    if isinstance(e, TimeoutError):
                        raise e
                    results["failed"] += len(dates)
                    error_msg = f"{stock}: {str(e)}"
                    results["errors"].append(error_msg)
                    logger.error(f"[{i}/{len(stock_list)}] {stock} âŒ {e}")

                # æ›´æ–°è¿›åº¦
                progress.update(overall_task, advance=len(dates))

                # é—´éš”é¿å…é™æµ
                time.sleep(0.1)

    except TimeoutError:
        pass  # è¶…æ—¶å¤„ç†ï¼Œæ­£å¸¸é€€å‡º
    finally:
        if timeout_set:
            signal.alarm(0)  # å–æ¶ˆè¶…æ—¶

    return results


def create_gui_progress():
    """åˆ›å»ºGUIè¿›åº¦çª—å£"""
    try:
        import tkinter as tk
        from tkinter import ttk
        import threading

        root = tk.Tk()
        root.title("å…¨æ¯æ•°æ®ä¸‹è½½å™¨ - è¿›åº¦ç›‘æ§")
        root.geometry("600x400")

        # æ ‡é¢˜
        title_label = tk.Label(
            root, text="å…¨æ¯æ—¶é—´æœºå™¨æ•°æ®ä¸‹è½½å™¨", font=("Arial", 16, "bold")
        )
        title_label.pack(pady=10)

        # è¿›åº¦æ¡
        progress_var = tk.DoubleVar()
        progress_bar = ttk.Progressbar(
            root, variable=progress_var, maximum=100, length=500
        )
        progress_bar.pack(pady=10)

        # è¿›åº¦æ ‡ç­¾
        progress_label = tk.Label(root, text="å‡†å¤‡å¼€å§‹ä¸‹è½½...", font=("Arial", 12))
        progress_label.pack(pady=5)

        # çŠ¶æ€ä¿¡æ¯
        status_text = tk.Text(root, height=15, width=70)
        status_scrollbar = tk.Scrollbar(root, command=status_text.yview)
        status_text.configure(yscrollcommand=status_scrollbar.set)

        status_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=10, pady=5)
        status_scrollbar.pack(side=tk.RIGHT, fill=tk.Y, pady=5)

        # ç”¨äºæ›´æ–°GUIçš„é˜Ÿåˆ—
        import queue

        update_queue = queue.Queue()

        def update_gui():
            try:
                while True:
                    msg = update_queue.get_nowait()
                    status_text.insert(tk.END, msg + "\n")
                    status_text.see(tk.END)
                    status_text.update_idletasks()
            except queue.Empty:
                pass
            root.after(100, update_gui)  # æ¯100msæ£€æŸ¥ä¸€æ¬¡

        root.after(100, update_gui)

        return root, progress_var, progress_label, update_queue
    except ImportError:
        return None, None, None, None


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="å…¨æ¯æ—¶é—´æœºå™¨æ•°æ®ä¸‹è½½å™¨")
    parser.add_argument(
        "--start-date", type=str, default="20251220", help="å¼€å§‹æ—¥æœŸ (YYYYMMDD)"
    )
    parser.add_argument(
        "--end-date", type=str, default="20260110", help="ç»“æŸæ—¥æœŸ (YYYYMMDD)"
    )
    parser.add_argument(
        "--output",
        type=str,
        default="data/holographic_universe.json",
        help="è¾“å‡ºæ–‡ä»¶è·¯å¾„",
    )
    parser.add_argument("--workers", type=int, default=4, help="å¹¶å‘æ•°")
    parser.add_argument(
        "--type",
        type=str,
        choices=["tick", "kline", "all"],
        default="tick",
        help="æ•°æ®ç±»å‹",
    )
    parser.add_argument(
        "--timeout", type=int, default=3600, help="ä¸‹è½½è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤3600ç§’/1å°æ—¶ï¼‰"
    )
    parser.add_argument("--gui", action="store_true", help="å¯ç”¨GUIè¿›åº¦çª—å£")

    args = parser.parse_args()

    print("=" * 60)
    print("ã€å…¨æ¯æ—¶é—´æœºå™¨æ•°æ®ä¸‹è½½å™¨ã€‘")
    print("=" * 60)

    # è§£ææ—¥æœŸåŒºé—´
    start_date = datetime.strptime(args.start_date, "%Y%m%d")
    end_date = datetime.strptime(args.end_date, "%Y%m%d")

    # ç”Ÿæˆæ—¥æœŸåˆ—è¡¨ï¼ˆåªä¿ç•™å·¥ä½œæ—¥ï¼‰
    dates = []
    current = start_date
    while current <= end_date:
        if current.weekday() < 5:  # å·¥ä½œæ—¥
            dates.append(current.strftime("%Y%m%d"))
        current += timedelta(days=1)

    logger.info(f"ã€æ—¥æœŸåŒºé—´ã€‘{dates[0]} ~ {dates[-1]} ({len(dates)} å¤©)")
    print(f"ğŸ“… æ—¥æœŸåŒºé—´: {dates[0]} ~ {dates[-1]} ({len(dates)} å¤©)")
    print(f"âš¡ è¶…æ—¶è®¾ç½®: {args.timeout} ç§’")

    # Step 1: è·å–ç²—ç­›è‚¡ç¥¨æ± 
    print("\nğŸ“Š Step 1: è·å–ç²—ç­›è‚¡ç¥¨æ± ...")
    stock_list = get_universe_for_dates(dates[:5])  # å–å‰5ä¸ªæ—¥æœŸçš„ç²—ç­›ç»“æœ

    if not stock_list:
        logger.error("ã€ç²—ç­›ã€‘æœªèƒ½è·å–ä»»ä½•è‚¡ç¥¨")
        print("âŒ ç²—ç­›å¤±è´¥ï¼Œæ— æ³•è·å–è‚¡ç¥¨æ± ")
        return

    print(f"âœ… ç²—ç­›å®Œæˆ: {len(stock_list)} åªè‚¡ç¥¨")
    logger.info(f"ã€ç²—ç­›å®Œæˆã€‘å…± {len(stock_list)} åªè‚¡ç¥¨")

    # ä¿å­˜è‚¡ç¥¨æ± 
    import json

    output_path = PROJECT_ROOT / args.output
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(
            {
                "dates": dates,
                "stocks": stock_list,
                "count": len(stock_list),
                "created_at": datetime.now().isoformat(),
            },
            f,
            ensure_ascii=False,
            indent=2,
        )
    print(f"ğŸ’¾ è‚¡ç¥¨æ± å·²ä¿å­˜: {output_path}")

    # Step 2: ä¸‹è½½Tickæ•°æ®
    print(f"\nğŸ“¥ Step 2: ä¸‹è½½Tickæ•°æ® ({len(stock_list)} åª Ã— {len(dates)} å¤©)...")

    if args.gui:
        # å¯åŠ¨GUIè¿›åº¦çª—å£
        root, progress_var, progress_label, update_queue = create_gui_progress()
        if root:
            import threading

            def download_with_progress():
                results = download_tick_batch(stock_list, dates, timeout=args.timeout)
                print("ä¸‹è½½å®Œæˆï¼")
                # è¿™é‡Œå¯ä»¥æ·»åŠ å®Œæˆåçš„å¤„ç†
                return results

            # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œä¸‹è½½
            download_thread = threading.Thread(target=download_with_progress)
            download_thread.daemon = True
            download_thread.start()

            # å¯åŠ¨GUIä¸»å¾ªç¯
            root.mainloop()
        else:
            # å¦‚æœGUIä¸å¯ç”¨ï¼Œä½¿ç”¨æ§åˆ¶å°è¿›åº¦
            results = download_tick_batch(stock_list, dates, timeout=args.timeout)
    else:
        # ä½¿ç”¨æ§åˆ¶å°è¿›åº¦
        results = download_tick_batch(stock_list, dates, timeout=args.timeout)

    # è¾“å‡ºç»“æœ
    print("\n" + "=" * 60)
    print("ã€ä¸‹è½½å®Œæˆã€‘")
    print(f"  æ€»ä»»åŠ¡: {results['total']}")
    print(f"  æˆåŠŸ: {results['success']}")
    print(f"  å¤±è´¥: {results['failed']}")
    print(f"  è·³è¿‡: {results['skipped']}")

    if results["errors"]:
        print(f"\né”™è¯¯åˆ—è¡¨ (å‰10æ¡):")
        for err in results["errors"][:10]:
            print(f"  - {err}")

    print("=" * 60)


if __name__ == "__main__":
    main()
