# -*- coding: utf-8 -*-
"""
å…¨æ¯æ—¶é—´æœºå™¨æ•°æ®ä¸‹è½½å™¨
æ‰¹é‡ä¸‹è½½12.24-01.05åŒºé—´æ‰€æœ‰ç²—ç­›è‚¡ç¥¨çš„Tickæ•°æ®

Author: é¡¹ç›®æ€»ç›‘
Date: 2026-02-23
"""
import os
import sys
import time
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from dotenv import load_dotenv
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(PROJECT_ROOT / 'logs' / 'download_holographic.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


def get_universe_for_dates(dates: List[str]) -> List[str]:
    """
    è·å–å¤šä¸ªæ—¥æœŸçš„ç²—ç­›è‚¡ç¥¨æ± å¹¶åˆå¹¶å»é‡

    CTOè§„èŒƒ: ç¬¬ä¸€å±‚ç²—ç­›å·²æ”¹ç”¨QMTçš„snapshotè¿›è¡Œå®æ—¶å¿«ç…§è¿‡æ»¤
    ä½†ä¸ºäº†æ•°æ®ä¸‹è½½å™¨çš„å…¼å®¹æ€§ï¼Œä¿æŒä½¿ç”¨Tushare daily_basicä½œä¸ºä¸»è¦ç²—ç­›æ–¹æ³•
    å› ä¸ºä¸‹è½½å™¨éœ€è¦åœ¨éäº¤æ˜“æ—¶é—´ä¹Ÿèƒ½è·å–å†å²è‚¡ç¥¨æ± ï¼ŒQMTå†å²æ•°æ®å¯èƒ½ä¸å¯ç”¨

    Args:
        dates: æ—¥æœŸåˆ—è¡¨ ['YYYYMMDD', ...]

    Returns:
        å»é‡åçš„è‚¡ç¥¨ä»£ç åˆ—è¡¨
    """
    from logic.data_providers.universe_builder import UniverseBuilder
    import random

    builder = UniverseBuilder()
    all_stocks = set()

    for date in dates:
        try:
            logger.info(f"ã€ç²—ç­›-å…¼å®¹æ¨¡å¼ã€‘{date} å¼€å§‹...")
            
            # ä½¿ç”¨Tushareä½œä¸ºä¸»è¦æ–¹æ³•ï¼Œå› ä¸ºå®ƒå¯ä»¥åœ¨éäº¤æ˜“æ—¶é—´è·å–å†å²æ•°æ®
            stocks = builder.get_daily_universe(date)
            
            # å¦‚æœTushareæ–¹æ³•å¤±è´¥æˆ–è¿”å›ç©ºåˆ—è¡¨ï¼Œä½œä¸ºå¤‡é€‰ä»QMTè·å–å…¨å¸‚åœºè‚¡ç¥¨çš„å­é›†
            if not stocks:
                logger.warning(f"ã€ç²—ç­›-å…¼å®¹æ¨¡å¼ã€‘{date} Tushareæ–¹æ³•è¿”å›ç©ºåˆ—è¡¨ï¼Œä½¿ç”¨QMTå¤‡é€‰æ–¹æ¡ˆ")
                from xtquant import xtdata
                
                all_stocks_list = xtdata.get_stock_list_in_sector('æ²ªæ·±Aè‚¡')
                if all_stocks_list:
                    # éšæœºé€‰æ‹©ä¸€éƒ¨åˆ†è‚¡ç¥¨ä½œä¸ºå¤‡é€‰ï¼Œç¡®ä¿æœ‰æ•°æ®å¯ä¸‹è½½
                    sample_size = min(100, len(all_stocks_list))
                    stocks = random.sample(all_stocks_list, sample_size)
                    logger.info(f"ã€ç²—ç­›-å…¼å®¹æ¨¡å¼ã€‘{date} QMTå¤‡é€‰æ–¹æ¡ˆè·å–åˆ° {len(stocks)} åªè‚¡ç¥¨")
                else:
                    logger.error(f"ã€ç²—ç­›-å…¼å®¹æ¨¡å¼ã€‘{date} QMTä¹Ÿæ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
                    continue
            
            all_stocks.update(stocks)
            logger.info(f"ã€ç²—ç­›-å…¼å®¹æ¨¡å¼ã€‘{date} è·å–åˆ° {len(stocks)} åªï¼Œç´¯è®¡ {len(all_stocks)} åª")
            
        except Exception as e:
            logger.error(f"ã€ç²—ç­›-å…¼å®¹æ¨¡å¼ã€‘{date} å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            continue

    return list(all_stocks)


def download_tick_batch(stock_list: List[str], dates: List[str]) -> Dict:
    """
    æ‰¹é‡ä¸‹è½½Tickæ•°æ®
    
    Args:
        stock_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        dates: æ—¥æœŸåˆ—è¡¨
    
    Returns:
        ä¸‹è½½ç»“æœç»Ÿè®¡
    """
    try:
        from xtquant import xtdata
    except ImportError:
        logger.error("xtquantæœªå®‰è£…")
        return {'error': 'xtquantæœªå®‰è£…'}
    
    results = {
        'total': len(stock_list) * len(dates),
        'success': 0,
        'failed': 0,
        'skipped': 0,
        'errors': []
    }
    
    # å¯åŠ¨VIPæœåŠ¡
    try:
        from xtquant import xtdatacenter as xtdc
        from logic.core.path_resolver import PathResolver
        
        vip_token = os.getenv('QMT_VIP_TOKEN', '')
        # ä»ç¯å¢ƒå˜é‡è·å–QMTè·¯å¾„
        data_dir = os.getenv('QMT_PATH', '')
        
        if not data_dir:
            # å¦‚æœç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œä½¿ç”¨PathResolverè·å–è·¯å¾„
            data_dir = str(PathResolver.get_qmt_data_dir())
        
        if vip_token:
            xtdc.set_data_home_dir(data_dir)
            xtdc.set_token(vip_token)
            xtdc.init()
            port = xtdc.listen(port=(58620, 58630))
            logger.info(f"ã€VIPæœåŠ¡ã€‘å·²å¯åŠ¨ï¼Œç«¯å£: {port}")
    except Exception as e:
        logger.warning(f"ã€VIPæœåŠ¡ã€‘å¯åŠ¨å¤±è´¥: {e}ï¼Œä½¿ç”¨æ™®é€šæ¨¡å¼")
    
    logger.info(f"ã€ä¸‹è½½ä»»åŠ¡ã€‘è‚¡ç¥¨: {len(stock_list)} åªï¼Œæ—¥æœŸ: {len(dates)} å¤©ï¼Œæ€»è®¡: {results['total']} ä¸ªä»»åŠ¡")
    
    start_date = dates[0]
    end_date = dates[-1]
    
    for i, stock in enumerate(stock_list, 1):
        try:
            # æ ‡å‡†åŒ–ä»£ç 
            if '.' not in stock:
                if stock.startswith('6'):
                    stock = f"{stock}.SH"
                else:
                    stock = f"{stock}.SZ"
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ®
            try:
                existing = xtdata.get_local_data(
                    field_list=['time'],
                    stock_list=[stock],
                    period='tick',
                    start_time=start_date,
                    end_time=end_date
                )
                
                if existing and stock in existing and len(existing[stock]) > 1000:
                    results['skipped'] += len(dates)
                    logger.debug(f"[{i}/{len(stock_list)}] {stock} å·²æœ‰æ•°æ®ï¼Œè·³è¿‡")
                    continue
            except:
                pass
            
            # ä¸‹è½½
            xtdata.download_history_data(
                stock_code=stock,
                period='tick',
                start_time=start_date,
                end_time=end_date
            )
            
            # éªŒè¯
            data = xtdata.get_local_data(
                field_list=['time'],
                stock_list=[stock],
                period='tick',
                start_time=start_date,
                end_time=end_date
            )
            
            if data and stock in data and len(data[stock]) > 100:
                results['success'] += len(dates)
                logger.info(f"[{i}/{len(stock_list)}] {stock} âœ… ({len(data[stock])} ticks)")
            else:
                results['failed'] += len(dates)
                logger.warning(f"[{i}/{len(stock_list)}] {stock} âŒ æ•°æ®ä¸è¶³")
                
        except Exception as e:
            results['failed'] += len(dates)
            error_msg = f"{stock}: {str(e)}"
            results['errors'].append(error_msg)
            logger.error(f"[{i}/{len(stock_list)}] {stock} âŒ {e}")
        
        # é—´éš”é¿å…é™æµ
        time.sleep(0.1)
    
    return results


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='å…¨æ¯æ—¶é—´æœºå™¨æ•°æ®ä¸‹è½½å™¨')
    parser.add_argument('--start-date', type=str, default='20251220', help='å¼€å§‹æ—¥æœŸ (YYYYMMDD)')
    parser.add_argument('--end-date', type=str, default='20260110', help='ç»“æŸæ—¥æœŸ (YYYYMMDD)')
    parser.add_argument('--output', type=str, default='data/holographic_universe.json', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--workers', type=int, default=4, help='å¹¶å‘æ•°')
    parser.add_argument('--type', type=str, choices=['tick', 'kline', 'all'], default='tick', help='æ•°æ®ç±»å‹')
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("ã€å…¨æ¯æ—¶é—´æœºå™¨æ•°æ®ä¸‹è½½å™¨ã€‘")
    print("=" * 60)
    
    # è§£ææ—¥æœŸåŒºé—´
    start_date = datetime.strptime(args.start_date, '%Y%m%d')
    end_date = datetime.strptime(args.end_date, '%Y%m%d')
    
    # ç”Ÿæˆæ—¥æœŸåˆ—è¡¨ï¼ˆåªä¿ç•™å·¥ä½œæ—¥ï¼‰
    dates = []
    current = start_date
    while current <= end_date:
        if current.weekday() < 5:  # å·¥ä½œæ—¥
            dates.append(current.strftime('%Y%m%d'))
        current += timedelta(days=1)
    
    logger.info(f"ã€æ—¥æœŸåŒºé—´ã€‘{dates[0]} ~ {dates[-1]} ({len(dates)} å¤©)")
    print(f"ğŸ“… æ—¥æœŸåŒºé—´: {dates[0]} ~ {dates[-1]} ({len(dates)} å¤©)")
    
    # Step 1: è·å–ç²—ç­›è‚¡ç¥¨æ± 
    print("\nğŸ“Š Step 1: è·å–ç²—ç­›è‚¡ç¥¨æ± ...")
    stock_list = get_universe_for_dates(dates[:5])  # å–å‰5ä¸ªæ—¥æœŸçš„ç²—ç­›ç»“æœ
    
    if not stock_list:
        logger.error("ã€ç²—ç­›ã€‘æœªèƒ½è·å–ä»»ä½•è‚¡ç¥¨")
        print("âŒ ç²—ç­›å¤±è´¥ï¼Œæ— æ³•è·å–è‚¡ç¥¨æ± ")
        return
    
    print(f"âœ… ç²—ç­›å®Œæˆ: {len(stock_list)} åªè‚¡ç¥¨")
    logger.info(f"ã€ç²—ç­›å®Œæˆã€‘å…± {len(stock_list)} åªè‚¡ç¥¨")
    
    # ä¿å­˜è‚¡ç¥¨æ± 
    import json
    output_path = PROJECT_ROOT / args.output
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump({
            'dates': dates,
            'stocks': stock_list,
            'count': len(stock_list),
            'created_at': datetime.now().isoformat()
        }, f, ensure_ascii=False, indent=2)
    print(f"ğŸ’¾ è‚¡ç¥¨æ± å·²ä¿å­˜: {output_path}")
    
    # Step 2: ä¸‹è½½Tickæ•°æ®
    print(f"\nğŸ“¥ Step 2: ä¸‹è½½Tickæ•°æ® ({len(stock_list)} åª Ã— {len(dates)} å¤©)...")
    results = download_tick_batch(stock_list, dates)
    
    # è¾“å‡ºç»“æœ
    print("\n" + "=" * 60)
    print("ã€ä¸‹è½½å®Œæˆã€‘")
    print(f"  æ€»ä»»åŠ¡: {results['total']}")
    print(f"  æˆåŠŸ: {results['success']}")
    print(f"  å¤±è´¥: {results['failed']}")
    print(f"  è·³è¿‡: {results['skipped']}")
    
    if results['errors']:
        print(f"\né”™è¯¯åˆ—è¡¨ (å‰10æ¡):")
        for err in results['errors'][:10]:
            print(f"  - {err}")
    
    print("=" * 60)


if __name__ == '__main__':
    main()
