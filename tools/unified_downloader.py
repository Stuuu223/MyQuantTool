#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€ä¸‹è½½å™¨ - All-in-One Data Downloader
æ”¯æŒæ—¥Kã€Tickã€å…¨æ¯æ•°æ®ä¸‹è½½ï¼Œæ–­ç‚¹ç»­ä¼ ï¼ŒRichè¿›åº¦æ¡

ç”¨æ³•:
    python tools/unified_downloader.py --type daily_k --days 365
    python tools/unified_downloader.py --type tick --start-date 20250101 --end-date 20260225
    python tools/unified_downloader.py --type holographic --date 20260224

Author: CTOé‡æ„
Date: 2026-02-25
"""

import os
import sys
import json
import time
import click
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# çŠ¶æ€æ–‡ä»¶è·¯å¾„
STATE_DIR = PROJECT_ROOT / "data"
STATE_DIR.mkdir(parents=True, exist_ok=True)


def get_state_file(download_type: str) -> Path:
    """è·å–çŠ¶æ€æ–‡ä»¶è·¯å¾„"""
    return STATE_DIR / f"download_state_{download_type}.json"


def load_state(download_type: str) -> Dict:
    """åŠ è½½æ–­ç‚¹çŠ¶æ€"""
    state_file = get_state_file(download_type)
    if state_file.exists():
        try:
            with open(state_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            pass
    return {"completed": [], "failed": [], "last_update": None}


def save_state(download_type: str, state: Dict):
    """ä¿å­˜æ–­ç‚¹çŠ¶æ€"""
    state_file = get_state_file(download_type)
    state["last_update"] = datetime.now().isoformat()
    with open(state_file, 'w', encoding='utf-8') as f:
        json.dump(state, f, ensure_ascii=False, indent=2)


def generate_dates(start_date: str, end_date: str) -> List[str]:
    """ç”Ÿæˆæ—¥æœŸåˆ—è¡¨ï¼ˆåªä¿ç•™å·¥ä½œæ—¥ï¼‰"""
    start = datetime.strptime(start_date, "%Y%m%d")
    end = datetime.strptime(end_date, "%Y%m%d")
    dates = []
    current = start
    while current <= end:
        if current.weekday() < 5:  # å·¥ä½œæ—¥
            dates.append(current.strftime("%Y%m%d"))
        current += timedelta(days=1)
    return dates


def get_last_n_trading_days(n: int = 60) -> tuple:
    """è·å–æœ€è¿‘Nä¸ªäº¤æ˜“æ—¥çš„èµ·æ­¢æ—¥æœŸ - CTOæŒ‡ä»¤ï¼šæ™ºèƒ½é»˜è®¤60å¤©é»„é‡‘å‘¨æœŸ
    
    Returns:
        (start_date, end_date) æ ¼å¼: YYYYMMDD
    """
    from xtquant import xtdata
    
    # è·å–ä»Šå¤©æ˜¯å‘¨å‡ ï¼Œè®¡ç®—å¾€å‰æ¨å¤šä¹…èƒ½æ‹¿åˆ°Nä¸ªäº¤æ˜“æ—¥
    # ä¿å®ˆä¼°è®¡ï¼šNä¸ªäº¤æ˜“æ—¥çº¦ç­‰äºN*7/5ä¸ªè‡ªç„¶æ—¥ï¼ˆè€ƒè™‘å‘¨æœ«ï¼‰
    search_days = int(n * 7 / 5) + 10  # åŠ 10å¤©ç¼“å†²
    
    end_date = datetime.now()
    start_search = end_date - timedelta(days=search_days)
    
    # ç”Ÿæˆå€™é€‰æ—¥æœŸï¼ˆå·¥ä½œæ—¥ï¼‰
    dates = []
    current = start_search
    while current <= end_date:
        if current.weekday() < 5:  # å‘¨ä¸€åˆ°å‘¨äº”
            dates.append(current.strftime("%Y%m%d"))
        current += timedelta(days=1)
    
    # å–æœ€åNä¸ª
    trading_days = dates[-n:] if len(dates) >= n else dates
    
    return trading_days[0], trading_days[-1], trading_days


def download_daily_k(days: int = 365, resume: bool = True):
    """ä¸‹è½½å…¨å¸‚åœºæ—¥Kæ•°æ®"""
    from xtquant import xtdata
    from rich.progress import Progress, BarColumn, TextColumn, TimeRemainingColumn
    from rich.console import Console
    
    console = Console()
    
    # è®¡ç®—æ—¥æœŸèŒƒå›´
    today = datetime.now()
    start_date = (today - timedelta(days=days)).strftime("%Y%m%d")
    end_date = today.strftime("%Y%m%d")
    
    console.print(f"\n[bold cyan]ğŸ“Š æ—¥Kæ•°æ®ä¸‹è½½å™¨[/bold cyan]")
    console.print(f"ğŸ“… æ—¥æœŸèŒƒå›´: {start_date} ~ {end_date} ({days}å¤©)")
    
    # åŠ è½½æ–­ç‚¹çŠ¶æ€
    state = load_state("daily_k") if resume else {"completed": [], "failed": []}
    completed_set = set(state.get("completed", []))
    
    # è·å–è‚¡ç¥¨åˆ—è¡¨
    all_stocks = xtdata.get_stock_list_in_sector('æ²ªæ·±Aè‚¡')
    console.print(f"ğŸ“ˆ è‚¡ç¥¨æ•°é‡: {len(all_stocks)} åª")
    
    # è¿‡æ»¤å·²å®Œæˆçš„
    pending_stocks = [s for s in all_stocks if s not in completed_set]
    console.print(f"â­ï¸  å¾…ä¸‹è½½: {len(pending_stocks)} åª (å·²å®Œæˆ: {len(completed_set)})")
    
    if not pending_stocks:
        console.print("[green]âœ… æ‰€æœ‰æ•°æ®å·²ä¸‹è½½å®Œæˆï¼[/green]")
        return
    
    # åˆ†æ‰¹ä¸‹è½½
    BATCH_SIZE = 500
    total_batches = (len(pending_stocks) + BATCH_SIZE - 1) // BATCH_SIZE
    
    success_count = len(completed_set)
    failed_count = len(state.get("failed", []))
    
    with Progress(
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
        TimeRemainingColumn(),
        console=console,
    ) as progress:
        task = progress.add_task("[cyan]ä¸‹è½½è¿›åº¦", total=len(pending_stocks))
        
        for i in range(0, len(pending_stocks), BATCH_SIZE):
            batch = pending_stocks[i:i+BATCH_SIZE]
            batch_num = i // BATCH_SIZE + 1
            
            try:
                xtdata.download_history_data2(
                    stock_list=batch,
                    period='1d',
                    start_time=start_date,
                    end_time=end_date
                )
                
                # ã€CTOä¿®å¤ã€‘æ‰¹æ¬¡é—´å¼ºåˆ¶ç­‰å¾…2ç§’ï¼Œè®©xtdataå†™å®Œç£ç›˜ï¼Œé¿å…STATUS_NO_MEMORY
                time.sleep(2)
                
                # æ ‡è®°å®Œæˆ
                for stock in batch:
                    state["completed"].append(stock)
                    completed_set.add(stock)
                
                success_count += len(batch)
                progress.update(task, advance=len(batch))
                
            except Exception as e:
                # ã€CTOä¿®å¤ã€‘å¼‚å¸¸æ—¶ç«‹å³åœæ­¢ï¼Œä¸å†ç»§ç»­ç¡¬è·‘å–‚æ­»è¿›ç¨‹
                console.print(f"[red]âŒ xtdataæœåŠ¡å¼‚å¸¸ï¼Œç«‹å³åœæ­¢: {e}[/red]")
                console.print("[red]âš ï¸ è¯·æ£€æŸ¥QMTå®¢æˆ·ç«¯çŠ¶æ€åé‡è¯•[/red]")
                save_state("daily_k", state)
                return
            
            # å®šæœŸä¿å­˜çŠ¶æ€
            if batch_num % 5 == 0:
                save_state("daily_k", state)
    
    # æœ€ç»ˆä¿å­˜çŠ¶æ€
    save_state("daily_k", state)
    
    console.print(f"\n[green]âœ… ä¸‹è½½å®Œæˆï¼[/green]")
    console.print(f"   æˆåŠŸ: {success_count} åª")
    console.print(f"   å¤±è´¥: {failed_count} åª")


def download_tick_data(start_date: str, end_date: str, stock_list: List[str] = None, resume: bool = True):
    """ä¸‹è½½Tickæ•°æ®"""
    from xtquant import xtdata
    from rich.progress import Progress, BarColumn, TextColumn, TimeRemainingColumn
    from rich.console import Console
    
    console = Console()
    
    console.print(f"\n[bold cyan]ğŸ“Š Tickæ•°æ®ä¸‹è½½å™¨[/bold cyan]")
    console.print(f"ğŸ“… æ—¥æœŸèŒƒå›´: {start_date} ~ {end_date}")
    
    # åŠ è½½æ–­ç‚¹çŠ¶æ€
    state_key = f"tick_{start_date}_{end_date}"
    state = load_state(state_key) if resume else {"completed": [], "failed": []}
    completed_set = set(state.get("completed", []))
    
    # è·å–è‚¡ç¥¨åˆ—è¡¨
    if not stock_list:
        stock_list = xtdata.get_stock_list_in_sector('æ²ªæ·±Aè‚¡')
    
    console.print(f"ğŸ“ˆ è‚¡ç¥¨æ•°é‡: {len(stock_list)} åª")
    
    # è¿‡æ»¤å·²å®Œæˆçš„
    pending_stocks = [s for s in stock_list if s not in completed_set]
    console.print(f"â­ï¸  å¾…ä¸‹è½½: {len(pending_stocks)} åª (å·²å®Œæˆ: {len(completed_set)})")
    
    if not pending_stocks:
        console.print("[green]âœ… æ‰€æœ‰æ•°æ®å·²ä¸‹è½½å®Œæˆï¼[/green]")
        return
    
    success_count = len(completed_set)
    failed_count = len(state.get("failed", []))
    
    with Progress(
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
        TimeRemainingColumn(),
        console=console,
    ) as progress:
        task = progress.add_task("[cyan]ä¸‹è½½è¿›åº¦", total=len(pending_stocks))
        
        for i, stock in enumerate(pending_stocks):
            try:
                # æ ‡å‡†åŒ–ä»£ç 
                if "." not in stock:
                    if stock.startswith("6"):
                        stock = f"{stock}.SH"
                    else:
                        stock = f"{stock}.SZ"
                
                # ä¸‹è½½
                xtdata.download_history_data(
                    stock_code=stock,
                    period="tick",
                    start_time=start_date,
                    end_time=end_date
                )
                
                # éªŒè¯
                data = xtdata.get_local_data(
                    field_list=["time"],
                    stock_list=[stock],
                    period="tick",
                    start_time=start_date,
                    end_time=end_date
                )
                
                if data and stock in data and len(data[stock]) > 100:
                    state["completed"].append(stock)
                    success_count += 1
                else:
                    state["failed"].append(stock)
                    failed_count += 1
                
            except Exception as e:
                state["failed"].append(stock)
                failed_count += 1
            
            progress.update(task, advance=1)
            
            # å®šæœŸä¿å­˜çŠ¶æ€
            if (i + 1) % 50 == 0:
                save_state(state_key, state)
            
            # é¿å…é™æµ
            time.sleep(0.1)
    
    # æœ€ç»ˆä¿å­˜çŠ¶æ€
    save_state(state_key, state)
    
    console.print(f"\n[green]âœ… ä¸‹è½½å®Œæˆï¼[/green]")
    console.print(f"   æˆåŠŸ: {success_count} åª")
    console.print(f"   å¤±è´¥: {failed_count} åª")


def start_vip_service():
    """å¯åŠ¨VIPæœåŠ¡ - CTOè¡¥å……ï¼šåŠ é€Ÿæ•°æ®ä¸‹è½½"""
    try:
        from xtquant import xtdatacenter as xtdc
        from logic.core.path_resolver import PathResolver
        
        vip_token = os.getenv("QMT_VIP_TOKEN", "")
        data_dir = os.getenv("QMT_PATH", "")
        
        if not data_dir:
            data_dir = str(PathResolver.get_qmt_data_dir())
        
        if vip_token:
            xtdc.set_data_home_dir(data_dir)
            xtdc.set_token(vip_token)
            xtdc.init()
            port = xtdc.listen(port=(58620, 58630))
            return True, port
        return False, None
    except Exception as e:
        return False, str(e)


def download_holographic(date: str, resume: bool = True, timeout: int = 3600):
    """ä¸‹è½½å…¨æ¯æ•°æ®ï¼ˆV18åŒRatioç­›é€‰åçš„è‚¡ç¥¨Tickï¼‰
    
    ç­›é€‰æ¡ä»¶ï¼ˆå¯¹é½å®ç›˜live_sniperå‚æ•°ï¼‰ï¼š
    - é‡æ¯”åˆ†ä½æ•°: 0.95
    - æ¢æ‰‹ç‡èŒƒå›´: 3% - 70%
    - å‰”é™¤: ç§‘åˆ›æ¿ã€åŒ—äº¤æ‰€
    
    æ–°å¢åŠŸèƒ½ï¼ˆCTOè¡¥å……ï¼‰ï¼š
    - VIPæœåŠ¡åŠ é€Ÿ
    - è¶…æ—¶æ§åˆ¶
    - é‡è¯•æœºåˆ¶
    - è·³è¿‡å·²æœ‰æ•°æ®
    """
    from xtquant import xtdata
    from rich.progress import Progress, BarColumn, TextColumn, TimeRemainingColumn
    from rich.console import Console
    from logic.core.config_manager import get_config_manager
    
    console = Console()
    config_manager = get_config_manager()
    
    # è·å–å®ç›˜å‚æ•°
    live_sniper_config = config_manager._config.get('live_sniper', {})
    volume_percentile = live_sniper_config.get('volume_ratio_percentile', 0.95)
    min_turnover = live_sniper_config.get('min_active_turnover_rate', 3.0)
    max_turnover = live_sniper_config.get('death_turnover_rate', 70.0)
    
    console.print(f"\n[bold cyan]ğŸ“Š å…¨æ¯æ•°æ®ä¸‹è½½å™¨ (V18åŒRatioç­›é€‰)[/bold cyan]")
    console.print(f"ğŸ“… ç›®æ ‡æ—¥æœŸ: {date}")
    console.print(f"ğŸ“ ç­›é€‰å‚æ•°:")
    console.print(f"   é‡æ¯”åˆ†ä½æ•°: {volume_percentile}")
    console.print(f"   æ¢æ‰‹ç‡èŒƒå›´: {min_turnover}% - {max_turnover}%")
    console.print(f"â±ï¸ è¶…æ—¶è®¾ç½®: {timeout}ç§’")
    
    # å¯åŠ¨VIPæœåŠ¡ - CTOè¡¥å……
    vip_started, vip_result = start_vip_service()
    if vip_started:
        console.print(f"[green]âœ… VIPæœåŠ¡å·²å¯åŠ¨ï¼Œç«¯å£: {vip_result}[/green]")
    else:
        console.print(f"[yellow]âš ï¸ VIPæœåŠ¡æœªå¯åŠ¨: {vip_result}[/yellow]")
    
    # åŠ è½½æ–­ç‚¹çŠ¶æ€
    state_key = f"holographic_{date}"
    state = load_state(state_key) if resume else {"completed": [], "failed": []}
    completed_set = set(state.get("completed", []))
    
    # è·å–ç²—ç­›è‚¡ç¥¨æ±  - CTOå¼ºåˆ¶ï¼šç¦æ­¢å›é€€åˆ°å…¨å¸‚åœº
    console.print("\nğŸ” æ‰§è¡ŒV18åŒRatioç²—ç­›...")
    try:
        from logic.data_providers.universe_builder import UniverseBuilder
        builder = UniverseBuilder()
        stock_list = builder.get_daily_universe(date)
        
        if not stock_list:
            console.print(f"[red]âŒ ç²—ç­›è¿”å›ç©ºè‚¡ç¥¨æ± ï¼Œå¯èƒ½æ˜¯éäº¤æ˜“æ—¥æˆ–æ•°æ®é—®é¢˜[/red]")
            console.print(f"[red]ğŸ’¡ æç¤º: çº¯è¡€QMTç²—ç­›æœªè·å–åˆ°ä»»ä½•æ•°æ®ï¼è¯·æ£€æŸ¥è¯¥æ—¥æœŸçš„æ—¥Kæ•°æ®æ˜¯å¦å·²å­˜åœ¨äºæœ¬åœ°ï¼[/red]")
            return
            
    except Exception as e:
        console.print(f"[red]âŒ ç²—ç­›å¤±è´¥: {e}[/red]")
        console.print(f"[yellow]ğŸ’¡ æç¤º: è¯·ç¡®ä¿QMTæœ¬åœ°æ•°æ®å·²ä¸‹è½½å®Œæ•´[/yellow]")
        return
    
    console.print(f"\nâœ… ç²—ç­›å®Œæˆ: {len(stock_list)} åªè‚¡ç¥¨")
    
    # ä¿å­˜è‚¡ç¥¨æ±  - CTOè¡¥å……
    universe_file = STATE_DIR / f"holographic_universe_{date}.json"
    with open(universe_file, 'w', encoding='utf-8') as f:
        json.dump({
            "date": date,
            "stocks": stock_list,
            "count": len(stock_list),
            "created_at": datetime.now().isoformat(),
            "params": {
                "volume_percentile": volume_percentile,
                "min_turnover": min_turnover,
                "max_turnover": max_turnover
            }
        }, f, ensure_ascii=False, indent=2)
    console.print(f"ğŸ’¾ è‚¡ç¥¨æ± å·²ä¿å­˜: {universe_file}")
    
    # è¿‡æ»¤å·²å®Œæˆçš„
    pending_stocks = [s for s in stock_list if s not in completed_set]
    console.print(f"â­ï¸  å¾…ä¸‹è½½: {len(pending_stocks)} åª (å·²å®Œæˆ: {len(completed_set)})")
    
    if not pending_stocks:
        console.print("[green]âœ… æ‰€æœ‰æ•°æ®å·²ä¸‹è½½å®Œæˆï¼[/green]")
        return
    
    success_count = len(completed_set)
    failed_count = len(state.get("failed", []))
    skipped_count = 0
    
    # è¶…æ—¶æ§åˆ¶
    start_time = time.time()
    
    with Progress(
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
        TimeRemainingColumn(),
        console=console,
    ) as progress:
        task = progress.add_task("[cyan]ä¸‹è½½è¿›åº¦", total=len(pending_stocks))
        
        for i, stock in enumerate(pending_stocks):
            # è¶…æ—¶æ£€æŸ¥
            if time.time() - start_time > timeout:
                console.print(f"\n[yellow]â° è¶…æ—¶ {timeout}ç§’ï¼Œä¿å­˜è¿›åº¦å¹¶é€€å‡º[/yellow]")
                break
            
            try:
                # æ ‡å‡†åŒ–ä»£ç 
                if "." not in stock:
                    if stock.startswith("6"):
                        stock = f"{stock}.SH"
                    else:
                        stock = f"{stock}.SZ"
                
                # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ® - CTOè¡¥å……ï¼šè·³è¿‡å·²ä¸‹è½½
                try:
                    existing = xtdata.get_local_data(
                        field_list=["time"],
                        stock_list=[stock],
                        period="tick",
                        start_time=date,
                        end_time=date
                    )
                    if existing and stock in existing and len(existing[stock]) > 1000:
                        state["completed"].append(stock)
                        completed_set.add(stock)
                        skipped_count += 1
                        progress.update(task, advance=1)
                        continue
                except:
                    pass
                
                # ä¸‹è½½
                download_success = False
                for retry in range(2):  # CTOè¡¥å……ï¼šé‡è¯•æœºåˆ¶
                    try:
                        xtdata.download_history_data(
                            stock_code=stock,
                            period="tick",
                            start_time=date,
                            end_time=date
                        )
                        
                        # éªŒè¯
                        data = xtdata.get_local_data(
                            field_list=["time"],
                            stock_list=[stock],
                            period="tick",
                            start_time=date,
                            end_time=date
                        )
                        
                        if data and stock in data and len(data[stock]) > 100:
                            download_success = True
                            break
                        elif retry == 0:
                            time.sleep(1)  # é‡è¯•å‰ç­‰å¾…
                    except Exception as e:
                        if retry == 0:
                            time.sleep(1)
                
                if download_success:
                    state["completed"].append(stock)
                    success_count += 1
                else:
                    state["failed"].append(stock)
                    failed_count += 1
                
            except Exception as e:
                state["failed"].append(stock)
                failed_count += 1
            
            progress.update(task, advance=1)
            
            # å®šæœŸä¿å­˜çŠ¶æ€
            if (i + 1) % 20 == 0:
                save_state(state_key, state)
            
            # é¿å…é™æµ
            time.sleep(0.1)
    
    # æœ€ç»ˆä¿å­˜çŠ¶æ€
    save_state(state_key, state)
    
    console.print(f"\n[green]âœ… ä¸‹è½½å®Œæˆï¼[/green]")
    console.print(f"   æˆåŠŸ: {success_count} åª")
    console.print(f"   å¤±è´¥: {failed_count} åª")
    console.print(f"   è·³è¿‡: {skipped_count} åª")


def download_holographic_range(start_date: str, end_date: str, resume: bool = True, timeout: int = 3600):
    """æ—¥æœŸèŒƒå›´å…¨æ¯æ•°æ®ä¸‹è½½ - CTOå¯¹é½é›†å¤§æˆç³»ç»Ÿ
    
    éå†æ¯ä¸ªäº¤æ˜“æ—¥ï¼Œæ‰§è¡ŒV18ç­›é€‰åä¸‹è½½tickæ•°æ®
    
    ç”¨æ³•:
        python tools/unified_downloader.py --type holographic --start-date 20250101 --end-date 20260225
    """
    from xtquant import xtdata
    from rich.console import Console
    from logic.core.config_manager import get_config_manager
    
    console = Console()
    config_manager = get_config_manager()
    
    # è·å–å®ç›˜å‚æ•°
    live_sniper_config = config_manager._config.get('live_sniper', {})
    volume_percentile = live_sniper_config.get('volume_ratio_percentile', 0.95)
    min_turnover = live_sniper_config.get('min_active_turnover_rate', 3.0)
    max_turnover = live_sniper_config.get('death_turnover_rate', 70.0)
    
    # ç”Ÿæˆäº¤æ˜“æ—¥åˆ—è¡¨
    dates = generate_dates(start_date, end_date)
    
    console.print(f"\n[bold cyan]ğŸ“Š å…¨æ¯æ•°æ®æ‰¹é‡ä¸‹è½½å™¨ (æ—¥æœŸèŒƒå›´)[/bold cyan]")
    console.print(f"ğŸ“… æ—¥æœŸèŒƒå›´: {start_date} ~ {end_date}")
    console.print(f"ğŸ“… äº¤æ˜“æ—¥æ•°: {len(dates)} å¤©")
    console.print(f"ğŸ“ ç­›é€‰å‚æ•°: é‡æ¯”åˆ†ä½æ•°={volume_percentile}, æ¢æ‰‹ç‡={min_turnover}%-{max_turnover}%")
    console.print(f"â±ï¸ æ¯æ—¥è¶…æ—¶: {timeout}ç§’")
    
    # å¯åŠ¨VIPæœåŠ¡
    vip_started, vip_result = start_vip_service()
    if vip_started:
        console.print(f"[green]âœ… VIPæœåŠ¡å·²å¯åŠ¨ï¼Œç«¯å£: {vip_result}[/green]")
    else:
        console.print(f"[yellow]âš ï¸ VIPæœåŠ¡æœªå¯åŠ¨: {vip_result}[/yellow]")
    
    # ç»Ÿè®¡
    total_stats = {
        "total_days": len(dates),
        "success_days": 0,
        "skip_days": 0,
        "error_days": 0,
        "total_stocks": 0,
        "total_downloaded": 0,
        "total_skipped": 0
    }
    
    # éå†æ¯ä¸ªäº¤æ˜“æ—¥
    for i, date in enumerate(dates, 1):
        console.print(f"\n[bold]â”â”â” [{i}/{len(dates)}] {date} â”â”â”[/bold]")
        
        try:
            # è·å–ç²—ç­›è‚¡ç¥¨æ± 
            from logic.data_providers.universe_builder import UniverseBuilder
            builder = UniverseBuilder()
            stock_list = builder.get_daily_universe(date)
            
            if not stock_list:
                console.print(f"[yellow]â­ï¸  {date} æ— ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨ï¼ˆå¯èƒ½æ˜¯éäº¤æ˜“æ—¥ï¼‰[/yellow]")
                total_stats["skip_days"] += 1
                continue
            
            console.print(f"ğŸ“Š ç²—ç­›è‚¡ç¥¨æ•°: {len(stock_list)} åª")
            total_stats["total_stocks"] += len(stock_list)
            
            # åŠ è½½å½“æ—¥æ–­ç‚¹çŠ¶æ€
            state_key = f"holographic_{date}"
            state = load_state(state_key) if resume else {"completed": [], "failed": []}
            completed_set = set(state.get("completed", []))
            
            # è¿‡æ»¤å·²å®Œæˆçš„
            pending_stocks = [s for s in stock_list if s not in completed_set]
            
            if not pending_stocks:
                console.print(f"[green]âœ… {date} æ‰€æœ‰æ•°æ®å·²ä¸‹è½½ï¼Œè·³è¿‡[/green]")
                total_stats["skip_days"] += 1
                total_stats["total_skipped"] += len(stock_list)
                continue
            
            console.print(f"â­ï¸  å¾…ä¸‹è½½: {len(pending_stocks)} åª")
            
            # ä¸‹è½½å½“æ—¥tick
            day_start = time.time()
            day_success = 0
            day_skip = 0
            day_failed = 0
            
            for stock in pending_stocks:
                # è¶…æ—¶æ£€æŸ¥
                if time.time() - day_start > timeout:
                    console.print(f"[yellow]â° {date} è¶…æ—¶ï¼Œä¿å­˜è¿›åº¦[/yellow]")
                    break
                
                try:
                    # æ ‡å‡†åŒ–ä»£ç 
                    if "." not in stock:
                        if stock.startswith("6"):
                            stock = f"{stock}.SH"
                        else:
                            stock = f"{stock}.SZ"
                    
                    # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ®
                    try:
                        existing = xtdata.get_local_data(
                            field_list=["time"],
                            stock_list=[stock],
                            period="tick",
                            start_time=date,
                            end_time=date
                        )
                        if existing and stock in existing and len(existing[stock]) > 1000:
                            state["completed"].append(stock)
                            day_skip += 1
                            continue
                    except:
                        pass
                    
                    # ä¸‹è½½
                    download_success = False
                    for retry in range(2):
                        try:
                            xtdata.download_history_data(
                                stock_code=stock,
                                period="tick",
                                start_time=date,
                                end_time=date
                            )
                            
                            # éªŒè¯
                            data = xtdata.get_local_data(
                                field_list=["time"],
                                stock_list=[stock],
                                period="tick",
                                start_time=date,
                                end_time=date
                            )
                            
                            if data and stock in data and len(data[stock]) > 100:
                                download_success = True
                                break
                        except:
                            time.sleep(0.5)
                    
                    if download_success:
                        state["completed"].append(stock)
                        day_success += 1
                    else:
                        state["failed"].append(stock)
                        day_failed += 1
                    
                except Exception as e:
                    state["failed"].append(stock)
                    day_failed += 1
                
                time.sleep(0.05)
            
            # ä¿å­˜çŠ¶æ€
            save_state(state_key, state)
            
            total_stats["success_days"] += 1
            total_stats["total_downloaded"] += day_success
            total_stats["total_skipped"] += day_skip
            
            console.print(f"âœ… {date} å®Œæˆ: ä¸‹è½½{day_success}åª, è·³è¿‡{day_skip}åª, å¤±è´¥{day_failed}åª")
            
        except Exception as e:
            console.print(f"[red]âŒ {date} å¤„ç†å¤±è´¥: {e}[/red]")
            total_stats["error_days"] += 1
    
    # æ±‡æ€»æŠ¥å‘Š
    console.print(f"\n{'='*60}")
    console.print(f"[bold green]ğŸ“Š å…¨æ¯æ•°æ®æ‰¹é‡ä¸‹è½½å®Œæˆ[/bold green]")
    console.print(f"{'='*60}")
    console.print(f"ğŸ“… æ€»äº¤æ˜“æ—¥: {total_stats['total_days']} å¤©")
    console.print(f"âœ… æˆåŠŸå¤©æ•°: {total_stats['success_days']} å¤©")
    console.print(f"â­ï¸  è·³è¿‡å¤©æ•°: {total_stats['skip_days']} å¤©")
    console.print(f"âŒ é”™è¯¯å¤©æ•°: {total_stats['error_days']} å¤©")
    console.print(f"ğŸ“Š ç´¯è®¡è‚¡ç¥¨: {total_stats['total_stocks']} åª")
    console.print(f"ğŸ“¥ ç´¯è®¡ä¸‹è½½: {total_stats['total_downloaded']} åª")
    console.print(f"â­ï¸  ç´¯è®¡è·³è¿‡: {total_stats['total_skipped']} åª")
    console.print(f"{'='*60}")


@click.command()
@click.option('--type', 'download_type', 
              type=click.Choice(['daily_k', 'tick', 'holographic']),
              default='daily_k',
              help='ä¸‹è½½ç±»å‹: daily_k=æ—¥K, tick=Tickæ•°æ®, holographic=å…¨æ¯æ•°æ®')
@click.option('--start-date', default=None, help='å¼€å§‹æ—¥æœŸ (YYYYMMDD)')
@click.option('--end-date', default=None, help='ç»“æŸæ—¥æœŸ (YYYYMMDD)')
@click.option('--date', default=None, help='å•æ—¥æ—¥æœŸ (YYYYMMDD)ï¼Œç”¨äºå…¨æ¯ä¸‹è½½')
@click.option('--days', default=365, type=int, help='ä¸‹è½½å¤©æ•° (ç”¨äºæ—¥Kï¼Œé»˜è®¤365å¤©)')
@click.option('--timeout', default=3600, type=int, help='ä¸‹è½½è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤3600ç§’/1å°æ—¶ï¼‰')
@click.option('--no-resume', is_flag=True, help='ç¦ç”¨æ–­ç‚¹ç»­ä¼ ï¼Œä»å¤´å¼€å§‹')
def main(download_type, start_date, end_date, date, days, timeout, no_resume):
    """
    ç»Ÿä¸€ä¸‹è½½å™¨ - All-in-One Data Downloader
    
    ç”¨æ³•ç¤ºä¾‹:
        python tools/unified_downloader.py --type daily_k --days 365
        python tools/unified_downloader.py --type tick --start-date 20250101 --end-date 20260225
        python tools/unified_downloader.py --type holographic --date 20260224
        python tools/unified_downloader.py --type holographic --start-date 20250101 --end-date 20260225
        python tools/unified_downloader.py --type holographic  # æ™ºèƒ½é»˜è®¤æœ€è¿‘60ä¸ªäº¤æ˜“æ—¥
    
    CTOæˆ˜ç•¥è¯´æ˜:
        å…¨æ¯æ•°æ®é»˜è®¤ä¸‹è½½æœ€è¿‘60ä¸ªäº¤æ˜“æ—¥ - è¿™æ˜¯è¶…çŸ­çº¿ç­–ç•¥çš„é»„é‡‘å›æµ‹å‘¨æœŸ
        æ¶µç›–å½“ä¸‹å¸‚åœºæœ€æ ¸å¿ƒçš„æƒ…ç»ªå‘¨æœŸï¼ˆå†°ç‚¹->é«˜æ½®->é€€æ½®çš„å®Œæ•´è½®å›ï¼‰
        æ•°æ®é‡é€‚ä¸­(~10-20GB)ï¼Œä¸‹è½½æ—¶é—´å¯æ§(1-2å°æ—¶)ï¼Œæ ·æœ¬æœ‰æ•ˆæ€§æœ€ä½³
    """
    resume = not no_resume
    
    click.echo("=" * 60)
    click.echo("ğŸ“Š ç»Ÿä¸€ä¸‹è½½å™¨ - All-in-One Data Downloader")
    click.echo("=" * 60)
    
    if download_type == 'daily_k':
        download_daily_k(days=days, resume=resume)
    
    elif download_type == 'tick':
        if not start_date or not end_date:
            click.echo("âŒ Tickä¸‹è½½éœ€è¦æŒ‡å®š --start-date å’Œ --end-date")
            return
        download_tick_data(start_date, end_date, resume=resume)
    
    elif download_type == 'holographic':
        if start_date and end_date:
            # æ—¥æœŸèŒƒå›´å…¨æ¯ä¸‹è½½
            download_holographic_range(start_date, end_date, resume=resume, timeout=timeout)
        elif date:
            # å•æ—¥å…¨æ¯ä¸‹è½½
            download_holographic(date, resume=resume, timeout=timeout)
        else:
            # CTOæŒ‡ä»¤ï¼šæ™ºèƒ½é»˜è®¤æœ€è¿‘60ä¸ªäº¤æ˜“æ—¥ï¼ˆé»„é‡‘å›æµ‹å‘¨æœŸï¼‰
            click.echo("ğŸ’¡ æœªæŒ‡å®šæ—¥æœŸï¼ŒåŸºäºè¶…çŸ­çº¿ç³»ç»Ÿç‰¹æ€§ï¼Œè‡ªåŠ¨è®¾å®šä¸ºã€æœ€è¿‘60ä¸ªäº¤æ˜“æ—¥ã€‘çš„é»„é‡‘å›æµ‹å‘¨æœŸ...")
            start_date, end_date, trading_days = get_last_n_trading_days(60)
            click.echo(f"ğŸ“… è‡ªåŠ¨è®¡ç®—æ—¥æœŸèŒƒå›´: {start_date} ~ {end_date} (å…±{len(trading_days)}ä¸ªäº¤æ˜“æ—¥)")
            download_holographic_range(start_date, end_date, resume=resume, timeout=timeout)


# =============================================================================
# V20.0 å…¨æ¯ä¸‹è½½å™¨ - ä¸Šä¸‹æ–‡åˆ‡ç‰‡ä¸é¶å‘ä¸‹è½½ (CTO Phase A2)
# =============================================================================

class HolographicDownloaderV20:
    """
    V20æè‡´å…¨æ¯ä¸‹è½½å™¨ - ä¸Šä¸‹æ–‡åˆ‡ç‰‡ä¸é¶å‘ä¸‹è½½
    
    æ ¸å¿ƒåŠŸèƒ½:
    1. é•œåƒé™ç»´è¿‡æ»¤: é‡æ¯”0.90åˆ†ä½ + 3.0%æ¢æ‰‹ + high>pre_close
    2. ä¸Šä¸‹æ–‡åˆ‡ç‰‡ä¸‹è½½: å‰30å30å¤©(å…±60ä¸ªäº¤æ˜“æ—¥)
    3. ä¸‹è½½æ³¨å†Œè¡¨: é¿å…é‡å¤I/O
    4. target_poolè®°å½•: ç”ŸæˆJSONé”™é¢˜æœ¬
    
    ä¸¥ç¦: Magic Numberã€Tushareã€Forå¾ªç¯éå†
    """
    
    def __init__(self):
        self.config = get_config_manager()
        self.qmt_manager = QmtDataManager()
        self.registry_file = PathResolver.get_data_dir() / 'holographic_download_registry.json'
        self.registry = self._load_registry()
        
    def _load_registry(self) -> Dict:
        """åŠ è½½ä¸‹è½½æ³¨å†Œè¡¨"""
        if self.registry_file.exists():
            with open(self.registry_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    
    def _save_registry(self):
        """ä¿å­˜ä¸‹è½½æ³¨å†Œè¡¨"""
        with open(self.registry_file, 'w', encoding='utf-8') as f:
            json.dump(self.registry, f, ensure_ascii=False, indent=2)
    
    def calculate_download_candidates(self, date: str) -> List[Dict]:
        """
        è®¡ç®—å½“æ—¥éœ€è¦ä¸‹è½½çš„è‚¡ç¥¨åˆ—è¡¨ - é•œåƒé™ç»´è¿‡æ»¤
        
        Returns:
            List[Dict]: è‚¡ç¥¨ä¿¡æ¯åˆ—è¡¨ï¼Œæ¯åªåŒ…å«code/volume_ratio/turnover/max_change
        """
        console = Console()
        console.print(f"\n[bold cyan]ğŸ“Š V20å…¨æ¯ä¸‹è½½å™¨ - è®¡ç®— {date} å€™é€‰è‚¡ç¥¨[/bold cyan]")
        
        # ä»ConfigManagerè¯»å–é…ç½® (ä¸¥ç¦Magic Number!)
        hd_config = self.config.get('holographic_download', {})
        volume_ratio_download = hd_config.get('volume_ratio_download', 0.90)
        min_turnover_rate = hd_config.get('min_turnover_rate', 3.0)
        price_condition = hd_config.get('price_condition', 'high > pre_close')
        
        # 1. åŠ è½½å½“æ—¥å…¨å¸‚åœºæ—¥Kæ•°æ®
        console.print("   åŠ è½½æ—¥Kæ•°æ®...")
        all_stocks = self._get_full_universe()
        daily_k_data = self._load_daily_k_data(all_stocks, date)
        
        if daily_k_data.empty:
            console.print("[red]   æœªè·å–åˆ°æ—¥Kæ•°æ®[/red]")
            return []
        
        # 2. è®¡ç®—é‡æ¯” (å‘é‡åŒ–ï¼Œä¸¥ç¦Forå¾ªç¯!)
        console.print("   è®¡ç®—é‡æ¯”...")
        daily_k_data['volume_ratio'] = daily_k_data.apply(
            lambda row: row['volume'] / row['ma5_volume'] if row['ma5_volume'] > 0 else 0,
            axis=1
        )
        
        # 3. è®¡ç®—æ¢æ‰‹ç‡
        daily_k_data['turnover_rate'] = daily_k_data.apply(
            lambda row: (row['volume'] / row['float_volume'] * 100) if row['float_volume'] > 0 else 0,
            axis=1
        )
        
        # 4. è®¡ç®—æœ€é«˜ä»·æ¶¨å¹… (high > pre_close)
        daily_k_data['max_change_pct'] = daily_k_data.apply(
            lambda row: (row['high'] - row['pre_close']) / row['pre_close'] * 100 if row['pre_close'] > 0 else 0,
            axis=1
        )
        
        # 5. å‘é‡åŒ–ç­›é€‰ (ä¸¥ç¦Forå¾ªç¯éå†!)
        console.print("   æ‰§è¡Œé•œåƒé™ç»´è¿‡æ»¤...")
        
        # é‡æ¯” >= 0.90åˆ†ä½ (åŠ¨æ€è®¡ç®—)
        volume_ratio_threshold = daily_k_data['volume_ratio'].quantile(volume_ratio_download)
        volume_ratio_threshold = max(volume_ratio_threshold, 1.5)  # æœ€å°ä¿æŠ¤é˜ˆå€¼
        
        # ä¸‰æ¡ä»¶ç­›é€‰ (å‘é‡åŒ–å¸ƒå°”ç´¢å¼•)
        mask = (
            (daily_k_data['volume_ratio'] >= volume_ratio_threshold) &      # é‡æ¯”æ¡ä»¶
            (daily_k_data['turnover_rate'] >= min_turnover_rate) &          # æ¢æ‰‹æ¡ä»¶
            (daily_k_data['max_change_pct'] > 0)                             # high > pre_close
        )
        
        candidates = daily_k_data[mask].copy()
        
        # 6. æ„å»ºç»“æœ
        results = []
        for _, row in candidates.iterrows():
            results.append({
                'code': row['stock_code'],
                'volume_ratio': round(row['volume_ratio'], 2),
                'turnover': round(row['turnover_rate'], 2),
                'max_change': round(row['max_change_pct'], 2),
                'volume': int(row['volume']),
                'float_volume': int(row['float_volume']) if row['float_volume'] > 0 else 0
            })
        
        console.print(f"[green]   âœ… ç­›é€‰å®Œæˆ: {len(results)} åªè‚¡ç¥¨ç¬¦åˆæ¡ä»¶[/green]")
        console.print(f"   ğŸ“Š é‡æ¯”é˜ˆå€¼: {volume_ratio_threshold:.2f}, æ¢æ‰‹é˜ˆå€¼: {min_turnover_rate}%")
        
        return results
    
    def download_holographic_context(self, stock_code: str, trigger_dates: List[str]):
        """
        ä¸‹è½½è‚¡ç¥¨çš„ä¸Šä¸‹æ–‡Tickæ•°æ® - å‰30å30å¤©
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            trigger_dates: è§¦å‘æ—¥æœŸåˆ—è¡¨
        """
        console = Console()
        
        # è®¡ç®—æ—¥æœŸèŒƒå›´
        from datetime import datetime, timedelta
        
        min_trigger = min(trigger_dates)
        max_trigger = max(trigger_dates)
        
        # å¾€å‰æ¨30ä¸ªäº¤æ˜“æ—¥ï¼Œå¾€åæ¨30ä¸ªäº¤æ˜“æ—¥
        start_date = self._get_trade_date_offset(min_trigger, -30)
        end_date = self._get_trade_date_offset(max_trigger, 30)
        
        console.print(f"   {stock_code}: ä¸‹è½½åŒºé—´ {start_date} ~ {end_date}")
        
        # æ£€æŸ¥æ³¨å†Œè¡¨ï¼Œè¿‡æ»¤å·²ä¸‹è½½çš„æ—¥æœŸ
        already_downloaded = self.registry.get(stock_code, [])
        all_dates = self._get_trade_dates_between(start_date, end_date)
        dates_to_download = [d for d in all_dates if d not in already_downloaded]
        
        if not dates_to_download:
            console.print(f"   â­ï¸  {stock_code} æ‰€æœ‰æ•°æ®å·²ä¸‹è½½ï¼Œè·³è¿‡")
            return
        
        console.print(f"   ğŸ“¥ éœ€ä¸‹è½½ {len(dates_to_download)} å¤©ï¼Œå·²å­˜åœ¨ {len(already_downloaded)} å¤©")
        
        # ä¸‹è½½Tickæ•°æ®
        success_dates = []
        for date in dates_to_download:
            try:
                # è°ƒç”¨QMTä¸‹è½½
                self.qmt_manager.download_tick_data([stock_code], date)
                success_dates.append(date)
                time.sleep(0.1)  # é¿å…é™æµ
            except Exception as e:
                console.print(f"   [red]âŒ {stock_code} {date} ä¸‹è½½å¤±è´¥: {e}[/red]")
        
        # æ›´æ–°æ³¨å†Œè¡¨
        if stock_code not in self.registry:
            self.registry[stock_code] = []
        self.registry[stock_code].extend(success_dates)
        self._save_registry()
        
        console.print(f"   [green]âœ… {stock_code} æˆåŠŸä¸‹è½½ {len(success_dates)} å¤©[/green]")
    
    def generate_target_pool(self, date: str, candidates: List[Dict]):
        """
        ç”Ÿæˆtarget_poolè®°å½•æ–‡ä»¶
        
        Args:
            date: æ—¥æœŸ
            candidates: å€™é€‰è‚¡ç¥¨åˆ—è¡¨
        """
        hd_config = self.config.get('holographic_download', {})
        
        target_pool = {
            'date': date,
            'filter_criteria': {
                'volume_ratio_percentile': hd_config.get('volume_ratio_download', 0.90),
                'turnover_threshold': hd_config.get('min_turnover_rate', 3.0),
                'price_condition': hd_config.get('price_condition', 'high > pre_close'),
                'context_days': hd_config.get('context_days_total', 60)
            },
            'target_stocks': candidates,
            'statistics': {
                'total_scanned': 5191,  # å…¨å¸‚åœº
                'selected': len(candidates),
                'selection_rate': f"{len(candidates)/5191*100:.2f}%"
            }
        }
        
        output_file = PathResolver.get_data_dir() / f'holographic_target_{date}.json'
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(target_pool, f, ensure_ascii=False, indent=2)
        
        console = Console()
        console.print(f"[green]   ğŸ“ å·²ç”Ÿæˆç›®æ ‡æ± è®°å½•: {output_file}[/green]")
    
    def run_v20_download(self, date: str):
        """
        V20å…¨æ¯ä¸‹è½½ä¸»å…¥å£
        
        Args:
            date: æ—¥æœŸ 'YYYYMMDD'
        """
        console = Console()
        console.print(f"\n[bold green]={'='*60}[/bold green]")
        console.print(f"[bold green]ğŸš€ V20æè‡´å…¨æ¯ä¸‹è½½å™¨å¯åŠ¨[/bold green]")
        console.print(f"[bold green]   æ—¥æœŸ: {date}[/bold green]")
        console.print(f"[bold green]={'='*60}[/bold green]\n")
        
        # Step 1: è®¡ç®—å€™é€‰è‚¡ç¥¨
        candidates = self.calculate_download_candidates(date)
        
        if not candidates:
            console.print("[yellow]âš ï¸  ä»Šæ—¥æ— ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨[/yellow]")
            return
        
        # Step 2: ç”Ÿæˆtarget_poolè®°å½•
        self.generate_target_pool(date, candidates)
        
        # Step 3: ä¸‹è½½ä¸Šä¸‹æ–‡Tickæ•°æ®
        console.print(f"\n[bold]ğŸ“¥ å¼€å§‹ä¸‹è½½ä¸Šä¸‹æ–‡Tickæ•°æ®...[/bold]")
        
        stock_codes = [c['code'] for c in candidates]
        trigger_dates = [date]  # å½“å‰æ—¥æœŸä½œä¸ºè§¦å‘æ—¥æœŸ
        
        for i, stock_code in enumerate(stock_codes, 1):
            console.print(f"\n[{i}/{len(stock_codes)}] {stock_code}")
            try:
                self.download_holographic_context(stock_code, trigger_dates)
            except Exception as e:
                console.print(f"[red]   ä¸‹è½½å¼‚å¸¸: {e}[/red]")
        
        console.print(f"\n[bold green]âœ… V20å…¨æ¯ä¸‹è½½å®Œæˆï¼[/bold green]")
        console.print(f"[green]   å€™é€‰è‚¡ç¥¨: {len(candidates)} åª[/green]")
        console.print(f"[green]   ä¸‹è½½æ³¨å†Œè¡¨: {self.registry_file}[/green]")
    
    def _get_full_universe(self) -> List[str]:
        """è·å–å…¨å¸‚åœºè‚¡ç¥¨åˆ—è¡¨"""
        try:
            from xtquant import xtdata
            return xtdata.get_stock_list_in_sector('æ²ªæ·±Aè‚¡')
        except:
            return []
    
    def _load_daily_k_data(self, stock_list: List[str], date: str) -> pd.DataFrame:
        """åŠ è½½æ—¥Kæ•°æ®"""
        try:
            from xtquant import xtdata
            
            # è·å–å‰5å¤©çš„æ•°æ®è®¡ç®—MA5
            end_date = date
            start_date = (datetime.strptime(date, '%Y%m%d') - timedelta(days=10)).strftime('%Y%m%d')
            
            data = xtdata.get_local_data(
                field_list=['time', 'open', 'high', 'low', 'close', 'volume', 'amount'],
                stock_list=stock_list,
                period='1d',
                start_time=start_date,
                end_time=end_date
            )
            
            rows = []
            for stock_code, df in data.items():
                if df is not None and not df.empty:
                    latest = df.iloc[-1]
                    # è®¡ç®—MA5
                    ma5 = df['volume'].tail(5).mean() if len(df) >= 5 else df['volume'].mean()
                    # è·å–æ˜¨æ”¶
                    pre_close = df.iloc[-2]['close'] if len(df) >= 2 else latest['open']
                    # è·å–æµé€šè‚¡æœ¬
                    float_volume = self._get_float_volume(stock_code)
                    
                    rows.append({
                        'stock_code': stock_code,
                        'open': latest['open'],
                        'high': latest['high'],
                        'low': latest['low'],
                        'close': latest['close'],
                        'volume': latest['volume'],
                        'ma5_volume': ma5,
                        'pre_close': pre_close,
                        'float_volume': float_volume
                    })
            
            return pd.DataFrame(rows)
        except Exception as e:
            logger.error(f"åŠ è½½æ—¥Kæ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def _get_float_volume(self, stock_code: str) -> float:
        """è·å–æµé€šè‚¡æœ¬"""
        try:
            from xtquant import xtdata
            detail = xtdata.get_instrument_detail(stock_code, True)
            if detail:
                return float(detail.get('FloatVolume', 0)) if hasattr(detail, 'get') else float(getattr(detail, 'FloatVolume', 0))
        except:
            pass
        return 0
    
    def _get_trade_date_offset(self, date: str, offset: int) -> str:
        """è·å–åç§»åçš„äº¤æ˜“æ—¥"""
        # ç®€åŒ–å®ç°ï¼šæŒ‰è‡ªç„¶æ—¥åç§»ï¼Œå®é™…åº”ä½¿ç”¨äº¤æ˜“æ—¥å†
        current = datetime.strptime(date, '%Y%m%d')
        offset_days = offset * 7 // 5  # ç²—ç•¥ä¼°è®¡
        result = current + timedelta(days=offset_days)
        return result.strftime('%Y%m%d')
    
    def _get_trade_dates_between(self, start: str, end: str) -> List[str]:
        """è·å–æ—¥æœŸèŒƒå›´å†…çš„æ‰€æœ‰æ—¥æœŸ"""
        dates = []
        current = datetime.strptime(start, '%Y%m%d')
        end_dt = datetime.strptime(end, '%Y%m%d')
        while current <= end_dt:
            dates.append(current.strftime('%Y%m%d'))
            current += timedelta(days=1)
        return dates


# ä¾¿æ·å…¥å£
def run_v20_holographic_download(date: str = None):
    """
    V20å…¨æ¯ä¸‹è½½ä¾¿æ·å…¥å£
    
    Usage:
        python -c "from tools.unified_downloader import run_v20_holographic_download; run_v20_holographic_download('20260224')"
    """
    if date is None:
        date = datetime.now().strftime('%Y%m%d')
    
    downloader = HolographicDownloaderV20()
    downloader.run_v20_download(date)


if __name__ == "__main__":
    main()
