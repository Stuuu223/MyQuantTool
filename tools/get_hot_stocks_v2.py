#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çƒ­é—¨è‚¡ç¥¨ç­›é€‰å™¨ V2ï¼ˆä¸¥æ ¼é˜²å°ç‰ˆï¼‰

æ ¸å¿ƒæ”¹è¿›ï¼š
1. ç§»é™¤é«˜é£é™©çš„"çƒ­é—¨æ¦‚å¿µæ¿å—"æ‰¹é‡è°ƒç”¨ï¼ˆå®¹æ˜“è§¦å‘å°ç¦ï¼‰
2. èšç„¦æœ€å¯é çš„ç­–ç•¥ï¼šæˆäº¤é¢Top Nï¼ˆæµåŠ¨æ€§æœ€å¥½çš„è‚¡ç¥¨ï¼‰
3. å¢åŠ éšæœºå»¶è¿Ÿ + ç¼“å­˜æœºåˆ¶
4. Tushare ä¼˜å…ˆï¼ˆTokenè®¤è¯ï¼Œä¸å—IPé™åˆ¶ï¼‰
5. æ›´ä¿å®ˆçš„é€Ÿç‡é™åˆ¶ï¼š8ç§’é—´éš”ï¼Œç¡®ä¿ä¸è¶…è¿‡ 7.5 req/min

Author: MyQuantTool Team
Date: 2026-02-10
"""

import sys
import os
import time
import random
import json
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict
import pandas as pd
import argparse

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
    from logic.rate_limiter import RateLimiter
    RATE_LIMITER = RateLimiter(
        max_requests_per_minute=7,      # æ›´ä¿å®ˆï¼š7 < 20/3
        max_requests_per_hour=80,       # æ›´ä¿å®ˆï¼š80 < 200/2
        min_request_interval=8,         # 8ç§’é—´éš”
        enable_logging=True
    )
except ImportError:
    RATE_LIMITER = None

TUSHARE_TOKEN = os.getenv('TUSHARE_TOKEN', '')
if not TUSHARE_TOKEN:
    config_file = project_root / 'config' / 'tushare_token.txt'
    if config_file.exists():
        TUSHARE_TOKEN = config_file.read_text().strip()

CACHE_DIR = project_root / 'data' / 'cache'
CACHE_DIR.mkdir(parents=True, exist_ok=True)


def load_cache(cache_key: str, expire_hours: int = 12) -> List[str] | None:
    """ä»ç¼“å­˜åŠ è½½æ•°æ®ï¼ˆé¿å…é‡å¤è°ƒç”¨APIï¼‰"""
    cache_file = CACHE_DIR / f"{cache_key}.json"
    
    if not cache_file.exists():
        return None
    
    try:
        with open(cache_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        cache_time = datetime.fromisoformat(data['timestamp'])
        if datetime.now() - cache_time < timedelta(hours=expire_hours):
            print(f"   ğŸ“¦ ä»ç¼“å­˜åŠ è½½ï¼ˆ{cache_key}ï¼‰ï¼Œç¼“å­˜æ—¶é—´: {cache_time.strftime('%H:%M:%S')}")
            return data['codes']
    except:
        pass
    
    return None


def save_cache(cache_key: str, codes: List[str]):
    """ä¿å­˜åˆ°ç¼“å­˜"""
    cache_file = CACHE_DIR / f"{cache_key}.json"
    
    data = {
        'timestamp': datetime.now().isoformat(),
        'codes': codes
    }
    
    with open(cache_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def random_delay(min_sec: float = 1.0, max_sec: float = 3.0):
    """éšæœºå»¶è¿Ÿï¼ˆé¿å…æœºå™¨äººæ£€æµ‹ï¼‰"""
    delay = random.uniform(min_sec, max_sec)
    time.sleep(delay)


def get_top_volume_stocks_tushare(top_n: int = 500, date: str = None) -> List[str]:
    """
    Tushare Proï¼šè·å–æˆäº¤é¢ Top Nï¼ˆæœ€å¯é çš„æ–¹å¼ï¼‰
    
    ä¼˜åŠ¿ï¼š
    - Tokenè®¤è¯ï¼Œä¸å—IPé™åˆ¶
    - é«˜æƒé™è´¦æˆ·é…é¢å¤§
    - æ•°æ®ç¨³å®š
    """
    print(f"\nğŸ’° Tushare Proï¼šè·å–æˆäº¤é¢ Top {top_n} è‚¡ç¥¨...")
    
    if not TUSHARE_TOKEN:
        print("   âš ï¸  Tushare Token æœªé…ç½®ï¼Œè·³è¿‡")
        return []
    
    cache_key = f"tushare_volume_top_{top_n}_{date or 'latest'}"
    cached = load_cache(cache_key, expire_hours=12)
    if cached:
        return cached
    
    if RATE_LIMITER:
        RATE_LIMITER.wait_if_needed()
    
    try:
        import tushare as ts
        ts.set_token(TUSHARE_TOKEN)
        pro = ts.pro_api()
        
        # è·å–äº¤æ˜“æ—¥
        if date:
            trade_date = date.replace('-', '')
        else:
            today = datetime.now()
            trade_date = today.strftime('%Y%m%d')
            
            # å°è¯•æœ€è¿‘5ä¸ªäº¤æ˜“æ—¥
            for i in range(5):
                try:
                    df = pro.daily(
                        trade_date=trade_date,
                        fields='ts_code,amount'
                    )
                    if len(df) > 0:
                        break
                    trade_date = (today - timedelta(days=i+1)).strftime('%Y%m%d')
                except Exception as e:
                    print(f"   âš ï¸  å°è¯•æ—¥æœŸ {trade_date} å¤±è´¥: {e}")
                    trade_date = (today - timedelta(days=i+1)).strftime('%Y%m%d')
        
        if RATE_LIMITER:
            RATE_LIMITER.record_request()
        
        random_delay(1, 2)
        
        # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼ˆå‰”é™¤STï¼‰
        df_basic = pro.stock_basic(
            exchange='',
            list_status='L',
            fields='ts_code,name,market'
        )
        
        df = df.merge(df_basic, on='ts_code', how='left')
        
        # è¿‡æ»¤
        df = df[~df['name'].str.contains('ST', na=False)]      # å‰”é™¤ST
        df = df[~df['ts_code'].str.match(r'^(8|4|9)')]         # å‰”é™¤åŒ—äº¤æ‰€
        df = df[df['market'].isin(['ä¸»æ¿', 'åˆ›ä¸šæ¿', 'ç§‘åˆ›æ¿'])]  # åªè¦ä¸»æµå¸‚åœº
        
        # æŒ‰æˆäº¤é¢æ’åº
        df = df.nlargest(top_n, 'amount')
        
        codes = df['ts_code'].tolist()
        
        print(f"   âœ… æˆåŠŸè·å– {len(codes)} åªè‚¡ç¥¨")
        print(f"   ğŸ“Š äº¤æ˜“æ—¥æœŸ: {trade_date}")
        print(f"   ğŸ’µ æœ€å°æˆäº¤é¢: {df['amount'].min():.2f} ä¸‡å…ƒ")
        
        save_cache(cache_key, codes)
        return codes
        
    except Exception as e:
        print(f"   âŒ å¤±è´¥: {e}")
        return []


def get_top_volume_stocks_akshare(top_n: int = 500) -> List[str]:
    """
    AkShare å¤‡é€‰æ–¹æ¡ˆï¼šè·å–æˆäº¤é¢ Top N
    
    æ³¨æ„ï¼š
    - åªåœ¨ Tushare å¤±è´¥æ—¶ä½¿ç”¨
    - æœ‰IPå°ç¦é£é™©
    - éœ€è¦æ›´é•¿çš„å»¶è¿Ÿ
    """
    print(f"\nğŸ’° AkShare å¤‡ç”¨ï¼šè·å–æˆäº¤é¢ Top {top_n} è‚¡ç¥¨...")
    
    cache_key = f"akshare_volume_top_{top_n}_{datetime.now().strftime('%Y%m%d')}"
    cached = load_cache(cache_key, expire_hours=6)  # AkShare ç¼“å­˜æ—¶é—´æ›´çŸ­
    if cached:
        return cached
    
    if RATE_LIMITER:
        RATE_LIMITER.wait_if_needed()
    
    try:
        import akshare as ak
        
        print("   â³ æ­£åœ¨è·å–å®æ—¶è¡Œæƒ…ï¼ˆå¯èƒ½éœ€è¦15-30ç§’ï¼‰...")
        df = ak.stock_zh_a_spot_em()
        
        if RATE_LIMITER:
            RATE_LIMITER.record_request()
        
        random_delay(2, 4)  # AkShare éœ€è¦æ›´é•¿å»¶è¿Ÿ
        
        # è¿‡æ»¤
        df = df[~df['åç§°'].str.contains('ST', na=False)]
        df = df[~df['ä»£ç '].str.match(r'^(8|4|9)')]
        
        df['æˆäº¤é¢'] = pd.to_numeric(df['æˆäº¤é¢'], errors='coerce')
        df = df.nlargest(top_n, 'æˆäº¤é¢')
        
        # è½¬æ¢æ ¼å¼
        codes = []
        for _, row in df.iterrows():
            code = str(row['ä»£ç '])
            if code.startswith('6'):
                codes.append(f"{code}.SH")
            else:
                codes.append(f"{code}.SZ")
        
        print(f"   âœ… æˆåŠŸè·å– {len(codes)} åªè‚¡ç¥¨")
        print(f"   ğŸ’µ æœ€å°æˆäº¤é¢: {df['æˆäº¤é¢'].min():.2f} å…ƒ")
        
        save_cache(cache_key, codes)
        return codes
        
    except Exception as e:
        print(f"   âŒ å¤±è´¥: {e}")
        return []


def get_stable_hot_stocks(
    top_n: int = 500,
    mode: str = 'tushare',
    date: str = None
) -> List[str]:
    """
    ç»Ÿä¸€å…¥å£ï¼šä¼˜å…ˆ Tushareï¼Œå¤±è´¥æ—¶é™çº§åˆ° AkShare
    """
    print("\n" + "=" * 60)
    print("ğŸ”¥ çƒ­é—¨è‚¡ç¥¨ç­›é€‰å™¨ V2ï¼ˆä¸¥æ ¼é˜²å°ç‰ˆï¼‰")
    print("=" * 60)
    print(f"\nğŸ“Œ ç­–ç•¥ï¼šæˆäº¤é¢ Top {top_n}ï¼ˆæµåŠ¨æ€§æœ€å¥½çš„è‚¡ç¥¨ï¼‰")
    print(f"ğŸ“Œ æ¨¡å¼ï¼š{mode}")
    
    codes = []
    
    if mode in ['tushare', 'both']:
        codes = get_top_volume_stocks_tushare(top_n, date)
    
    if len(codes) == 0 and mode in ['akshare', 'both']:
        print("\nâš ï¸  Tushare å¤±è´¥ï¼Œåˆ‡æ¢åˆ° AkShare å¤‡ç”¨æ–¹æ¡ˆ...")
        codes = get_top_volume_stocks_akshare(top_n)
    
    if len(codes) == 0:
        print("\nâŒ æ‰€æœ‰æ•°æ®æºå‡å¤±è´¥ï¼")
        return []
    
    # å»é‡å¹¶æ’åº
    codes = sorted(list(set(codes)))
    
    print(f"\nâœ… æœ€ç»ˆè·å¾— {len(codes)} åªçƒ­é—¨è‚¡ç¥¨")
    print(f"   ç¤ºä¾‹: {codes[:5]}")
    
    return codes


def main():
    parser = argparse.ArgumentParser(description='çƒ­é—¨è‚¡ç¥¨ç­›é€‰å™¨ V2ï¼ˆé˜²å°ç‰ˆï¼‰')
    parser.add_argument('--mode', type=str, default='tushare',
                        choices=['tushare', 'akshare', 'both'],
                        help='æ•°æ®æºï¼štushareï¼ˆæ¨èï¼‰ | akshare | both')
    parser.add_argument('--top', type=int, default=500,
                        help='è‚¡ç¥¨æ•°é‡ï¼ˆé»˜è®¤500ï¼‰')
    parser.add_argument('--date', type=str, default=None,
                        help='æŒ‡å®šæ—¥æœŸï¼ˆYYYY-MM-DDï¼‰ï¼Œé»˜è®¤æœ€è¿‘äº¤æ˜“æ—¥')
    parser.add_argument('--output', type=str, default='data/hot_stocks_v2.txt',
                        help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    args = parser.parse_args()
    
    # è·å–è‚¡ç¥¨åˆ—è¡¨
    codes = get_stable_hot_stocks(
        top_n=args.top,
        mode=args.mode,
        date=args.date
    )
    
    if len(codes) == 0:
        print("\nâŒ æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨ï¼Œç¨‹åºé€€å‡º")
        return
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    output_path = Path(args.output)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        for code in codes:
            f.write(code + '\n')
    
    print(f"\nğŸ’¾ å·²ä¿å­˜åˆ°: {output_path}")
    print("\n" + "=" * 60)
    print("âœ… å®Œæˆï¼ä¸‹ä¸€æ­¥ï¼š")
    print(f"   python tools/download_from_list.py --list {output_path} --days 90")
    print("=" * 60)


if __name__ == "__main__":
    main()