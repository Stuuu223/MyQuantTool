#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç ”ç©¶æµæ°´çº¿V2.0 - åŠ¨æ€è½¨è¿¹ç‰ˆ
CTOæŒ‡ä»¤ï¼šä»é™æ€æ ‡ç­¾å‡çº§åˆ°åŠ¨æ€è½¨è¿¹ç ”ç©¶

æ ¸å¿ƒå‡çº§ï¼š
1. è‡ªåŠ¨åˆ‡åˆ†äº‹ä»¶åŒºé—´ï¼ˆèµ·ç‚¹-è¿‡ç¨‹-ç»ˆç‚¹ï¼‰
2. çœŸèµ·çˆ†ï¼šæ¨å‡æ—¶é•¿T_upã€ç©ºé—´Î”p_upã€èµ„é‡‘è½¨è¿¹
3. éª—ç‚®ï¼šæ¬ºéª—æ—¶é•¿T_fakeã€å¹…åº¦Î”p_fakeã€å è½T_down
"""

import sys
from pathlib import Path
from datetime import datetime
import json
import pandas as pd

PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from logic.services.data_service import data_service
from logic.qmt_historical_provider import QMTHistoricalProvider
from logic.rolling_metrics import RollingFlowCalculator
from logic.event_lifecycle_analyzer import EventLifecycleAnalyzer, TrueBreakoutEvent, TrapEvent


def analyze_single_day_with_lifecycle(code: str, name: str, date: str, label: str) -> dict:
    """
    åˆ†æå•æ—¥æ•°æ®ï¼Œæå–äº‹ä»¶ç”Ÿå‘½å‘¨æœŸ
    """
    try:
        # 1. æ ¼å¼åŒ–ä»£ç 
        formatted_code = data_service._format_code(code)
        
        # 2. è·å–æ˜¨æ”¶ä»·
        pre_close = data_service.get_pre_close(code, date)
        if pre_close <= 0:
            return {'status': 'failed', 'error': 'æ— æ³•è·å–æ˜¨æ”¶ä»·'}
        
        # 3. åŠ è½½Tickæ•°æ®
        start_time = date.replace('-', '') + '093000'
        end_time = date.replace('-', '') + '150000'
        
        provider = QMTHistoricalProvider(
            stock_code=formatted_code,
            start_time=start_time,
            end_time=end_time,
            period='tick'
        )
        
        tick_count = provider.get_tick_count()
        if tick_count == 0:
            return {'status': 'failed', 'error': 'æ— Tickæ•°æ®'}
        
        # 4. è®¡ç®—èµ„é‡‘æµ
        calc = RollingFlowCalculator(windows=[1, 5, 15])
        results = []
        last_tick = None
        
        for tick in provider.iter_ticks():
            metrics = calc.add_tick(tick, last_tick)
            true_change = (tick['lastPrice'] - pre_close) / pre_close * 100
            
            results.append({
                'time': datetime.fromtimestamp(int(tick['time']) / 1000),
                'price': tick['lastPrice'],
                'true_change_pct': true_change,
                'flow_1min': metrics.flow_1min.total_flow,
                'flow_5min': metrics.flow_5min.total_flow,
                'flow_15min': metrics.flow_15min.total_flow,
            })
            last_tick = tick
        
        df = pd.DataFrame(results)
        
        # 5. äº‹ä»¶ç”Ÿå‘½å‘¨æœŸåˆ†æ
        analyzer = EventLifecycleAnalyzer(
            breakout_threshold=5.0,
            trap_reversal_threshold=3.0,
            max_drawdown_threshold=5.0
        )
        
        events = analyzer.analyze_day(df, pre_close)
        
        # 6. æå–å…³é”®äº‹ä»¶
        result = {
            'code': code,
            'name': name,
            'date': date,
            'pre_close': pre_close,
            'final_change_pct': df['true_change_pct'].iloc[-1],
            'max_change_pct': df['true_change_pct'].max(),
            'min_change_pct': df['true_change_pct'].min(),
            'tick_count': len(df),
            'status': 'success'
        }
        
        # æ·»åŠ çœŸèµ·çˆ†äº‹ä»¶è¯¦æƒ…
        if events['breakouts']:
            evt = events['breakouts'][0]  # å–ç¬¬ä¸€ä¸ª
            if evt.push_phase:
                result.update({
                    'breakout_t_start': evt.push_phase.t_start,
                    'breakout_t_end': evt.push_phase.t_end,
                    'breakout_duration': evt.push_phase.duration_minutes,
                    'breakout_change_start': evt.push_phase.change_start_pct,
                    'breakout_change_end': evt.push_phase.change_end_pct,
                    'breakout_change_peak': evt.push_phase.change_peak_pct,
                    'breakout_max_drawdown': evt.push_phase.max_drawdown_pct,
                    'breakout_total_inflow': evt.push_phase.total_inflow,
                    'breakout_max_flow_5min': evt.push_phase.max_flow_5min,
                    'breakout_sustain_ratio': evt.push_phase.sustain_ratio,
                    'breakout_efficiency': evt.push_phase.price_efficiency,
                    'is_gradual_push': evt.is_gradual_push,
                })
        
        # æ·»åŠ éª—ç‚®äº‹ä»¶è¯¦æƒ…
        if events['traps']:
            evt = events['traps'][0]
            if evt.fake_phase:
                result.update({
                    'trap_t_fake': evt.t_fake,
                    'trap_t_peak': evt.t_peak,
                    'trap_t_fail': evt.t_fail,
                    'trap_fake_duration': evt.fake_duration,
                    'trap_fake_change': evt.fake_change_pct,
                    'trap_fall_duration': evt.fall_duration,
                    'trap_fall_change': evt.fall_change_pct,
                })
        
        return result
        
    except Exception as e:
        return {'status': 'failed', 'error': str(e)}


def run_pipeline_v2(config_path: Path, output_dir: Path, log_dir: Path):
    """
    æ‰§è¡ŒV2æµæ°´çº¿
    """
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_dir.mkdir(parents=True, exist_ok=True)
    log_dir.mkdir(parents=True, exist_ok=True)
    
    log_file_path = log_dir / f"pipeline_v2_{timestamp}.log"
    
    with open(log_file_path, 'w', encoding='utf-8') as log_file:
        # å¤´ä¿¡æ¯
        header = f"""
{'='*80}
ç ”ç©¶æµæ°´çº¿V2.0 - åŠ¨æ€è½¨è¿¹ç‰ˆ
å¼€å§‹æ—¶é—´: {datetime.now().isoformat()}
{'='*80}
"""
        print(header)
        log_file.write(header + '\n')
        
        # ç¯å¢ƒæ£€æŸ¥
        print("\nã€1. ç¯å¢ƒè‡ªæ£€ã€‘")
        passed, env_info = data_service.env_check()
        if not passed:
            print("âŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥")
            return
        print(f"âœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡")
        
        # åŠ è½½é…ç½®
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        samples = config.get('samples', [])
        print(f"\nã€2. åŠ è½½é…ç½®ã€‘æ ·æœ¬æ•°: {len(samples)}")
        
        # æ‰§è¡Œåˆ†æ
        all_results = []
        
        for sample in samples:
            code = sample['code']
            name = sample['name']
            
            for date_info in sample.get('dates', []):
                if isinstance(date_info, dict):
                    date = date_info['date']
                    label = date_info['label']
                    verified = date_info.get('verified', False)
                    
                    # åªå¤„ç†verified=trueçš„
                    if not verified:
                        continue
                    
                    print(f"\nåˆ†æ {code} {name} {date} ({label})")
                    result = analyze_single_day_with_lifecycle(code, name, date, label)
                    result['label'] = label
                    
                    if result['status'] == 'success':
                        print(f"  âœ… å®Œæˆ")
                        if 'breakout_duration' in result:
                            print(f"     æ¨å‡æ—¶é•¿: {result['breakout_duration']:.1f}åˆ†é’Ÿ")
                            print(f"     æ¶¨å¹…: {result['breakout_change_start']:.1f}% -> {result['breakout_change_end']:.1f}%")
                        if 'trap_fake_duration' in result:
                            print(f"     æ¬ºéª—æ—¶é•¿: {result['trap_fake_duration']:.1f}åˆ†é’Ÿ")
                    else:
                        print(f"  âŒ å¤±è´¥: {result.get('error', 'unknown')}")
                    
                    all_results.append(result)
        
        # ä¿å­˜ç»“æœ
        if all_results:
            df = pd.DataFrame([r for r in all_results if r['status'] == 'success'])
            output_file = output_dir / f"lifecycle_analysis_{timestamp}.csv"
            df.to_csv(output_file, index=False)
            print(f"\nâœ… ç»“æœå·²ä¿å­˜: {output_file}")
            
            # ç»Ÿè®¡
            print("\nã€ç»Ÿè®¡æ±‡æ€»ã€‘")
            print(f"æˆåŠŸæ¡ˆä¾‹: {len(df)}")
            
            if 'breakout_duration' in df.columns:
                print(f"\nçœŸèµ·çˆ†äº‹ä»¶:")
                print(f"  å¹³å‡æ¨å‡æ—¶é•¿: {df['breakout_duration'].mean():.1f}åˆ†é’Ÿ")
                print(f"  å¹³å‡æ¶¨å¹…: {df['breakout_change_end'].mean():.1f}%")
                print(f"  å¹³å‡èµ„é‡‘æµå…¥: {df['breakout_total_inflow'].mean()/1e6:.1f}M")
            
            if 'trap_fake_duration' in df.columns:
                print(f"\néª—ç‚®äº‹ä»¶:")
                print(f"  å¹³å‡æ¬ºéª—æ—¶é•¿: {df['trap_fake_duration'].mean():.1f}åˆ†é’Ÿ")
                print(f"  å¹³å‡å è½æ—¶é•¿: {df['trap_fall_duration'].mean():.1f}åˆ†é’Ÿ")
        
        print(f"\nğŸ“„ æ—¥å¿—: {log_file_path}")


if __name__ == "__main__":
    config_path = PROJECT_ROOT / "data" / "wanzhu_data" / "research_labels_v2.json"
    output_dir = PROJECT_ROOT / "data" / "wanzhu_data" / "lifecycle_results"
    log_dir = PROJECT_ROOT / "logs" / "pipeline_v2"
    
    run_pipeline_v2(config_path, output_dir, log_dir)
