# -*- coding: utf-8 -*-
"""
Tushare ËµÑÈáëÊµÅÊï∞ÊçÆÂØºÂÖ•ËÑöÊú¨

ÂäüËÉΩÔºö
- Â∞Ü Tushare ÊãâÂèñÁöÑËµÑÈáëÊµÅ JSON Êï∞ÊçÆÂØºÂÖ•Âà∞ SQLite ÁºìÂ≠ò
- Ë°•ÂÖ® fund_flow_cache.db ‰∏≠Áº∫Â§±ÁöÑÊó•ÊúüÊï∞ÊçÆ

ÊâßË°åÊó∂Èó¥ÔºöÁ∫¶ 1-2 ÂàÜÈíü

Author: iFlow CLI
Version: V1.0
Date: 2026-02-09 10:22 AM
"""

import json
import sqlite3
import os
from pathlib import Path
from datetime import datetime
import sys

# Ê∑ªÂä†È°πÁõÆÊ†πÁõÆÂΩïÂà∞Ë∑ØÂæÑ
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ÈÖçÁΩÆ
TUSHARE_DATA_DIR = 'data/money_flow_tushare'
CACHE_DB_PATH = 'data/fund_flow_cache.db'


def import_tushare_data():
    """ÂØºÂÖ• Tushare Êï∞ÊçÆÂà∞ SQLite ÁºìÂ≠ò"""
    print("=" * 80)
    print("üöÄ ÂºÄÂßãÂØºÂÖ• Tushare ËµÑÈáëÊµÅÊï∞ÊçÆÂà∞ SQLite ÁºìÂ≠ò")
    print("=" * 80)
    print(f"‚è∞ ÂºÄÂßãÊó∂Èó¥: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()

    # 1. Ê£ÄÊü• Tushare Êï∞ÊçÆÁõÆÂΩï
    if not os.path.exists(TUSHARE_DATA_DIR):
        print(f"‚ùå Tushare Êï∞ÊçÆÁõÆÂΩï‰∏çÂ≠òÂú®: {TUSHARE_DATA_DIR}")
        return False

    # 2. ËØªÂèñÊâÄÊúâ Tushare JSON Êñá‰ª∂
    tushare_files = []
    for filename in os.listdir(TUSHARE_DATA_DIR):
        if filename.startswith('moneyflow_') and filename.endswith('.json'):
            tushare_files.append(filename)

    tushare_files.sort()
    print(f"üìÅ ÊâæÂà∞ {len(tushare_files)} ‰∏™ Tushare Êï∞ÊçÆÊñá‰ª∂")

    if not tushare_files:
        print("‚ùå Êú™ÊâæÂà∞ Tushare Êï∞ÊçÆÊñá‰ª∂")
        return False

    # 3. ËøûÊé• SQLite Êï∞ÊçÆÂ∫ì
    if not os.path.exists(CACHE_DB_PATH):
        print(f"‚ùå SQLite Êï∞ÊçÆÂ∫ì‰∏çÂ≠òÂú®: {CACHE_DB_PATH}")
        return False

    conn = sqlite3.connect(CACHE_DB_PATH)
    cursor = conn.cursor()

    # 4. ÁªüËÆ°Áé∞ÊúâÊï∞ÊçÆ
    cursor.execute('SELECT COUNT(*) FROM fund_flow_daily')
    existing_count = cursor.fetchone()[0]
    print(f"üìä Áé∞ÊúâÁºìÂ≠òËÆ∞ÂΩï: {existing_count:,} Êù°")

    # 5. ÂØºÂÖ•Êï∞ÊçÆ
    total_imported = 0
    total_skipped = 0

    for filename in tushare_files:
        print(f"\nüì• Â§ÑÁêÜ: {filename}")

        # ËØªÂèñ JSON Êñá‰ª∂
        filepath = os.path.join(TUSHARE_DATA_DIR, filename)
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)

        # ÈÅçÂéÜÊâÄÊúâËÇ°Á•®
        imported = 0
        skipped = 0

        for code_6digit, flow_data in data.items():
            # ÊûÑÈÄ†Êï∞ÊçÆ
            date = flow_data['date']

            # Tushare Â≠óÊÆµÊò†Â∞ÑÂà∞ SQLite Â≠óÊÆµ
            # Tushare ÁöÑÂçï‰ΩçÊòØ"ËÇ°"ÔºåSQLite ÁöÑÂçï‰ΩçÊòØ"ÂÖÉ"
            # ÈúÄË¶ÅËΩ¨Êç¢ÔºöÂÅáËÆæ‰ª∑Ê†º‰∏∫ 10 ÂÖÉÔºåÂàô ÂÖÉ = ËÇ° * 10
            # ‰ΩÜ Tushare ÁöÑÊï∞ÊçÆÂ∑≤ÁªèÊòØÂáÄÈ¢ùÔºåÂçï‰Ωç‰∏çÁ°ÆÂÆö
            # ‰∏∫‰∫ÜÂÆâÂÖ®ÔºåÊàë‰ª¨Áõ¥Êé•‰ΩøÁî® Tushare ÁöÑÂÄº

            super_large_net = flow_data.get('net_lg', 0)  # Â§ßÂçïÂáÄÊµÅÂÖ•ÔºàTushareÔºâ
            large_net = 0  # Tushare Ê≤°ÊúâÂçïÁã¨ÁöÑÂ§ßÂçï
            medium_net = flow_data.get('net_md', 0)  # ‰∏≠ÂçïÂáÄÊµÅÂÖ•
            small_net = flow_data.get('net_sm', 0)  # Â∞èÂçïÂáÄÊµÅÂÖ•

            # ËÆ°ÁÆóÂ≠óÊÆµ
            institution_net = super_large_net + large_net  # Êú∫ÊûÑÂáÄÊµÅÂÖ•
            retail_net = medium_net + small_net  # Êï£Êà∑ÂáÄÊµÅÂÖ•

            # Ë∂ÖÂ§ßÂçïÂç†ÊØî
            total = abs(super_large_net) + abs(large_net) + abs(medium_net) + abs(small_net)
            super_ratio = (abs(super_large_net) / total * 100) if total > 0 else 0

            # Â∞ùËØïÊèíÂÖ•ÔºàÂ¶ÇÊûúÂ∑≤Â≠òÂú®ÂàôË∑≥ËøáÔºâ
            try:
                cursor.execute('''
                    INSERT OR IGNORE INTO fund_flow_daily
                    (stock_code, date, super_large_net, large_net, medium_net, small_net,
                     institution_net, retail_net, super_ratio)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    code_6digit, date,
                    super_large_net, large_net, medium_net, small_net,
                    institution_net, retail_net, super_ratio
                ))

                if cursor.rowcount > 0:
                    imported += 1
                else:
                    skipped += 1

            except Exception as e:
                print(f"   ‚ö†Ô∏è  ÊèíÂÖ•Â§±Ë¥• {code_6digit}: {e}")
                skipped += 1

        # Êèê‰∫§‰∫ãÂä°
        conn.commit()
        print(f"   ‚úÖ ÂØºÂÖ•: {imported} Êù°ÔºåË∑≥Ëøá: {skipped} Êù°")

        total_imported += imported
        total_skipped += skipped

    # 6. ÁªüËÆ°ÁªìÊûú
    cursor.execute('SELECT COUNT(*) FROM fund_flow_daily')
    new_count = cursor.fetchone()[0]

    print()
    print("=" * 80)
    print(f"üìä ÂØºÂÖ•ÂÆåÊàêÔºÅ")
    print(f"   ÂØºÂÖ•: {total_imported:,} Êù°")
    print(f"   Ë∑≥Ëøá: {total_skipped:,} Êù°")
    print(f"   ÁºìÂ≠òÊÄªËÆ°: {new_count:,} Êù°Ôºà‰πãÂâç: {existing_count:,} Êù°Ôºâ")
    print()
    print("üí° ‰∏ã‰∏ÄÊ≠•:")
    print("   1. ÈáçÂêØ Monitor: start_event_driven_monitor.bat")
    print("   2. ËµÑÈáëÊµÅÊï∞ÊçÆÂ∫îËØ•Â∑≤ÁªèË°•ÂÖ®")
    print("   3. ËØ±Â§öÊ£ÄÊµãÂ∫îËØ•ËÉΩÊ≠£Â∏∏Â∑•‰Ωú")
    print("=" * 80)
    print(f"‚è∞ ÁªìÊùüÊó∂Èó¥: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # ÂÖ≥Èó≠ËøûÊé•
    conn.close()

    return total_imported > 0


if __name__ == "__main__":
    try:
        success = import_tushare_data()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Áî®Êà∑‰∏≠Êñ≠")
        sys.exit(1)
    except Exception as e:
        print(f"\n\n‚ùå ÊâßË°åÂ§±Ë¥•: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)