#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
é¡½ä¸»150åª58å¤©Tickè¡Œä¸ºå›æ”¾ï¼ˆLevel1æœ€å°æ–¹æ¡ˆï¼‰

çº¦æŸæ¡ä»¶ï¼ˆä¸¥æ ¼éµå®ˆï¼‰ï¼š
- âŒ ä¸importä»»ä½•èµ„é‡‘provider
- âŒ ä¸å†™"å‡€æµå…¥Xä¸‡"
- âœ… attack_scoreåªåˆ†æ¡£ï¼ˆå¼±/ä¸­/å¼ºï¼‰
- âœ… TrapDetectoråªç”¨ä»·é‡æ¨¡å¼ï¼ˆsurge/flash/washï¼‰

è¾“å‡ºæ ¼å¼ï¼ˆæ¯åªè‚¡ç¥¨æ¯å¤©ï¼‰ï¼š
{
  "code": "300017.SZ",
  "date": "2026-01-26",
  "signals": ["HALFWAY_BREAKOUT"],
  "attack_score": "STRONG",
  "is_trap": true,
  "trap_reasons": ["SURGE_VOLUME_PULLBACK"],
  "notes": "Level1-only proxy, no real capital flow numbers"
}

æ£€æŸ¥ç‚¹ï¼ˆä¸‰ä»¶äº‹ï¼‰ï¼š
1. å“ªå‡ å¤©æœ‰ä¿¡å·
2. è¿™äº›ä¿¡å·å¯¹åº”çš„æ”»å‡»è¯„åˆ†æ˜¯å¼±/ä¸­/å¼º
3. TrapDetectoræœ‰æ²¡æœ‰æŠŠå…¸å‹è¯±å¤šæŒ¡ä½

Author: AI Project Director
Date: 2026-02-19
Version: V1.0 (Level1-only)
"""

import sys
import json
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# ================= é…ç½® =================
CONFIG = {
    'wanzhu_csv': PROJECT_ROOT / 'data' / 'wanzhu_data' / 'processed' / 'wanzhu_selected_150.csv',
    'start_date': '2025-11-21',
    'end_date': '2026-02-13',
    'time_windows': [
        ('09:45', '10:30'),  # æ—©ç›˜çª—å£
        ('10:30', '13:30'),  # ä¸­ç›˜çª—å£
        ('13:30', '14:55'),  # å°¾ç›˜çª—å£
    ],
    'halfway_params': {
        'volatility_threshold': 0.03,      # æ³¢åŠ¨ç‡é˜ˆå€¼
        'volume_surge': 1.5,                # é‡èƒ½æ”¾å¤§å€æ•°
        'breakout_strength': 0.01,          # çªç ´å¼ºåº¦
    },
    'trap_params': {
        'surge_threshold': 0.03,           # æ€¥é€Ÿæ‹‰å‡é˜ˆå€¼ï¼ˆ3%ï¼‰
        'flash_volume_ratio': 5.0,          # ç¬é—´æ”¾é‡å€æ•°
        'wash_volatility': 0.02,            # éœ‡è¡æ´—ç›˜æ³¢åŠ¨ç‡
    }
}

# ================= æ•°æ®åŠ è½½ =================

def load_wanzhu_stocks(csv_path: Path) -> List[str]:
    """åŠ è½½é¡½ä¸»150åªè‚¡ç¥¨"""
    df = pd.read_csv(csv_path)
    codes = []
    for _, row in df.iterrows():
        code = str(row['code']).zfill(6)
        market = 'SH' if code.startswith('6') else 'SZ'
        codes.append(f'{code}.{market}')
    logger.info(f"âœ… åŠ è½½é¡½ä¸»æ¦œå•: {len(codes)} åª")
    return codes

def load_tick_data(stock_code: str, date_str: str) -> Optional[pd.DataFrame]:
    """åŠ è½½å•æ—¥Tickæ•°æ®ï¼ˆLevel1ï¼‰ï¼Œå¸¦å­—æ®µå…œåº•æ˜ å°„å’Œå¤±è´¥åŸå› åˆ†ç±»"""
    try:
        from xtquant import xtdata
        
        start_time = date_str.replace('-', '') + '093000'
        end_time = date_str.replace('-', '') + '150000'
        
        # å°è¯•è·å–tickæ•°æ®
        tick_df = xtdata.get_market_data_ex(
            field_list=['time', 'lastPrice', 'volume', 'amount', 'bidPrice', 'askPrice'],
            stock_list=[stock_code],
            period='tick',
            start_time=start_time,
            end_time=end_time
        )
        
        # æƒ…å†µ1ï¼šè‚¡ç¥¨ä¸åœ¨è¿”å›ç»“æœä¸­
        if stock_code not in tick_df:
            logger.warning(f"  âš ï¸ {stock_code} {date_str} XTDATA_ERROR: è¿”å›æ•°æ®ä¸­ä¸åŒ…å«è¯¥è‚¡ç¥¨")
            return None
        
        df = tick_df[stock_code]
        
        # æƒ…å†µ2ï¼šDataFrameä¸ºç©ºï¼ˆ0è¡Œï¼‰
        if df.empty:
            logger.warning(f"  âš ï¸ {stock_code} {date_str} NO_ROWS: DataFrameä¸ºç©º (å½¢çŠ¶: {df.shape})")
            return None
        
        # å¤åˆ¶å¹¶é‡ç½®ç´¢å¼•
        df = df.copy()
        if 'index' in df.columns or df.index.name in ('time', 'stime'):
            df = df.reset_index()
        
        # å­—æ®µå…œåº•æ˜ å°„å’Œæ£€æŸ¥
        cols = df.columns.tolist()
        
        # 1) timeå­—æ®µæ£€æŸ¥
        if 'time' not in cols:
            logger.warning(f"  âš ï¸ {stock_code} {date_str} MISSING_FIELDS: ç¼ºå°‘timeå­—æ®µ")
            return None
        
        # 2) lastPriceå­—æ®µå…œåº•ï¼šå¦‚æœæ²¡æœ‰lastPriceä½†æœ‰closeï¼Œç”¨closeæ›¿ä»£
        if 'lastPrice' not in cols:
            if 'close' in cols:
                df['lastPrice'] = df['close']
                logger.debug(f"  ğŸ”„ {stock_code} {date_str} ä½¿ç”¨closeå­—æ®µæ›¿ä»£lastPrice")
            else:
                logger.warning(f"  âš ï¸ {stock_code} {date_str} MISSING_FIELDS: ç¼ºå°‘lastPrice/closeå­—æ®µ")
                return None
        
        # 3) volumeå­—æ®µæ£€æŸ¥ï¼ˆå¿…éœ€ï¼‰
        if 'volume' not in cols:
            logger.warning(f"  âš ï¸ {stock_code} {date_str} MISSING_FIELDS: ç¼ºå°‘volumeå­—æ®µ")
            return None
        
        # åˆ›å»ºæ—¶é—´æˆ³åˆ—ï¼ˆæ”¯æŒæ•´æ•°æ¯«ç§’æ—¶é—´æˆ³å’Œå­—ç¬¦ä¸²æ ¼å¼ï¼‰
        if 'timestamp' not in cols:
            try:
                # å°è¯•è§£æä¸ºæ•´æ•°æ¯«ç§’æ—¶é—´æˆ³
                if df['time'].dtype in (np.int64, np.float64, int, float):
                    df['timestamp'] = pd.to_datetime(df['time'], unit='ms')
                else:
                    # å°è¯•è§£æä¸ºå­—ç¬¦ä¸²æ ¼å¼
                    df['timestamp'] = pd.to_datetime(df['time'].astype(str), format='%Y%m%d%H%M%S', errors='coerce')
            except Exception as e:
                logger.warning(f"  âš ï¸ {stock_code} {date_str} æ—¶é—´è§£æå¤±è´¥: {e}")
                # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•æ··åˆæ ¼å¼
                df['timestamp'] = pd.to_datetime(df['time'].astype(str), errors='coerce')
        
        # æ£€æŸ¥æ—¶é—´è§£ææ˜¯å¦æˆåŠŸ
        if df['timestamp'].isna().all():
            logger.warning(f"  âš ï¸ {stock_code} {date_str} æ—¶é—´è§£æå…¨éƒ¨å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ—¶é—´")
            df['timestamp'] = pd.to_datetime(df['time'].astype(str), errors='coerce')
        
        # åªä¿ç•™æœ‰æ•ˆæˆäº¤Tickï¼ˆlastPrice > 0ï¼‰
        df = df[df['lastPrice'] > 0].copy()
        
        # å¦‚æœè¿‡æ»¤åä¸ºç©ºï¼Œè¿”å›None
        if df.empty:
            logger.warning(f"  âš ï¸ {stock_code} {date_str} NO_ROWS: è¿‡æ»¤åæ— æœ‰æ•ˆæˆäº¤Tick")
            return None
        
        # æŒ‰æ—¶é—´æ’åº
        df = df.sort_values('timestamp').reset_index(drop=True)
        
        logger.debug(f"  âœ… {stock_code} {date_str} åŠ è½½æˆåŠŸ: {len(df)} æ¡Tickæ•°æ®")
        return df
        
    except Exception as e:
        logger.warning(f"  âš ï¸ {stock_code} {date_str} XTDATA_ERROR: {e}")
        return None

# ================= Level1 æ”»å‡»Proxyè®¡ç®— =================

def calculate_price_strength(tick_df: pd.DataFrame) -> float:
    """
    è®¡ç®—ä»·æ ¼å¼ºåº¦ï¼ˆprice_strengthï¼‰
    
    å…¬å¼ï¼šprice_strength = (lastPrice - preClose) / preClose
    """
    if tick_df.empty:
        return 0.0
    
    # ä½¿ç”¨ç¬¬ä¸€æ¡ä½œä¸ºæ˜¨æ”¶ä»·çš„proxyï¼ˆå®é™…åº”ç”¨ä¸­åº”è¯¥ä»æ—¥çº¿è·å–ï¼‰
    pre_close = tick_df['lastPrice'].iloc[0]
    last_price = tick_df['lastPrice'].iloc[-1]
    
    if pre_close <= 0:
        return 0.0
    
    return (last_price - pre_close) / pre_close

def calculate_bid_pressure(tick_df: pd.DataFrame) -> float:
    """
    è®¡ç®—ä¹°ç›˜å‹å¼ºï¼ˆbid_pressureï¼‰
    
    ç®€åŒ–ç‰ˆæœ¬ï¼šç»Ÿè®¡"ä¸»åŠ¨ä¹°å•é‡ - ä¸»åŠ¨å–å•é‡"çš„æ¯”ä¾‹
    è¿‘ä¼¼è§„åˆ™ï¼šæ¶¨ä»·å¯¹åº”ä¹°ä¸»åŠ¨ã€è·Œä»·å¯¹åº”å–ä¸»åŠ¨
    """
    if tick_df.empty:
        return 0.0
    
    # è®¡ç®—ä»·æ ¼å˜åŒ–æ–¹å‘
    tick_df['price_change'] = tick_df['lastPrice'].diff().fillna(0)
    
    # ç®€åŒ–ï¼šä»·æ ¼ä¸Šæ¶¨å¯¹åº”ä¹°ä¸»åŠ¨ï¼Œä¸‹è·Œå¯¹åº”å–ä¸»åŠ¨
    buy_volume = tick_df[tick_df['price_change'] > 0]['volume'].sum()
    sell_volume = tick_df[tick_df['price_change'] < 0]['volume'].sum()
    total_volume = tick_df['volume'].sum()
    
    if total_volume <= 0:
        return 0.0
    
    # bid_pressure = (ä¹°å•é‡ - å–å•é‡) / æ€»æˆäº¤é‡
    return (buy_volume - sell_volume) / total_volume

def calculate_attack_score(price_strength: float, bid_pressure: float) -> str:
    """
    è®¡ç®—æ”»å‡»è¯„åˆ†ï¼ˆattack_scoreï¼‰
    
    åªåˆ†æ¡£ï¼šå¼± / ä¸­ / å¼º
    ä¸æš´éœ²å†…éƒ¨å…¬å¼
    
    è§„åˆ™ï¼š
    - price_strengthå’Œbid_pressureéƒ½åœ¨å†å²åˆ†å¸ƒçš„ä¸Š20% â†’ å¼º
    - åªé«˜ä¸€ä¸ª â†’ ä¸­
    - éƒ½ä¸€èˆ¬ â†’ å¼±
    
    ç®€åŒ–å®ç°ï¼ˆä½¿ç”¨å›ºå®šé˜ˆå€¼ï¼‰ï¼š
    - price_strength > 0.02 ä¸” bid_pressure > 0.1 â†’ å¼º
    - price_strength > 0.02 æˆ– bid_pressure > 0.1 â†’ ä¸­
    - å…¶ä»– â†’ å¼±
    """
    if price_strength > 0.02 and bid_pressure > 0.1:
        return "STRONG"
    elif price_strength > 0.02 or bid_pressure > 0.1:
        return "MEDIUM"
    else:
        return "WEAK"

# ================= ä¿¡å·æ£€æµ‹ï¼ˆHalfwayï¼‰ =================

def detect_halfway_signal(tick_df: pd.DataFrame, params: Dict) -> bool:
    """
    æ£€æµ‹Halfwayä¿¡å·ï¼ˆåªç”¨ä»·é‡ä¸‰æ¡ä»¶ï¼Œä¸å¼•å…¥èµ„é‡‘é˜ˆå€¼ï¼‰
    
    ä¸‰å¤§æ¡ä»¶ï¼š
    1. æ³¢åŠ¨ç‡åˆ¤æ–­: volatility <= volatility_threshold
    2. é‡èƒ½æ”¾å¤§: volume_surge >= volume_surge_threshold
    3. çªç ´å¼ºåº¦: breakout_strength >= breakout_strength_threshold
    """
    if tick_df.empty or len(tick_df) < 5:
        return False
    
    # 1. è®¡ç®—æ³¢åŠ¨ç‡
    prices = tick_df['lastPrice'].values
    volatility = np.std(prices) / np.mean(prices) if np.mean(prices) > 0 else 0
    
    # 2. è®¡ç®—é‡èƒ½æ”¾å¤§ï¼ˆç®€å•ç‰ˆæœ¬ï¼šä½¿ç”¨æˆäº¤é‡åˆ†å¸ƒï¼‰
    volumes = tick_df['volume'].values
    volume_surge = np.max(volumes) / np.mean(volumes) if np.mean(volumes) > 0 else 1.0
    
    # 3. è®¡ç®—çªç ´å¼ºåº¦
    breakout_strength = (prices[-1] - prices[0]) / prices[0] if prices[0] > 0 else 0
    
    # ä¸‰ä¸ªæ¡ä»¶åŒæ—¶æ»¡è¶³
    volatility_ok = volatility <= params['volatility_threshold']
    volume_ok = volume_surge >= params['volume_surge']
    breakout_ok = breakout_strength >= params['breakout_strength']
    
    return volatility_ok and volume_ok and breakout_ok

# ================= è¯±å¤šæ£€æµ‹ï¼ˆTrapDetector - ä»·é‡æ¨¡å¼ï¼‰ =================

def detect_trap_price_volume(tick_df: pd.DataFrame, params: Dict) -> List[str]:
    """
    æ£€æµ‹è¯±å¤šæ¨¡å¼ï¼ˆåªç”¨ä»·é‡æ¨¡å¼ï¼Œä¸ä½¿ç”¨çœŸå®èµ„é‡‘æ•°æ®ï¼‰
    
    ä¸‰ç§æ¨¡å¼ï¼š
    1. SURGE_VOLUME_PULLBACKï¼šæ€¥é€Ÿæ‹‰å‡ + å†²é«˜å›è½ï¼ˆæ‹‰é«˜å‡ºè´§ï¼‰
    2. FLASH_ATTACKï¼šå°¾ç›˜çªç„¶ä¸€æ ¹å†²é«˜
    3. WASH_TRADINGï¼šçŸ­æ—¶é—´å†…é«˜é¢‘å¯¹å€’ç—•è¿¹
    """
    trap_reasons = []
    
    if tick_df.empty or len(tick_df) < 10:
        return trap_reasons
    
    prices = tick_df['lastPrice'].values
    volumes = tick_df['volume'].values
    timestamps = pd.to_datetime(tick_df['index'], format='%Y%m%d%H%M%S')
    
    # æ¨¡å¼1ï¼šSURGE_VOLUME_PULLBACKï¼ˆæ€¥é€Ÿæ‹‰å‡ + å†²é«˜å›è½ï¼‰
    # æ£€æµ‹ï¼šçŸ­æ—¶é—´å†…æ¶¨å¹…è¶…è¿‡é˜ˆå€¼ï¼Œç„¶åå›è½
    for i in range(5, len(prices) - 5):
        window_prices = prices[i-5:i+5]
        max_price = np.max(window_prices)
        last_price = prices[i+5]
        pre_price = prices[i-5]
        
        surge_strength = (max_price - pre_price) / pre_price if pre_price > 0 else 0
        pullback_strength = (max_price - last_price) / max_price if max_price > 0 else 0
        
        if surge_strength >= params['surge_threshold'] and pullback_strength >= params['surge_threshold']:
            trap_reasons.append("SURGE_VOLUME_PULLBACK")
            break
    
    # æ¨¡å¼2ï¼šFLASH_ATTACKï¼ˆå°¾ç›˜çªç„¶ä¸€æ ¹å†²é«˜ï¼‰
    # æ£€æµ‹ï¼šæœ€å5åˆ†é’Ÿå†…çªç„¶æ”¾é‡æ‹‰å‡
    if len(prices) >= 5:
        last_5_prices = prices[-5:]
        last_5_volumes = volumes[-5:]
        avg_volume = np.mean(volumes[:-5]) if len(volumes) > 5 else 1.0
        
        max_volume = np.max(last_5_volumes)
        flash_surge = (last_5_prices[-1] - last_5_prices[0]) / last_5_prices[0] if last_5_prices[0] > 0 else 0
        
        if max_volume >= avg_volume * params['flash_volume_ratio'] and flash_surge >= params['surge_threshold']:
            trap_reasons.append("FLASH_ATTACK")
    
    # æ¨¡å¼3ï¼šWASH_TRADINGï¼ˆçŸ­æ—¶é—´å†…é«˜é¢‘å¯¹å€’ç—•è¿¹ï¼‰
    # æ£€æµ‹ï¼šä»·æ ¼é¢‘ç¹æ³¢åŠ¨ï¼Œæˆäº¤é‡æ”¾å¤§
    if len(prices) >= 10:
        window_volatility = np.std(prices[-10:]) / np.mean(prices[-10:]) if np.mean(prices[-10:]) > 0 else 0
        avg_volume = np.mean(volumes[:-10]) if len(volumes) > 10 else 1.0
        surge_volume = np.mean(volumes[-10:]) / avg_volume if avg_volume > 0 else 1.0
        
        if window_volatility >= params['wash_volatility'] and surge_volume >= params['flash_volume_ratio']:
            trap_reasons.append("WASH_TRADING")
    
    return trap_reasons

# ================= è¡Œä¸ºå›æ”¾ä¸»æµç¨‹ =================

def run_wanzhu_behavior_replay(stock_codes: List[str], start_date: str, end_date: str, 
                              max_stocks: int = None, max_days: int = None) -> Dict:
    """è¿è¡Œé¡½ä¸»150åª58å¤©Tickè¡Œä¸ºå›æ”¾
    
    Args:
        stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        max_stocks: æœ€å¤§è‚¡ç¥¨æ•°é‡ï¼ˆå–å‰Nåªï¼‰
        max_days: æ¯åªè‚¡ç¥¨æœ€å¤§å¤©æ•°ï¼ˆå–æœ€è¿‘Nä¸ªäº¤æ˜“æ—¥ï¼‰
    """
    
    # åº”ç”¨max_stocksé™åˆ¶
    if max_stocks is not None:
        stock_codes = stock_codes[:max_stocks]
    
    results = {
        'meta': {
            'version': 'V1.0 (Level1-only)',
            'generated_at': datetime.now().isoformat(),
            'total_stocks': len(stock_codes),
            'start_date': start_date,
            'end_date': end_date,
            'max_stocks': max_stocks,
            'max_days': max_days,
            'note': 'Level1-only proxy, no real capital flow numbers'
        },
        'summary': {
            'total_days': 0,
            'total_signals': 0,
            'strong_attack_days': 0,
            'medium_attack_days': 0,
            'weak_attack_days': 0,
            'trap_days': 0,
        },
        'daily_records': [],
        'stock_records': {},
        'stock_stats': {}  # æ–°å¢ï¼šæ¯åªè‚¡ç¥¨çš„è¡Œä¸ºç»Ÿè®¡
    }
    
    # æ—¥æœŸèŒƒå›´
    date_range = pd.date_range(start_date, end_date, freq='D')
    results['summary']['total_days'] = len(date_range)
    
    # ç»Ÿè®¡æ•°æ®
    signal_days_count = set()
    attack_score_counts = {'STRONG': 0, 'MEDIUM': 0, 'WEAK': 0}
    
    logger.info(f"ğŸš€ å¼€å§‹è¡Œä¸ºå›æ”¾: {len(stock_codes)} åªè‚¡ç¥¨, {len(date_range)} å¤©")
    if max_stocks:
        logger.info(f"  é™åˆ¶: max_stocks={max_stocks}")
    if max_days:
        logger.info(f"  é™åˆ¶: max_days={max_days}")
    logger.info(f"{'='*60}")
    
    # éå†æ¯åªè‚¡ç¥¨
    for stock_idx, stock_code in enumerate(stock_codes, 1):
        logger.info(f"\n[{stock_idx}/{len(stock_codes)}] {stock_code}")
        
        stock_records = []
        
        # æ”¶é›†è¯¥è‚¡ç¥¨æœ‰æ•°æ®çš„æ‰€æœ‰äº¤æ˜“æ—¥
        available_dates = []
        for date in date_range:
            date_str = date.strftime('%Y-%m-%d')
            tick_df = load_tick_data(stock_code, date_str)
            if tick_df is not None and not tick_df.empty:
                available_dates.append(date)
        
        # åº”ç”¨max_daysé™åˆ¶ï¼ˆå–æœ€è¿‘Nä¸ªäº¤æ˜“æ—¥ï¼‰
        if max_days is not None and len(available_dates) > max_days:
            available_dates = available_dates[-max_days:]
        
        if not available_dates:
            logger.warning(f"  âš ï¸  {stock_code} æ— å¯ç”¨Tickæ•°æ®")
            continue
        
        # éå†æ¯ä¸ªäº¤æ˜“æ—¥ï¼ˆå·²æŒ‰æ—¥æœŸæ’åºï¼‰
        stock_records = []
        stock_stats = {
            'signal_days': 0,
            'strong_days': 0,
            'medium_days': 0,
            'weak_days': 0,
            'trap_days': 0,
            'clean_strong_days': 0,  # å¼ºæ”»å‡»ä½†æ²¡è¢«TRAPæ‹¦ä½
            'total_tested_days': len(available_dates)
        }
        
        for date in available_dates:
            date_str = date.strftime('%Y-%m-%d')
            
            # åŠ è½½Tickæ•°æ®
            tick_df = load_tick_data(stock_code, date_str)
            if tick_df is None or tick_df.empty:
                continue
            
            # æ£€æŸ¥ä¿¡å·
            signals = []
            if detect_halfway_signal(tick_df, CONFIG['halfway_params']):
                signals.append('HALFWAY_BREAKOUT')
            
            # è®¡ç®—æ”»å‡»è¯„åˆ†
            price_strength = calculate_price_strength(tick_df)
            bid_pressure = calculate_bid_pressure(tick_df)
            attack_score = calculate_attack_score(price_strength, bid_pressure)
            
            # CTOè¦æ±‚ï¼šæ— ä¿¡å·æ—¥attack_scoreè®¾ä¸ºWEAK
            if not signals:
                attack_score = 'WEAK'
            
            # æ£€æµ‹è¯±å¤šï¼ˆä»·é‡æ¨¡å¼ï¼‰
            trap_reasons = detect_trap_price_volume(tick_df, CONFIG['trap_params'])
            is_trap = len(trap_reasons) > 0
            
            # è®°å½•ç»“æœ
            record = {
                'code': stock_code,
                'date': date_str,
                'signals': signals,
                'attack_score': attack_score,
                'is_trap': is_trap,
                'trap_reasons': trap_reasons,
                'notes': 'Level1-only proxy, no real capital flow numbers'
            }
            
            # æ›´æ–°è‚¡ç¥¨ç»Ÿè®¡
            if signals:
                stock_records.append(record)
                stock_stats['signal_days'] += 1
                stock_stats[f'{attack_score.lower()}_days'] += 1
                
                # ç»Ÿè®¡
                signal_days_count.add(date_str)
                attack_score_counts[attack_score] += 1
                
                if is_trap:
                    stock_stats['trap_days'] += 1
                    results['summary']['trap_days'] += 1
                elif attack_score == 'STRONG':
                    # å¼ºæ”»å‡»ä½†æ²¡è¢«TRAPæ‹¦ä½
                    stock_stats['clean_strong_days'] += 1
            else:
                # æ— ä¿¡å·æ—¥ï¼Œåªç»Ÿè®¡attack_scoreï¼ˆå·²ç»æ˜¯WEAKï¼‰
                attack_score_counts[attack_score] += 1
            
            results['daily_records'].append(record)
        
        # æ±‡æ€»è‚¡ç¥¨è®°å½•
        if stock_records:
            results['stock_records'][stock_code] = {
                'total_signals': len(stock_records),
                'trap_count': sum(1 for r in stock_records if r['is_trap']),
                'signals': stock_records
            }
        
        # ä¿å­˜è‚¡ç¥¨ç»Ÿè®¡
        results['stock_stats'][stock_code] = stock_stats
        
        # æ˜¾ç¤ºè¿›åº¦
        if stock_idx % 10 == 0 or stock_idx == len(stock_codes):
            logger.info(f"  è¿›åº¦: {stock_idx}/{len(stock_codes)}")
    
    # æ›´æ–°æ±‡æ€»ç»Ÿè®¡
    results['summary']['total_signals'] = len(results['daily_records'])
    results['summary']['strong_attack_days'] = attack_score_counts['STRONG']
    results['summary']['medium_attack_days'] = attack_score_counts['MEDIUM']
    results['summary']['weak_attack_days'] = attack_score_counts['WEAK']
    
    # è®¡ç®—å¤´éƒ¨å¤§å“¥è¯„åˆ†å’Œæ’åº
    alpha = 0.5  # TRAPæ‰£åˆ†ç³»æ•°
    rankings = []
    
    for stock_code, stats in results['stock_stats'].items():
        if stats['total_tested_days'] == 0:
            continue
        
        # å¤´éƒ¨å¤§å“¥è¯„åˆ† = clean_strong_days - alpha * trap_days
        score = stats['clean_strong_days'] - alpha * stats['trap_days']
        
        # TRAPæ¯”ä¾‹
        trap_ratio = stats['trap_days'] / stats['signal_days'] if stats['signal_days'] > 0 else 0
        
        rankings.append({
            'code': stock_code,
            'score': round(score, 2),
            'signal_days': stats['signal_days'],
            'clean_strong_days': stats['clean_strong_days'],
            'trap_days': stats['trap_days'],
            'trap_ratio': round(trap_ratio, 3),
            'total_tested_days': stats['total_tested_days']
        })
    
    # æŒ‰scoreé™åºæ’åºï¼ˆå¤´éƒ¨å¤§å“¥ï¼‰
    rankings.sort(key=lambda x: x['score'], reverse=True)
    results['top_stocks'] = rankings[:20]  # Top 20
    
    # æŒ‰trap_ratioé™åºæ’åºï¼ˆå…¸å‹æ‚æ¯›ï¼‰
    rankings.sort(key=lambda x: x['trap_ratio'], reverse=True)
    results['junk_stocks'] = rankings[:20]  # Top 20 æ‚æ¯›
    
    logger.info(f"\n{'='*60}")
    logger.info(f"âœ… è¡Œä¸ºå›æ”¾å®Œæˆ")
    logger.info(f"  æ€»ä¿¡å·å¤©æ•°: {results['summary']['total_signals']}")
    logger.info(f"  å¼ºæ”»å‡»: {results['summary']['strong_attack_days']}")
    logger.info(f"  ä¸­æ”»å‡»: {results['summary']['medium_attack_days']}")
    logger.info(f"  å¼±æ”»å‡»: {results['summary']['weak_attack_days']}")
    logger.info(f"  TRAPè¿‡æ»¤: {results['summary']['trap_days']}")
    
    # æ˜¾ç¤ºTop 5å¤´éƒ¨å¤§å“¥
    logger.info(f"\nğŸ“Š Top 5 å¤´éƒ¨å¤§å“¥ï¼ˆæŒ‰è¯„åˆ†æ’åºï¼‰:")
    for i, stock in enumerate(results['top_stocks'][:5], 1):
        logger.info(f"  {i}. {stock['code']}: score={stock['score']}, "
                   f"clean_strong={stock['clean_strong_days']}, "
                   f"trap={stock['trap_days']} ({stock['trap_ratio']:.1%})")
    
    # æ˜¾ç¤ºTop 5å…¸å‹æ‚æ¯›
    logger.info(f"\nâš ï¸  Top 5 å…¸å‹æ‚æ¯›ï¼ˆæŒ‰TRAPæ¯”ä¾‹æ’åºï¼‰:")
    for i, stock in enumerate(results['junk_stocks'][:5], 1):
        logger.info(f"  {i}. {stock['code']}: trap_ratio={stock['trap_ratio']:.1%}, "
                   f"trap={stock['trap_days']}/{stock['signal_days']}")
    
    logger.info(f"{'='*60}")
    
    return results

# ================= é…ç½®æ–‡ä»¶åŠ è½½ =================

def load_hot_cases_config(config_path: Path) -> Dict:
    """åŠ è½½å¿…èƒœæ ·æœ¬æµ‹è¯•é…ç½®"""
    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
    
    logger.info(f"âœ… åŠ è½½å¿…èƒœæ ·æœ¬é…ç½®: {config_path}")
    logger.info(f"  æµ‹è¯•ç”¨ä¾‹æ•°: {len(config['test_cases'])}")
    
    return config

def run_hot_cases_replay(config: Dict) -> Dict:
    """è¿è¡Œå¿…èƒœæ ·æœ¬æµ‹è¯•"""
    
    test_cases = config['test_cases']
    
    results = {
        'meta': {
            'version': config['meta']['version'],
            'description': config['meta']['description'],
            'generated_at': datetime.now().isoformat(),
            'total_test_cases': len(test_cases),
            'note': config['meta']['note']
        },
        'summary': {
            'total_test_dates': 0,
            'total_signals': 0,
            'strong_attack_days': 0,
            'medium_attack_days': 0,
            'weak_attack_days': 0,
            'trap_days': 0,
        },
        'test_results': []
    }
    
    logger.info(f"ğŸš€ å¼€å§‹å¿…èƒœæ ·æœ¬æµ‹è¯•: {len(test_cases)} åªè‚¡ç¥¨")
    logger.info(f"{'='*60}")
    
    # ç»Ÿè®¡æ•°æ®
    attack_score_counts = {'STRONG': 0, 'MEDIUM': 0, 'WEAK': 0}
    
    # éå†æ¯ä¸ªæµ‹è¯•ç”¨ä¾‹
    for case_idx, case in enumerate(test_cases, 1):
        stock_code = case['code']
        stock_name = case['name']
        stock_type = case['type']
        test_dates = case['test_dates']
        expected = case.get('expected_behavior', {})
        
        logger.info(f"\n[{case_idx}/{len(test_cases)}] {stock_code} {stock_name} ({stock_type})")
        
        # éå†æ¯ä¸ªæµ‹è¯•æ—¥æœŸ
        for date_str in test_dates:
            if date_str.startswith('YYYY'):
                logger.info(f"  â­ï¸  è·³è¿‡å ä½æ—¥æœŸ: {date_str}")
                continue
            
            # åŠ è½½Tickæ•°æ®
            tick_df = load_tick_data(stock_code, date_str)
            if tick_df is None or tick_df.empty:
                logger.warning(f"  âš ï¸  {date_str} æ— Tickæ•°æ®")
                continue
            
            # æ£€æŸ¥ä¿¡å·
            signals = []
            if detect_halfway_signal(tick_df, CONFIG['halfway_params']):
                signals.append('HALFWAY_BREAKOUT')
            
            # è®¡ç®—æ”»å‡»è¯„åˆ†
            price_strength = calculate_price_strength(tick_df)
            bid_pressure = calculate_bid_pressure(tick_df)
            attack_score = calculate_attack_score(price_strength, bid_pressure)
            
            # CTOè¦æ±‚ï¼šæ— ä¿¡å·æ—¥attack_scoreè®¾ä¸ºWEAK
            if not signals:
                attack_score = 'WEAK'
            
            # æ£€æµ‹è¯±å¤šï¼ˆä»·é‡æ¨¡å¼ï¼‰
            trap_reasons = detect_trap_price_volume(tick_df, CONFIG['trap_params'])
            is_trap = len(trap_reasons) > 0
            
            # è®°å½•ç»“æœ
            result = {
                'code': stock_code,
                'name': stock_name,
                'type': stock_type,
                'date': date_str,
                'signals': signals,
                'attack_score': attack_score,
                'is_trap': is_trap,
                'trap_reasons': trap_reasons,
                'expected_behavior': expected,
                'notes': 'Level1-only proxy, no real capital flow numbers'
            }
            
            results['test_results'].append(result)
            
            # ç»Ÿè®¡
            attack_score_counts[attack_score] += 1
            if is_trap:
                results['summary']['trap_days'] += 1
            if signals:
                results['summary']['total_signals'] += 1
            
            # æ˜¾ç¤ºå•æ¡ç»“æœ
            logger.info(f"  {date_str}: signals={signals}, attack={attack_score}, trap={is_trap}")
        
        results['summary']['total_test_dates'] = len(results['test_results'])
    
    # æ›´æ–°æ±‡æ€»ç»Ÿè®¡
    results['summary']['strong_attack_days'] = attack_score_counts['STRONG']
    results['summary']['medium_attack_days'] = attack_score_counts['MEDIUM']
    results['summary']['weak_attack_days'] = attack_score_counts['WEAK']
    
    logger.info(f"\n{'='*60}")
    logger.info(f"âœ… å¿…èƒœæ ·æœ¬æµ‹è¯•å®Œæˆ")
    logger.info(f"  æ€»æµ‹è¯•æ—¥æœŸ: {results['summary']['total_test_dates']}")
    logger.info(f"  æ€»ä¿¡å·æ•°: {results['summary']['total_signals']}")
    logger.info(f"  å¼ºæ”»å‡»: {results['summary']['strong_attack_days']}")
    logger.info(f"  ä¸­æ”»å‡»: {results['summary']['medium_attack_days']}")
    logger.info(f"  å¼±æ”»å‡»: {results['summary']['weak_attack_days']}")
    logger.info(f"  TRAPè¿‡æ»¤: {results['summary']['trap_days']}")
    logger.info(f"{'='*60}")
    
    return results

# ================= ä¸»å‡½æ•° =================

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='é¡½ä¸»è¡Œä¸ºå›æ”¾ï¼ˆLevel1æœ€å°æ–¹æ¡ˆï¼‰')
    parser.add_argument('--config', type=str, help='å¿…èƒœæ ·æœ¬æµ‹è¯•é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--max-stocks', type=int, default=None, help='æœ€å¤§è‚¡ç¥¨æ•°é‡ï¼ˆå–å‰Nåªï¼‰')
    parser.add_argument('--max-days', type=int, default=None, help='æ¯åªè‚¡ç¥¨æœ€å¤§å¤©æ•°ï¼ˆå–æœ€è¿‘Nä¸ªäº¤æ˜“æ—¥ï¼‰')
    args = parser.parse_args()
    
    logger.info("=" * 60)
    if args.config:
        logger.info("å¿…èƒœæ ·æœ¬æµ‹è¯•ï¼ˆLevel1æœ€å°æ–¹æ¡ˆï¼‰")
    else:
        logger.info("é¡½ä¸»150åª58å¤©Tickè¡Œä¸ºå›æ”¾ï¼ˆLevel1æœ€å°æ–¹æ¡ˆï¼‰")
    logger.info("=" * 60)
    
    if args.config:
        # å¿…èƒœæ ·æœ¬æµ‹è¯•æ¨¡å¼
        config_path = Path(args.config)
        if not config_path.exists():
            logger.error(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            return
        
        config = load_hot_cases_config(config_path)
        results = run_hot_cases_replay(config)
        
        # ä¿å­˜æŠ¥å‘Š
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_path = PROJECT_ROOT / 'backtest' / 'results' / f'hot_cases_5stocks_{timestamp}.json'
    else:
        # å…¨é‡å›æ”¾æ¨¡å¼
        stock_codes = load_wanzhu_stocks(CONFIG['wanzhu_csv'])
        if not stock_codes:
            logger.error("âŒ æ²¡æœ‰æ‰¾åˆ°é¡½ä¸»è‚¡ç¥¨åˆ—è¡¨")
            return
        
        results = run_wanzhu_behavior_replay(
            stock_codes=stock_codes,
            start_date=CONFIG['start_date'],
            end_date=CONFIG['end_date'],
            max_stocks=args.max_stocks,
            max_days=args.max_days
        )
        
        # ä¿å­˜æŠ¥å‘Š
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_path = PROJECT_ROOT / 'backtest' / 'results' / f'wanzhu_behavior_replay_{timestamp}.json'
    
    report_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2, default=str)
    
    logger.info(f"\nğŸ’¾ æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

if __name__ == '__main__':
    main()