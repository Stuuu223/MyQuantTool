"""
è‡ªä¸»å­¦ä¹ ç³»ç»Ÿ UI
æ”¯æŒAutoMLã€å› æœæ¨æ–­ã€åœ¨çº¿å­¦ä¹ å’Œäº¤æ˜“ä¿¡å·ç”Ÿæˆ
"""

import numpy as np
import streamlit as st
import pandas as pd
import plotly.graph_objects as go
from datetime import datetime, timedelta
from logic.autonomous_learning_system import AutonomousLearningSystem
from logic.data_manager import DataManager
from logic.akshare_data_loader import AKShareDataLoader
import logging

logger = logging.getLogger(__name__)


def render_autonomous_learning_tab(db: DataManager, config):
    """æ¸²æŸ“è‡ªä¸»å­¦ä¹ æ ‡ç­¾é¡µ"""
    
    st.title("ğŸ¤– çœŸæ­£çš„è‡ªä¸»å­¦ä¹ ç³»ç»Ÿ")
    st.markdown("---")
    
    st.info("""
    **æ ¸å¿ƒç‰¹æ€§**:
    - âœ… è‡ªåŠ¨ç‰¹å¾å‘ç°: è‡ªåŠ¨ç”Ÿæˆ100+ç‰¹å¾ï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç‰¹å¾
    - âœ… AutoML: è‡ªåŠ¨æ¯”è¾ƒ4ç§æ¨¡å‹ï¼Œé€‰æ‹©æœ€ä½³æ¨¡å‹
    - âœ… å› æœå‘ç°: çœŸæ­£çš„å› æœæ¨æ–­ï¼ˆæ ¼å…°æ°å› æœæ£€éªŒï¼‰
    - âœ… åœ¨çº¿å­¦ä¹ : æŒç»­ä»æ–°æ•°æ®ä¸­å­¦ä¹ 
    - âœ… å…ƒå­¦ä¹ : å¿«é€Ÿé€‚åº”æ–°ä»»åŠ¡ï¼ˆ10ä¸ªæ ·æœ¬ï¼‰
    - âœ… äº¤æ˜“ä¿¡å·: ç”Ÿæˆä¹°å…¥/å–å‡ºä¿¡å·
    """)
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    if 'autonomous_system' not in st.session_state:
        st.session_state.autonomous_system = AutonomousLearningSystem()
        st.session_state.model_trained = False
        st.session_state.trained_data = None
    
    system = st.session_state.autonomous_system
    
    # ä¾§è¾¹æ æ§åˆ¶ - ä¼˜åŒ–å¸ƒå±€
    with st.sidebar:
        st.header("âš™ï¸ æ§åˆ¶é¢æ¿")

        # æ•°æ®æºé€‰æ‹©
        with st.expander("ğŸ“Š æ•°æ®æº", expanded=True):
            data_source = st.selectbox(
                "é€‰æ‹©æ•°æ®æº",
                ["AkShareçœŸå®æ•°æ®", "æ¨¡æ‹Ÿæ•°æ®"],
                help="é€‰æ‹©ä½¿ç”¨çœŸå®æ•°æ®è¿˜æ˜¯æ¨¡æ‹Ÿæ•°æ®"
            )

            # è‚¡ç¥¨ä»£ç 
            if data_source == "AkShareçœŸå®æ•°æ®":
                stock_code = st.text_input(
                    "è‚¡ç¥¨ä»£ç ",
                    value="000001",
                    help="è‚¡ç¥¨ä»£ç ï¼Œä¾‹å¦‚ï¼š000001ï¼ˆå¹³å®‰é“¶è¡Œï¼‰"
                )

                period = st.selectbox(
                    "æ—¶é—´å‘¨æœŸ",
                    ["daily", "weekly", "monthly"],
                    index=0,
                    help="Kçº¿å‘¨æœŸ"
                )

        # è®­ç»ƒå‚æ•°
        with st.expander("ğŸ“ è®­ç»ƒå‚æ•°"):
            n_days = st.slider(
                "è®­ç»ƒå¤©æ•°",
                min_value=30,
                max_value=365,
                value=180,
                step=30,
                help="ç”¨äºè®­ç»ƒçš„å†å²æ•°æ®å¤©æ•°"
            )

        # äº¤æ˜“ä¿¡å·å‚æ•°
        with st.expander("ğŸ“ˆ äº¤æ˜“ä¿¡å·"):
            buy_threshold = st.slider(
                "ä¹°å…¥é˜ˆå€¼",
                min_value=-0.05,
                max_value=0.05,
                value=0.02,
                step=0.005,
                help="é¢„æµ‹ä¸Šæ¶¨è¶…è¿‡æ­¤é˜ˆå€¼æ—¶ä¹°å…¥"
            )

            sell_threshold = st.slider(
                "å–å‡ºé˜ˆå€¼",
                min_value=-0.05,
                max_value=0.05,
                value=-0.02,
                step=0.005,
                help="é¢„æµ‹ä¸‹è·Œè¶…è¿‡æ­¤é˜ˆå€¼æ—¶å–å‡º"
            )
        
        # ç³»ç»ŸçŠ¶æ€
        st.subheader("ğŸ“Š ç³»ç»ŸçŠ¶æ€")
        if st.session_state.model_trained:
            status = system.get_system_status()
            st.metric("è®­ç»ƒçŠ¶æ€", "âœ… å·²è®­ç»ƒ")
            st.metric("ç‰¹å¾æ•°é‡", status['n_features'])
            st.metric("æ¨¡å‹ç±»å‹", status['model_type'] or 'N/A')
            
            if status['system_state'].get('last_update'):
                st.metric("æœ€åæ›´æ–°", status['system_state']['last_update'][:19])
        else:
            st.metric("è®­ç»ƒçŠ¶æ€", "âŒ æœªè®­ç»ƒ")
    
    # ä¸»å†…å®¹åŒº
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("AutoML", "4ç§æ¨¡å‹")
    
    with col2:
        st.metric("ç‰¹å¾å·¥ç¨‹", "100+ç‰¹å¾")
    
    with col3:
        st.metric("å› æœæ¨æ–­", "æ ¼å…°æ°æ£€éªŒ")
    
    # æ•°æ®åŠ è½½å’Œè®­ç»ƒ
    st.markdown("---")
    st.header("ğŸ“Š æ•°æ®åŠ è½½ä¸è®­ç»ƒ")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        if st.button("ğŸš€ åŠ è½½æ•°æ®å¹¶è®­ç»ƒ", use_container_width=True):
            with st.spinner("æ­£åœ¨åŠ è½½æ•°æ®å¹¶è®­ç»ƒ..."):
                try:
                    # åŠ è½½æ•°æ®
                    if data_source == "AkShareçœŸå®æ•°æ®":
                        loader = AKShareDataLoader()
                        data = loader.get_stock_daily(
                            code=stock_code,
                            start_date=(datetime.now() - timedelta(days=n_days*2)).strftime('%Y%m%d'),
                            end_date=datetime.now().strftime('%Y%m%d'),
                            adjust="qfq"
                        )

                        if data is None or len(data) == 0:
                            st.error(f"æ— æ³•è·å–è‚¡ç¥¨ {stock_code} çš„æ•°æ®")
                            return

                        # æ£€æŸ¥æ•°æ®åˆ—å
                        st.info(f"è·å–åˆ°çš„æ•°æ®åˆ—: {list(data.columns)}")

                        # åªå–æœ€è¿‘n_dayså¤©
                        data = data.tail(n_days).reset_index(drop=True)

                        # ç¡®ä¿æ•°æ®åŒ…å«å¿…è¦çš„åˆ—
                        required_columns = ['æ—¥æœŸ', 'å¼€ç›˜', 'æ”¶ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æˆäº¤é‡']
                        missing_columns = [col for col in required_columns if col not in data.columns]

                        if missing_columns:
                            st.error(f"æ•°æ®ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_columns}")
                            st.error(f"å¯ç”¨åˆ—: {list(data.columns)}")
                            return

                        # é‡å‘½ååˆ—ä»¥åŒ¹é…ç³»ç»ŸæœŸæœ›çš„æ ¼å¼
                        column_mapping = {
                            'æ—¥æœŸ': 'date',
                            'å¼€ç›˜': 'open',
                            'æ”¶ç›˜': 'close',
                            'æœ€é«˜': 'high',
                            'æœ€ä½': 'low',
                            'æˆäº¤é‡': 'volume',
                            'æˆäº¤é¢': 'amount'
                        }
                        data = data.rename(columns=column_mapping)

                        st.success(f"æˆåŠŸè·å– {len(data)} æ¡çœŸå®æ•°æ®")
                    else:
                        # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
                        np.random.seed(42)
                        dates = pd.date_range(start=datetime.now() - timedelta(days=n_days), periods=n_days)
                        data = pd.DataFrame({
                            'date': dates,
                            'open': 100 + np.cumsum(np.random.normal(0, 1, n_days)),
                            'high': 100 + np.cumsum(np.random.normal(0, 1, n_days)) + np.random.uniform(0, 2, n_days),
                            'low': 100 + np.cumsum(np.random.normal(0, 1, n_days)) - np.random.uniform(0, 2, n_days),
                            'close': 100 + np.cumsum(np.random.normal(0, 1, n_days)),
                            'volume': np.random.uniform(1000000, 5000000, n_days),
                            'amount': (100 + np.cumsum(np.random.normal(0, 1, n_days))) * np.random.uniform(1000000, 5000000, n_days)
                        })
                        st.success(f"ç”Ÿæˆ {len(data)} æ¡æ¨¡æ‹Ÿæ•°æ®")

                    st.session_state.trained_data = data
                    
                    # è®­ç»ƒç³»ç»Ÿ
                    result = system.initialize(data, target='close')
                    
                    st.session_state.model_trained = True
                    st.success(f"è®­ç»ƒå®Œæˆï¼")
                    st.info(f"ç‰¹å¾æ•°é‡: {result['n_features']}")
                    st.info(f"æœ€ä½³æ¨¡å‹: {result['best_model_type']}")
                    st.info(f"æœ€ä½³åˆ†æ•°: {result['best_score']:.6f}")
                    
                except Exception as e:
                    st.error(f"è®­ç»ƒå¤±è´¥: {str(e)}")
                    logger.error(f"è®­ç»ƒå¤±è´¥: {e}", exc_info=True)
    
    # æ˜¾ç¤ºæ•°æ®
    if st.session_state.model_trained and st.session_state.trained_data is not None:
        data = st.session_state.trained_data
        
        with col2:
            st.subheader("ğŸ“ˆ æ•°æ®é¢„è§ˆ")
            st.dataframe(data.tail(10), use_container_width=True)
            
            # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡
            st.subheader("ğŸ“Š æ•°æ®ç»Ÿè®¡")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("æ•°æ®å¤©æ•°", len(data))
            with col2:
                st.metric("ä»·æ ¼èŒƒå›´", f"{data['close'].min():.2f} - {data['close'].max():.2f}")
            with col3:
                st.metric("å¹³å‡æˆäº¤é‡", f"{data['volume'].mean():.0f}")
    
    # äº¤æ˜“ä¿¡å·ç”Ÿæˆ
    if st.session_state.model_trained:
        st.markdown("---")
        st.header("ğŸ“ˆ äº¤æ˜“ä¿¡å·ç”Ÿæˆ")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            if st.button("ğŸ¯ ç”Ÿæˆäº¤æ˜“ä¿¡å·", use_container_width=True):
                with st.spinner("æ­£åœ¨ç”Ÿæˆäº¤æ˜“ä¿¡å·..."):
                    try:
                        data = st.session_state.trained_data
                        
                        # è·å–ç‰¹å¾
                        features, feature_df = system.feature_engine.discover_features(data, target='close')
                        
                        # åªé€‰æ‹©æ•°å€¼ç±»å‹çš„ç‰¹å¾
                        numeric_features = []
                        for feat in features:
                            if feat in feature_df.columns and pd.api.types.is_numeric_dtype(feature_df[feat]):
                                numeric_features.append(feat)
                        
                        # é¢„æµ‹
                        X = feature_df[numeric_features].fillna(0).values
                        predictions = system.model.predict(X)
                        
                        # è®¡ç®—æ”¶ç›Šç‡
                        actual_returns = data['close'].pct_change().fillna(0)
                        predicted_returns = pd.Series(predictions).pct_change().fillna(0)
                        
                        # ç”Ÿæˆä¿¡å·
                        signals = pd.DataFrame({
                            'date': data['date'],
                            'close': data['close'],
                            'predicted': predictions,
                            'predicted_return': predicted_returns,
                            'actual_return': actual_returns
                        })
                        
                        signals['signal'] = 'hold'
                        signals.loc[signals['predicted_return'] > buy_threshold, 'signal'] = 'buy'
                        signals.loc[signals['predicted_return'] < sell_threshold, 'signal'] = 'sell'
                        
                        st.session_state.signals = signals
                        
                        # æ˜¾ç¤ºä¿¡å·ç»Ÿè®¡
                        buy_count = (signals['signal'] == 'buy').sum()
                        sell_count = (signals['signal'] == 'sell').sum()
                        hold_count = (signals['signal'] == 'hold').sum()
                        
                        st.success("äº¤æ˜“ä¿¡å·ç”Ÿæˆå®Œæˆï¼")
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("ä¹°å…¥ä¿¡å·", buy_count, delta=f"{buy_count/len(signals)*100:.1f}%")
                        with col2:
                            st.metric("å–å‡ºä¿¡å·", sell_count, delta=f"{sell_count/len(signals)*100:.1f}%")
                        with col3:
                            st.metric("æŒæœ‰ä¿¡å·", hold_count, delta=f"{hold_count/len(signals)*100:.1f}%")
                        
                    except Exception as e:
                        st.error(f"ç”Ÿæˆä¿¡å·å¤±è´¥: {str(e)}")
                        logger.error(f"ç”Ÿæˆä¿¡å·å¤±è´¥: {e}", exc_info=True)
        
        # æ˜¾ç¤ºäº¤æ˜“ä¿¡å·
        if 'signals' in st.session_state:
            signals = st.session_state.signals
            
            with col2:
                st.subheader("ğŸ“Š ä¿¡å·åˆ†å¸ƒ")
                
                # ä¿¡å·åˆ†å¸ƒå›¾
                signal_counts = signals['signal'].value_counts()
                fig = go.Figure(data=[
                    go.Bar(name=signal, x=[signal], y=[count])
                    for signal, count in signal_counts.items()
                ])
                fig.update_layout(
                    title="äº¤æ˜“ä¿¡å·åˆ†å¸ƒ",
                    xaxis_title="ä¿¡å·ç±»å‹",
                    yaxis_title="æ•°é‡",
                    height=300
                )
                st.plotly_chart(fig, use_container_width=True)
            
            # æ˜¾ç¤ºä¿¡å·è¡¨æ ¼
            st.subheader("ğŸ“‹ äº¤æ˜“ä¿¡å·è¯¦æƒ…")
            
            # åªæ˜¾ç¤ºæœ‰ä¿¡å·çš„è¡Œ
            signal_df = signals[signals['signal'] != 'hold'].copy()
            if len(signal_df) > 0:
                # æ·»åŠ é¢œè‰²æ ‡è®°
                def highlight_signal(val):
                    if val == 'buy':
                        return 'background-color: #d4edda'
                    elif val == 'sell':
                        return 'background-color: #f8d7da'
                    return ''
                
                styled_df = signal_df.style.applymap(highlight_signal, subset=['signal'])
                st.dataframe(styled_df, use_container_width=True)
            else:
                st.info("å½“å‰æ²¡æœ‰ä¹°å…¥æˆ–å–å‡ºä¿¡å·")
            
            # ç»˜åˆ¶ä»·æ ¼å’Œä¿¡å·
            st.subheader("ğŸ“ˆ ä»·æ ¼èµ°åŠ¿ä¸ä¿¡å·")
            
            fig = go.Figure()
            
            # æ·»åŠ ä»·æ ¼çº¿
            fig.add_trace(go.Scatter(
                x=signals['date'],
                y=signals['close'],
                mode='lines',
                name='ä»·æ ¼',
                line=dict(color='blue', width=2)
            ))
            
            # æ·»åŠ ä¹°å…¥ä¿¡å·
            buy_signals = signals[signals['signal'] == 'buy']
            if len(buy_signals) > 0:
                fig.add_trace(go.Scatter(
                    x=buy_signals['date'],
                    y=buy_signals['close'],
                    mode='markers',
                    name='ä¹°å…¥',
                    marker=dict(color='green', size=10, symbol='triangle-up')
                ))
            
            # æ·»åŠ å–å‡ºä¿¡å·
            sell_signals = signals[signals['signal'] == 'sell']
            if len(sell_signals) > 0:
                fig.add_trace(go.Scatter(
                    x=sell_signals['date'],
                    y=sell_signals['close'],
                    mode='markers',
                    name='å–å‡º',
                    marker=dict(color='red', size=10, symbol='triangle-down')
                ))
            
            fig.update_layout(
                title="ä»·æ ¼èµ°åŠ¿ä¸äº¤æ˜“ä¿¡å·",
                xaxis_title="æ—¥æœŸ",
                yaxis_title="ä»·æ ¼",
                height=400,
                hovermode='x unified'
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    # å› æœæ¨ç†
    if st.session_state.model_trained:
        st.markdown("---")
        st.header("ğŸ§  å› æœæ¨ç†")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            question = st.text_area(
                "è¾“å…¥é—®é¢˜",
                value="å“ªäº›å› ç´ å½±å“è‚¡ä»·ï¼Ÿ",
                height=100,
                help="è¾“å…¥ä½ æƒ³äº†è§£çš„å› æœé—®é¢˜"
            )
            
            if st.button("ğŸ” è¿›è¡Œå› æœæ¨ç†", use_container_width=True):
                with st.spinner("æ­£åœ¨åˆ†æå› æœå…³ç³»..."):
                    try:
                        data = st.session_state.trained_data
                        reasoning = system.causal_reasoning(data, question)
                        st.session_state.causal_reasoning = reasoning
                    except Exception as e:
                        st.error(f"å› æœæ¨ç†å¤±è´¥: {str(e)}")
                        logger.error(f"å› æœæ¨ç†å¤±è´¥: {e}", exc_info=True)
        
        # æ˜¾ç¤ºæ¨ç†ç»“æœ
        if 'causal_reasoning' in st.session_state:
            with col2:
                st.subheader("ğŸ“Š æ¨ç†ç»“æœ")
                st.markdown(st.session_state.causal_reasoning)
    
    # ç³»ç»ŸçŠ¶æ€è¯¦æƒ…
    if st.session_state.model_trained:
        st.markdown("---")
        st.header("ğŸ“Š ç³»ç»ŸçŠ¶æ€è¯¦æƒ…")
        
        status = system.get_system_status()
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("ğŸ¯ ç‰¹å¾é‡è¦æ€§")
            if status['feature_importance']:
                # æ˜¾ç¤ºTop 10ç‰¹å¾
                top_features = sorted(
                    status['feature_importance'].items(),
                    key=lambda x: x[1],
                    reverse=True
                )[:10]
                
                feature_df = pd.DataFrame(top_features, columns=['ç‰¹å¾', 'é‡è¦æ€§'])
                st.dataframe(feature_df, use_container_width=True)
        
        with col2:
            st.subheader("ğŸ”— å› æœå…³ç³»å›¾")
            if status['causal_graph']:
                causal_df = pd.DataFrame([
                    {'åŸå› ': cause, 'ç»“æœ': effect, 'å¼ºåº¦': strength}
                    for cause, effects in status['causal_graph'].items()
                    for effect, strength in effects.items()
                ])
                st.dataframe(causal_df, use_container_width=True)
            else:
                st.info("æš‚æ— å› æœå…³ç³»æ•°æ®")
    
    # æŒç»­å­¦ä¹ 
    if st.session_state.model_trained:
        st.markdown("---")
        st.header("ğŸ”„ æŒç»­å­¦ä¹ ")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.info("ğŸ’¡ æŒç»­å­¦ä¹ å¯ä»¥è®©ç³»ç»Ÿä»æ–°æ•°æ®ä¸­ä¸æ–­æ”¹è¿›æ€§èƒ½")
            
            if st.button("ğŸ“¥ æ·»åŠ æ–°æ•°æ®å¹¶å­¦ä¹ ", use_container_width=True):
                with st.spinner("æ­£åœ¨æ·»åŠ æ–°æ•°æ®å¹¶å­¦ä¹ ..."):
                    try:
                        # ç”Ÿæˆæ–°æ•°æ®ï¼ˆæ¨¡æ‹Ÿï¼‰
                        n_new = 10
                        if data_source == "AkShareçœŸå®æ•°æ®":
                            # è·å–æœ€æ–°æ•°æ®
                            loader = AKShareDataLoader()
                            new_data = loader.get_stock_daily(
                                code=stock_code,
                                start_date=datetime.now().strftime('%Y%m%d'),
                                end_date=(datetime.now() + timedelta(days=1)).strftime('%Y%m%d'),
                                adjust="qfq"
                            )
                        else:
                            # æ¨¡æ‹Ÿæ–°æ•°æ®
                            last_price = st.session_state.trained_data['close'].iloc[-1]
                            last_date = st.session_state.trained_data['date'].iloc[-1]
                            # ç¡®ä¿last_dateæ˜¯datetimeå¯¹è±¡
                            if hasattr(last_date, 'to_pydatetime'):
                                last_date = last_date.to_pydatetime()
                            elif isinstance(last_date, pd.Timestamp):
                                last_date = last_date.to_pydatetime()
                            elif not isinstance(last_date, datetime):
                                last_date = datetime.combine(last_date, datetime.min.time())

                            new_dates = pd.date_range(
                                start=last_date + timedelta(days=1),
                                periods=n_new
                            )
                            new_data = pd.DataFrame({
                                'date': new_dates,
                                'open': last_price + np.cumsum(np.random.normal(0, 1, n_new)),
                                'high': last_price + np.cumsum(np.random.normal(0, 1, n_new)) + np.random.uniform(0, 2, n_new),
                                'low': last_price + np.cumsum(np.random.normal(0, 1, n_new)) - np.random.uniform(0, 2, n_new),
                                'close': last_price + np.cumsum(np.random.normal(0, 1, n_new)),
                                'volume': np.random.uniform(1000000, 5000000, n_new),
                                'amount': (last_price + np.cumsum(np.random.normal(0, 1, n_new))) * np.random.uniform(1000000, 5000000, n_new)
                            })
                        
                        # æŒç»­å­¦ä¹ 
                        result = system.continuous_learning(new_data, target='close')
                        
                        st.success(f"æŒç»­å­¦ä¹ å®Œæˆï¼")
                        st.info(f"æ–°æ ·æœ¬æ•°: {result['n_new_samples']}")
                        st.info(f"æ–°åˆ†æ•°: {result['new_score']:.6f}")
                        
                    except Exception as e:
                        st.error(f"æŒç»­å­¦ä¹ å¤±è´¥: {str(e)}")
                        logger.error(f"æŒç»­å­¦ä¹ å¤±è´¥: {e}", exc_info=True)
        
        with col2:
            st.subheader("ğŸ“ˆ å­¦ä¹ å†å²")
            if len(system.learning_history) > 0:
                history_df = pd.DataFrame(system.learning_history)
                st.dataframe(history_df, use_container_width=True)
            else:
                st.info("æš‚æ— å­¦ä¹ å†å²")