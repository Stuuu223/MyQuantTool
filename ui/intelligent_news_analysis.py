"""æ™ºèƒ½æ–°é—»åˆ†æUIé¡µé¢"""
import streamlit as st
import pandas as pd
import plotly.graph_objects as go
from logic.intelligent_news_analyzer import IntelligentNewsAnalyzer, NewsItem, NewsAnalysisResult
from logic.llm_interface import LLMManager, LLMMessage, get_llm_manager
from datetime import datetime


def render_intelligent_news_analysis_tab(db, config):
    """æ¸²æŸ“æ™ºèƒ½æ–°é—»åˆ†ææ ‡ç­¾é¡µ"""
    
    st.subheader("ğŸ“° æ™ºèƒ½æ–°é—»åˆ†æ")
    st.caption("åŸºäºå¤šå±‚è¿‡æ»¤æœºåˆ¶çš„æ™ºèƒ½æ–°é—»åˆ†æç³»ç»Ÿ")
    st.markdown("---")
    
    # è¯´æ˜
    st.info("""
    **å¤šå±‚è¿‡æ»¤æœºåˆ¶**ï¼š
    1. **è´¨é‡è¯„ä¼°**ï¼šæ¥æºå¯ä¿¡åº¦ã€æ—¶æ•ˆæ€§ã€å®Œæ•´æ€§ã€ä¿¡æ¯å¯†åº¦ã€æ ‡é¢˜è´¨é‡
    2. **ç›¸å…³æ€§è¯„ä¼°**ï¼šè‚¡ç¥¨ç›¸å…³æ€§ã€è¡Œä¸šç›¸å…³æ€§ã€ä¸»é¢˜ç›¸å…³æ€§
    3. **æƒ…ç»ªåˆ†æ**ï¼šæ­£é¢/è´Ÿé¢/ä¸­æ€§ï¼Œæƒ…ç»ªå¼ºåº¦ï¼Œå…³é”®è¯æå–
    4. **å½±å“åº¦è¯„ä¼°**ï¼šå¸‚åœºå½±å“ã€è¡Œä¸šå½±å“ã€ä¸ªè‚¡å½±å“ã€æŒç»­æ—¶é—´
    """)
    
    # è¾“å…¥åŒºåŸŸ
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ“ æ–°é—»ä¿¡æ¯")
        
        news_title = st.text_input(
            "æ–°é—»æ ‡é¢˜",
            value="æŸå…¬å¸å‘å¸ƒä¸šç»©é¢„å‘Šï¼Œå‡€åˆ©æ¶¦åŒæ¯”å¢é•¿50%",
            help="è¾“å…¥æ–°é—»æ ‡é¢˜"
        )
        
        news_content = st.text_area(
            "æ–°é—»å†…å®¹",
            value="æŸå…¬å¸ä»Šæ—¥å‘å¸ƒä¸šç»©é¢„å‘Šï¼Œé¢„è®¡2024å¹´ä¸ŠåŠå¹´å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿50%ï¼Œä¸»è¦å—ç›Šäºä¸»è¥ä¸šåŠ¡å¢é•¿å’Œæ–°äº§å“æ¨å‡ºã€‚å…¬å¸è¡¨ç¤ºï¼Œå°†ç»§ç»­åŠ å¤§ç ”å‘æŠ•å…¥ï¼Œæå‡å¸‚åœºç«äº‰åŠ›ã€‚å—æ­¤æ¶ˆæ¯å½±å“ï¼Œç›¸å…³æ¦‚å¿µè‚¡æœ‰æœ›å—ç›Šã€‚",
            height=150,
            help="è¾“å…¥æ–°é—»å†…å®¹"
        )
        
        news_source = st.text_input(
            "æ–°é—»æ¥æº",
            value="è¯åˆ¸æ—¶æŠ¥",
            help="è¾“å…¥æ–°é—»æ¥æº"
        )
    
    with col2:
        st.subheader("âš™ï¸ åˆ†æé…ç½®")
        
        target_stocks = st.text_input(
            "ç›®æ ‡è‚¡ç¥¨ä»£ç ",
            value="600519,000858",
            help="è¾“å…¥ç›®æ ‡è‚¡ç¥¨ä»£ç ï¼Œç”¨é€—å·åˆ†éš”"
        )
        
        # è¿‡æ»¤é˜ˆå€¼
        st.write("**è¿‡æ»¤é˜ˆå€¼**")
        quality_threshold = st.slider(
            "è´¨é‡é˜ˆå€¼",
            0, 100, 60,
            help="è´¨é‡è¯„åˆ†ä½äºæ­¤å€¼å°†è¢«è¿‡æ»¤"
        )
        
        relevance_threshold = st.slider(
            "ç›¸å…³æ€§é˜ˆå€¼",
            0, 100, 50,
            help="ç›¸å…³æ€§è¯„åˆ†ä½äºæ­¤å€¼å°†è¢«è¿‡æ»¤"
        )
        
        impact_threshold = st.slider(
            "å½±å“åº¦é˜ˆå€¼",
            0, 100, 50,
            help="å½±å“åº¦è¯„åˆ†ä½äºæ­¤å€¼å°†è¢«è¿‡æ»¤"
        )
        
        # LLMæä¾›å•†é€‰æ‹©
        st.write("**LLMæä¾›å•†**")
        llm_provider = st.selectbox(
            "é€‰æ‹©æä¾›å•†",
            ["local", "openai", "deepseek"],
            help="é€‰æ‹©ç”¨äºæƒ…ç»ªåˆ†æçš„LLMæä¾›å•†"
        )
        
        if llm_provider != "local":
            api_key = st.text_input(
                "APIå¯†é’¥",
                type="password",
                help=f"è¾“å…¥{llm_provider.upper()}çš„APIå¯†é’¥"
            )
    
    # åˆ†ææŒ‰é’®
    if st.button("ğŸ” å¼€å§‹åˆ†æ", key="analyze_news"):
        with st.spinner('æ™ºèƒ½åˆ†æç³»ç»Ÿæ­£åœ¨å·¥ä½œ...'):
            try:
                # éªŒè¯è¾“å…¥
                if not news_title or not news_content:
                    st.error("âŒ è¯·è¾“å…¥æ–°é—»æ ‡é¢˜å’Œå†…å®¹")
                    return
                
                # åˆ›å»ºæ–°é—»é¡¹
                news = NewsItem(
                    title=news_title,
                    content=news_content,
                    source=news_source,
                    publish_time=datetime.now(),
                    url="",
                    related_stocks=[s.strip() for s in target_stocks.split(',') if s.strip()]
                )
                
                # è·å–ç›®æ ‡è‚¡ç¥¨åˆ—è¡¨
                target_list = [s.strip() for s in target_stocks.split(',') if s.strip()]
                
                # é…ç½®LLMç®¡ç†å™¨
                llm_manager = get_llm_manager()
                
                if llm_provider != "local" and api_key:
                    from logic.llm_interface import OpenAIProvider, DeepSeekProvider
                    
                    if llm_provider == "openai":
                        provider = OpenAIProvider(api_key=api_key)
                    elif llm_provider == "deepseek":
                        provider = DeepSeekProvider(api_key=api_key)
                    
                    llm_manager.add_provider(llm_provider, provider)
                    llm_manager.set_default(llm_provider, llm_manager.providers[llm_provider].list_models()[0])
                
                # åˆ›å»ºåˆ†æå™¨
                analyzer = IntelligentNewsAnalyzer(llm_manager=llm_manager)
                
                # è®¾ç½®è¿‡æ»¤é˜ˆå€¼
                analyzer.quality_threshold = quality_threshold
                analyzer.relevance_threshold = relevance_threshold
                analyzer.impact_threshold = impact_threshold
                
                # æ‰§è¡Œåˆ†æ
                result = analyzer.analyze(news, target_list)
                
                # æ˜¾ç¤ºç»“æœ
                st.success(f"âœ… åˆ†æå®Œæˆï¼ç»¼åˆè¯„åˆ†: {result.overall_score:.1f}/100")
                
                # æ˜¾ç¤ºç»¼åˆå»ºè®®
                st.markdown("---")
                st.subheader("ğŸ¯ ç»¼åˆå»ºè®®")
                
                # æ ¹æ®é€šè¿‡çŠ¶æ€æ˜¾ç¤ºä¸åŒé¢œè‰²
                if result.passed_filters:
                    st.markdown(f"### âœ… {result.recommendation}")
                else:
                    st.markdown(f"### âŒ {result.recommendation}")
                
                # æ˜¾ç¤ºè¿‡æ»¤çŠ¶æ€
                if not result.passed_filters:
                    st.warning("**æœªé€šè¿‡è¿‡æ»¤åŸå› **ï¼š")
                    for reason in result.filter_reasons:
                        st.write(f"- {reason}")
                
                # æ˜¾ç¤ºç»¼åˆè¯„åˆ†
                col_score1, col_score2, col_score3, col_score4 = st.columns(4)
                with col_score1:
                    st.metric("ç»¼åˆè¯„åˆ†", f"{result.overall_score:.1f}/100")
                with col_score2:
                    st.metric("è´¨é‡è¯„åˆ†", f"{result.quality_score:.1f}/100")
                with col_score3:
                    st.metric("ç›¸å…³æ€§è¯„åˆ†", f"{result.relevance_score:.1f}/100")
                with col_score4:
                    st.metric("å½±å“åº¦è¯„åˆ†", f"{result.impact_score:.1f}/100")
                
                # æ˜¾ç¤ºæƒ…ç»ªåˆ†æ
                col_sent1, col_sent2 = st.columns(2)
                with col_sent1:
                    sentiment_emoji = "ğŸ˜Š" if result.sentiment == "positive" else "ğŸ˜Ÿ" if result.sentiment == "negative" else "ğŸ˜"
                    st.metric("æƒ…ç»ªå€¾å‘", f"{sentiment_emoji} {result.sentiment}")
                with col_sent2:
                    st.metric("æƒ…ç»ªå¼ºåº¦", f"{abs(result.sentiment_score)*100:.0f}%")
                
                # æ˜¾ç¤ºå››å±‚è¿‡æ»¤è¯¦ç»†ç»“æœ
                st.markdown("---")
                st.subheader("ğŸ“Š å››å±‚è¿‡æ»¤è¯¦ç»†ç»“æœ")
                
                # åˆ›å»ºé€‰é¡¹å¡
                tab1, tab2, tab3, tab4 = st.tabs(["ç¬¬ä¸€å±‚ï¼šè´¨é‡è¯„ä¼°", "ç¬¬äºŒå±‚ï¼šç›¸å…³æ€§è¯„ä¼°", "ç¬¬ä¸‰å±‚ï¼šæƒ…ç»ªåˆ†æ", "ç¬¬å››å±‚ï¼šå½±å“åº¦è¯„ä¼°"])
                
                with tab1:
                    st.write("**è´¨é‡è¯„ä¼°è¯¦æƒ…**")
                    
                    # è´¨é‡è¯„åˆ†é›·è¾¾å›¾
                    quality_data = {
                        'ç»´åº¦': ['æ¥æºå¯ä¿¡åº¦', 'æ—¶æ•ˆæ€§', 'å†…å®¹å®Œæ•´æ€§', 'ä¿¡æ¯å¯†åº¦', 'æ ‡é¢˜è´¨é‡'],
                        'å¾—åˆ†': [
                            result.quality_details.get('source', {}).get('score', 0),
                            result.quality_details.get('timeliness', {}).get('score', 0),
                            result.quality_details.get('completeness', {}).get('score', 0),
                            result.quality_details.get('density', {}).get('score', 0),
                            result.quality_details.get('title', {}).get('score', 0)
                        ],
                        'æ»¡åˆ†': [
                            result.quality_details.get('source', {}).get('max', 30),
                            result.quality_details.get('timeliness', {}).get('max', 25),
                            result.quality_details.get('completeness', {}).get('max', 20),
                            result.quality_details.get('density', {}).get('max', 15),
                            result.quality_details.get('title', {}).get('max', 10)
                        ]
                    }
                    
                    quality_df = pd.DataFrame(quality_data)
                    st.dataframe(quality_df, use_container_width=True, hide_index=True)
                    
                    # è´¨é‡è¯„åˆ†è¿›åº¦æ¡
                    st.write("**è´¨é‡è¯„åˆ†**")
                    st.progress(result.quality_score / 100)
                    st.write(f"{result.quality_score:.1f}/100")
                    
                    # è¯¦ç»†è¯´æ˜
                    with st.expander("æŸ¥çœ‹è¯¦ç»†è¯´æ˜"):
                        if 'source' in result.quality_details:
                            st.write(f"**æ¥æº**: {result.quality_details['source']['source']}")
                            st.write(f"å¾—åˆ†: {result.quality_details['source']['score']:.1f}/{result.quality_details['source']['max']}")
                        
                        if 'timeliness' in result.quality_details:
                            st.write(f"**å‘å¸ƒæ—¶é—´**: {result.quality_details['timeliness']['publish_time']}")
                            st.write(f"å¾—åˆ†: {result.quality_details['timeliness']['score']:.1f}/{result.quality_details['timeliness']['max']}")
                        
                        if 'completeness' in result.quality_details:
                            st.write(f"**å†…å®¹é•¿åº¦**: {result.quality_details['completeness']['content_length']} å­—ç¬¦")
                            st.write(f"å¾—åˆ†: {result.quality_details['completeness']['score']:.1f}/{result.quality_details['completeness']['max']}")
                
                with tab2:
                    st.write("**ç›¸å…³æ€§è¯„ä¼°è¯¦æƒ…**")
                    
                    # ç›¸å…³æ€§è¯„åˆ†é›·è¾¾å›¾
                    relevance_data = {
                        'ç»´åº¦': ['è‚¡ç¥¨ç›¸å…³æ€§', 'è¡Œä¸šç›¸å…³æ€§', 'ä¸»é¢˜ç›¸å…³æ€§'],
                        'å¾—åˆ†': [
                            result.relevance_details.get('stock_relevance', {}).get('score', 0),
                            result.relevance_details.get('industry_relevance', {}).get('score', 0),
                            result.relevance_details.get('topic_relevance', {}).get('score', 0)
                        ],
                        'æ»¡åˆ†': [
                            result.relevance_details.get('stock_relevance', {}).get('max', 40),
                            result.relevance_details.get('industry_relevance', {}).get('max', 30),
                            result.relevance_details.get('topic_relevance', {}).get('max', 30)
                        ]
                    }
                    
                    relevance_df = pd.DataFrame(relevance_data)
                    st.dataframe(relevance_df, use_container_width=True, hide_index=True)
                    
                    # ç›¸å…³æ€§è¯„åˆ†è¿›åº¦æ¡
                    st.write("**ç›¸å…³æ€§è¯„åˆ†**")
                    st.progress(result.relevance_score / 100)
                    st.write(f"{result.relevance_score:.1f}/100")
                    
                    # ç›¸å…³è‚¡ç¥¨
                    if news.related_stocks:
                        st.write(f"**ç›¸å…³è‚¡ç¥¨**: {', '.join(news.related_stocks)}")
                    
                    # ç›®æ ‡è‚¡ç¥¨åŒ¹é…åº¦
                    if target_list:
                        matched = set(news.related_stocks) & set(target_list)
                        st.write(f"**åŒ¹é…è‚¡ç¥¨**: {', '.join(matched) if matched else 'æ— '}")
                
                with tab3:
                    st.write("**æƒ…ç»ªåˆ†æè¯¦æƒ…**")
                    
                    # æƒ…ç»ªå¯è§†åŒ–
                    col_sent_a, col_sent_b = st.columns(2)
                    with col_sent_a:
                        sentiment_emoji = "ğŸ˜Š" if result.sentiment == "positive" else "ğŸ˜Ÿ" if result.sentiment == "negative" else "ğŸ˜"
                        st.metric("æƒ…ç»ªå€¾å‘", f"{sentiment_emoji} {result.sentiment}")
                    with col_sent_b:
                        st.metric("æƒ…ç»ªåˆ†æ•°", f"{result.sentiment_score:.2f}")
                    
                    # æƒ…ç»ªå¼ºåº¦æ¡
                    st.write("**æƒ…ç»ªå¼ºåº¦**")
                    intensity = abs(result.sentiment_score)
                    if result.sentiment == "positive":
                        st.success(f"æ­£é¢æƒ…ç»ªå¼ºåº¦: {intensity*100:.0f}%")
                        st.progress(intensity)
                    elif result.sentiment == "negative":
                        st.error(f"è´Ÿé¢æƒ…ç»ªå¼ºåº¦: {intensity*100:.0f}%")
                        st.progress(intensity)
                    else:
                        st.info(f"ä¸­æ€§æƒ…ç»ª: {intensity*100:.0f}%")
                        st.progress(intensity)
                    
                    # å…³é”®è¯
                    keywords = result.sentiment_details.get('keywords', [])
                    if keywords:
                        st.write("**å…³é”®æƒ…ç»ªè¯**:")
                        for kw in keywords:
                            st.write(f"- {kw}")
                
                with tab4:
                    st.write("**å½±å“åº¦è¯„ä¼°è¯¦æƒ…**")
                    
                    # å½±å“åº¦è¯„åˆ†é›·è¾¾å›¾
                    impact_data = {
                        'ç»´åº¦': ['å¸‚åœºå½±å“', 'è¡Œä¸šå½±å“', 'ä¸ªè‚¡å½±å“', 'æŒç»­æ—¶é—´'],
                        'å¾—åˆ†': [
                            result.impact_details.get('market_impact', {}).get('score', 0),
                            result.impact_details.get('industry_impact', {}).get('score', 0),
                            result.impact_details.get('stock_impact', {}).get('score', 0),
                            result.impact_details.get('duration', {}).get('score', 0)
                        ],
                        'æ»¡åˆ†': [
                            result.impact_details.get('market_impact', {}).get('max', 30),
                            result.impact_details.get('industry_impact', {}).get('max', 25),
                            result.impact_details.get('stock_impact', {}).get('max', 25),
                            result.impact_details.get('duration', {}).get('max', 20)
                        ]
                    }
                    
                    impact_df = pd.DataFrame(impact_data)
                    st.dataframe(impact_df, use_container_width=True, hide_index=True)
                    
                    # å½±å“åº¦è¯„åˆ†è¿›åº¦æ¡
                    st.write("**å½±å“åº¦è¯„åˆ†**")
                    st.progress(result.impact_score / 100)
                    st.write(f"{result.impact_score:.1f}/100")
                    
                    # ç›¸å…³è‚¡ç¥¨æ•°é‡
                    st.write(f"**ç›¸å…³è‚¡ç¥¨æ•°é‡**: {len(news.related_stocks)}")
                
                # ç»¼åˆè¯„åˆ†å¯è§†åŒ–
                st.markdown("---")
                st.subheader("ğŸ“ˆ ç»¼åˆè¯„åˆ†å¯è§†åŒ–")
                
                fig = _create_score_chart(result)
                st.plotly_chart(fig, use_container_width=True)
                
            except Exception as e:
                st.error(f"âŒ åˆ†æå¤±è´¥: {str(e)}")
                import traceback
                st.error(traceback.format_exc())
    
    # ä¾§è¾¹æ  - ç³»ç»Ÿè¯´æ˜
    with st.sidebar:
        st.markdown("---")
        st.subheader("ğŸ“– ç³»ç»Ÿè¯´æ˜")
        
        st.info("""
        **å¤šå±‚è¿‡æ»¤æœºåˆ¶**ï¼š
        
        æ¯å±‚è¿‡æ»¤éƒ½æœ‰ç‹¬ç«‹çš„è¯„åˆ†ç³»ç»Ÿï¼Œåªæœ‰é€šè¿‡æ‰€æœ‰å±‚çš„æ–°é—»æ‰ä¼šè¢«æ¨èã€‚
        
        **ç»¼åˆè¯„åˆ†è®¡ç®—**ï¼š
        - è´¨é‡è¯„åˆ† Ã— 30%
        - ç›¸å…³æ€§è¯„åˆ† Ã— 25%
        - æƒ…ç»ªå¼ºåº¦ Ã— 20%
        - å½±å“åº¦è¯„åˆ† Ã— 25%
        """)
        
        st.markdown("---")
        st.subheader("ğŸ¯ è¯„åˆ†æ ‡å‡†")
        
        st.info("""
        **ç»¼åˆè¯„åˆ†**ï¼š
        - 80-100åˆ†ï¼šå¼ºçƒˆæ¨èå…³æ³¨
        - 60-80åˆ†ï¼šæ¨èå…³æ³¨
        - 0-60åˆ†ï¼šå¯ä»¥å…³æ³¨
        - æœªé€šè¿‡è¿‡æ»¤ï¼šä¸å»ºè®®å…³æ³¨
        """)
        
        st.markdown("---")
        st.subheader("ğŸ¤– LLMæä¾›å•†")
        
        st.info("""
        **æ”¯æŒçš„æä¾›å•†**ï¼š
        - Localï¼šæœ¬åœ°è§„åˆ™ï¼ˆå…è´¹ï¼‰
        - OpenAIï¼šGPTç³»åˆ—ï¼ˆéœ€è¦APIå¯†é’¥ï¼‰
        - DeepSeekï¼šDeepSeekç³»åˆ—ï¼ˆéœ€è¦APIå¯†é’¥ï¼‰
        
        å¯ä»¥æ ¹æ®éœ€è¦é€‰æ‹©ä¸åŒçš„æä¾›å•†è¿›è¡Œæƒ…ç»ªåˆ†æã€‚
        """)


def _create_score_chart(result: NewsAnalysisResult):
    """åˆ›å»ºè¯„åˆ†å›¾è¡¨"""
    fig = go.Figure()
    
    # æ·»åŠ ç»¼åˆè¯„åˆ†
    fig.add_trace(go.Bar(
        x=['ç»¼åˆè¯„åˆ†'],
        y=[result.overall_score],
        name='ç»¼åˆè¯„åˆ†',
        marker_color='rgba(55, 128, 191, 0.8)'
    ))
    
    # æ·»åŠ å„å±‚è¯„åˆ†
    fig.add_trace(go.Bar(
        x=['è´¨é‡è¯„ä¼°', 'ç›¸å…³æ€§è¯„ä¼°', 'å½±å“åº¦è¯„ä¼°'],
        y=[result.quality_score, result.relevance_score, result.impact_score],
        name='å„å±‚è¯„åˆ†',
        marker_color='rgba(219, 64, 82, 0.8)'
    ))
    
    # æ·»åŠ é˜ˆå€¼çº¿
    fig.add_hline(y=result.quality_threshold, line_dash="dash", line_color="orange", 
                 annotation_text=f"è´¨é‡é˜ˆå€¼ {result.quality_threshold}")
    fig.add_hline(y=result.relevance_threshold, line_dash="dash", line_color="green", 
                 annotation_text=f"ç›¸å…³æ€§é˜ˆå€¼ {result.relevance_threshold}")
    fig.add_hline(y=result.impact_threshold, line_dash="dash", line_color="blue", 
                 annotation_text=f"å½±å“åº¦é˜ˆå€¼ {result.impact_threshold}")
    
    fig.update_layout(
        title="æ–°é—»åˆ†æè¯„åˆ†å¯¹æ¯”",
        height=400,
        xaxis_title="è¯„åˆ†ç±»å‹",
        yaxis_title="åˆ†æ•°",
        yaxis_range=[0, 100],
        showlegend=True,
        barmode='group'
    )
    
    return fig