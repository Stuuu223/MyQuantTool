#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å…¨æ¯å›æ¼”å¼•æ“ V2 - ä¼˜åŒ–ç‰ˆï¼ˆæ”¯æŒç¼“å­˜å’Œæ–­ç‚¹ç»­ä¼ ï¼‰

æ‰§è¡Œæµç¨‹ï¼š
1. Tushareç²—ç­›ï¼ˆ5000â†’~500ï¼‰
2. æˆäº¤é¢è¿‡æ»¤ï¼ˆ~500â†’~100ï¼‰
3. é‡æ¯”ç­›é€‰ï¼ˆ~100â†’Top 20ï¼‰
4. V18éªŒé’æœºç²¾ç®—

Author: AIé‡åŒ–å·¥ç¨‹å¸ˆ
Date: 2026-02-23
"""

import sys
import os
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple
import pandas as pd
import numpy as np
import json
import time

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).resolve().parent
sys.path.insert(0, str(PROJECT_ROOT))

from logic.core.metric_definitions import MetricDefinitions
from logic.core.sanity_guards import SanityGuards
from logic.core.path_resolver import PathResolver
from logic.utils.price_utils import get_pre_close, calc_true_change
from logic.utils.logger import get_logger

logger = get_logger(__name__)

try:
    from xtquant import xtdata
    HAS_QMT = True
except ImportError:
    HAS_QMT = False

try:
    import tushare as ts
    HAS_TUSHARE = True
except ImportError:
    HAS_TUSHARE = False

# Tushare Token
TUSHARE_TOKEN = "1430dca9cc3419b91928e162935065bcd3531fa82976fee8355d550b"


class HolographicBacktestEngine:
    """å…¨æ¯å›æ¼”å¼•æ“ V2"""
    
    def __init__(self, date: str, cache_dir: Optional[str] = None):
        self.date = date
        self.date_fmt = f"{date[:4]}-{date[4:6]}-{date[6:]}"
        
        # åˆå§‹åŒ–Tushare
        self.pro = None
        if HAS_TUSHARE:
            ts.set_token(TUSHARE_TOKEN)
            self.pro = ts.pro_api()
        
        # åˆå§‹åŒ–è·¯å¾„
        PathResolver.initialize()
        self.output_dir = PathResolver.get_data_dir() / "backtest_out"
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ç¼“å­˜ç›®å½•
        self.cache_dir = Path(cache_dir) if cache_dir else PathResolver.get_data_dir() / "cache" / "holographic"
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # ç»“æœå­˜å‚¨
        self.layer1_stocks: List[Dict] = []
        self.layer2_stocks: List[Dict] = []
        self.layer3_stocks: List[Dict] = []
        self.final_top10: List[Dict] = []
        
        logger.info(f"å…¨æ¯å›æ¼”å¼•æ“åˆå§‹åŒ–: {date}")
    
    def _get_cache_file(self, layer: str) -> Path:
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        return self.cache_dir / f"{self.date}_{layer}.json"
    
    def _load_cache(self, layer: str) -> Optional[List[Dict]]:
        """ä»ç¼“å­˜åŠ è½½æ•°æ®"""
        cache_file = self._get_cache_file(layer)
        if cache_file.exists():
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                logger.info(f"ä»ç¼“å­˜åŠ è½½ {layer}: {len(data)} æ¡")
                return data
            except Exception as e:
                logger.warning(f"ç¼“å­˜åŠ è½½å¤±è´¥: {e}")
        return None
    
    def _save_cache(self, layer: str, data: List[Dict]):
        """ä¿å­˜æ•°æ®åˆ°ç¼“å­˜"""
        cache_file = self._get_cache_file(layer)
        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        logger.info(f"ç¼“å­˜å·²ä¿å­˜ {layer}: {len(data)} æ¡")
    
    def layer1_tushare_coarse_filter(self, use_cache: bool = True) -> List[Dict]:
        """ç¬¬ä¸€å±‚ï¼šTushareç²—ç­›"""
        logger.info("=" * 60)
        logger.info("ç¬¬ä¸€å±‚ï¼šTushareç²—ç­›")
        logger.info("=" * 60)
        
        # å°è¯•ä»ç¼“å­˜åŠ è½½
        if use_cache:
            cached = self._load_cache('layer1')
            if cached:
                self.layer1_stocks = cached
                return cached
        
        if not self.pro:
            logger.error("Tushareæœªåˆå§‹åŒ–")
            return []
        
        try:
            # è·å–å…¨å¸‚åœºè‚¡ç¥¨åˆ—è¡¨
            df_basic = self.pro.stock_basic(exchange='', list_status='L', 
                                            fields='ts_code,name,industry,market')
            logger.info(f"å…¨å¸‚åœºè‚¡ç¥¨æ€»æ•°: {len(df_basic)}")
            
            # è¿‡æ»¤åŒ—äº¤æ‰€å’ŒST
            df_basic = df_basic[~df_basic['ts_code'].str.startswith(('8', '4'))]
            df_basic = df_basic[~df_basic['name'].str.contains('ST', na=False)]
            logger.info(f"è¿‡æ»¤åŒ—äº¤æ‰€å’ŒSTå: {len(df_basic)}")
            
            # è·å–å½“æ—¥è¡Œæƒ…æ•°æ®
            df_daily = self.pro.daily(trade_date=self.date)
            
            if df_daily is None or df_daily.empty:
                logger.error(f"è·å–{self.date}æ—¥è¡Œæƒ…æ•°æ®å¤±è´¥")
                return []
            
            # åˆå¹¶æ•°æ®
            df_merged = df_basic.merge(df_daily, on='ts_code', how='inner')
            df_merged = df_merged[df_merged['vol'] > 0]
            
            # è½¬æ¢ä¸ºåˆ—è¡¨
            stocks = []
            for _, row in df_merged.iterrows():
                stock = {
                    'ts_code': row['ts_code'],
                    'code': row['ts_code'].split('.')[0],
                    'name': row['name'],
                    'industry': row.get('industry', ''),
                    'market': row.get('market', ''),
                    'close': float(row['close']),
                    'open': float(row['open']),
                    'high': float(row['high']),
                    'low': float(row['low']),
                    'vol': float(row['vol']),
                    'amount': float(row['amount']),
                    'pre_close': float(row['pre_close']),
                }
                stocks.append(stock)
            
            self.layer1_stocks = stocks
            self._save_cache('layer1', stocks)
            logger.info(f"ç¬¬ä¸€å±‚ç­›é€‰å®Œæˆ: {len(stocks)} åªè‚¡ç¥¨")
            return stocks
            
        except Exception as e:
            logger.error(f"ç¬¬ä¸€å±‚ç­›é€‰å¤±è´¥: {e}", exc_info=True)
            return []
    
    def layer2_amount_filter(self, min_avg_amount: float = 3000, use_cache: bool = True) -> List[Dict]:
        """ç¬¬äºŒå±‚ï¼šæˆäº¤é¢è¿‡æ»¤"""
        logger.info("=" * 60)
        logger.info(f"ç¬¬äºŒå±‚ï¼šæˆäº¤é¢è¿‡æ»¤ > {min_avg_amount}ä¸‡")
        logger.info("=" * 60)
        
        if use_cache and not self.layer1_stocks:
            cached = self._load_cache('layer2')
            if cached:
                self.layer2_stocks = cached
                return cached
        
        if not self.pro:
            return []
        
        try:
            # è·å–å‰5ä¸ªäº¤æ˜“æ—¥
            end_date = datetime.strptime(self.date, "%Y%m%d")
            start_date = end_date - timedelta(days=30)
            start_date_str = start_date.strftime("%Y%m%d")
            
            df_trade_cal = self.pro.trade_cal(start_date=start_date_str, end_date=self.date)
            trade_days = df_trade_cal[df_trade_cal['is_open'] == 1]['cal_date'].tolist()
            
            if len(trade_days) < 6:
                logger.error(f"äº¤æ˜“æ—¥æ•°æ®ä¸è¶³: {len(trade_days)}å¤©")
                return []
            
            prev_5_days = trade_days[-6:-1]
            logger.info(f"å‰5ä¸ªäº¤æ˜“æ—¥: {prev_5_days}")
            
            filtered_stocks = []
            
            for i, stock in enumerate(self.layer1_stocks):
                try:
                    ts_code = stock['ts_code']
                    
                    # è·å–5æ—¥è¡Œæƒ…
                    df_5d = self.pro.daily(ts_code=ts_code, start_date=prev_5_days[0], 
                                           end_date=prev_5_days[-1])
                    
                    if df_5d is None or df_5d.empty or len(df_5d) < 3:
                        continue
                    
                    avg_amount = df_5d['amount'].mean()
                    
                    if avg_amount >= min_avg_amount:
                        stock['avg_amount_5d'] = float(avg_amount)
                        stock['avg_vol_5d'] = float(df_5d['vol'].mean())
                        filtered_stocks.append(stock)
                    
                    # æ¯10åªæ‰“å°ä¸€æ¬¡è¿›åº¦
                    if (i + 1) % 100 == 0:
                        logger.info(f"  å·²å¤„ç† {i+1}/{len(self.layer1_stocks)} åª")
                        
                except Exception as e:
                    continue
            
            self.layer2_stocks = filtered_stocks
            self._save_cache('layer2', filtered_stocks)
            logger.info(f"ç¬¬äºŒå±‚ç­›é€‰å®Œæˆ: {len(filtered_stocks)} åªè‚¡ç¥¨")
            return filtered_stocks
            
        except Exception as e:
            logger.error(f"ç¬¬äºŒå±‚ç­›é€‰å¤±è´¥: {e}", exc_info=True)
            return []
    
    def layer3_volume_ratio_filter(self, min_volume_ratio: float = 3.0, top_n: int = 20, 
                                   use_cache: bool = True) -> List[Dict]:
        """ç¬¬ä¸‰å±‚ï¼šé‡æ¯”ç­›é€‰"""
        logger.info("=" * 60)
        logger.info(f"ç¬¬ä¸‰å±‚ï¼šé‡æ¯”ç­›é€‰ Top {top_n} > {min_volume_ratio}")
        logger.info("=" * 60)
        
        if use_cache and not self.layer2_stocks:
            cached = self._load_cache('layer3')
            if cached:
                self.layer3_stocks = cached
                return cached
        
        try:
            stocks_with_ratio = []
            
            for stock in self.layer2_stocks:
                try:
                    if 'avg_vol_5d' in stock and stock['avg_vol_5d'] > 0:
                        volume_ratio = stock['vol'] / stock['avg_vol_5d']
                        
                        if volume_ratio >= min_volume_ratio:
                            stock['volume_ratio'] = float(volume_ratio)
                            stocks_with_ratio.append(stock)
                except Exception as e:
                    continue
            
            # æŒ‰é‡æ¯”æ’åºï¼Œå–Top N
            stocks_sorted = sorted(stocks_with_ratio, key=lambda x: x['volume_ratio'], reverse=True)
            top_stocks = stocks_sorted[:top_n]
            
            self.layer3_stocks = top_stocks
            self._save_cache('layer3', top_stocks)
            
            logger.info(f"ç¬¬ä¸‰å±‚ç­›é€‰å®Œæˆ: {len(top_stocks)} åªè‚¡ç¥¨")
            for i, s in enumerate(top_stocks, 1):
                logger.info(f"  {i}. {s['ts_code']} {s['name']} é‡æ¯”={s['volume_ratio']:.2f}")
            
            return top_stocks
            
        except Exception as e:
            logger.error(f"ç¬¬ä¸‰å±‚ç­›é€‰å¤±è´¥: {e}", exc_info=True)
            return []
    
    def calculate_base_score_v18(self, volume_ratio: float, true_change: float, 
                                   amount: float, max_amount_in_pool: float = 500000) -> float:
        """
        V18é«˜åˆ†è¾¨ç‡åŸºç¡€åˆ†è®¡ç®— - çº¿æ€§æå€¼æ˜ å°„
        
        ä¿®å¤P11-A3: åºŸé™¤ä¸€åˆ€åˆ‡40åˆ†ï¼Œå®ç°é«˜åˆ†è¾¨ç‡è¯„åˆ†
        20%æ¢æ‰‹ç¥¨çš„å¾—åˆ†æ˜¾è‘—é«˜äº5%æ¢æ‰‹ç¥¨
        
        Args:
            volume_ratio: é‡æ¯”
            true_change: çœŸå®æ¶¨å¹…(%)
            amount: å½“æ—¥æˆäº¤é¢(å…ƒ)
            max_amount_in_pool: å½“æ—¥æ± å†…æœ€å¤§æˆäº¤é¢ï¼Œç”¨äºå½’ä¸€åŒ–
            
        Returns:
            float: åŸºç¡€åˆ†(0-100)
        """
        # 1. é‡æ¯”ç»´åº¦ (0-40åˆ†) - é‡æ¯”10æ¯”é‡æ¯”3å¾—åˆ†é«˜
        # å‡è®¾é‡æ¯”èŒƒå›´0-20ï¼Œçº¿æ€§æ˜ å°„åˆ°0-40åˆ†
        turnover_score = min(volume_ratio / 20.0, 1.0) * 40.0
        
        # 2. æ¶¨å¹…ç»´åº¦ (0-30åˆ†) - æ¶¨å¹…15%æ¯”æ¶¨å¹…5%å¾—åˆ†é«˜
        # æ¶¨å¹…èŒƒå›´0-20%ï¼Œçº¿æ€§æ˜ å°„åˆ°0-30åˆ†
        change_score = min(abs(true_change) / 20.0, 1.0) * 30.0
        
        # 3. èµ„é‡‘å¼ºåº¦ç»´åº¦ (0-30åˆ†) - åŸºäºæˆäº¤é¢åœ¨æ± å†…çš„ç›¸å¯¹ä½ç½®
        if max_amount_in_pool > 0:
            capital_score = min(amount / max_amount_in_pool, 1.0) * 30.0
        else:
            capital_score = 15.0  # é»˜è®¤å€¼
        
        base_score = turnover_score + change_score + capital_score
        
        logger.debug(f"åŸºç¡€åˆ†è®¡ç®—: é‡æ¯”åˆ†={turnover_score:.1f}, æ¶¨å¹…åˆ†={change_score:.1f}, "
                    f"èµ„é‡‘åˆ†={capital_score:.1f}, æ€»åˆ†={base_score:.1f}")
        
        return base_score
    
    def apply_vwap_penalty(self, score: float, current_price: float, vwap: float) -> tuple[float, float]:
        """
        VWAPæƒ©ç½šæ‰£åˆ†åˆ¶ - ä¿®å¤P11-A4
        
        ä»·æ ¼ä½äºVWAPè¯´æ˜ä¸»åŠ›æ´¾å‘ï¼Œæ˜¯éª—ç‚®ç¥¨ä¿¡å·
        åºŸé™¤ä¹˜æ•°åˆ¶ï¼Œæ”¹ä¸ºæ‰£åˆ†åˆ¶
        
        Args:
            score: å½“å‰å¾—åˆ†
            current_price: å½“å‰ä»·æ ¼
            vwap: VWAPå‡ä»·
            
        Returns:
            tuple: (æ‰£åˆ†åå¾—åˆ†, æƒ©ç½šåˆ†å€¼)
        """
        penalty = 0.0
        
        if current_price < vwap:
            # è®¡ç®—åç¦»ç¨‹åº¦
            deviation = (vwap - current_price) / vwap
            
            # åç¦»è¶Šå¤§æ‰£åˆ†è¶Šå¤šï¼ˆæœ€å¤šæ‰£30åˆ†ï¼‰
            penalty = min(deviation * 100, 30)
            score -= penalty
            
            logger.warning(f"ğŸš¨ VWAPæƒ©ç½š: ä»·æ ¼{current_price:.2f}ä½äºå‡ä»·{vwap:.2f}, "
                          f"åç¦»{deviation*100:.1f}%, æ‰£åˆ†{penalty:.1f}")
        else:
            # ä»·æ ¼åœ¨VWAPä¸Šæ–¹ï¼Œç»™äºˆå°å¹…å¥–åŠ±ï¼ˆæœ€å¤š+5åˆ†ï¼‰
            deviation = (current_price - vwap) / vwap
            bonus = min(deviation * 50, 5)
            score += bonus
            logger.debug(f"âœ… VWAPå¥–åŠ±: ä»·æ ¼{current_price:.2f}é«˜äºå‡ä»·{vwap:.2f}, "
                        f"å¥–åŠ±{bonus:.1f}åˆ†")
        
        # ç¡®ä¿ä¸ä½äº0
        return max(0, score), penalty
    
    def apply_sustain_penalty(self, score: float, sustain_factor: float) -> tuple[float, float]:
        """
        Sustainæƒ©ç½šæ‰£åˆ†åˆ¶ - ä¿®å¤P11-A2
        
        åºŸé™¤Sustainä¹˜æ•°ï¼ˆé¿å…ä¸€ç¥¨å¦å†³å¯¼è‡´final_score=0.0ï¼‰
        æ”¹ä¸ºæ‰£åˆ†åˆ¶ï¼šæŒç»­æ€§å·®çš„ç¥¨æ‰£åˆ†ï¼Œå¥½çš„ä¸æ‰£åˆ†
        
        Args:
            score: å½“å‰å¾—åˆ†
            sustain_factor: æŒç»­æ€§å› å­(0-100)
            
        Returns:
            tuple: (æ‰£åˆ†åå¾—åˆ†, æƒ©ç½šåˆ†å€¼)
        """
        penalty = 0.0
        
        if sustain_factor < 50:
            # æŒç»­æ€§ä½äº50%ï¼Œæ‰£åˆ†ï¼ˆæœ€å¤šæ‰£25åˆ†ï¼‰
            penalty = (50 - sustain_factor) / 2  # 0-25åˆ†
            score -= penalty
            logger.warning(f"ğŸš¨ Sustainæƒ©ç½š: æŒç»­æ€§{sustain_factor:.1f}%è¿‡ä½, æ‰£åˆ†{penalty:.1f}")
        elif sustain_factor > 80:
            # æŒç»­æ€§å¥½ï¼Œç»™äºˆå°å¹…å¥–åŠ±ï¼ˆæœ€å¤š+5åˆ†ï¼‰
            bonus = (sustain_factor - 80) / 4  # 0-5åˆ†
            score += bonus
            logger.debug(f"âœ… Sustainå¥–åŠ±: æŒç»­æ€§{sustain_factor:.1f}%ä¼˜ç§€, å¥–åŠ±{bonus:.1f}åˆ†")
        
        return max(0, score), penalty
    
    def v18_precise_calculation(self) -> List[Dict]:
        """
        V18éªŒé’æœºç²¾ç®— - ä¿®å¤ç‰ˆ
        
        ä¿®å¤å†…å®¹:
        1. P11-A2: Sustainä»ä¹˜æ•°æ”¹ä¸ºæ‰£åˆ†åˆ¶ï¼Œé¿å…final_score=0.0
        2. P11-A3: åŸºç¡€åˆ†ä»é«˜åˆ†è¾¨ç‡çº¿æ€§æ˜ å°„è®¡ç®—
        3. P11-A4: VWAPä»ä¹˜æ•°æ”¹ä¸ºæ‰£åˆ†åˆ¶
        """
        logger.info("=" * 60)
        logger.info("V18éªŒé’æœºç²¾ç®— (P11ä¿®å¤ç‰ˆ)")
        logger.info("ä¿®å¤: Sustainæƒ©ç½šåˆ¶/VWAPæƒ©ç½šåˆ¶/é«˜åˆ†è¾¨ç‡åŸºç¡€åˆ†")
        logger.info("=" * 60)
        
        if not HAS_QMT:
            logger.error("QMTä¸å¯ç”¨")
            return []
        
        try:
            results = []
            
            # å…ˆè®¡ç®—æ± å†…æœ€å¤§æˆäº¤é¢ï¼Œç”¨äºåŸºç¡€åˆ†å½’ä¸€åŒ–
            max_amount_in_pool = max([s.get('amount', 0) for s in self.layer3_stocks]) if self.layer3_stocks else 0
            logger.info(f"æ± å†…æœ€å¤§æˆäº¤é¢: {max_amount_in_pool/10000:.0f}ä¸‡")
            
            for stock in self.layer3_stocks:
                try:
                    ts_code = stock['ts_code']
                    code = stock['code']
                    name = stock['name']
                    amount = float(stock.get('amount', 0))
                    
                    # æ ‡å‡†åŒ–ä»£ç æ ¼å¼
                    if code.startswith('6'):
                        qmt_code = f"{code}.SH"
                    else:
                        qmt_code = f"{code}.SZ"
                    
                    logger.info(f"å¤„ç†: {qmt_code} {name}")
                    
                    # è·å–æ˜¨æ”¶ä»·
                    try:
                        pre_close = get_pre_close(qmt_code, self.date)
                    except Exception as e:
                        logger.warning(f"è·å–æ˜¨æ”¶ä»·å¤±è´¥ {qmt_code}: {e}")
                        continue
                    
                    # ä¸‹è½½Tickæ•°æ®ï¼ˆ09:30-09:45ï¼‰
                    start_time = f"{self.date}093000"
                    end_time = f"{self.date}094500"
                    
                    xtdata.download_history_data(
                        stock_code=qmt_code,
                        period='tick',
                        start_time=start_time,
                        end_time=end_time
                    )
                    
                    ticks = xtdata.get_local_data(
                        field_list=['time', 'lastPrice', 'volume', 'amount'],
                        stock_code_list=[qmt_code],
                        period='tick',
                        start_time=start_time,
                        end_time=end_time
                    )
                    
                    if qmt_code not in ticks or ticks[qmt_code] is None or ticks[qmt_code].empty:
                        logger.warning(f"æ— Tickæ•°æ®: {qmt_code}")
                        continue
                    
                    df_ticks = ticks[qmt_code]
                    
                    # æ‰¾åˆ°09:40çš„ä»·æ ¼
                    target_time = f"{self.date}094000"
                    target_ts = datetime.strptime(target_time, "%Y%m%d%H%M%S").timestamp() * 1000
                    
                    df_ticks['time_diff'] = abs(df_ticks['time'] - target_ts)
                    nearest_idx = df_ticks['time_diff'].idxmin()
                    price_0940 = float(df_ticks.loc[nearest_idx, 'lastPrice'])
                    
                    # è·å–å¼€ç›˜ä»·
                    open_time = f"{self.date}093000"
                    open_ts = datetime.strptime(open_time, "%Y%m%d%H%M%S").timestamp() * 1000
                    df_ticks['open_diff'] = abs(df_ticks['time'] - open_ts)
                    open_idx = df_ticks['open_diff'].idxmin()
                    open_price = float(df_ticks.loc[open_idx, 'lastPrice'])
                    
                    # è®¡ç®—çœŸå®æ¶¨å¹…ï¼ˆåŸºäºæ˜¨æ”¶ä»·ï¼‰
                    true_change_0940 = MetricDefinitions.TRUE_CHANGE(price_0940, pre_close)
                    
                    # è®¡ç®—VWAPï¼ˆ09:30-09:40ï¼‰
                    df_morning = df_ticks[df_ticks['time'] <= target_ts]
                    vwap = price_0940
                    if len(df_morning) > 0:
                        vol_diff = df_morning['volume'].diff().fillna(0)
                        price_x_vol = df_morning['lastPrice'] * vol_diff
                        total_amount = price_x_vol.sum()
                        total_volume = vol_diff.sum()
                        if total_volume > 0:
                            vwap = float(total_amount / total_volume)
                    
                    # Sustainå› å­ï¼ˆä»…ç”¨äºè®°å½•å’Œæƒ©ç½šï¼Œä¸ç”¨äºä¹˜æ•°ï¼‰
                    time_0935 = f"{self.date}093500"
                    ts_0935 = datetime.strptime(time_0935, "%Y%m%d%H%M%S").timestamp() * 1000
                    df_sustain = df_ticks[(df_ticks['time'] >= ts_0935) & (df_ticks['time'] <= target_ts)]
                    
                    sustain_factor = 100.0  # é»˜è®¤100%
                    if len(df_sustain) > 0:
                        sustain_threshold = open_price * 0.98
                        sustain_count = len(df_sustain[df_sustain['lastPrice'] >= sustain_threshold])
                        sustain_factor = sustain_count / len(df_sustain) * 100
                    
                    # èµ„é‡‘å æ¯”
                    capital_share_pct = amount / 10000
                    
                    # ==================== V18è¯„åˆ†è®¡ç®—ï¼ˆä¿®å¤ç‰ˆï¼‰ ====================
                    volume_ratio = stock.get('volume_ratio', 1)
                    
                    # 1. è®¡ç®—é«˜åˆ†è¾¨ç‡åŸºç¡€åˆ† (P11-A3)
                    base_score = self.calculate_base_score_v18(
                        volume_ratio, true_change_0940, amount, max_amount_in_pool
                    )
                    
                    # 2. æ¶¨å¹…ä¹˜æ•°ï¼ˆä¿ç•™ä½†è°ƒæ•´èŒƒå›´ï¼‰
                    multiplier = 1.0 + (true_change_0940 / 200)  # æ¶¨å¹…10% -> ä¹˜æ•°1.05
                    
                    # 3. åˆæ­¥å¾—åˆ†
                    preliminary_score = base_score * multiplier
                    
                    # 4. åº”ç”¨VWAPæƒ©ç½š (P11-A4)
                    score_after_vwap, vwap_penalty = self.apply_vwap_penalty(
                        preliminary_score, price_0940, vwap
                    )
                    
                    # 5. åº”ç”¨Sustainæƒ©ç½š (P11-A2)
                    final_score, sustain_penalty = self.apply_sustain_penalty(
                        score_after_vwap, sustain_factor
                    )
                    
                    # 6. å°é¡¶100åˆ†
                    final_score = min(final_score, 100.0)
                    
                    # è°ƒè¯•ä¿¡æ¯
                    logger.info(f"  ğŸ“Š {qmt_code} åŸºç¡€åˆ†={base_score:.1f}, ä¹˜æ•°={multiplier:.3f}, "
                               f"VWAPæƒ©ç½š={vwap_penalty:.1f}, Sustainæƒ©ç½š={sustain_penalty:.1f}, "
                               f"æœ€ç»ˆå¾—åˆ†={final_score:.1f}")
                    
                    result = {
                        'stock_code': qmt_code,
                        'name': name,
                        'pre_close': float(pre_close),
                        'open_price': float(open_price),
                        'price_0940': float(price_0940),
                        'true_change_0940': round(true_change_0940, 2),
                        'volume_ratio': round(volume_ratio, 2),
                        'vwap': round(vwap, 2),
                        'sustain_factor': round(sustain_factor, 2),
                        'capital_share_pct': round(capital_share_pct, 2),
                        'base_score': round(base_score, 2),
                        'multiplier': round(multiplier, 3),
                        'vwap_penalty': round(vwap_penalty, 2),
                        'sustain_penalty': round(sustain_penalty, 2),
                        'final_score': round(final_score, 2),
                        'scoring_formula': 'base_score * multiplier - vwap_penalty - sustain_penalty'
                    }
                    
                    results.append(result)
                    
                except Exception as e:
                    logger.error(f"V18ç²¾ç®—å¤±è´¥ {stock['ts_code']}: {e}")
                    continue
            
            # æŒ‰ç»¼åˆå¾—åˆ†æ’åºï¼Œå–Top 10
            results_sorted = sorted(results, key=lambda x: x['final_score'], reverse=True)
            self.final_top10 = results_sorted[:10]
            
            # ä¿å­˜å®Œæ•´ç»“æœåˆ°ç¼“å­˜
            self._save_cache('v18_full', results_sorted)
            
            logger.info(f"V18ç²¾ç®—å®Œæˆ: {len(self.final_top10)} åªè‚¡ç¥¨")
            
            # æ‰“å°ä¿®å¤éªŒè¯ä¿¡æ¯
            non_zero_scores = [r for r in results if r['final_score'] > 0]
            logger.info(f"âœ… ä¿®å¤éªŒè¯: {len(non_zero_scores)}/{len(results)} åªè‚¡ç¥¨final_score>0")
            
            return self.final_top10
            
        except Exception as e:
            logger.error(f"V18ç²¾ç®—å¤±è´¥: {e}", exc_info=True)
            return []
    
    def find_zhitexincai_ranking(self) -> Dict:
        """æŸ¥æ‰¾å¿—ç‰¹æ–°ææ’å"""
        target_code = "300986.SZ"
        
        # åŠ è½½å®Œæ•´V18ç»“æœ
        cache_file = self._get_cache_file('v18_full')
        if cache_file.exists():
            with open(cache_file, 'r', encoding='utf-8') as f:
                all_results = json.load(f)
        else:
            all_results = self.final_top10
        
        for i, stock in enumerate(all_results, 1):
            if stock['stock_code'] == target_code:
                return {
                    'rank': i,
                    'in_top10': i <= 10,
                    'data': stock
                }
        
        return {'rank': -1, 'in_top10': False, 'data': None}
    
    def generate_report(self) -> Dict:
        """ç”ŸæˆæŠ¥å‘Š"""
        report = {
            'date': self.date,
            'layer1_count': len(self.layer1_stocks),
            'layer2_count': len(self.layer2_stocks),
            'layer3_count': len(self.layer3_stocks),
            'final_top10': [{'rank': i + 1, **stock} for i, stock in enumerate(self.final_top10)],
            'zhitexincai': self.find_zhitexincai_ranking()
        }
        return report
    
    def save_report(self, report: Dict) -> str:
        """ä¿å­˜æŠ¥å‘Š"""
        output_file = self.output_dir / f"{self.date}_holographic_report.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        logger.info(f"æŠ¥å‘Šå·²ä¿å­˜: {output_file}")
        return str(output_file)
    
    def run_full_backtest(self) -> Dict:
        """æ‰§è¡Œå®Œæ•´å›æ¼”"""
        logger.info(f"\n{'='*60}")
        logger.info(f"å¼€å§‹å…¨æ¯å›æ¼”: {self.date}")
        logger.info(f"{'='*60}\n")
        
        # å››å±‚ç­›é€‰
        self.layer1_tushare_coarse_filter()
        self.layer2_amount_filter()
        self.layer3_volume_ratio_filter()
        self.v18_precise_calculation()
        
        # ç”Ÿæˆå¹¶ä¿å­˜æŠ¥å‘Š
        report = self.generate_report()
        self.save_report(report)
        self._print_summary(report)
        
        return report
    
    def _print_summary(self, report: Dict):
        """æ‰“å°æ‘˜è¦"""
        logger.info(f"\n{'='*60}")
        logger.info("å…¨æ¯å›æ¼”æŠ¥å‘Šæ‘˜è¦")
        logger.info(f"{'='*60}")
        logger.info(f"æ—¥æœŸ: {report['date']}")
        logger.info(f"ç¬¬ä¸€å±‚(Tushareç²—ç­›): {report['layer1_count']} åª")
        logger.info(f"ç¬¬äºŒå±‚(æˆäº¤é¢è¿‡æ»¤): {report['layer2_count']} åª")
        logger.info(f"ç¬¬ä¸‰å±‚(é‡æ¯”ç­›é€‰): {report['layer3_count']} åª")
        
        logger.info("\nTop 10 æ’å:")
        for stock in report['final_top10']:
            logger.info(f"  {stock['rank']}. {stock['stock_code']} {stock['name']} "
                       f"æ¶¨å¹…={stock['true_change_0940']:.2f}% "
                       f"é‡æ¯”={stock['volume_ratio']:.2f} "
                       f"å¾—åˆ†={stock['final_score']:.2f}")
        
        ztxc = report['zhitexincai']
        if ztxc['rank'] > 0:
            logger.info(f"\nå¿—ç‰¹æ–°æ(300986.SZ) æ’å: {ztxc['rank']} "
                       f"({'åœ¨Top10å†…' if ztxc['in_top10'] else 'ä¸åœ¨Top10'})")
        else:
            logger.info("\nå¿—ç‰¹æ–°æ(300986.SZ) æœªè¿›å…¥æœ€ç»ˆæ’å")
        
        logger.info(f"{'='*60}\n")


def run_single_date(date: str) -> Optional[Dict]:
    """æ‰§è¡Œå•æ—¥å›æ¼”"""
    try:
        engine = HolographicBacktestEngine(date)
        return engine.run_full_backtest()
    except Exception as e:
        logger.error(f"å¤„ç†æ—¥æœŸ {date} å¤±è´¥: {e}", exc_info=True)
        return None


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    parser = argparse.ArgumentParser(description='å…¨æ¯å›æ¼”å¼•æ“')
    parser.add_argument('--date', type=str, help='æ—¥æœŸ (YYYYMMDD)')
    parser.add_argument('--all', action='store_true', help='æ‰§è¡Œæ‰€æœ‰æ—¥æœŸ')
    args = parser.parse_args()
    
    if args.all:
        dates = ['20251231', '20260105']
        reports = {}
        for date in dates:
            reports[date] = run_single_date(date)
        
        # å¯¹æ¯”æ’å
        if '20251231' in reports and '20260105' in reports:
            logger.info("\n" + "=" * 60)
            logger.info("å¿—ç‰¹æ–°ææ’åå¯¹æ¯”")
            logger.info("=" * 60)
            rank_1231 = reports['20251231']['zhitexincai']['rank'] if reports['20251231'] else -1
            rank_0105 = reports['20260105']['zhitexincai']['rank'] if reports['20260105'] else -1
            logger.info(f"12æœˆ31æ—¥æ’å: {rank_1231 if rank_1231 > 0 else 'æœªå…¥æ¦œ'}")
            logger.info(f"1æœˆ5æ—¥æ’å: {rank_0105 if rank_0105 > 0 else 'æœªå…¥æ¦œ'}")
    
    elif args.date:
        run_single_date(args.date)
    
    else:
        # é»˜è®¤æ‰§è¡Œ12æœˆ31æ—¥
        run_single_date('20251231')


if __name__ == "__main__":
    main()
