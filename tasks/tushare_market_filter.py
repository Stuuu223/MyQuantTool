#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ã€CTOæŒ‡ä»¤ã€‘Tushareäº‘ç«¯ç²—ç­›è„šæœ¬
ä»»åŠ¡ï¼šç”¨Tushare Proåœ¨äº‘ç«¯å®Œæˆç¬¬ä¸€æ®µç²—ç­›ï¼ˆ5000â†’200ï¼‰ï¼Œç»ä¸ç¢°QMTå†å²æ•°æ®

æ¶æ„ï¼šäº‘ç«¯ç²—ç­› + æœ¬åœ°ç²¾ç‚¼
- Layer 1: Tushareè·å–å…¨å¸‚åœºåŸºç¡€æ•°æ®ï¼ˆST/åœç‰Œè¿‡æ»¤ï¼‰
- Layer 2: Tushareè·å–å‰5æ—¥æˆäº¤é¢ï¼ˆæ—¥å‡>3000ä¸‡ï¼‰
- Layer 3: Tushare/æç®€QMTè·å–æ—©ç›˜é‡æ¯”ï¼ˆ>3ï¼‰

è¾“å‡ºï¼š20251231_candidates_200.csvï¼ˆçœŸå®å¼‚åŠ¨è‚¡ç¥¨åå•ï¼‰
"""

import sys
sys.path.insert(0, 'E:\\MyQuantTool')

import pandas as pd
import tushare as ts
from datetime import datetime, timedelta
from pathlib import Path
import time
import json

# é…ç½®
TOKEN_FILE = Path('E:/MyQuantTool/config/tushare_token.txt')
OUTPUT_DIR = Path('E:/MyQuantTool/data/scan_results')
TRADE_DATE = '20251231'  # ç›®æ ‡äº¤æ˜“æ—¥

# è¿‡æ»¤å‚æ•°
MIN_AVG_AMOUNT = 3000  # ä¸‡å…ƒï¼Œ5æ—¥æ—¥å‡æˆäº¤é¢åº•çº¿
VOLUME_RATIO_THRESHOLD = 3.0  # é‡æ¯”é˜ˆå€¼
MAX_OUTPUT = 200  # æœ€å¤§è¾“å‡ºæ•°é‡


def get_tushare_token() -> str:
    """è¯»å–Tushare Token"""
    if TOKEN_FILE.exists():
        token = TOKEN_FILE.read_text().strip()
        if token and not token.startswith('æ›¿æ¢'):
            return token
    raise ValueError("è¯·å…ˆé…ç½®Tushare Tokenåˆ° config/tushare_token.txt")


def init_tushare():
    """åˆå§‹åŒ–Tushare Pro"""
    token = get_tushare_token()
    ts.set_token(token)
    return ts.pro_api()


def layer1_static_filter(pro) -> pd.DataFrame:
    """
    Layer 1: Tushareé™æ€è¿‡æ»¤ï¼ˆ5000â†’çº¦4500ï¼‰
    - å‰”é™¤ST/*ST/é€€å¸‚
    - å‰”é™¤åŒ—äº¤æ‰€ï¼ˆ8/4å¼€å¤´ï¼‰
    - å‰”é™¤åœç‰Œ
    """
    print("\n" + "="*80)
    print("ã€Layer 1ã€‘Tushareé™æ€è¿‡æ»¤")
    print("="*80)
    
    # è·å–å…¨å¸‚åœºè‚¡ç¥¨åŸºç¡€ä¿¡æ¯
    df = pro.stock_basic(exchange='', list_status='L', 
                         fields='ts_code,symbol,name,area,industry,list_date')
    print(f"   å…¨å¸‚åœºè‚¡ç¥¨æ€»æ•°: {len(df)}")
    
    # å‰”é™¤åŒ—äº¤æ‰€ï¼ˆ8/4å¼€å¤´ï¼‰
    df = df[~df['ts_code'].str.startswith(('8', '4'))]
    print(f"   å‰”é™¤åŒ—äº¤æ‰€å: {len(df)}")
    
    # å‰”é™¤STï¼ˆåç§°ä¸­åŒ…å«STï¼‰
    df = df[~df['name'].str.contains('ST', na=False)]
    print(f"   å‰”é™¤STå: {len(df)}")
    
    return df


def layer2_amount_filter(pro, df_base: pd.DataFrame, trade_date: str) -> pd.DataFrame:
    """
    Layer 2: Tushareæˆäº¤é¢è¿‡æ»¤ï¼ˆçº¦4500â†’çº¦800ï¼‰
    - è®¡ç®—å‰5æ—¥æ—¥å‡æˆäº¤é¢
    - å‰”é™¤<3000ä¸‡çš„æ­»æ°´ç¥¨
    """
    print("\n" + "="*80)
    print("ã€Layer 2ã€‘Tushareæˆäº¤é¢è¿‡æ»¤")
    print("="*80)
    
    # è®¡ç®—å‰5ä¸ªäº¤æ˜“æ—¥
    date_obj = datetime.strptime(trade_date, '%Y%m%d')
    dates = []
    for i in range(1, 10):  # æœ€å¤šå¾€å‰æ‰¾10å¤©
        d = date_obj - timedelta(days=i)
        d_str = d.strftime('%Y%m%d')
        # ç®€å•åˆ¤æ–­æ˜¯å¦ä¸ºäº¤æ˜“æ—¥ï¼ˆéå‘¨æœ«ï¼‰
        if d.weekday() < 5:  # 0-4æ˜¯å‘¨ä¸€åˆ°å‘¨äº”
            dates.append(d_str)
        if len(dates) >= 5:
            break
    
    print(f"   åˆ†ææ—¥æœŸèŒƒå›´: {dates[-1]} è‡³ {dates[0]}")
    
    # æ‰¹é‡è·å–æ—¥çº¿æ•°æ®ï¼ˆå‰å¤æƒï¼‰
    all_daily = []
    for date in dates:
        try:
            df_daily = pro.daily(trade_date=date, fields='ts_code,amount')
            if not df_daily.empty:
                all_daily.append(df_daily)
                print(f"   âœ… {date}: {len(df_daily)}åª")
            time.sleep(0.5)  # é¿å…é™æµ
        except Exception as e:
            print(f"   âŒ {date}: {e}")
    
    if not all_daily:
        raise ValueError("æ— æ³•è·å–å†å²æ—¥çº¿æ•°æ®")
    
    # åˆå¹¶å¹¶è®¡ç®—5æ—¥å¹³å‡æˆäº¤é¢
    df_all = pd.concat(all_daily)
    df_avg = df_all.groupby('ts_code')['amount'].mean().reset_index()
    df_avg.columns = ['ts_code', 'avg_amount_5d']
    
    # åˆå¹¶åˆ°åŸºç¡€æ•°æ®
    df = df_base.merge(df_avg, on='ts_code', how='inner')
    
    # è¿‡æ»¤ï¼šæ—¥å‡æˆäº¤é¢>3000ä¸‡ï¼ˆamountå•ä½æ˜¯åƒå…ƒï¼Œæ‰€ä»¥3000ä¸‡=30000åƒå…ƒï¼‰
    df = df[df['avg_amount_5d'] >= MIN_AVG_AMOUNT * 10]  # Tushare amountå•ä½æ˜¯åƒå…ƒ
    
    print(f"   5æ—¥æ—¥å‡æˆäº¤>{MIN_AVG_AMOUNT}ä¸‡: {len(df)}åª")
    
    return df


def layer3_volume_ratio_filter(pro, df_base: pd.DataFrame, trade_date: str) -> pd.DataFrame:
    """
    Layer 3: Tushareé‡æ¯”è¿‡æ»¤ï¼ˆçº¦800â†’200ï¼‰
    - è·å–å½“æ—¥æ—©ç›˜æˆäº¤é‡
    - è®¡ç®—é‡æ¯”ï¼ˆ vs è¿‡å»5æ—¥åŒæœŸï¼‰
    - ä¿ç•™é‡æ¯”>3çš„å‰200åª
    """
    print("\n" + "="*80)
    print("ã€Layer 3ã€‘Tushareé‡æ¯”è¿‡æ»¤")
    print("="*80)
    
    # è·å–å½“æ—¥åˆ†é’Ÿæ•°æ®ï¼ˆTushareçš„1åˆ†é’Ÿçº¿æ¥å£éœ€è¦ç§¯åˆ†æƒé™ï¼‰
    # ä½¿ç”¨daily_basicæ¥å£è·å–å½“æ—¥æˆäº¤é‡å’Œé‡æ¯”
    try:
        df_today = pro.daily_basic(trade_date=trade_date, 
                                   fields='ts_code,turnover_rate,volume_ratio')
        print(f"   âœ… è·å–å½“æ—¥æŒ‡æ ‡: {len(df_today)}åª")
    except Exception as e:
        print(f"   âŒ è·å–å½“æ—¥æŒ‡æ ‡å¤±è´¥: {e}")
        return df_base.head(MAX_OUTPUT)  # é™çº§ï¼šç›´æ¥è¿”å›å‰200
    
    # åˆå¹¶æ•°æ®
    df = df_base.merge(df_today, on='ts_code', how='inner')
    
    # è¿‡æ»¤ï¼šé‡æ¯”>3
    df = df[df['volume_ratio'] >= VOLUME_RATIO_THRESHOLD]
    print(f"   é‡æ¯”>{VOLUME_RATIO_THRESHOLD}: {len(df)}åª")
    
    # æŒ‰é‡æ¯”æ’åºï¼Œå–å‰200
    df = df.sort_values('volume_ratio', ascending=False).head(MAX_OUTPUT)
    print(f"   Top {MAX_OUTPUT}: {len(df)}åª")
    
    return df


def save_candidates(df: pd.DataFrame, trade_date: str):
    """ä¿å­˜å€™é€‰è‚¡ç¥¨åå•"""
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    output_file = OUTPUT_DIR / f"{trade_date}_candidates_{len(df)}.csv"
    df.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"\n   ğŸ’¾ å·²ä¿å­˜: {output_file}")
    
    # åŒæ—¶ä¿å­˜JSONæ ¼å¼
    json_file = OUTPUT_DIR / f"{trade_date}_candidates_{len(df)}.json"
    df.to_json(json_file, orient='records', force_ascii=False, indent=2)
    print(f"   ğŸ’¾ å·²ä¿å­˜: {json_file}")
    
    return output_file


def main():
    """ä¸»å‡½æ•°"""
    print("="*80)
    print("ã€CTOæŒ‡ä»¤ã€‘Tushareäº‘ç«¯ç²—ç­›ï¼ˆ5000â†’200ï¼‰")
    print("="*80)
    print(f"ç›®æ ‡æ—¥æœŸ: {TRADE_DATE}")
    print(f"æˆäº¤é¢åº•çº¿: {MIN_AVG_AMOUNT}ä¸‡")
    print(f"é‡æ¯”é˜ˆå€¼: {VOLUME_RATIO_THRESHOLD}")
    print("="*80)
    
    # åˆå§‹åŒ–Tushare
    print("\n1ï¸âƒ£ åˆå§‹åŒ–Tushare Pro...")
    try:
        pro = init_tushare()
        print("   âœ… Tushare Proåˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"   âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # Layer 1: é™æ€è¿‡æ»¤
    df = layer1_static_filter(pro)
    
    # Layer 2: æˆäº¤é¢è¿‡æ»¤
    df = layer2_amount_filter(pro, df, TRADE_DATE)
    
    # Layer 3: é‡æ¯”è¿‡æ»¤
    df = layer3_volume_ratio_filter(pro, df, TRADE_DATE)
    
    # ä¿å­˜ç»“æœ
    output_file = save_candidates(df, TRADE_DATE)
    
    # è¾“å‡ºæ‘˜è¦
    print("\n" + "="*80)
    print("ã€ç­›é€‰ç»“æœæ‘˜è¦ã€‘")
    print("="*80)
    print(f"æ€»è‚¡ç¥¨æ•°: 5000+")
    print(f"æœ€ç»ˆå…¥é€‰: {len(df)}åª")
    print(f"å‹ç¼©ç‡: {(1 - len(df)/5000)*100:.1f}%")
    print(f"\nTop 10å€™é€‰:")
    for i, row in df.head(10).iterrows():
        print(f"   {row['ts_code']} | {row['name']} | é‡æ¯”:{row.get('volume_ratio', 'N/A')}")
    
    # æ£€æŸ¥å¿—ç‰¹æ–°æ
    zhite = df[df['ts_code'] == '300986.SZ']
    if not zhite.empty:
        print(f"\nğŸ¯ å¿—ç‰¹æ–°æ(300986.SZ): âœ… å…¥é€‰")
        print(f"   æ’å: {zhite.index[0] + 1}")
        print(f"   é‡æ¯”: {zhite.iloc[0].get('volume_ratio', 'N/A')}")
    else:
        print(f"\nğŸ¯ å¿—ç‰¹æ–°æ(300986.SZ): âŒ æœªå…¥é€‰")
    
    print("\n" + "="*80)
    print("âœ… Tushareäº‘ç«¯ç²—ç­›å®Œæˆ")
    print(f"è¾“å‡ºæ–‡ä»¶: {output_file}")
    print("ä¸‹ä¸€æ­¥: ä½¿ç”¨å®šå‘Tickä¸‹è½½è„šæœ¬è·å–200åªè‚¡ç¥¨çš„Tickæ•°æ®")
    print("="*80)


if __name__ == '__main__':
    main()
