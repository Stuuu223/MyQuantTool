#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç«ä»·å¿«ç…§è°ƒåº¦é‡‡é›†å™¨ - CTOæ¶æ„å†³ç­–ç‰ˆ

æ ¸å¿ƒæ¶æ„å†³ç­–ï¼ˆ2026-02-13 CTOæ‰¹å‡†ï¼‰ï¼š
1. è§¦å‘æ–¹å¼ï¼šå†…ç½®Spin-waitå¾ªç¯ï¼ˆç²¾åº¦è¦æ±‚ï¼Œä¸æ¥å—ä»»åŠ¡è®¡åˆ’çš„ä¸ç¡®å®šæ€§ï¼‰
2. é‡‡é›†æ—¶é—´ï¼š09:25:03ï¼ˆé¿å¼€æ•°æ®ä¼ è¾“å»¶è¿Ÿï¼Œç¡®ä¿å·²æ’®åˆï¼‰
3. å¤±è´¥é‡è¯•ï¼šRediså¿«é€Ÿå¤±è´¥ / SQLiteå¼‚æ­¥æ— é™é‡è¯•
4. é¢„çƒ­æ£€æŸ¥ï¼š09:24:00ï¼Œå¤±è´¥æ—¶æŠ¥è­¦ï¼ˆä¸è‡ªåŠ¨é™çº§ï¼‰
5. Redisè¿‡æœŸï¼š25å°æ—¶ï¼ˆå®‰å…¨è¾¹é™…ï¼‰

è¿è¡Œæ–¹å¼ï¼š
    python tasks/scheduled_auction_collector.py

ç‰¹æ€§ï¼š
- ç²¾å‡†æ—¶é—´æ§åˆ¶ï¼ˆè‡ªæ—‹ç­‰å¾…ï¼Œè¯¯å·®<10msï¼‰
- QMTè¿æ¥é¢„çƒ­ï¼ˆ09:24:00ï¼‰
- Redisçƒ­æ•°æ®æé€Ÿå†™å…¥
- SQLiteå¼‚æ­¥å½’æ¡£
- ä¸‹æ¸¸ç­–ç•¥è§¦å‘é€šçŸ¥

Author: MyQuantTool CTO Team
Date: 2026-02-13
Version: V1.0 (CTOæ¶æ„å†³ç­–ç‰ˆ)
"""

import sys
import os
import time
import json
import threading
import queue
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from logic.utils.logger import get_logger
from logic.database_manager import DatabaseManager
from logic.auction_snapshot_manager import AuctionSnapshotManager
from logic.data.qmt_manager import QMTManager

logger = get_logger(__name__)


class ScheduledAuctionCollector:
    """
    ç«ä»·å¿«ç…§è°ƒåº¦é‡‡é›†å™¨

    æ ¸å¿ƒæµç¨‹ï¼š
    1. 09:24:00 - QMTè¿æ¥é¢„çƒ­
    2. 09:25:03 - ç²¾å‡†è§¦å‘é‡‡é›†
    3. æé€Ÿå†™å…¥Redisï¼ˆçƒ­æ•°æ®ï¼‰
    4. å¼‚æ­¥å½’æ¡£SQLiteï¼ˆå†·æ•°æ®ï¼‰
    5. è§¦å‘ä¸‹æ¸¸ç­–ç•¥
    """

    def __init__(self):
        """åˆå§‹åŒ–é‡‡é›†å™¨"""
        logger.info("=" * 80)
        logger.info("ğŸŸ¢ ç«ä»·é‡‡é›†å®ˆæŠ¤è¿›ç¨‹å¯åŠ¨")
        logger.info("=" * 80)

        # åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
        self.db_manager = DatabaseManager()

        # å¼ºåˆ¶åˆå§‹åŒ–Redisè¿æ¥
        try:
            self.db_manager._init_redis()
            self.db_manager._redis_initialized = True
            logger.info("âœ… Redisè¿æ¥å·²å¼ºåˆ¶åˆå§‹åŒ–")
        except Exception as e:
            logger.warning(f"âš ï¸ Redisåˆå§‹åŒ–å¤±è´¥: {e}")

        # åˆå§‹åŒ–ç«ä»·å¿«ç…§ç®¡ç†å™¨
        self.snapshot_manager = AuctionSnapshotManager(self.db_manager)

        # åˆå§‹åŒ–QMTç®¡ç†å™¨
        self.qmt_manager = QMTManager()

        # SQLiteå¼‚æ­¥å†™å…¥é˜Ÿåˆ—
        self.sqlite_queue = queue.Queue()
        self.sqlite_worker_thread = None
        self.sqlite_worker_running = False

        # æ•°æ®åº“è·¯å¾„
        self.db_path = project_root / "data" / "auction_snapshots.db"

        # å…¨å¸‚åœºè‚¡ç¥¨ä»£ç ï¼ˆç¼“å­˜ï¼‰
        self.all_codes = []

        # é¢„çƒ­çŠ¶æ€
        self.has_warmup = False

        logger.info(f"ğŸ’¾ RedisçŠ¶æ€: {'å¯ç”¨' if self.snapshot_manager.is_available else 'ä¸å¯ç”¨'}")
        logger.info(f"ğŸ“Š QMTè¿æ¥: {'å·²è¿æ¥' if self.qmt_manager.data_connected else 'æœªè¿æ¥'}")

        # å¯åŠ¨SQLiteå¼‚æ­¥å†™å…¥çº¿ç¨‹
        self._start_sqlite_worker()

    def _start_sqlite_worker(self):
        """å¯åŠ¨SQLiteå¼‚æ­¥å†™å…¥å·¥ä½œçº¿ç¨‹"""
        self.sqlite_worker_running = True
        self.sqlite_worker_thread = threading.Thread(
            target=self._sqlite_worker_loop,
            name="SQLiteWorker",
            daemon=True
        )
        self.sqlite_worker_thread.start()
        logger.info("âœ… SQLiteå¼‚æ­¥å†™å…¥çº¿ç¨‹å·²å¯åŠ¨")

    def _sqlite_worker_loop(self):
        """SQLiteå¼‚æ­¥å†™å…¥å·¥ä½œå¾ªç¯"""
        logger.info("ğŸ”„ SQLiteå¼‚æ­¥å†™å…¥å·¥ä½œçº¿ç¨‹å·²å°±ç»ª")

        while self.sqlite_worker_running:
            try:
                # ä»é˜Ÿåˆ—è·å–ä»»åŠ¡ï¼ˆé˜»å¡ç­‰å¾…ï¼Œè¶…æ—¶1ç§’ï¼‰
                task = self.sqlite_queue.get(timeout=1.0)

                if task is None:  # åœæ­¢ä¿¡å·
                    break

                # æ‰§è¡Œå†™å…¥ä»»åŠ¡
                try:
                    self._save_to_sqlite_sync(task['data'], task['date'])
                    self.sqlite_queue.task_done()
                except Exception as e:
                    logger.error(f"âŒ SQLiteå†™å…¥å¤±è´¥ï¼Œé‡æ–°æ’é˜Ÿ: {e}")
                    # å¤±è´¥é‡æ–°æ’é˜Ÿï¼ˆæ— é™é‡è¯•ï¼‰
                    self.sqlite_queue.put(task)
                    time.sleep(1.0)  # å»¶è¿Ÿåé‡è¯•

            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"âŒ SQLiteå·¥ä½œçº¿ç¨‹å¼‚å¸¸: {e}")
                time.sleep(1.0)

        logger.info("ğŸ›‘ SQLiteå¼‚æ­¥å†™å…¥å·¥ä½œçº¿ç¨‹å·²åœæ­¢")

    def _load_all_codes(self):
        """åŠ è½½å…¨å¸‚åœºè‚¡ç¥¨ä»£ç """
        try:
            if self.qmt_manager.data_connected and self.qmt_manager.xtdata:
                stocks = self.qmt_manager.xtdata.get_stock_list_in_sector('æ²ªæ·±Aè‚¡')
                self.all_codes = stocks
                logger.info(f"âœ… å·²åŠ è½½å…¨å¸‚åœºè‚¡ç¥¨ä»£ç : {len(stocks)} åª")
                return stocks
            else:
                logger.error("âŒ QMTæœªè¿æ¥ï¼Œæ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
                return []
        except Exception as e:
            logger.error(f"âŒ è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            return []

    def warmup_qmt_connection(self):
        """
        é¢„çƒ­QMTè¿æ¥ï¼ˆ09:24:00è§¦å‘ï¼‰

        ç­–ç•¥ï¼š
        - æµ‹è¯•è·å–600519.SHçš„tickæ•°æ®
        - å¤±è´¥æ—¶æ‰“å°çº¢è‰²é«˜äº®æŠ¥è­¦
        - ä¸è‡ªåŠ¨é™çº§ï¼ˆå®å¯ä¸äº¤æ˜“ï¼Œä¸ç”¨é”™è¯¯æ•°æ®ï¼‰
        """
        logger.info("=" * 80)
        logger.info("ğŸ”¥ [09:24:00] å¼€å§‹QMTè¿æ¥é¢„çƒ­...")
        logger.info("=" * 80)

        try:
            if not self.qmt_manager.data_connected or not self.qmt_manager.xtdata:
                raise ValueError("QMTæœªè¿æ¥")

            # æµ‹è¯•è·å–ä¸€åªæ´»è·ƒè‚¡
            test_data = self.qmt_manager.xtdata.get_full_tick(['600519.SH'])

            if not test_data or '600519.SH' not in test_data:
                raise ValueError("QMTè¿”å›ç©ºæ•°æ®")

            logger.info("âœ… QMTè¿æ¥æ­£å¸¸ï¼Œé¢„çƒ­å®Œæˆ")
            logger.info(f"   æµ‹è¯•æ•°æ®: {test_data['600519.SH'].get('lastPrice', 0):.2f}")

        except Exception as e:
            logger.error("=" * 80)
            logger.error("âŒ ä¸¥é‡è­¦å‘Šï¼šQMTè¿æ¥å¼‚å¸¸ï¼")
            logger.error(f"   é”™è¯¯ä¿¡æ¯: {e}")
            logger.error("   è¯·åœ¨1åˆ†é’Ÿå†…æ£€æŸ¥QMTå®¢æˆ·ç«¯ï¼")
            logger.error("=" * 80)

            # Windowså¼¹çª—å¼ºæé†’ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            try:
                import ctypes
                ctypes.windll.user32.MessageBoxW(
                    0,
                    f"QMTè¿æ¥å¼‚å¸¸ï¼\né”™è¯¯: {e}\n\nè¯·ç«‹å³æ£€æŸ¥QMTå®¢æˆ·ç«¯ï¼",
                    "ç«ä»·é‡‡é›†å™¨ - ä¸¥é‡è­¦å‘Š",
                    0x10 | 0x1  # MB_ICONERROR | MB_SYSTEMMODAL
                )
            except:
                pass

            # ä¸è‡ªåŠ¨é™çº§ï¼Œç­‰å¾…äººå·¥ä»‹å…¥
            raise

    def save_to_redis_pipeline(self, raw_data: Dict[str, Any], date: str):
        """
        æé€Ÿå†™å…¥Redisï¼ˆçƒ­æ•°æ®ï¼‰

        ç­–ç•¥ï¼š
        - ä½¿ç”¨Redis Pipelineæ‰¹é‡å†™å…¥
        - å¿«é€Ÿå¤±è´¥ï¼ˆä»…é‡è¯•1æ¬¡ï¼‰
        - è¿‡æœŸæ—¶é—´ï¼š25å°æ—¶
        """
        if not self.snapshot_manager.is_available:
            logger.warning("âš ï¸ Redisä¸å¯ç”¨ï¼Œè·³è¿‡çƒ­æ•°æ®å†™å…¥")
            return

        logger.info("âš¡ï¸ å¼€å§‹Redisçƒ­æ•°æ®æé€Ÿå†™å…¥...")

        try:
            t0 = time.time()

            # ä½¿ç”¨Pipelineæ‰¹é‡å†™å…¥
            if self.db_manager._redis_client:
                import redis
                pipe = self.db_manager._redis_client.pipeline()

                # æ‰¹é‡è®¾ç½®ï¼ˆè¿‡æœŸ25å°æ—¶ï¼‰
                expire_seconds = 25 * 3600

                for code, data in raw_data.items():
                    # ç®€å•æ¸…æ´—
                    auction_data = {
                        'code': code,
                        'last_price': data.get('lastPrice', 0),
                        'last_close': data.get('lastClose', 0),
                        'volume': data.get('volume', 0),
                        'amount': data.get('amount', 0),
                        'timestamp': datetime.now().isoformat()
                    }

                    key = f"auction:{date}:{code}"
                    pipe.set(key, json.dumps(auction_data), ex=expire_seconds)

                # æ‰§è¡Œæ‰¹é‡å†™å…¥
                pipe.execute()

                elapsed = time.time() - t0
                logger.info(f"âœ… Redisçƒ­æ•°æ®å†™å…¥å®Œæˆ: {len(raw_data)} åªè‚¡ç¥¨, è€—æ—¶ {elapsed:.3f}s")

        except Exception as e:
            logger.error(f"âŒ Rediså†™å…¥å¤±è´¥ï¼ˆå¿«é€Ÿå¤±è´¥ï¼‰: {e}")
            # ä¸é‡è¯•ï¼Œå¿«é€Ÿå¤±è´¥

    def save_to_sqlite_async(self, raw_data: Dict[str, Any], date: str):
        """
        å¼‚æ­¥å½’æ¡£SQLiteï¼ˆå†·æ•°æ®ï¼‰

        ç­–ç•¥ï¼š
        - æ”¾å…¥é˜Ÿåˆ—ï¼Œå¼‚æ­¥å¤„ç†
        - æ— é™é‡è¯•ï¼ˆæ™š10åˆ†é’Ÿå†™å…¥ä¹Ÿæ²¡å…³ç³»ï¼‰
        """
        logger.info("ğŸ“¦ SQLiteå½’æ¡£ä»»åŠ¡å·²åŠ å…¥é˜Ÿåˆ—ï¼ˆå¼‚æ­¥å¤„ç†ï¼‰")

        task = {
            'data': raw_data,
            'date': date,
            'timestamp': datetime.now().isoformat()
        }

        self.sqlite_queue.put(task)

    def _save_to_sqlite_sync(self, raw_data: Dict[str, Any], date: str):
        """
        åŒæ­¥å†™å…¥SQLiteï¼ˆç”±å·¥ä½œçº¿ç¨‹è°ƒç”¨ï¼‰
        """
        import sqlite3

        conn = sqlite3.connect(str(self.db_path))
        cursor = conn.cursor()

        # ç¡®ä¿è¡¨å­˜åœ¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS auction_snapshots (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                date TEXT NOT NULL,
                code TEXT NOT NULL,
                name TEXT,
                auction_time TEXT,
                auction_price REAL,
                auction_volume INTEGER,
                auction_amount REAL,
                auction_change REAL,
                volume_ratio REAL,
                buy_orders INTEGER,
                sell_orders INTEGER,
                bid_vol_1 INTEGER,
                ask_vol_1 INTEGER,
                market_type TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(date, code)
            )
        """)

        # æ‰¹é‡æ’å…¥
        snapshots = []

        for code, data in raw_data.items():
            last_price = data.get('lastPrice', 0)
            last_close = data.get('lastClose', 0)

            if last_close > 0:
                auction_change = (last_price - last_close) / last_close
            else:
                auction_change = 0.0

            snapshot = {
                'date': date,
                'code': code,
                'name': data.get('stockName', ''),
                'auction_time': f"{date} 09:25:00",
                'auction_price': last_price,
                'auction_volume': data.get('volume', 0),
                'auction_amount': data.get('amount', 0),
                'auction_change': auction_change,
                'volume_ratio': 0.0,
                'buy_orders': 0,
                'sell_orders': 0,
                'bid_vol_1': data.get('bidVol', [0])[0] if data.get('bidVol') else 0,
                'ask_vol_1': data.get('askVol', [0])[0] if data.get('askVol') else 0,
                'market_type': 'SH' if code.endswith('.SH') else 'SZ'
            }

            snapshots.append(snapshot)

        # æ‰¹é‡æ’å…¥
        cursor.executemany("""
            INSERT OR REPLACE INTO auction_snapshots (
                date, code, name, auction_time, auction_price, auction_volume,
                auction_amount, auction_change, volume_ratio, buy_orders,
                sell_orders, bid_vol_1, ask_vol_1, market_type
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, [
            (s['date'], s['code'], s['name'], s['auction_time'],
             s['auction_price'], s['auction_volume'], s['auction_amount'],
             s['auction_change'], s['volume_ratio'], s['buy_orders'],
             s['sell_orders'], s['bid_vol_1'], s['ask_vol_1'], s['market_type'])
            for s in snapshots
        ])

        conn.commit()
        conn.close()

        logger.info(f"âœ… SQLiteå½’æ¡£å®Œæˆ: {len(snapshots)} åªè‚¡ç¥¨")

    def notify_strategy_analyzers(self):
        """
        è§¦å‘ä¸‹æ¸¸ç­–ç•¥åˆ†æå™¨

        ç­–ç•¥ï¼š
        - å†™å…¥Redisé€šçŸ¥æ ‡è®°
        - ç­–ç•¥åˆ†æå™¨ç›‘å¬æ­¤æ ‡è®°
        - éé˜»å¡æ–¹å¼
        """
        if not self.snapshot_manager.is_available:
            return

        try:
            today = datetime.now().strftime("%Y%m%d")
            notification_key = f"auction:notification:{today}"
            self.db_manager._redis_client.set(
                notification_key,
                json.dumps({
                    'status': 'ready',
                    'timestamp': datetime.now().isoformat(),
                    'message': 'ç«ä»·æ•°æ®å·²å°±ç»ªï¼Œç­–ç•¥åˆ†æå™¨å¯ä»¥å¼€å§‹å·¥ä½œ'
                }),
                ex=3600  # 1å°æ—¶è¿‡æœŸ
            )
            logger.info("ğŸ“¢ å·²å‘é€é€šçŸ¥ï¼šç«ä»·æ•°æ®å°±ç»ª")
        except Exception as e:
            logger.warning(f"âš ï¸ å‘é€ç­–ç•¥é€šçŸ¥å¤±è´¥: {e}")

    def run_daily(self):
        """
        è¿è¡Œæ¯æ—¥è°ƒåº¦é‡‡é›†

        æ ¸å¿ƒæµç¨‹ï¼š
        1. æ™ºèƒ½é¢„çƒ­ï¼ˆ09:24:00ï¼‰
        2. ç²¾å‡†æ•è·ï¼ˆ09:25:03ï¼‰
        3. æé€Ÿé‡‡é›†
        4. Redisçƒ­å†™å…¥
        5. è§¦å‘ç­–ç•¥
        6. SQLiteå¼‚æ­¥å½’æ¡£
        """
        logger.info("ğŸŸ¢ ç«ä»·é‡‡é›†å®ˆæŠ¤è¿›ç¨‹å·²å¯åŠ¨ï¼Œç­‰å¾…ç›®æ ‡æ—¶é—´...")

        # æå‰åŠ è½½è‚¡ç¥¨ä»£ç 
        self._load_all_codes()

        if not self.all_codes:
            logger.error("âŒ æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨ï¼Œé€€å‡º")
            return

        # è‡ªæ—‹ç­‰å¾…å¾ªç¯
        while True:
            now = datetime.now()
            current_time = now.strftime("%H:%M:%S")
            date = now.strftime("%Y-%m-%d")

            # --- é˜¶æ®µ1: æ™ºèƒ½é¢„çƒ­ï¼ˆ09:24:00ï¼‰---
            if current_time >= "09:24:00" and not self.has_warmup:
                try:
                    self.warmup_qmt_connection()
                    self.has_warmup = True
                except Exception as e:
                    logger.error(f"âŒ é¢„çƒ­å¤±è´¥ï¼Œç»§ç»­ç­‰å¾…äººå·¥ä»‹å…¥...")
                    # é¢„çƒ­å¤±è´¥åç»§ç»­å¾ªç¯ï¼Œç­‰å¾…äººå·¥ä¿®å¤

            # --- é˜¶æ®µ2: ç²¾å‡†æ•è·ï¼ˆ09:25:03ï¼‰---
            if current_time >= "09:25:03" and self.has_warmup:
                logger.info("=" * 80)
                logger.info("ğŸš€ [09:25:03] çª—å£è§¦å‘ï¼å¼€å§‹æé€Ÿé‡‡é›†...")
                logger.info("=" * 80)
                break

            # æä½èµ„æºæ¶ˆè€—çš„è‡ªæ—‹ï¼ˆ10msï¼‰
            time.sleep(0.01)

        # --- é˜¶æ®µ3: æ ¸å¿ƒæ‰§è¡Œ ---
        try:
            t0 = time.time()

            # 1. ç«‹å³è·å–å…¨å¸‚åœºå¿«ç…§ï¼ˆIOå¯†é›†ï¼‰
            logger.info(f"ğŸ“¡ æ­£åœ¨è·å–å…¨å¸‚åœºå¿«ç…§ï¼ˆ{len(self.all_codes)} åªè‚¡ç¥¨ï¼‰...")

            if self.qmt_manager.xtdata:
                raw_data = self.qmt_manager.xtdata.get_full_tick(self.all_codes)
            else:
                raise ValueError("QMT xtdataä¸å¯ç”¨")

            if not raw_data:
                raise ValueError("QMTè¿”å›ç©ºæ•°æ®")

            logger.info(f"âœ… è·å–åˆ° {len(raw_data)} åªè‚¡ç¥¨çš„å¿«ç…§æ•°æ®")

            # 2. æé€Ÿæ¸…æ´— + Rediså†™å…¥ï¼ˆCPUå¯†é›†ï¼‰
            self.save_to_redis_pipeline(raw_data, date)

            elapsed_redis = time.time() - t0
            logger.info(f"âš¡ï¸ Redisçƒ­æ•°æ®å°±ç»ªï¼Œæ€»è€—æ—¶ {elapsed_redis:.3f}s")

            # 3. è§¦å‘ä¸‹æ¸¸ç­–ç•¥ï¼ˆéé˜»å¡ï¼‰
            self.notify_strategy_analyzers()

            # 4. æ…¢é€Ÿå½’æ¡£ï¼ˆå¼‚æ­¥ï¼‰
            self.save_to_sqlite_async(raw_data, date)

            total_elapsed = time.time() - t0
            logger.info("=" * 80)
            logger.info(f"âœ… ç«ä»·é‡‡é›†æ ¸å¿ƒæµç¨‹å®Œæˆï¼Œæ€»è€—æ—¶ {total_elapsed:.3f}s")
            logger.info("=" * 80)

        except Exception as e:
            logger.critical(f"âŒ ç«ä»·é‡‡é›†æ ¸å¿ƒæµç¨‹å´©æºƒ: {e}")
            logger.critical("è¯·ç«‹å³æ£€æŸ¥ç³»ç»ŸçŠ¶æ€ï¼")

    def stop(self):
        """åœæ­¢é‡‡é›†å™¨"""
        logger.info("ğŸ›‘ æ­£åœ¨åœæ­¢ç«ä»·é‡‡é›†å™¨...")

        # åœæ­¢SQLiteå·¥ä½œçº¿ç¨‹
        self.sqlite_worker_running = False
        if self.sqlite_worker_thread:
            self.sqlite_queue.put(None)  # å‘é€åœæ­¢ä¿¡å·
            self.sqlite_worker_thread.join(timeout=5.0)

        logger.info("âœ… ç«ä»·é‡‡é›†å™¨å·²åœæ­¢")


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='ç«ä»·å¿«ç…§è°ƒåº¦é‡‡é›†å™¨ - CTOæ¶æ„å†³ç­–ç‰ˆ')
    parser.add_argument('--test', action='store_true', help='æµ‹è¯•æ¨¡å¼ï¼ˆç«‹å³æ‰§è¡Œï¼Œä¸ç­‰å¾…æ—¶é—´ï¼‰')
    parser.add_argument('--date', type=str, help='æµ‹è¯•æ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰')

    args = parser.parse_args()

    collector = ScheduledAuctionCollector()

    try:
        if args.test:
            # æµ‹è¯•æ¨¡å¼ï¼šç«‹å³æ‰§è¡Œ
            date = args.date or datetime.now().strftime("%Y-%m-%d")
            logger.info(f"ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šç«‹å³æ‰§è¡Œé‡‡é›† {date}")

            # åŠ è½½è‚¡ç¥¨ä»£ç 
            collector._load_all_codes()

            # æ¨¡æ‹Ÿé‡‡é›†
            if collector.qmt_manager.xtdata:
                raw_data = collector.qmt_manager.xtdata.get_full_tick(collector.all_codes[:100])  # åªé‡‡é›†100åªæµ‹è¯•

                collector.save_to_redis_pipeline(raw_data, date)
                collector.notify_strategy_analyzers()
                collector.save_to_sqlite_async(raw_data, date)

                logger.info("âœ… æµ‹è¯•é‡‡é›†å®Œæˆ")
        else:
            # æ­£å¸¸æ¨¡å¼ï¼šç­‰å¾…æ—¶é—´
            collector.run_daily()

    except KeyboardInterrupt:
        logger.info("\nâš ï¸ ç”¨æˆ·ä¸­æ–­")
    finally:
        collector.stop()


if __name__ == "__main__":
    main()