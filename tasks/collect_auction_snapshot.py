#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç«ä»·å¿«ç…§é‡‡é›†è„šæœ¬ (Phase3 ç¬¬1å‘¨) - æ‰¹é‡ä¼˜åŒ–ç‰ˆ

åŠŸèƒ½ï¼š
1. æ¯ä¸ªäº¤æ˜“æ—¥09:25é‡‡é›†å…¨å¸‚åœºç«ä»·å¿«ç…§ï¼ˆæ‰¹é‡APIï¼‰
2. ä¿å­˜ç«ä»·æ•°æ®åˆ°SQLiteå’ŒRedis
3. æ”¯æŒæ‰¹é‡é‡‡é›†å’Œå®æ—¶æ›´æ–°

ä½¿ç”¨æ–¹æ³•ï¼š
    # é‡‡é›†ä»Šæ—¥ç«ä»·å¿«ç…§
    python tasks/collect_auction_snapshot.py
    
    # é‡‡é›†æŒ‡å®šæ—¥æœŸç«ä»·å¿«ç…§ï¼ˆç”¨äºè¡¥æ•°æ®ï¼‰
    python tasks/collect_auction_snapshot.py --date 2026-02-10
    
    # æ‰¹é‡é‡‡é›†å†å²ç«ä»·å¿«ç…§
    python tasks/collect_auction_snapshot.py --start-date 2026-02-01 --end-date 2026-02-10

æ•°æ®ä¿å­˜ï¼š
- SQLite: data/auction_snapshots.db
- Redis: auction:YYYYMMDD:CODE (24å°æ—¶è¿‡æœŸ)

æ€§èƒ½ï¼š
- æ‰¹é‡é‡‡é›†ï¼š500åª/æ‰¹
- é¢„æœŸé€Ÿåº¦ï¼š5190åªè‚¡ç¥¨ < 30ç§’
"""

import sys
import os
import json
import time
import argparse
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from logic.logger import get_logger
from logic.database_manager import DatabaseManager
from logic.auction_snapshot_manager import AuctionSnapshotManager

logger = get_logger(__name__)


class AuctionSnapshotCollector:
    """
    ç«ä»·å¿«ç…§é‡‡é›†å™¨
    
    è´Ÿè´£é‡‡é›†å…¨å¸‚åœºç«ä»·æ•°æ®å¹¶ä¿å­˜åˆ°æ•°æ®åº“
    """
    
    def __init__(self, db_path: str = None):
        """
        åˆå§‹åŒ–é‡‡é›†å™¨
        
        Args:
            db_path: SQLiteæ•°æ®åº“è·¯å¾„ï¼ˆé»˜è®¤ï¼šdata/auction_snapshots.dbï¼‰
        """
        # æ•°æ®åº“è·¯å¾„
        if db_path is None:
            db_path = project_root / "data" / "auction_snapshots.db"
        else:
            db_path = Path(db_path)
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        db_path.parent.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
        self.db_manager = DatabaseManager()
        self.db_path = str(db_path)
        
        # åˆå§‹åŒ–ç«ä»·å¿«ç…§ç®¡ç†å™¨
        self.snapshot_manager = AuctionSnapshotManager(self.db_manager)
        
        # åˆå§‹åŒ–æ•°æ®åº“è¡¨
        self._init_database()
        
        logger.info(f"âœ… ç«ä»·å¿«ç…§é‡‡é›†å™¨åˆå§‹åŒ–æˆåŠŸ")
        logger.info(f"ğŸ“ æ•°æ®åº“è·¯å¾„: {self.db_path}")
        logger.info(f"ğŸ’¾ RedisçŠ¶æ€: {'å¯ç”¨' if self.snapshot_manager.is_available else 'ä¸å¯ç”¨'}")
    
    def _init_database(self):
        """
        åˆå§‹åŒ–SQLiteæ•°æ®åº“è¡¨
        """
        try:
            import sqlite3
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # åˆ›å»ºç«ä»·å¿«ç…§è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS auction_snapshots (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    date TEXT NOT NULL,
                    code TEXT NOT NULL,
                    name TEXT,
                    auction_time TEXT,
                    auction_price REAL,
                    auction_volume INTEGER,
                    auction_amount REAL,
                    auction_change REAL,
                    volume_ratio REAL,
                    buy_orders INTEGER,
                    sell_orders INTEGER,
                    bid_vol_1 INTEGER,
                    ask_vol_1 INTEGER,
                    market_type TEXT,
                    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(date, code)
                )
            """)
            
            # åˆ›å»ºç´¢å¼•
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_date 
                ON auction_snapshots(date)
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_code 
                ON auction_snapshots(code)
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_date_code 
                ON auction_snapshots(date, code)
            """)
            
            conn.commit()
            conn.close()
            
            logger.info("âœ… æ•°æ®åº“è¡¨åˆå§‹åŒ–æˆåŠŸ")
        
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def get_all_stock_codes(self) -> List[str]:
        """
        è·å–å…¨å¸‚åœºè‚¡ç¥¨ä»£ç åˆ—è¡¨
        
        Returns:
            è‚¡ç¥¨ä»£ç åˆ—è¡¨
        """
        try:
            # å°è¯•ä»QMTè·å–è‚¡ç¥¨åˆ—è¡¨
            try:
                import xtquant.xtdata as xtdata
                
                # è·å–æ‰€æœ‰Aè‚¡ä»£ç 
                sh_stocks = xtdata.get_stock_list_in_sector("æ²ªæ·±Aè‚¡")
                logger.info(f"âœ… ä»QMTè·å–åˆ° {len(sh_stocks)} åªè‚¡ç¥¨")
                return sh_stocks
            
            except Exception as e:
                logger.warning(f"âš ï¸ QMTè·å–å¤±è´¥: {e}ï¼Œå°è¯•ä½¿ç”¨AkShare")
                
                # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨AkShare
                import akshare as ak
                
                stock_list = ak.stock_info_a_code_name()
                codes = stock_list['code'].tolist()
                
                # è½¬æ¢ä¸ºQMTæ ¼å¼ï¼ˆ6ä½æ•°å­—+å¸‚åœºåç¼€ï¼‰
                formatted_codes = []
                for code in codes:
                    if code.startswith('6'):
                        formatted_codes.append(f"{code}.SH")
                    elif code.startswith(('0', '3')):
                        formatted_codes.append(f"{code}.SZ")
                
                logger.info(f"âœ… ä»AkShareè·å–åˆ° {len(formatted_codes)} åªè‚¡ç¥¨")
                return formatted_codes
        
        except Exception as e:
            logger.error(f"âŒ è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    def save_snapshots_batch(self, snapshots: List[Dict[str, Any]]) -> int:
        """
        æ‰¹é‡ä¿å­˜å¿«ç…§åˆ°SQLiteï¼ˆä½¿ç”¨äº‹åŠ¡æå‡æ€§èƒ½ï¼‰
        
        Args:
            snapshots: å¿«ç…§åˆ—è¡¨
        
        Returns:
            æˆåŠŸä¿å­˜çš„æ•°é‡
        """
        if not snapshots:
            return 0
        
        try:
            import sqlite3
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æ‰¹é‡æ’å…¥ï¼ˆä½¿ç”¨executemanyï¼‰
            cursor.executemany("""
                INSERT OR REPLACE INTO auction_snapshots (
                    date, code, name, auction_time, auction_price, auction_volume,
                    auction_amount, auction_change, volume_ratio, buy_orders,
                    sell_orders, bid_vol_1, ask_vol_1, market_type
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, [
                (s['date'], s['code'], s['name'], s['auction_time'],
                 s['auction_price'], s['auction_volume'], s['auction_amount'],
                 s['auction_change'], s['volume_ratio'], s['buy_orders'],
                 s['sell_orders'], s['bid_vol_1'], s['ask_vol_1'], s['market_type'])
                for s in snapshots
            ])
            
            conn.commit()
            conn.close()
            
            return len(snapshots)
        
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡ä¿å­˜å¤±è´¥: {e}")
            return 0
    
    def collect_all_snapshots_batch(self, date: str = None, batch_size: int = 500) -> Dict[str, int]:
        """
        æ‰¹é‡é‡‡é›†å…¨å¸‚åœºç«ä»·å¿«ç…§ï¼ˆä½¿ç”¨QMTæ‰¹é‡APIï¼‰
        
        Args:
            date: æ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼Œé»˜è®¤ä¸ºä»Šå¤©ï¼‰
            batch_size: æ¯æ‰¹æ¬¡å¤„ç†çš„è‚¡ç¥¨æ•°é‡ï¼ˆé»˜è®¤500ï¼‰
        
        Returns:
            é‡‡é›†ç»Ÿè®¡ä¿¡æ¯ {"total": æ€»æ•°, "success": æˆåŠŸæ•°, "failed": å¤±è´¥æ•°}
        """
        if date is None:
            date = datetime.now().strftime("%Y-%m-%d")
        
        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡é‡‡é›† {date} çš„ç«ä»·å¿«ç…§")
        
        # è·å–è‚¡ç¥¨åˆ—è¡¨
        stock_codes = self.get_all_stock_codes()
        total = len(stock_codes)
        
        if total == 0:
            logger.error("âŒ æœªè·å–åˆ°è‚¡ç¥¨åˆ—è¡¨")
            return {'total': 0, 'success': 0, 'failed': 0}
        
        total_batches = (total + batch_size - 1) // batch_size
        logger.info(f"ğŸ“Š å…±éœ€é‡‡é›† {total} åªè‚¡ç¥¨ï¼Œåˆ† {total_batches} æ‰¹æ¬¡ï¼Œæ¯æ‰¹ {batch_size} åª")
        
        # æ‰¹é‡é‡‡é›†
        import xtquant.xtdata as xtdata
        
        success_count = 0
        failed_count = 0
        processed = 0
        
        start_time = time.time()
        
        # åˆ†æ‰¹å¤„ç†
        for i in range(0, total, batch_size):
            batch_codes = stock_codes[i:i + batch_size]
            batch_num = i // batch_size + 1
            
            batch_start = time.time()
            logger.info(f"ğŸ”„ å¤„ç†ç¬¬ {batch_num}/{total_batches} æ‰¹æ¬¡ï¼ˆ{len(batch_codes)} åªè‚¡ç¥¨ï¼‰")
            
            try:
                # ğŸ”¥ å…³é”®ï¼šæ‰¹é‡è·å–tickæ•°æ®
                tick_data = xtdata.get_full_tick(batch_codes)
                
                if not tick_data:
                    logger.warning(f"âš ï¸ ç¬¬ {batch_num} æ‰¹æ¬¡æœªè·å–åˆ°æ•°æ®")
                    failed_count += len(batch_codes)
                    continue
                
                # å‡†å¤‡æ‰¹é‡ä¿å­˜çš„æ•°æ®
                batch_snapshots = []
                
                # å¤„ç†æ¯åªè‚¡ç¥¨çš„æ•°æ®
                for code in batch_codes:
                    processed += 1
                    
                    if code not in tick_data:
                        failed_count += 1
                        continue
                    
                    try:
                        data = tick_data[code]
                        
                        # æå–ç«ä»·æ•°æ®
                        auction_data = {
                            'date': date,
                            'code': code,
                            'name': data.get('stockName', ''),
                            'auction_time': f"{date} 09:25:00",
                            'auction_price': data.get('lastPrice', 0),
                            'auction_volume': data.get('volume', 0),
                            'auction_amount': data.get('amount', 0),
                            'auction_change': data.get('pctChg', 0),
                            'volume_ratio': data.get('volumeRatio', 0),
                            'buy_orders': data.get('buyOrdersVolume', 0),
                            'sell_orders': data.get('sellOrdersVolume', 0),
                            'bid_vol_1': data.get('bidVol', [0])[0] if data.get('bidVol') else 0,
                            'ask_vol_1': data.get('askVol', [0])[0] if data.get('askVol') else 0,
                            'market_type': 'SH' if code.endswith('.SH') else 'SZ',
                        }
                        
                        batch_snapshots.append(auction_data)
                        
                        # åŒæ—¶ä¿å­˜åˆ°Redisï¼ˆç”¨äºå¿«é€ŸæŸ¥è¯¢ï¼‰
                        if self.snapshot_manager.is_available:
                            self.snapshot_manager.save_auction_snapshot(
                                code.split('.')[0],
                                auction_data
                            )
                    
                    except Exception as e:
                        logger.warning(f"âš ï¸ å¤„ç† {code} å¤±è´¥: {e}")
                        failed_count += 1
                
                # æ‰¹é‡ä¿å­˜åˆ°SQLite
                saved_count = self.save_snapshots_batch(batch_snapshots)
                success_count += saved_count
                failed_count += len(batch_codes) - saved_count
                
                # æ‰¹æ¬¡ç»Ÿè®¡
                batch_time = time.time() - batch_start
                elapsed = time.time() - start_time
                avg_time_per_stock = elapsed / processed if processed > 0 else 0
                eta_seconds = avg_time_per_stock * (total - processed)
                
                logger.info(
                    f"ğŸ“ˆ è¿›åº¦: {processed}/{total} ({processed/total*100:.1f}%) | "
                    f"æˆåŠŸ: {success_count} | å¤±è´¥: {failed_count} | "
                    f"æ‰¹æ¬¡è€—æ—¶: {batch_time:.1f}s | é¢„è®¡å‰©ä½™: {eta_seconds:.0f}s"
                )
                
                # æ‰¹æ¬¡é—´çŸ­æš‚å»¶è¿Ÿï¼ˆé¿å…è¯·æ±‚è¿‡å¿«ï¼‰
                time.sleep(0.05)
            
            except Exception as e:
                logger.error(f"âŒ ç¬¬ {batch_num} æ‰¹æ¬¡å¤±è´¥: {e}")
                failed_count += len(batch_codes)
        
        total_time = time.time() - start_time
        logger.info(
            f"âœ… æ‰¹é‡é‡‡é›†å®Œæˆ - æ€»æ•°: {total}, æˆåŠŸ: {success_count}, å¤±è´¥: {failed_count}, "
            f"æ€»è€—æ—¶: {total_time:.1f}s, å¹³å‡: {total_time/total*1000:.1f}ms/è‚¡"
        )
        
        return {
            'total': total,
            'success': success_count,
            'failed': failed_count,
            'time_seconds': total_time
        }
    
    def get_snapshot_stats(self, date: str = None) -> Dict[str, Any]:
        """
        è·å–ç«ä»·å¿«ç…§ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            date: æ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼Œé»˜è®¤ä¸ºä»Šå¤©ï¼‰
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        try:
            import sqlite3
            
            if date is None:
                date = datetime.now().strftime("%Y-%m-%d")
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æŸ¥è¯¢ç»Ÿè®¡ä¿¡æ¯
            cursor.execute("""
                SELECT 
                    COUNT(*) as total,
                    COUNT(CASE WHEN auction_change > 0.03 THEN 1 END) as high_open_count,
                    COUNT(CASE WHEN auction_change < -0.03 THEN 1 END) as low_open_count,
                    COUNT(CASE WHEN volume_ratio > 2.0 THEN 1 END) as high_volume_count,
                    AVG(auction_change) as avg_change,
                    AVG(volume_ratio) as avg_volume_ratio
                FROM auction_snapshots
                WHERE date = ?
            """, (date,))
            
            row = cursor.fetchone()
            conn.close()
            
            if row:
                return {
                    'date': date,
                    'total': row[0],
                    'high_open_count': row[1],
                    'low_open_count': row[2],
                    'high_volume_count': row[3],
                    'avg_change': row[4],
                    'avg_volume_ratio': row[5]
                }
            else:
                return {'date': date, 'total': 0}
        
        except Exception as e:
            logger.error(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {'date': date, 'error': str(e)}


def main():
    """
    ä¸»å‡½æ•°
    """
    parser = argparse.ArgumentParser(description='ç«ä»·å¿«ç…§é‡‡é›†è„šæœ¬ï¼ˆæ‰¹é‡ä¼˜åŒ–ç‰ˆï¼‰')
    parser.add_argument('--date', type=str, help='é‡‡é›†æ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰')
    parser.add_argument('--start-date', type=str, help='å¼€å§‹æ—¥æœŸï¼ˆç”¨äºæ‰¹é‡é‡‡é›†ï¼‰')
    parser.add_argument('--end-date', type=str, help='ç»“æŸæ—¥æœŸï¼ˆç”¨äºæ‰¹é‡é‡‡é›†ï¼‰')
    parser.add_argument('--batch-size', type=int, default=500, help='æ¯æ‰¹æ¬¡è‚¡ç¥¨æ•°é‡ï¼ˆé»˜è®¤500ï¼‰')
    parser.add_argument('--stats', action='store_true', help='æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–é‡‡é›†å™¨
    collector = AuctionSnapshotCollector()
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if args.stats:
        stats = collector.get_snapshot_stats(args.date)
        logger.info(f"\nğŸ“Š ç«ä»·å¿«ç…§ç»Ÿè®¡ä¿¡æ¯ï¼š")
        logger.info(f"æ—¥æœŸ: {stats.get('date')}")
        logger.info(f"æ€»æ•°: {stats.get('total')}")
        logger.info(f"é«˜å¼€è‚¡ç¥¨: {stats.get('high_open_count')} (æ¶¨å¹…>3%)")
        logger.info(f"ä½å¼€è‚¡ç¥¨: {stats.get('low_open_count')} (è·Œå¹…>3%)")
        logger.info(f"æ”¾é‡è‚¡ç¥¨: {stats.get('high_volume_count')} (é‡æ¯”>2.0)")
        logger.info(f"å¹³å‡æ¶¨å¹…: {stats.get('avg_change', 0)*100:.2f}%")
        logger.info(f"å¹³å‡é‡æ¯”: {stats.get('avg_volume_ratio', 0):.2f}")
        return
    
    # æ‰¹é‡é‡‡é›†
    if args.start_date and args.end_date:
        start = datetime.strptime(args.start_date, "%Y-%m-%d")
        end = datetime.strptime(args.end_date, "%Y-%m-%d")
        
        current = start
        while current <= end:
            date_str = current.strftime("%Y-%m-%d")
            
            # è·³è¿‡å‘¨æœ«
            if current.weekday() < 5:  # 0-4 æ˜¯å‘¨ä¸€åˆ°å‘¨äº”
                logger.info(f"\n{'='*60}")
                logger.info(f"é‡‡é›†æ—¥æœŸ: {date_str}")
                logger.info(f"{'='*60}")
                
                result = collector.collect_all_snapshots_batch(date_str, args.batch_size)
                
                logger.info(
                    f"\nç»“æœ: æ€»æ•°={result['total']}, æˆåŠŸ={result['success']}, "
                    f"å¤±è´¥={result['failed']}, è€—æ—¶={result.get('time_seconds', 0):.1f}s"
                )
            else:
                logger.info(f"â­ï¸  è·³è¿‡å‘¨æœ«: {date_str}")
            
            current += timedelta(days=1)
            time.sleep(1)  # é¿å…é¢‘ç¹è¯·æ±‚
    
    # å•æ—¥é‡‡é›†
    else:
        date = args.date or datetime.now().strftime("%Y-%m-%d")
        
        logger.info(f"\n{'='*60}")
        logger.info(f"é‡‡é›†æ—¥æœŸ: {date}")
        logger.info(f"{'='*60}\n")
        
        result = collector.collect_all_snapshots_batch(date, args.batch_size)
        
        logger.info(f"\n{'='*60}")
        logger.info(f"âœ… é‡‡é›†å®Œæˆ")
        logger.info(f"æ€»æ•°: {result['total']}")
        logger.info(f"æˆåŠŸ: {result['success']}")
        logger.info(f"å¤±è´¥: {result['failed']}")
        logger.info(f"æ€»è€—æ—¶: {result.get('time_seconds', 0):.1f}s")
        logger.info(f"{'='*60}\n")
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats = collector.get_snapshot_stats(date)
        logger.info(f"ğŸ“Š ç«ä»·å¿«ç…§ç»Ÿè®¡ä¿¡æ¯ï¼š")
        logger.info(f"é«˜å¼€è‚¡ç¥¨: {stats.get('high_open_count')} (æ¶¨å¹…>3%)")
        logger.info(f"ä½å¼€è‚¡ç¥¨: {stats.get('low_open_count')} (è·Œå¹…>3%)")
        logger.info(f"æ”¾é‡è‚¡ç¥¨: {stats.get('high_volume_count')} (é‡æ¯”>2.0)")


if __name__ == "__main__":
    main()
