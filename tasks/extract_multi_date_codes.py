"""
Extract stock codes from multiple date snapshots, deduplicate and aggregate
"""
import json
import os
from pathlib import Path
from typing import Set
from datetime import datetime

def extract_codes_from_snapshot(file_path: str) -> Set[str]:
    """ä»å•ä¸ªå¿«ç…§æ–‡ä»¶ä¸­æå–è‚¡ç¥¨ä»£ç """
    codes = set()
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        # å¿«ç…§æ–‡ä»¶ç»“æ„: { "results": { "opportunities": [...], "watchlist": [...], "blacklist": [...] } }
        if isinstance(data, dict):
            results = data.get('results', {})
            if isinstance(results, dict):
                # æå– opportunities, watchlist, blacklist ä¸­çš„è‚¡ç¥¨ä»£ç 
                for pool in ['opportunities', 'watchlist', 'blacklist']:
                    stocks = results.get(pool, [])
                    if isinstance(stocks, list):
                        for stock in stocks:
                            if isinstance(stock, dict):
                                code = stock.get('code') or stock.get('ts_code')
                                if code:
                                    codes.add(code)
    except Exception as e:
        print(f"  âš ï¸ è¯»å–å¤±è´¥ {file_path}: {e}")

    return codes

def extract_codes_from_date(scan_results_dir: str, date_str: str) -> Set[str]:
    """æå–æŒ‡å®šæ—¥æœŸæ‰€æœ‰å¿«ç…§çš„è‚¡ç¥¨ä»£ç """
    date_codes = set()
    date_path = Path(scan_results_dir)

    # æŸ¥æ‰¾è¯¥æ—¥æœŸçš„æ‰€æœ‰å¿«ç…§æ–‡ä»¶
    pattern = f"{date_str}*.json"
    snapshot_files = list(date_path.glob(pattern))

    print(f"\nğŸ“… {date_str}:")
    print(f"  æ‰¾åˆ° {len(snapshot_files)} ä¸ªå¿«ç…§æ–‡ä»¶")

    for file_path in snapshot_files:
        file_codes = extract_codes_from_snapshot(str(file_path))
        date_codes.update(file_codes)
        print(f"  - {file_path.name}: {len(file_codes)} åªè‚¡ç¥¨")

    return date_codes

def main():
    scan_results_dir = "data/scan_results"

    # è¦å¤„ç†çš„æ—¥æœŸåˆ—è¡¨
    dates = ["2026-02-05", "2026-02-06"]

    all_codes = set()
    date_codes_map = {}

    print("=" * 70)
    print("æå–å¤šæ—¥å¿«ç…§è‚¡ç¥¨ä»£ç ")
    print("=" * 70)

    for date_str in dates:
        date_codes = extract_codes_from_date(scan_results_dir, date_str)
        date_codes_map[date_str] = date_codes
        all_codes.update(date_codes)
        print(f"  âœ… {date_str} åˆè®¡: {len(date_codes)} åªè‚¡ç¥¨")

    print("\n" + "=" * 70)
    print("æ±‡æ€»ç»“æœ")
    print("=" * 70)
    print(f"æ‰€æœ‰å»é‡è‚¡ç¥¨æ•°: {len(all_codes)}")

    # ä¿å­˜æ±‡æ€»ä»£ç 
    output_file = "pending_equity_codes_multi_date.txt"
    with open(output_file, 'w', encoding='utf-8') as f:
        for code in sorted(all_codes):
            f.write(code + '\n')

    print(f"âœ… ä¿å­˜åˆ°: {output_file}")

    # ä¿å­˜æ¯ä¸ªæ—¥æœŸçš„ä»£ç æ•°
    summary_file = "pending_equity_codes_summary.txt"
    with open(summary_file, 'w', encoding='utf-8') as f:
        f.write(f"æ—¥æœŸèŒƒå›´: {dates[0]} ~ {dates[-1]}\n")
        f.write(f"æ€»è‚¡ç¥¨æ•°: {len(all_codes)}\n\n")
        for date_str, codes in date_codes_map.items():
            f.write(f"{date_str}: {len(codes)} åªè‚¡ç¥¨\n")

    print(f"âœ… ä¿å­˜ç»Ÿè®¡åˆ°: {summary_file}")

if __name__ == "__main__":
    main()