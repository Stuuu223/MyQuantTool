#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
åŒæ­¥å…¨Aè‚¡æµé€šå¸‚å€¼æ•°æ®ï¼ˆTushareç‰ˆæœ¬ï¼‰

åŠŸèƒ½ï¼š
1. ä» Tushare daily_basic æ¥å£è·å–æ¯æ—¥æŒ‡æ ‡
2. æŒ‰ trade_date ç´¢å¼•å­˜å‚¨å†å²æ•°æ®
3. æ”¯æŒå¢é‡æ›´æ–°ï¼ˆåªè·å–ç¼ºå¤±æ—¥æœŸï¼‰
4. è‡ªåŠ¨æ¸…ç†è¶…è¿‡30å¤©çš„è¿‡æœŸæ•°æ®
5. æä¾›æŸ¥è¯¢æ¥å£ä¾› intraday æ‰«æä½¿ç”¨

Author: iFlow CLI
Version: V2.0
"""

import os
import json
import sys
from datetime import datetime, timedelta
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    import tushare as ts
    TUSHARE_AVAILABLE = True
except ImportError:
    TUSHARE_AVAILABLE = False
    print("âš ï¸ è­¦å‘Š: Tushareæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install tushare")

# é…ç½®
DATA_FILE = Path("data/equity_info_tushare.json")
RETENTION_DAYS = 30  # ä¿ç•™æœ€è¿‘30å¤©çš„æ•°æ®
TOKEN = os.getenv('TUSHARE_TOKEN')  # ä»ç¯å¢ƒå˜é‡è¯»å–

# åˆå§‹åŒ– tushare
if TUSHARE_AVAILABLE and TOKEN:
    pro = ts.pro_api(TOKEN)
else:
    pro = None

def load_equity_info():
    """
    åŠ è½½ç°æœ‰çš„æµé€šå¸‚å€¼æ•°æ®

    Returns:
        dict: {
            "latest_update": "20250813",
            "retention_days": 30,
            "data": {
                "20250813": {
                    "603607.SH": {"float_mv": 1000000000, "total_mv": 2000000000, ...},
                    ...
                },
                ...
            }
        }
    """
    if not DATA_FILE.exists():
        return {
            "latest_update": None,
            "retention_days": RETENTION_DAYS,
            "data": {}
        }

    with open(DATA_FILE, 'r', encoding='utf-8') as f:
        return json.load(f)

def save_equity_info(equity_data):
    """
    ä¿å­˜æµé€šå¸‚å€¼æ•°æ®

    Args:
        equity_data: æ•°æ®å­—å…¸
    """
    DATA_FILE.parent.mkdir(parents=True, exist_ok=True)

    with open(DATA_FILE, 'w', encoding='utf-8') as f:
        json.dump(equity_data, f, ensure_ascii=False, indent=2)

    print(f"âœ… æ•°æ®å·²ä¿å­˜åˆ°: {DATA_FILE}")

def clean_old_data(equity_data):
    """
    æ¸…ç†è¶…è¿‡ä¿ç•™æœŸçš„æ•°æ®

    Args:
        equity_data: æ•°æ®å­—å…¸

    Returns:
        dict: æ¸…ç†åçš„æ•°æ®å­—å…¸
    """
    if not equity_data.get("data"):
        return equity_data

    # è®¡ç®—æˆªæ­¢æ—¥æœŸ
    cutoff_date = (datetime.now() - timedelta(days=RETENTION_DAYS)).strftime("%Y%m%d")

    # è¿‡æ»¤æ•°æ®
    cleaned_data = {
        date: data 
        for date, data in equity_data["data"].items() 
        if date >= cutoff_date
    }

    removed_count = len(equity_data["data"]) - len(cleaned_data)
    if removed_count > 0:
        print(f"ğŸ—‘ï¸  æ¸…ç†äº† {removed_count} ä¸ªè¿‡æœŸæ—¥æœŸçš„æ•°æ®")

    equity_data["data"] = cleaned_data
    return equity_data

def fetch_daily_basic(trade_date):
    """
    ä» tushare è·å–æŒ‡å®šæ—¥æœŸçš„æ¯æ—¥æŒ‡æ ‡æ•°æ®

    Args:
        trade_date: äº¤æ˜“æ—¥æœŸï¼Œæ ¼å¼ YYYYMMDDï¼Œå¦‚ '20250812'

    Returns:
        dict: {ts_code: {float_mv, total_mv, ...}}
    """
    if not pro:
        print("âŒ Tushareæœªæ­£ç¡®åˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥ TUSHARE_TOKEN ç¯å¢ƒå˜é‡")
        return {}

    print(f"ğŸ“Š æ­£åœ¨è·å– {trade_date} çš„æ¯æ—¥æŒ‡æ ‡æ•°æ®...")

    try:
        df = pro.daily_basic(
            trade_date=trade_date,
            fields='ts_code,trade_date,close,turnover_rate,volume_ratio,pe,pb,ps,total_mv,circ_mv'
        )

        if df.empty:
            print(f"âš ï¸  {trade_date} æ— æ•°æ®ï¼ˆå¯èƒ½æ˜¯éäº¤æ˜“æ—¥ï¼‰")
            return {}

        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        result = {}
        for _, row in df.iterrows():
            ts_code = row['ts_code']
            result[ts_code] = {
                'float_mv': row['circ_mv'] * 10000 if row['circ_mv'] else 0,  # ä¸‡å…ƒâ†’å…ƒ
                'total_mv': row['total_mv'] * 10000 if row['total_mv'] else 0,
                'close': row['close'],
                'turnover_rate': row['turnover_rate'],
                'pe': row['pe'],
                'pb': row['pb']
            }

        print(f"âœ… è·å–æˆåŠŸï¼š{len(result)} åªè‚¡ç¥¨")
        return result

    except Exception as e:
        print(f"âŒ è·å–æ•°æ®å¤±è´¥ï¼š{e}")
        return {}

def get_missing_dates(equity_data, days=5):
    """
    è·å–éœ€è¦è¡¥å……çš„äº¤æ˜“æ—¥æœŸåˆ—è¡¨

    Args:
        equity_data: ç°æœ‰æ•°æ®
        days: å‘å‰æŸ¥æ‰¾çš„å¤©æ•°

    Returns:
        list: ç¼ºå¤±çš„æ—¥æœŸåˆ—è¡¨ï¼Œæ ¼å¼ ['20250812', '20250813', ...]
    """
    existing_dates = set(equity_data.get("data", {}).keys())

    # ç”Ÿæˆæœ€è¿‘ N å¤©çš„æ—¥æœŸåˆ—è¡¨
    date_list = []
    for i in range(days):
        date = (datetime.now() - timedelta(days=i)).strftime("%Y%m%d")
        if date not in existing_dates:
            date_list.append(date)

    return sorted(date_list)

def sync_equity_info(incremental=True):
    """
    åŒæ­¥æµé€šå¸‚å€¼æ•°æ®

    Args:
        incremental: æ˜¯å¦å¢é‡æ›´æ–°ï¼ˆåªè·å–ç¼ºå¤±æ—¥æœŸï¼‰
    """
    if not TUSHARE_AVAILABLE:
        print("âŒ Tushareä¸å¯ç”¨ï¼Œæ— æ³•åŒæ­¥æ•°æ®")
        return

    print("=" * 60)
    print("å¼€å§‹åŒæ­¥æµé€šå¸‚å€¼æ•°æ®")
    print("=" * 60)

    # 1. åŠ è½½ç°æœ‰æ•°æ®
    equity_data = load_equity_info()

    # 2. ç¡®å®šéœ€è¦è·å–çš„æ—¥æœŸ
    if incremental:
        dates_to_fetch = get_missing_dates(equity_data, days=5)
        if not dates_to_fetch:
            print("âœ… æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°")
            return
        print(f"ğŸ“… éœ€è¦æ›´æ–°çš„æ—¥æœŸï¼š{dates_to_fetch}")
    else:
        # å…¨é‡æ›´æ–°ï¼šåªè·å–ä»Šå¤©
        dates_to_fetch = [datetime.now().strftime("%Y%m%d")]
        print(f"ğŸ“… å…¨é‡æ›´æ–°æ¨¡å¼ï¼š{dates_to_fetch}")

    # 3. é€æ—¥è·å–æ•°æ®
    for trade_date in dates_to_fetch:
        daily_data = fetch_daily_basic(trade_date)
        if daily_data:
            equity_data["data"][trade_date] = daily_data
            equity_data["latest_update"] = trade_date

    # 4. æ¸…ç†è¿‡æœŸæ•°æ®
    equity_data = clean_old_data(equity_data)

    # 5. ä¿å­˜æ•°æ®
    save_equity_info(equity_data)

    # 6. ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 60)
    print("åŒæ­¥å®Œæˆ")
    print("=" * 60)
    print(f"ğŸ“Š æ•°æ®æ—¥æœŸèŒƒå›´ï¼š{len(equity_data['data'])} å¤©")
    print(f"ğŸ“… æœ€æ–°æ—¥æœŸï¼š{equity_data.get('latest_update', 'N/A')}")
    if equity_data['data']:
        latest_date = max(equity_data['data'].keys())
        print(f"ğŸ“ˆ æœ€æ–°æ•°æ®è‚¡ç¥¨æ•°ï¼š{len(equity_data['data'][latest_date])}")

def get_circ_mv(ts_code, trade_date=None):
    """
    æŸ¥è¯¢æŒ‡å®šè‚¡ç¥¨åœ¨æŒ‡å®šæ—¥æœŸçš„æµé€šå¸‚å€¼

    Args:
        ts_code: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ '603607.SH'
        trade_date: äº¤æ˜“æ—¥æœŸï¼Œæ ¼å¼ YYYYMMDDã€‚å¦‚ä¸æŒ‡å®šï¼Œä½¿ç”¨æœ€æ–°æ—¥æœŸ

    Returns:
        float: æµé€šå¸‚å€¼ï¼ˆå…ƒï¼‰ï¼Œå¦‚æœæœªæ‰¾åˆ°è¿”å› 0
    """
    equity_data = load_equity_info()

    # å¦‚æœæœªæŒ‡å®šæ—¥æœŸï¼Œä½¿ç”¨æœ€æ–°æ—¥æœŸ
    if trade_date is None:
        trade_date = equity_data.get("latest_update")
        if not trade_date:
            return 0

    # æŸ¥è¯¢æ•°æ®
    daily_data = equity_data.get("data", {}).get(trade_date, {})
    stock_data = daily_data.get(ts_code, {})

    return stock_data.get('float_mv', 0)

if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='åŒæ­¥è‚¡ç¥¨æµé€šå¸‚å€¼æ•°æ®')
    parser.add_argument('--full', action='store_true', help='å…¨é‡æ›´æ–°ï¼ˆé»˜è®¤ä¸ºå¢é‡æ›´æ–°ï¼‰')
    parser.add_argument('--query', type=str, help='æŸ¥è¯¢æŒ‡å®šè‚¡ç¥¨çš„æµé€šå¸‚å€¼ï¼Œæ ¼å¼ï¼šè‚¡ç¥¨ä»£ç ')
    parser.add_argument('--date', type=str, help='æŒ‡å®šæŸ¥è¯¢æ—¥æœŸï¼Œæ ¼å¼ï¼šYYYYMMDD')

    args = parser.parse_args()

    if args.query:
        # æŸ¥è¯¢æ¨¡å¼
        circ_mv = get_circ_mv(args.query, args.date)
        print(f"\nè‚¡ç¥¨ä»£ç ï¼š{args.query}")
        print(f"äº¤æ˜“æ—¥æœŸï¼š{args.date or 'æœ€æ–°'}")
        print(f"æµé€šå¸‚å€¼ï¼š{circ_mv:,.0f} å…ƒ ({circ_mv/100000000:.2f} äº¿)")
    else:
        # åŒæ­¥æ¨¡å¼
        sync_equity_info(incremental=not args.full)
