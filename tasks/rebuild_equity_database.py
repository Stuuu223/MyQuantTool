# -*- coding: utf-8 -*-
"""
å…¨å¸‚åœºè‚¡æƒå†å²æ•°æ®åº“é‡å»ºè„šæœ¬

åŠŸèƒ½ï¼š
- æ‹‰å–è¿‡å»365å¤©çš„å…¨å¸‚åœº daily_basic æ•°æ®
- æ„å»º {code: {date: {...}}} æ—¶åºæ•°æ®ç»“æ„
- å½»åº•è§£å†³æ•°æ®ç¼ºå¤±é—®é¢˜

æ‰§è¡Œæ—¶é—´ï¼šçº¦ 5-10 åˆ†é’Ÿï¼ˆå–å†³äºç½‘ç»œé€Ÿåº¦ï¼‰

Author: iFlow CLI
Version: V1.0
Date: 2026-02-09 10:00 AM
"""

import tushare as ts
import json
import pandas as pd
from datetime import datetime, timedelta
import os
import time
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# é…ç½®
TOKEN = '1430dca9cc3419b91928e162935065bcd3531fa82976fee8355d550b'
OUTPUT_PATH = 'data/equity_info_tushare.json'
HISTORY_DAYS = 365
RATE_LIMIT = 0.3  # æ¯æ¬¡è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰

def fetch_trade_cal(start_date, end_date):
    """è·å–äº¤æ˜“æ—¥å†"""
    try:
        df = pro.trade_cal(exchange='', start_date=start_date, end_date=end_date)
        trade_dates = df[df['is_open'] == 1]['cal_date'].tolist()
        return trade_dates
    except Exception as e:
        print(f"âŒ è·å–äº¤æ˜“æ—¥å†å¤±è´¥: {e}")
        return []

def rebuild_database():
    """é‡å»ºå…¨å¸‚åœºå†å²æ•°æ®åº“"""
    print("=" * 80)
    print("ğŸš€ å¼€å§‹æ„å»ºå…¨å¸‚åœºå†å²æ•°æ®åº“")
    print(f"ğŸ“… æ—¶é—´èŒƒå›´: è¿‡å» {HISTORY_DAYS} å¤©")
    print("=" * 80)

    # 1. åˆå§‹åŒ– Tushare
    try:
        ts.set_token(TOKEN)
        global pro
        pro = ts.pro_api()
        print("âœ… Tushare è¿æ¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ Tushare è¿æ¥å¤±è´¥: {e}")
        return False

    # 2. ç¡®å®šæ—¥æœŸèŒƒå›´
    end_date = datetime.now().strftime('%Y%m%d')
    start_date = (datetime.now() - timedelta(days=HISTORY_DAYS)).strftime('%Y%m%d')

    print(f"ğŸ“… æ—¥æœŸèŒƒå›´: {start_date} -> {end_date}")

    # 3. è·å–äº¤æ˜“æ—¥å†
    trade_dates = fetch_trade_cal(start_date, end_date)
    trade_dates.sort(reverse=True)  # å€’åºï¼Œä¼˜å…ˆæ‹‰æœ€è¿‘çš„

    print(f"ğŸ“… äº¤æ˜“æ—¥æ•°é‡: {len(trade_dates)} å¤©")
    print("=" * 80)

    # 4. å‡†å¤‡æ•°æ®ç»“æ„: {code: {date: {...}}}
    full_data = {}

    # 5. é€æ—¥æ‹‰å–
    success_days = 0
    failed_days = 0
    total_stocks = 0

    for i, date in enumerate(trade_dates):
        print(f"ğŸ“¥ [{i+1}/{len(trade_dates)}] {date}...", end=" ", flush=True)

        try:
            # é™é¢‘ï¼Œé˜²å°
            time.sleep(RATE_LIMIT)

            # æ‹‰å– daily_basic
            df = pro.daily_basic(
                trade_date=date,
                fields='ts_code,circ_mv,total_mv,total_share,float_share,turnover_rate,pe,pb'
            )

            if df.empty:
                print("âš ï¸  æ— æ•°æ®")
                failed_days += 1
                continue

            # å­˜å…¥å†…å­˜ç»“æ„
            day_count = 0
            for _, row in df.iterrows():
                code = row['ts_code']
                if code not in full_data:
                    full_data[code] = {}

                # å•ä½è½¬æ¢ï¼šä¸‡å…ƒ -> å…ƒ
                full_data[code][date] = {
                    "circ_mv": row['circ_mv'] * 10000 if pd.notna(row['circ_mv']) else 0,
                    "total_mv": row['total_mv'] * 10000 if pd.notna(row['total_mv']) else 0,
                    "total_share": row['total_share'] * 10000 if pd.notna(row['total_share']) else 0,
                    "float_share": row['float_share'] * 10000 if pd.notna(row['float_share']) else 0,
                    "turnover_rate": row['turnover_rate'] if pd.notna(row['turnover_rate']) else 0,
                    "pe": row['pe'] if pd.notna(row['pe']) else 0,
                    "pb": row['pb'] if pd.notna(row['pb']) else 0
                }
                day_count += 1

            print(f"âœ… {day_count} æ¡")
            success_days += 1
            total_stocks += day_count

            # æ¯10å¤©æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
            if (i + 1) % 10 == 0:
                print(f"   ğŸ“Š è¿›åº¦: å·²å¤„ç† {i+1}/{len(trade_dates)} å¤©")

        except Exception as e:
            print(f"âŒ å¤±è´¥: {e}")
            failed_days += 1
            time.sleep(5)  # æŠ¥é”™å¤šæ­‡ä¼šå„¿

    print("=" * 80)
    print(f"ğŸ“Š ç»Ÿè®¡:")
    print(f"   æˆåŠŸ: {success_days} å¤©")
    print(f"   å¤±è´¥: {failed_days} å¤©")
    print(f"   æ€»è®°å½•: {total_stocks:,} æ¡")
    print(f"   è‚¡ç¥¨æ•°é‡: {len(full_data):,} åª")
    print("=" * 80)

    # 6. ä¿å­˜
    print("ğŸ’¾ æ­£åœ¨ä¿å­˜å¤§æ–‡ä»¶...")

    # åŒ…è£… metadata
    final_json = {
        "latest_update": end_date,
        "history_days": HISTORY_DAYS,
        "data_structure": "{code: {date: {...}}}",
        "trade_date_count": len(trade_dates),
        "stock_count": len(full_data),
        "data": full_data
    }

    # å…ˆå¤‡ä»½
    if os.path.exists(OUTPUT_PATH):
        backup_path = f"{OUTPUT_PATH}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        import shutil
        shutil.copy2(OUTPUT_PATH, backup_path)
        print(f"ğŸ’¾ å·²å¤‡ä»½: {backup_path}")

    # ä¿å­˜æ–°æ–‡ä»¶ï¼ˆä¸ç¼©è¿›ï¼Œå‡å°ä½“ç§¯ï¼‰
    with open(OUTPUT_PATH, 'w', encoding='utf-8') as f:
        json.dump(final_json, f, ensure_ascii=False)

    file_size_mb = os.path.getsize(OUTPUT_PATH) / 1024 / 1024
    print(f"âœ… æ•°æ®åº“æ„å»ºå®Œæˆï¼")
    print(f"   æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB")
    print(f"   æ–‡ä»¶è·¯å¾„: {OUTPUT_PATH}")
    print("=" * 80)
    print("âš ï¸  é‡è¦æç¤ºï¼š")
    print("   1. æ•°æ®ç»“æ„å·²æ”¹å˜ä¸º {code: {date: {...}}}")
    print("   2. éœ€è¦é…åˆæ›´æ–° equity_data_accessor.py")
    print("   3. å¯ä»¥ç§»é™¤æ—©ä¸Šçš„ Hotfix ä»£ç ")
    print("=" * 80)

    return True

if __name__ == "__main__":
    print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()

    success = rebuild_database()

    print()
    print(f"â° ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    sys.exit(0 if success else 1)