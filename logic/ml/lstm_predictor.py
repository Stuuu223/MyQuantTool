"""
LSTMé¢„æµ‹æ¨¡å‹æ¨¡å—
å±æ€§ï¼š
- æ¸¸èµ„ä¸Šé¾™è™æ¦œæ¦‚ç‡é¢„æµ‹
- è‚¡ç¥¨æ˜æ—¥ä¸Šæ¦œé¢„æµ‹
- æ—¶é—´åºåˆ—ç‰¹å¾å·¥ç¨‹
- æ¨¡å‹æ¨•ä¸«äº†å•†æ¡ˆæ³Šå˜
"""

import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
import pickle
import os
from pathlib import Path
import logging

try:
    from tensorflow.keras.models import Sequential, load_model
    from tensorflow.keras.layers import LSTM, Dense, Dropout, Input
    from tensorflow.keras.optimizers import Adam
    from tensorflow.keras.callbacks import EarlyStopping
    from sklearn.preprocessing import MinMaxScaler
    KERAS_AVAILABLE = True
except ImportError:
    KERAS_AVAILABLE = False
    logging.warning("TensorFlow/Kerasæœªå®‰è£…ï¼Œæ¨¡å‹åŠŸèƒ½å¯èƒ½å—é™")

logger = logging.getLogger(__name__)


@dataclass
class LSTMPrediction:
    """
LSTMé¢„æµ‹ç»“æœæ•°æ®ç±»
    """
    prediction_date: str  # é¢„æµ‹æ—¥æœŸ
    capital_name: str  # æ¸¸èµ„åç§°
    appearance_probability: float  # é¢„æµ‹ä¸Šé¦œæ–ˆæ¶„é¨
    confidence_score: float  # ä¿¡å®‰åº¦ (0-1)
    feature_importance: Dict[str, float]  # æœ€é‡è¦çš„3ä¸ªç‰¹å¾
    prediction_reason: str  # é¢„æµ‹ç†ç”±
    historical_success_rate: float  # æ­·å²æˆåŠŸç‡
    recommended_action: str  # æ¨èæ“ä½œ


class TimeSeriesFeatureEngineer:
    """
    æ—¶é—´åºåˆ—ç‰¹å¾å·¥ç¨‹ç±»
    """
    
    def __init__(self, lookback_days: int = 30):
        """
        Args:
            lookback_days: å›é¡§çª—å£ (æ­´å²å¤©æ•°)
        """
        self.lookback_days = lookback_days
        self.scalers = {}  # æ¯ä¸ªæ¸¸èµ„çš„æ®‹å½¹åŒ–å™¨
    
    def engineer_capital_features(
        self,
        capital_name: str,
        df_lhb_history: pd.DataFrame,
        df_kline: pd.DataFrame = None
    ) -> Tuple[np.ndarray, pd.DataFrame]:
        """
        ä¸ºæ¸¸èµ„æ±Ÿè–°æ—¶é—´åºåˆ—ç‰¹å¾
        
        Args:
            capital_name: æ¸¸èµ„åç§°
            df_lhb_history: é¾™è™æ¦œæ•´ä½“æ–·å¾·æ•³
            df_kline: Kçº¿æ–·å¾·æ•³ (å¯é€‰)
        
        Returns:
            (feature_array, feature_df): (æ ¹é²¨åŒ–ç‰¹å¾æ•°ç»„, åŸå§‹ç‰¹å¾DataFrame)
        """
        # ç­›é€‰æ¸¸èµ„æ•°æ®
        df_capital = df_lhb_history[
            df_lhb_history['æ¸¸èµ„åç§°'] == capital_name
        ].copy()
        
        if df_capital.empty:
            return None, None
        
        # æŒ‰æ—¥æœŸæ’åºå¹¶æ’å€’ (æ—§->u65b0)
        df_capital['æ—¥æœŸ'] = pd.to_datetime(df_capital['æ—¥æœŸ'])
        df_capital = df_capital.sort_values('æ—¥æœŸ').reset_index(drop=True)
        
        # æå–ç‰¹å¾
        feature_list = []
        
        for idx in range(len(df_capital)):
            features = self._extract_daily_features(
                df_capital,
                idx,
                df_kline
            )
            feature_list.append(features)
        
        df_features = pd.DataFrame(feature_list)
        
        # æ®‹å½¹åŒ–
        feature_cols = [
            'frequency',
            'total_amount',
            'avg_amount_per_stock',
            'buy_ratio',
            'stock_diversity',
            'momentum',
            'volatility',
            'win_rate'
        ]
        
        X = df_features[feature_cols].values
        
        if capital_name not in self.scalers:
            scaler = MinMaxScaler()
            X_scaled = scaler.fit_transform(X)
            self.scalers[capital_name] = scaler
        else:
            scaler = self.scalers[capital_name]
            X_scaled = scaler.transform(X)
        
        return X_scaled, df_features
    
    def _extract_daily_features(
        self,
        df_capital: pd.DataFrame,
        idx: int,
        df_kline: pd.DataFrame = None
    ) -> Dict:
        """
        æå–å•æ—¥æ¸¸èµ„ç‰¹å¾
        """
        row = df_capital.iloc[idx]
        
        # åŸºç¡€ç‰¹å¾
        features = {
            'date': row['æ—¥æœŸ'],
            'frequency': 1,  # æ¯ä¸€è¡Œä»£è¡¨ä¸€æ¬¡æ“ä½œ
            'total_amount': row.get('æˆäº¤é¢', 0),
            'buy_ratio': 1.0 if row.get('æ“ä½œæ–¹å‘', '') == 'ä¹°' else 0.0
        }
        
        # æ˜©å¤©æ•°æ®èšåˆ (å±å…‹å¸·å·ï¼Œ7æ—¥äº’æ”¶)
        if idx > 0:
            window_data = df_capital.iloc[max(0, idx-6):idx+1]
            features['stock_diversity'] = len(window_data['è‚¡ç¥¨ä»£ç '].unique())
            features['momentum'] = len(window_data[window_data['æ“ä½œæ–¹å‘']=='ä¹°']) / max(len(window_data), 1)
        else:
            features['stock_diversity'] = 1
            features['momentum'] = 0.5
        
        features['avg_amount_per_stock'] = features['total_amount'] / max(features['stock_diversity'], 1)
        
        # å¯¹æ‰‹ç­–ç•¥ (é¢„ç•™ç‰¹å¾)
        if idx < len(df_capital) - 1:
            next_row = df_capital.iloc[idx + 1]
            features['next_appear'] = 1  # é¢„æµ‹ç›®æ ‡: æ˜å¤©æ˜¯å¦ä¸Šæ¦œ
        else:
            features['next_appear'] = 0  # å°¾å¨æ•°æ®
        
        # æ•éœ„çª‘ Kçº¿ä¿¡æ¯
        if df_kline is not None and 'æ—¥æœŸ' in df_kline.columns:
            kline_date = pd.to_datetime(row['æ—¥æœŸ'])
            kline_data = df_kline[
                pd.to_datetime(df_kline['æ—¥æœŸ']) == kline_date
            ]
            
            if not kline_data.empty:
                kline_row = kline_data.iloc[0]
                features['market_volatility'] = kline_row.get('æ³¢åŠ¨ç‡', 0)
                features['market_momentum'] = 1 if kline_row.get('è¶‹åŠ¿', '') == 'å¼ºä¸Š' else 0
            else:
                features['market_volatility'] = 0
                features['market_momentum'] = 0.5
        else:
            features['market_volatility'] = 0
            features['market_momentum'] = 0.5
        
        # æŒ‰æŠ–åˆ†ç‡ (æ±Ÿå¹æ¶„é…‹æ¨)
        buy_records = len(df_capital[
            (df_capital['æ“ä½œæ–¹å‘'] == 'ä¹°') &
            (df_capital.index <= idx)
        ])
        total_records = idx + 1
        features['win_rate'] = buy_records / max(total_records, 1)
        
        # åˆ é™¤ä¸‹ä¸€æ—¥æ—¥æœŸ (ä¸å±äºå›é¡§)
        features.pop('next_appear', None)
        
        return features
    
    def create_sequences(
        self,
        X: np.ndarray,
        sequence_length: int = None
    ) -> Tuple[np.ndarray, np.ndarray]:
        """
        æ±Ÿæ»­æŸ©åºåˆ—æ¨¡å½¢ (å¾ªç¯è‡ªæ¨)
        
        Args:
            X: æ ¹é²¨åŒ–ç‰¹å¾æ•°ç»„ (N, features)
            sequence_length: åºåˆ—é•·åº¦ (ä¼šè¨ˆæ¨¡å› ç®€ä¸‡å…ƒ)
        
        Returns:
            (X_seq, y): (N-seq_len, seq_len, features), (N-seq_len,)
        """
        if sequence_length is None:
            sequence_length = self.lookback_days
        
        if len(X) < sequence_length:
            logger.warning(f"æ•°æ®ä¸è¶³{sequence_length}è§„æ ï¼Œè¿”å›ç©º")
            return None, None
        
        X_seq, y = [], []
        
        for i in range(len(X) - sequence_length):
            X_seq.append(X[i:i+sequence_length])
            # é¢„æµ‹ç›®æ ‡: ä¸‹ä¸€æ®µæ˜¯å¦å‡ºç° (dummy æ ‡ç­¾)
            y.append(1 if np.random.random() > 0.5 else 0)
        
        return np.array(X_seq), np.array(y)


class LSTMCapitalPredictor:
    """
    LSTMæ¸¸èµ„ä¸Šæ¦œé¢„æµ‹å™¨
    """
    
    def __init__(
        self,
        lookback_days: int = 30,
        model_dir: str = 'models'
    ):
        """
        Args:
            lookback_days: å›é¡§çª—å£
            model_dir: æ¨¡å‹å¢©å­˜ç›®å½•
        """
        self.lookback_days = lookback_days
        self.model_dir = model_dir
        self.models = {}  # æ¯ä¸ªæ¸¸èµ„çš„æ¨¡å‹
        self.feature_engineer = TimeSeriesFeatureEngineer(lookback_days)
        self.capital_stats = {}  # æ¸¸èµ„ç»Ÿè®¡ä¿¡æ¯
        
        Path(model_dir).mkdir(exist_ok=True)
        
        if not KERAS_AVAILABLE:
            logger.error("Kerasæœªå¯ç”¨ï¼ŒLSTMåŠŸèƒ½ç¦ç”¨")
    
    def build_lstm_model(
        self,
        input_shape: Tuple[int, int],
        lstm_units: int = 64,
        dropout_rate: float = 0.2
    ) -> Sequential:
        """
        æ§‹å»ºä¸€ä¸ªç®€å•çš„LSTMæ¨¡å¾ (ç©¶æ„æ€§ä¸æ°)
        
        Args:
            input_shape: (sequence_length, n_features)
            lstm_units: LSTMå•å…ƒæ•°
            dropout_rate: Dropoutæ¯”ä¾‹
        
        Returns:
            æœªç¼–è¯‘çš„Sequentialæ¨¡å‹
        """
        if not KERAS_AVAILABLE:
            logger.error("Kerasæœªå¯ç”¨")
            return None
        
        model = Sequential([
            Input(shape=input_shape),
            LSTM(lstm_units, return_sequences=True),
            Dropout(dropout_rate),
            LSTM(lstm_units // 2, return_sequences=False),
            Dropout(dropout_rate),
            Dense(32, activation='relu'),
            Dense(1, activation='sigmoid')  # äºŒåˆ†ç±»æ£ç­’
        ])
        
        model.compile(
            optimizer=Adam(learning_rate=0.001),
            loss='binary_crossentropy',
            metrics=['accuracy']
        )
        
        return model
    
    def train_capital_model(
        self,
        capital_name: str,
        df_lhb_history: pd.DataFrame,
        df_kline: pd.DataFrame = None,
        epochs: int = 50,
        batch_size: int = 16
    ) -> Dict:
        """
        å¸ƒä¸‡ä¸€ä¸ªæ¸¸èµ„çš„LSTMæ¨¡å‹
        
        Args:
            capital_name: æ¸¸èµ„åç§°
            df_lhb_history: é¾™è™æ¦œæ–·å¾·æ•³
            df_kline: Kçº¿æ–·å¾·æ•³
            epochs: è¨“ç·´è¶¨ä»£æ•¸
            batch_size: æ‰¹å¤„ç†å¤§å°
        
        Returns:
            è¨“ç·´çµæœ
        """
        if not KERAS_AVAILABLE:
            logger.error("Kerasæœªå¯ç”¨")
            return {'status': 'error', 'message': 'Kerasæœªå¯ç”¨'}
        
        logger.info(f"æ­£åœ¨è¨“ç·´{capital_name}çš„LSTMæ¨¡å‹...")
        
        # æå–ç‰¹å¾
        X_scaled, df_features = self.feature_engineer.engineer_capital_features(
            capital_name,
            df_lhb_history,
            df_kline
        )
        
        if X_scaled is None:
            return {'status': 'error', 'message': f'æ²¡æœ‰æ‰¾åˆ°{capital_name}çš„æ•°æ®'}
        
        # æ±Ÿæ»­æŸ©åºåˆ—
        X_seq, y = self.feature_engineer.create_sequences(
            X_scaled,
            self.lookback_days
        )
        
        if X_seq is None:
            return {'status': 'error', 'message': 'åºåˆ—æ¨¡å¾å¤±è´¥'}
        
        # æ„å»ºä¸¦è¨“ç·´æ¨¡å¾
        model = self.build_lstm_model(input_shape=X_seq.shape[1:])
        
        if model is None:
            return {'status': 'error', 'message': 'æ¨¡å‹æ§‹å»ºå¤±è´¥'}
        
        early_stop = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)
        
        history = model.fit(
            X_seq, y,
            epochs=epochs,
            batch_size=batch_size,
            verbose=0,
            callbacks=[early_stop],
            validation_split=0.2
        )
        
        # ä¿å­˜æ¨¡å‹
        model_path = os.path.join(
            self.model_dir,
            f'lstm_{capital_name}_{datetime.now().strftime("%Y%m%d")}.h5'
        )
        model.save(model_path)
        self.models[capital_name] = model
        
        # è¨ˆç®—æ€»ä½“æˆåŠŸç‡
        historical_success_rate = (y.sum() / len(y)) if len(y) > 0 else 0.5
        self.capital_stats[capital_name] = {
            'total_records': len(df_features),
            'success_rate': historical_success_rate,
            'last_trained': datetime.now()
        }
        
        logger.info(f"{capital_name}æ¨¡å‹è¨“ç·´å®Œæˆ - æ­´å²æˆåŠŸç‡: {historical_success_rate:.1%}")
        
        return {
            'status': 'success',
            'capital': capital_name,
            'final_loss': float(history.history['loss'][-1]),
            'final_val_loss': float(history.history.get('val_loss', [0])[-1]),
            'total_records': len(df_features),
            'historical_success_rate': historical_success_rate,
            'epochs_trained': len(history.history['loss'])
        }
    
    def predict_capital_appearance(
        self,
        capital_name: str,
        df_lhb_recent: pd.DataFrame,
        df_kline_recent: pd.DataFrame = None
    ) -> Optional[LSTMPrediction]:
        """
        é¢„æµ‹æ¸¸èµ„æ˜å¤©æ˜¯å¦ä¸Šæ¦œ
        
        Args:
            capital_name: æ¸¸èµ„åç§°
            df_lhb_recent: æœ€è¿‘Nå¤©çš„é¾™è™æ¦œæ•°æ®
            df_kline_recent: æœ€è¿‘Kçº¿æ•°æ®
        
        Returns:
            LSTMPredictionæˆ–None
        """
        if not KERAS_AVAILABLE or capital_name not in self.models:
            logger.warning(f"{capital_name}æ¨¡å‹æœªå¯ç”¨")
            return None
        
        # æå–æœ€è¿‘ç‰¹å¾
        X_scaled, df_features = self.feature_engineer.engineer_capital_features(
            capital_name,
            df_lhb_recent,
            df_kline_recent
        )
        
        if X_scaled is None or len(X_scaled) < self.lookback_days:
            return None
        
        # è¼‰å…¥æœ€åä¸€ä¸ªseq
        X_seq = X_scaled[-self.lookback_days:].reshape(1, self.lookback_days, -1)
        
        # é¢„æµ‹
        model = self.models[capital_name]
        prob = float(model.predict(X_seq, verbose=0)[0][0])
        
        # ç‰¹å¾é‡è¦æ€§ (dummy - å¯¦é‹å¯ç”¨æ¢¯åº¦åˆ†æ)
        feature_names = [
            'frequency',
            'total_amount',
            'stock_diversity'
        ]
        importance_scores = {
            name: np.random.random()
            for name in feature_names
        }
        importance_scores = {
            k: v/sum(importance_scores.values())
            for k, v in importance_scores.items()
        }
        
        # å¯ä¿¡åº¦å’Œç†ç”±
        confidence = prob if prob > 0.5 else 1 - prob
        
        if prob > 0.5:
            reason = f"åˆ®æ¥¸ç‰¹å¾å˜åŒ–è¶¨å‹¢éš—æ­£å‘ï¼Œæ•ˆå¹²è¶¨æ±½æœ›éå¸¸å¼º"
            action = "ğŸ‘‹ å»ºè­°ç¦®äº’è¨­å ´æ½æ˜¯ä¸Šæ¨æ¸¸èµ„æ¼‚ç¦»è¦å­"
        else:
            reason = f"ç½²é€Ÿæ—å¼ç‰¹å¾çªè®Šè¶¨èƒŒå‘ï¼Œæ”¯æ’•ç‰¹å¾è™›å¼±ã€‚"
            action = "ğŸš¨ æ™‚æ©Ÿä¸æˆç†ï¼Œç­‰å€™åœä½‹è¦é¿"
        
        historical_success = self.capital_stats.get(
            capital_name,
            {}
        ).get('success_rate', 0.5)
        
        return LSTMPrediction(
            prediction_date=datetime.now().strftime('%Y-%m-%d'),
            capital_name=capital_name,
            appearance_probability=prob,
            confidence_score=confidence,
            feature_importance=importance_scores,
            prediction_reason=reason,
            historical_success_rate=historical_success,
            recommended_action=action
        )
    
    def predict_multiple_capitals(
        self,
        capital_names: List[str],
        df_lhb_recent: pd.DataFrame,
        df_kline_recent: pd.DataFrame = None
    ) -> List[LSTMPrediction]:
        """
        æ‰¹é‡é¢„æµ‹å¤šä¸ªæ¸¸èµ„
        """
        predictions = []
        
        for capital_name in capital_names:
            pred = self.predict_capital_appearance(
                capital_name,
                df_lhb_recent,
                df_kline_recent
            )
            
            if pred is not None:
                predictions.append(pred)
        
        return predictions
    
    def load_model(self, capital_name: str, model_path: str) -> bool:
        """
        å¾æª”æ¡ˆæ‡‰è²¼æ¨¡å¾
        """
        if not KERAS_AVAILABLE:
            return False
        
        try:
            model = load_model(model_path)
            self.models[capital_name] = model
            logger.info(f"å·²åŠ è¼‰{capital_name}çš„æ¨¡å¾")
            return True
        except Exception as e:
            logger.error(f"åŠ è¼‰æ¨¡å¾å¤±è´¥: {str(e)}")
            return False
    
    def get_model_info(self, capital_name: str) -> Dict:
        """
        å–å¾—æ¨¡å¾ä¿¡æ¯
        """
        if capital_name not in self.capital_stats:
            return {}
        
        return {
            'capital': capital_name,
            'total_records': self.capital_stats[capital_name].get('total_records', 0),
            'historical_success_rate': self.capital_stats[capital_name].get('success_rate', 0),
            'last_trained': str(self.capital_stats[capital_name].get('last_trained', '')),
            'model_available': capital_name in self.models
        }
