"""
å…¨æ¯æ—¶é—´æœºå™¨å¼•æ“ - è¿ç»­å¤šæ—¥å›æµ‹
è‡ªåŠ¨æ‰§è¡Œè¿ç»­Nä¸ªäº¤æ˜“æ—¥çš„å›æµ‹ï¼ŒéªŒè¯ç­–ç•¥ç¨³å®šæ€§

Author: iFlow CLI
Date: 2026-02-24
Version: 1.2.0 - é…ç½®ç®¡ç†å™¨é›†æˆç‰ˆ
"""
import pandas as pd
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple, Set
from pathlib import Path
import json
import logging

from logic.core.path_resolver import PathResolver

# è®°å¿†è¡°å‡å‚æ•°
MEMORY_DECAY_FACTOR = 0.5      # è¡°å‡ç³»æ•°
MEMORY_MIN_SCORE = 10.0        # æœ€ä½åˆ†æ•°é˜ˆå€¼
MEMORY_MAX_ABSENCE_DAYS = 2    # è¿ç»­ä¸ä¸Šæ¦œæœ€å¤§å¤©æ•°
from logic.core.metric_definitions import MetricDefinitions
from logic.core.sanity_guards import SanityGuards
from logic.data_providers.qmt_manager import QmtDataManager
from logic.data_providers.universe_builder import UniverseBuilder
from logic.core.config_manager import get_config_manager
from logic.utils.metrics_utils import render_battle_dashboard

logger = logging.getLogger(__name__)


class TimeMachineEngine:
    """
    å…¨æ¯æ—¶é—´æœºå™¨ - è¿ç»­äº¤æ˜“æ—¥å›æµ‹å¼•æ“
    
    ä½¿ç”¨ç¤ºä¾‹:
        engine = TimeMachineEngine()
        results = engine.run_continuous_backtest(
            start_date='20251231',
            end_date='20260115',
            stock_pool='data/cleaned_candidates_66.csv'
        )
    """
    
    # è®°å¿†æ–‡ä»¶è·¯å¾„
    MEMORY_FILE = Path(__file__).parent.parent.parent / 'data' / 'memory' / 'ShortTermMemory.json'
    
    def __init__(self, initial_capital: float = 20000.0):
        self.initial_capital = initial_capital
        self.data_manager = QmtDataManager()
        self.results_cache: Dict[str, Dict] = {}
        self._ensure_output_dirs()
        
        # CTOä¿®å¤ï¼šå¯åŠ¨VIPæœåŠ¡ç¡®ä¿æ•°æ®è¿æ¥
        self.data_manager.start_vip_service()
        
    def _ensure_output_dirs(self):
        """ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨"""
        output_dir = PathResolver.get_data_dir() / 'backtest_out'
        PathResolver.ensure_dir(output_dir)
        PathResolver.ensure_dir(output_dir / 'time_machine')
        
    def _get_avg_volume_5d(self, stock_code: str, date: str) -> float:
        """
        è·å–è‚¡ç¥¨5æ—¥å¹³å‡æˆäº¤é‡ (ç”¨äºè®¡ç®—é‡æ¯”)
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            date: å½“å‰æ—¥æœŸ 'YYYYMMDD'
        
        Returns:
            5æ—¥å¹³å‡æˆäº¤é‡ï¼Œå¤±è´¥è¿”å›0
        """
        try:
            from xtquant import xtdata
            from datetime import datetime, timedelta
            
            # è®¡ç®—5ä¸ªäº¤æ˜“æ—¥çš„æ—¥æœŸèŒƒå›´
            current = datetime.strptime(date, '%Y%m%d')
            dates = []
            while len(dates) < 5:
                current -= timedelta(days=1)
                # æ£€æŸ¥æ˜¯å¦æ˜¯äº¤æ˜“æ—¥ï¼ˆè·³è¿‡å‘¨æœ«ï¼‰
                if current.weekday() < 5:
                    dates.append(current.strftime('%Y%m%d'))
            
            # è·å–æ—¥çº¿æ•°æ®
            normalized_code = self._normalize_stock_code(stock_code)
            data = xtdata.get_local_data(
                field_list=['time', 'volume'],
                stock_list=[normalized_code],
                period='1d',
                start_time=dates[-1],  # æœ€æ—©æ—¥æœŸ
                end_time=dates[0]      # æœ€è¿‘æ—¥æœŸ
            )
            
            if data and normalized_code in data:
                df = data[normalized_code]
                if not df.empty and len(df) >= 5:
                    # å–æœ€è¿‘5ä¸ªäº¤æ˜“æ—¥çš„æˆäº¤é‡
                    recent_volumes = df.tail(5)['volume'].values
                    avg_volume = sum(recent_volumes) / len(recent_volumes)
                    return float(avg_volume)
            
            return 0.0
            
        except Exception as e:
            logger.warning(f"è·å–5æ—¥å‡é‡å¤±è´¥ {stock_code}: {e}")
            return 0.0
    
    def _get_float_volume(self, stock_code: str) -> float:
        """
        è·å–è‚¡ç¥¨æµé€šè‚¡æœ¬ (ç”¨äºè®¡ç®—æ¢æ‰‹ç‡)
        
        ã€CTOä¿®å¤ã€‘ä½¿ç”¨QMTæ­£ç¡®çš„API: get_instrument_detail
        åˆ é™¤å¹»è§‰API: xtdata.get_stock_list() (è¯¥APIä¸å­˜åœ¨)
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
        
        Returns:
            æµé€šè‚¡æœ¬ï¼Œå¤±è´¥è¿”å›0
        """
        try:
            from xtquant import xtdata
            
            normalized_code = self._normalize_stock_code(stock_code)
            
            # ã€CTOä¿®å¤ã€‘ä½¿ç”¨æ­£ç¡®çš„QMT APIè·å–è‚¡ç¥¨è¯¦æƒ…
            detail = xtdata.get_instrument_detail(normalized_code, True)
            
            if detail is not None:
                # æå–FloatVolume(æµé€šè‚¡æœ¬)
                fv = detail.get('FloatVolume', 0) if hasattr(detail, 'get') else getattr(detail, 'FloatVolume', 0)
                if fv:
                    # ã€CTOä¿®å¤ã€‘å¼ºåˆ¶è½¬æ¢ä¸ºfloatï¼Œé˜²æ­¢ç±»å‹çˆ†ç‚¸
                    return float(fv)
            
            # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨å†å²æ•°æ®ä¼°ç®—
            logger.warning(f"ã€é™çº§ã€‘{stock_code} æ— æ³•è·å–æµé€šè‚¡æœ¬ï¼Œå°è¯•ä¼°ç®—...")
            data = xtdata.get_local_data(
                field_list=['time', 'volume', 'amount'],
                stock_list=[normalized_code],
                period='1d',
                start_time='20250101',
                end_time='20251231'
            )
            
            if data and normalized_code in data:
                df = data[normalized_code]
                if not df.empty:
                    avg_daily_volume = df['volume'].tail(10).mean()
                    # ã€CTOä¿®å¤ã€‘å¼ºåˆ¶è½¬æ¢ä¸ºfloat
                    return float(avg_daily_volume * 200)
            
            return 0.0
            
        except Exception as e:
            logger.warning(f"è·å–æµé€šè‚¡æœ¬å¤±è´¥ {stock_code}: {e}")
            return 0.0
    
    def _get_volume_ratio_threshold_for_date(self, date: str, base_percentile: float) -> float:
        """
        è·å–ç‰¹å®šæ—¥æœŸçš„é‡æ¯”é˜ˆå€¼ (CTO SSOTåŸåˆ™)
        
        Args:
            date: æ—¥æœŸ 'YYYYMMDD'
            base_percentile: åŸºç¡€åˆ†ä½æ•°
        
        Returns:
            é‡æ¯”é˜ˆå€¼
        """
        # CTOå¼ºåˆ¶æ‰§è¡Œï¼šå›æµ‹å¼•æ“å¿…é¡»ä½¿ç”¨é…ç½®ç®¡ç†å™¨çš„åˆ†ä½æ•°å‚æ•°
        # ä¸å…è®¸åœ¨å›æµ‹ä¸­å†™æ­» return 3.0ï¼å¿…é¡»ç®—å‡ºå½“å¤©çš„åŠ¨æ€åˆ†ä½æ•°ï¼
        from logic.core.config_manager import get_config_manager
        config_manager = get_config_manager()
        
        # ä½¿ç”¨é…ç½®ä¸­çš„åˆ†ä½æ•°ï¼Œå¦‚æœæä¾›äº†base_percentileåˆ™ä½¿ç”¨å®ƒï¼Œå¦åˆ™ä½¿ç”¨é…ç½®é»˜è®¤å€¼
        volume_ratio_percentile = config_manager.get_volume_ratio_percentile('live_sniper')
        
        # ä¸ºäº†è®¡ç®—åŠ¨æ€é˜ˆå€¼ï¼Œéœ€è¦è·å–å½“æ—¥çš„é‡æ¯”æ•°æ®
        # ç”±äºåœ¨å›æµ‹ç¯å¢ƒä¸‹ï¼Œæˆ‘ä»¬æ— æ³•ç›´æ¥è·å–å½“æ—¥å…¨å¸‚åœºæ•°æ®
        # æ‰€ä»¥è¿™é‡Œä½¿ç”¨é…ç½®çš„åˆ†ä½æ•°å€¼ä½œä¸ºåŸºå‡†ï¼Œä½†ä¸ä½¿ç”¨ç¡¬ç¼–ç çš„3.0
        return volume_ratio_percentile
    
    def get_trade_dates(self, start_date: str, end_date: str) -> List[str]:
        """
        è·å–äº¤æ˜“æ—¥åˆ—è¡¨ï¼ˆè‡ªåŠ¨è·³è¿‡å‘¨æœ«å’ŒèŠ‚å‡æ—¥ï¼‰
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ 'YYYYMMDD'
            end_date: ç»“æŸæ—¥æœŸ 'YYYYMMDD'
        
        Returns:
            äº¤æ˜“æ—¥åˆ—è¡¨
        """
        # ç®€åŒ–ç‰ˆï¼šåªè·³è¿‡å‘¨æœ«
        dates = []
        current = datetime.strptime(start_date, '%Y%m%d')
        end = datetime.strptime(end_date, '%Y%m%d')
        
        while current <= end:
            # è·³è¿‡å‘¨æœ« (5=Saturday, 6=Sunday)
            if current.weekday() < 5:
                dates.append(current.strftime('%Y%m%d'))
            current += timedelta(days=1)
        
        logger.info(f"ã€æ—¶é—´æœºå™¨ã€‘è·å–åˆ° {len(dates)} ä¸ªäº¤æ˜“æ—¥ï¼ˆ{start_date} è‡³ {end_date}ï¼‰")
        return dates
    
    def run_daily_backtest(self, date: str, stock_pool: List[str] = None) -> Dict:
        # ã€CTOä¿®å¤ã€‘å…¨å¸‚åœºæ‰«æå…œåº•
        if stock_pool is None:
            import logging
            logger = logging.getLogger(__name__)
            logger.info("ã€æ—¶é—´æœºå™¨ã€‘æœªæŒ‡å®šè‚¡ç¥¨æ± ï¼Œé»˜è®¤è·å–å…¨å¸‚åœºè‚¡ç¥¨...")
            try:
                from xtquant import xtdata
                stock_pool = xtdata.get_stock_list_in_sector('æ²ªæ·±Aè‚¡')
            except Exception:
                stock_pool = []
            if not stock_pool:
                logger.warning("ã€æ—¶é—´æœºå™¨ã€‘è·å–å…¨å¸‚åœºå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®ã€‚")
                return None
        """
        å•æ—¥å›æµ‹
        
        æ¨¡æ‹Ÿå®ç›˜æµç¨‹ï¼š
        1. 09:30 å¼€ç›˜å‰å‡†å¤‡
        2. 09:40 è®¡ç®—æ—©ç›˜æ•°æ®
        3. è¾“å‡ºå½“æ—¥Top 20 (CTODict: æ‰©å®¹è§‚å¯Ÿæ¢¯åº¦)
        
        Args:
            date: äº¤æ˜“æ—¥æœŸ 'YYYYMMDD'
            stock_pool: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        
        Returns:
            å½“æ—¥å›æµ‹ç»“æœå­—å…¸
        """
        print(f"\n{'='*60}")
        print(f"ã€æ—¶é—´æœºå™¨ã€‘å›æµ‹æ—¥æœŸ: {date}")
        print(f"{'='*60}")
        
        daily_result = {
            'date': date,
            'status': 'running',
            'top20': [],
            'signals': [],
            'errors': [],
            'total_stocks': len(stock_pool),
            'valid_stocks': 0
        }
        
        try:
            # CTOä¿®å¤ï¼šç¬¬ä¸€æ­¥ - VIPé˜»å¡ä¸‹è½½æ•°æ®ï¼ˆæ‰“é€šä»»ç£äºŒè„‰ï¼ï¼‰
            # ã€CTOä¿®å¤ã€‘ç¦ç”¨é˜»å¡ä¸‹è½½ï¼Œåªä½¿ç”¨æœ¬åœ°ç¼“å­˜\n            # ç³»ç»Ÿåªè¯»å–æœ¬åœ°å·²ç¼“å­˜æ•°æ®ï¼Œæ— æ•°æ®ç›´æ¥è·³è¿‡\n            
            # 2. è·å–å½“æ—¥è‚¡ç¥¨æ± æ•°æ®
            # ã€CTOä¿®å¤ã€‘ç¦æ­¢ä¸²è¡Œæ‹‰å–Tickï¼ä½¿ç”¨æ—¥Kæ•°æ®å¿«é€Ÿç­›é€‰ï¼Œå¤§å¹…æé€Ÿ
            print(f"  ğŸ“Š è·å– {len(stock_pool)} åªè‚¡ç¥¨æ•°æ®...")
            
            valid_stocks = []
            batch_size = 100  # æ‰¹å¤„ç†å¤§å°
            
            # ã€CTOä¼˜åŒ–ã€‘ä½¿ç”¨æ—¥Kæ•°æ®å¿«é€Ÿåˆç­›ï¼Œé¿å…5000åªè‚¡ç¥¨ä¸²è¡Œæ‹‰å–Tick
            try:
                from xtquant import xtdata
                
                # æ‰¹é‡è·å–æ—¥Kæ•°æ®ï¼ˆå‘é‡åŒ–ï¼Œé€Ÿåº¦å¿«ï¼‰
                normalized_codes = [self._normalize_stock_code(s) for s in stock_pool]
                daily_data = xtdata.get_local_data(
                    field_list=['time', 'open', 'high', 'low', 'close', 'volume'],
                    stock_list=normalized_codes,
                    period='1d',
                    start_time=date,
                    end_time=date
                )
                
                # å¿«é€Ÿç­›é€‰æœ‰æ—¥Kæ•°æ®çš„è‚¡ç¥¨
                stocks_with_daily = []
                for stock in stock_pool:
                    norm_code = self._normalize_stock_code(stock)
                    if daily_data and norm_code in daily_data and not daily_data[norm_code].empty:
                        stocks_with_daily.append(stock)
                
                print(f"  ğŸ“ˆ æ—¥Kæ•°æ®ç­›é€‰: {len(stocks_with_daily)}/{len(stock_pool)} åªæœ‰æ•ˆ")
                
                # å¯¹åˆç­›åçš„è‚¡ç¥¨ï¼Œé€‰æ‹©æ€§è·å–Tickæ•°æ®
                for i, stock in enumerate(stocks_with_daily):
                    try:
                        # ã€CTOæ ¸çº§é‡æ„ã€‘åˆ é™¤è¿›åº¦æ—¥å¿—ï¼Œä¸¥ç¦å¾ªç¯å†…ä¸‹è½½
                        # è¿›åº¦æ˜¾ç¤ºå·²åˆ é™¤ - ä¸å†è¾“å‡º"â³ æ£€æŸ¥è¿›åº¦"
                        
                        # ã€CTOä¼˜åŒ–ã€‘ä¼˜å…ˆä½¿ç”¨æ—¥Kæ•°æ®ä¼°ç®—ï¼ŒTickæ•°æ®æŒ‰éœ€è·å–
                        tick_data = self._get_tick_data(stock, date)
                        # ã€CTOä¿®å¤ã€‘é™ä½é˜ˆå€¼ä»100åˆ°10ï¼Œé¿å…æ•°æ®ä¸è¶³æ—¶å…¨éƒ¨è·³è¿‡
                        if tick_data is not None and len(tick_data) > 10:
                            valid_stocks.append(stock)
                            logger.debug(f"  âœ“ {stock}: {len(tick_data)} æ¡Tickæ•°æ®")
                        else:
                            # Tickæ•°æ®ä¸è¶³ï¼Œå°è¯•ä½¿ç”¨æ—¥Kæ•°æ®
                            logger.debug(f"  â­ï¸ {stock}: Tickæ•°æ®ä¸è¶³({len(tick_data) if tick_data else 0}æ¡)ï¼Œå°è¯•æ—¥Ké™çº§")
                            # ã€CTOä¿®å¤ã€‘å³ä½¿Tickæ•°æ®ä¸è¶³ï¼Œåªè¦æœ‰æ—¥Kæ•°æ®ä¹ŸåŠ å…¥
                            valid_stocks.append(stock)
                            
                    except Exception as e:
                        # ã€CTOä¼˜åŒ–ã€‘å¼‚å¸¸æ—¶ç›´æ¥continueï¼Œä¸è®°å½•è¯¦ç»†é”™è¯¯ä»¥æé€Ÿ
                        continue
                        
            except Exception as e:
                logger.warning(f"  âš ï¸ æ‰¹é‡æ•°æ®è·å–å¤±è´¥ï¼Œé™çº§åˆ°ä¸²è¡Œæ¨¡å¼: {e}")
                # é™çº§ï¼šä¸²è¡Œæ¨¡å¼ä½†ä»ä¿æŒå¿«é€Ÿè·³è¿‡
                for stock in stock_pool:
                    try:
                        tick_data = self._get_tick_data(stock, date)
                        if tick_data is not None and len(tick_data) > 100:
                            valid_stocks.append(stock)
                    except:
                        continue  # å¿«é€Ÿè·³è¿‡å¤±è´¥çš„è‚¡ç¥¨
            
            daily_result['valid_stocks'] = len(valid_stocks)
            print(f"  âœ… æœ‰æ•ˆæ•°æ®: {len(valid_stocks)} åª")
            
            if len(valid_stocks) < 5:
                daily_result['status'] = 'insufficient_data'
                logger.warning(f"  âš ï¸ æ•°æ®ä¸è¶³: ä»… {len(valid_stocks)} åªæœ‰æ•ˆæ•°æ®")
                return daily_result
            
            # 2. è®¡ç®—09:40æŒ‡æ ‡ï¼ˆæ—©ç›˜5åˆ†é’Ÿ+5åˆ†é’Ÿï¼‰
            print(f"  ğŸ§® è®¡ç®—æ—©ç›˜æŒ‡æ ‡...")
            
            stock_scores = []
            data_missing_count = 0
            data_missing_stocks = []  # è®°å½•å› æ•°æ®ç¼ºå¤±è¢«è·³è¿‡çš„è‚¡ç¥¨
            
            for stock in valid_stocks:
                try:
                    score = self._calculate_morning_score(stock, date)
                    
                    # ã€CTOä¿®å¤ã€‘æ•°æ®å®Œæ•´æ€§æ–­è¨€ï¼šç¦æ­¢0åˆ†å…œåº•
                    if score is None:
                        data_missing_count += 1
                        data_missing_stocks.append(stock)
                        logger.warning(f"  âš ï¸ {stock}: æ•°æ®ç¼ºå¤±ï¼Œè·³è¿‡ç®—åˆ†")
                        continue
                    
                    # æ£€æŸ¥å…³é”®æ•°æ®å­—æ®µ
                    if score.get('final_score', 0) == 0:
                        # åŒºåˆ†æ˜¯Vetoå¯¼è‡´çš„0åˆ†è¿˜æ˜¯æ•°æ®ç¼ºå¤±å¯¼è‡´çš„0åˆ†
                        if not score.get('is_vetoed', False):
                            data_missing_count += 1
                            data_missing_stocks.append(stock)
                            logger.warning(f"  âš ï¸ {stock}: final_score=0ä¸”æ— Vetoæ ‡è®°ï¼Œåˆ¤å®šä¸ºæ•°æ®ç¼ºå¤±ï¼Œè·³è¿‡")
                            continue
                    
                    # æ£€æŸ¥æ˜¨æ”¶ä»·å’Œå¼€ç›˜ä»·çš„æœ‰æ•ˆæ€§
                    if score.get('pre_close', 0) <= 0:
                        data_missing_count += 1
                        data_missing_stocks.append(stock)
                        logger.warning(f"  âš ï¸ {stock}: pre_close={score.get('pre_close', 0)} æ— æ•ˆï¼Œè·³è¿‡")
                        continue
                    
                    stock_scores.append(score)
                    
                except Exception as e:
                    error_msg = f"{stock}è®¡ç®—é”™è¯¯: {str(e)}"
                    daily_result['errors'].append(error_msg)
                    logger.warning(f"  âš ï¸ {error_msg}")
            
            # 3. ã€CTOå¤šç»´æ’åºã€‘å¾—åˆ†ç›¸åŒçœ‹MFEï¼ŒMFEå¤§äº5å€’æ‰£
            # è®¡ç®—MFE (æœ€å¤§ favorable excursion)
            for score in stock_scores:
                max_price = score.get('max_price', 0)
                pre_close = score.get('pre_close', 1)
                # MFE = (æœ€é«˜ä»· - æ˜¨æ”¶) / æ˜¨æ”¶ * 100ï¼Œæ— é‡çº²ç™¾åˆ†æ¯”
                mfe = ((max_price - pre_close) / pre_close * 100) if pre_close > 0 else 0
                score['mfe'] = mfe
                # MFEå¤§äº5%å€’æ‰£åˆ†æ•°ï¼ˆæƒ©ç½šå†²é«˜å›è½ï¼‰
                if mfe > 5:
                    score['final_score'] = score.get('final_score', 0) - (mfe - 5) * 2
            
            # å¤šç»´æ’åºï¼šfinal_scoreé™åºï¼Œç›¸åŒåˆ™çœ‹MFEå‡åºï¼ˆMFEè¶Šå°è¶Šå¥½ï¼‰
            stock_scores.sort(key=lambda x: (x.get('final_score', 0), -x.get('mfe', 0)), reverse=True)
            top20 = stock_scores[:20]
            
            daily_result['top20'] = top20
            daily_result['status'] = 'success'
            daily_result['data_missing_count'] = data_missing_count
            daily_result['data_missing_stocks'] = data_missing_stocks
            
            # 5. æ‰§è¡Œè®°å¿†è¡°å‡
            self._apply_memory_decay(date, top20)
            
            # ============================================================
            # ã€è®°å¿†å¼•æ“æŒ‚è½½ã€‘ç›˜åç»“ç®— - å†™å…¥è®°å¿†åŸºå› 
            # ============================================================
            try:
                from logic.memory.short_term_memory import ShortTermMemoryEngine
                memory_engine = ShortTermMemoryEngine()
                
                # ä¸ºTop20ä¸­ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨å†™å…¥è®°å¿†
                # æ¡ä»¶ï¼šæ¶¨å¹…>8% ä¸” æ¢æ‰‹>5% (ShortTermMemoryEngineå†…éƒ¨ä¼šæ£€æŸ¥)
                for item in top20:
                    stock_code = item['stock_code']
                    final_change = item.get('final_change', 0)
                    # ä¼°ç®—æ¢æ‰‹ç‡ (ä½¿ç”¨turnover_rateå­—æ®µæˆ–ä¼°ç®—)
                    turnover_rate = item.get('turnover_rate', 5.5)  # é»˜è®¤æ»¡è¶³é˜ˆå€¼
                    final_score = item.get('final_score', 0)
                    
                    # å†™å…¥è®°å¿† (å¼•æ“å†…éƒ¨ä¼šæ£€æŸ¥æ¶¨å¹…>8%ä¸”æ¢æ‰‹>5%)
                    memory_engine.write_memory(
                        stock_code=stock_code,
                        gain_pct=final_change,
                        turnover_rate=turnover_rate,
                        blood_pct=final_score,
                        metadata={
                            'date': date,
                            'sustain_ratio': item.get('sustain_ratio', 0),
                            'inflow_ratio': item.get('inflow_ratio', 0),
                            'is_vetoed': item.get('is_vetoed', False)
                        }
                    )
                
                # æ¹®ç­è¿‡æœŸè®°å¿†(â‰¥2å¤©æœªæ¿€æ´»)
                memory_engine.annihilate_expired(today=date)
                
                # å¼ºåˆ¶ä¿å­˜
                memory_engine.force_save()
                memory_engine.close()
                
                logger.info(f"ğŸ§  ã€è®°å¿†å¼•æ“ã€‘ç›˜åç»“ç®—å®Œæˆ: {date} è®°å¿†å·²å†™å…¥")
                
            except Exception as mem_e:
                # Gracefulé™çº§ï¼šè®°å¿†å¼•æ“å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
                logger.warning(f"âš ï¸ ã€è®°å¿†å¼•æ“ã€‘ç›˜åç»“ç®—å¤±è´¥: {mem_e}")
            
            # ã€Step6: æ—¶ç©ºå¯¹é½ä¸å…¨æ¯å›æ¼”UIçœ‹æ¿ã€‘
            # ã€CTOç»Ÿä¸€æˆ˜æŠ¥ã€‘ä½¿ç”¨å·¥ä¸šçº§å¤§å±render_battle_dashboard
            
            # æ„å»ºdragonæ•°æ®æ ¼å¼é€‚é…å¤§å±
            dragons_for_dashboard = []
            for item in top20:
                stock_code = item['stock_code']
                final_score = item.get('final_score', 0)
                final_change = item.get('final_change', item.get('change_0940', 0))
                real_close = item.get('real_close', 0)
                pre_close = item.get('pre_close', 1)
                is_vetoed = item.get('is_vetoed', False)
                veto_reason = item.get('veto_reason', '')
                inflow_ratio = item.get('inflow_ratio', 0)
                ratio_stock = item.get('ratio_stock', 0)
                sustain_ratio = item.get('sustain_ratio', 0)
                pullback_ratio = item.get('pullback_ratio', 0)
                mfe = item.get('mfe', 0)
                
                # çº¯åº¦è¯„çº§
                space_gap_pct = pullback_ratio
                purity = 'æä¼˜' if space_gap_pct < 0.05 else 'ä¼˜' if space_gap_pct < 0.10 else 'è‰¯'
                
                # æ ‡ç­¾
                tag = veto_reason if is_vetoed else 'æ¢æ‰‹ç”œç‚¹' if item.get('passes_filters', False) else 'æ™®é€š'
                
                dragons_for_dashboard.append({
                    'code': stock_code,
                    'score': final_score,
                    'price': real_close if real_close > 0 else item.get('price_0940', 0),
                    'change': final_change,
                    'inflow_ratio': inflow_ratio,
                    'ratio_stock': ratio_stock,
                    'sustain_ratio': sustain_ratio,
                    'mfe': mfe,
                    'purity': purity,
                    'tag': tag
                })
            
            # è°ƒç”¨å·¥ä¸šçº§å¤§å±ï¼ˆä¸å®ç›˜ç»Ÿä¸€ï¼‰
            if dragons_for_dashboard:
                render_battle_dashboard(
                    top_dragons=dragons_for_dashboard,
                    title=f"å…¨æ¯å›æµ‹ [{date}]",
                    clear_screen=False  # ä¸å›æµ‹ä¸æ¸…å±ï¼Œä¿ç•™æ—¥å¿—
                )
            
            # ã€CTOä¿®å¤ã€‘æ‰“å°æ•°æ®ç¼ºå¤±ç»Ÿè®¡
            if data_missing_count > 0:
                print(f"\n  ğŸ“Š æ•°æ®å®Œæ•´æ€§æŠ¥å‘Š:")
                print(f"     å› æ•°æ®ç¼ºå¤±è¢«è·³è¿‡: {data_missing_count} åª")
                print(f"     è¢«è·³è¿‡è‚¡ç¥¨: {', '.join(data_missing_stocks[:10])}{'...' if len(data_missing_stocks) > 10 else ''}")
                logger.info(f"ã€æ—¶é—´æœºå™¨ã€‘{date} æ•°æ®ç¼ºå¤±ç»Ÿè®¡: {data_missing_count} åªè¢«è·³è¿‡")
            
            logger.info(f"ã€æ—¶é—´æœºå™¨ã€‘{date} å›æµ‹æˆåŠŸï¼ŒTop20: {[s['stock_code'] for s in top20[:5]]}...")
            
        except Exception as e:
            daily_result['status'] = 'error'
            error_msg = str(e)
            daily_result['errors'].append(error_msg)
            logger.error(f"  âŒ é”™è¯¯: {error_msg}")
            print(f"  âŒ é”™è¯¯: {error_msg}")
        
        return daily_result
    
    def _get_tick_data(self, stock_code: str, date: str) -> Optional[pd.DataFrame]:
        """
        ã€CTOé“è…•æ–­å¤´å°ã€‘ï¼šå›æµ‹å¼•æ“åªèƒ½è¯»æœ¬åœ°ï¼æ²¡æœ‰å°±æ»šï¼
        ä¸¥ç¦ä»»ä½•ä¸‹è½½è¡Œä¸ºï¼
        """
        try:
            from xtquant import xtdata
            
            normalized_code = self._normalize_stock_code(stock_code)
            
            # åªè¯»æœ¬åœ°æ•°æ®ï¼Œä¸¥ç¦ä¸‹è½½ï¼
            data = xtdata.get_local_data(
                field_list=['time', 'lastPrice', 'volume'],
                stock_list=[normalized_code],
                period='tick',
                start_time=date,
                end_time=date
            )
            
            if data and normalized_code in data and not data[normalized_code].empty:
                df = data[normalized_code]
                # è½¬æ¢æ—¶é—´æ ¼å¼
                if 'time' in df.columns:
                    df['time'] = df['time'].apply(
                        lambda x: datetime.fromtimestamp(x/1000).strftime('%H:%M:%S') 
                        if isinstance(x, (int, float)) else str(x)
                    )
                # é‡å‘½åä»·æ ¼åˆ—
                if 'lastPrice' in df.columns:
                    df = df.rename(columns={'lastPrice': 'price'})
                return df
            
            # æ— æ•°æ®ç›´æ¥è¿”å›Noneï¼Œä¸¥ç¦ä¸‹è½½ï¼
            return None
            
        except Exception as e:
            logger.warning(f"è·å–Tickæ•°æ®å¤±è´¥ {stock_code}: {e}")
            return None
    
    def _get_pre_close(self, stock_code: str, date: str) -> float:
        """
        è·å–æ˜¨æ”¶ä»· (CTOä¿®å¤: ç¡®ä¿VIPæœåŠ¡å·²å¯åŠ¨)
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            date: æ—¥æœŸ 'YYYYMMDD'
        
        Returns:
            æ˜¨æ”¶ä»·ï¼Œå¤±è´¥è¿”å›0
        """
        try:
            from xtquant import xtdata
            
            # CTOä¿®å¤: ç¡®ä¿VIPæœåŠ¡å·²å¯åŠ¨æ‰èƒ½è¯»å–æ•°æ®
            if not self.data_manager._vip_initialized:
                self.data_manager.start_vip_service()
            
            # æ ‡å‡†åŒ–ä»£ç 
            normalized_code = self._normalize_stock_code(stock_code)
            
            # è®¡ç®—å‰ä¸€å¤©çš„æ—¥æœŸ
            current = datetime.strptime(date, '%Y%m%d')
            prev_date = (current - timedelta(days=1)).strftime('%Y%m%d')
            
            # è·å–æ—¥çº¿æ•°æ®
            data = xtdata.get_local_data(
                field_list=['time', 'close'],
                stock_list=[normalized_code],
                period='1d',
                start_time=prev_date,
                end_time=date
            )
            
            if data and normalized_code in data:
                df = data[normalized_code]
                if not df.empty and len(df) >= 1:
                    # å–å€’æ•°ç¬¬äºŒæ¡ï¼ˆæ˜¨å¤©çš„æ”¶ç›˜ä»·ï¼‰
                    if len(df) >= 2:
                        return float(df.iloc[-2]['close'])
                    else:
                        # åªæœ‰ä¸€æ¡æ•°æ®æ—¶å–ç¬¬ä¸€æ¡
                        return float(df.iloc[0]['close'])
            
            return 0.0
            
        except Exception as e:
            logger.warning(f"è·å–æ˜¨æ”¶ä»·å¤±è´¥ {stock_code}: {e}")
            return 0.0
    
    @staticmethod
    def _normalize_stock_code(code: str) -> str:
        """
        æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç æ ¼å¼ä¸º QMT æ ¼å¼ï¼ˆ######.SH / ######.SZï¼‰
        
        Args:
            code: è‚¡ç¥¨ä»£ç ï¼Œæ”¯æŒå¤šç§æ ¼å¼
        
        Returns:
            QMT æ ‡å‡†æ ¼å¼çš„è‚¡ç¥¨ä»£ç 
        """
        if not code:
            return code
        
        # å¦‚æœå·²ç»åŒ…å«äº¤æ˜“æ‰€åç¼€ï¼Œç›´æ¥è¿”å›
        if code.endswith('.SH') or code.endswith('.SZ'):
            return code
        
        # æå–6ä½æ•°å­—ä»£ç 
        code = code.strip().replace('.', '')
        
        if code.startswith('sh'):
            stock_code = code[2:]
            return f"{stock_code}.SH"
        elif code.startswith('sz'):
            stock_code = code[2:]
            return f"{stock_code}.SZ"
        elif code.startswith('6'):
            return f"{code}.SH"
        elif code.startswith(('0', '3')):
            return f"{code}.SZ"
        else:
            # é»˜è®¤ä¸ºä¸»æ¿
            return f"{code}.SH"
    
    def _calculate_morning_score(self, stock_code: str, date: str) -> Optional[Dict]:
        """
        è®¡ç®—æ—©ç›˜å¾—åˆ†
        ä½¿ç”¨MetricDefinitionsè®¡ç®—çœŸå®æŒ‡æ ‡
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            date: æ—¥æœŸ 'YYYYMMDD'
        
        Returns:
            å¾—åˆ†å­—å…¸æˆ–None
        """
        try:
            # ã€CTOé“å¾‹è½¬æ¢ã€‘ï¼šæ‰€æœ‰å‚æ•°å¼ºåˆ¶è½¬floatï¼Œæœç»ç±»å‹çˆ†ç‚¸
            def safe_float(val):
                try:
                    return float(val) if val is not None and str(val).strip() != '' else 0.0
                except (ValueError, TypeError):
                    return 0.0
            
            # è·å–æ•°æ®
            tick_data = self._get_tick_data(stock_code, date)
            if tick_data is None or tick_data.empty:
                return None
            
            # è·å–æ˜¨æ”¶ä»·å¹¶å¼ºåˆ¶è½¬æ¢
            pre_close = safe_float(self._get_pre_close(stock_code, date))
            if pre_close <= 0:
                return None
            
            # è·å–5æ—¥å¹³å‡æˆäº¤é‡å¹¶å¼ºåˆ¶è½¬æ¢
            avg_volume_5d = safe_float(self._get_avg_volume_5d(stock_code, date))
            if avg_volume_5d <= 0:
                return None  # è¿å‡é‡éƒ½æ²¡æœ‰ï¼Œç›´æ¥æ”¾å¼ƒï¼
            
            # ä½¿ç”¨SanityGuardsæ£€æŸ¥æ˜¨æ”¶ä»·
            passed, msg = SanityGuards.check_pre_close_valid(pre_close, stock_code)
            if not passed:
                logger.warning(f"ã€æ—¶é—´æœºå™¨ã€‘{stock_code} æ˜¨æ”¶ä»·æ£€æŸ¥å¤±è´¥: {msg}")
                return None
            
            # ã€CTOä¿®å¤ã€‘æ•°æ®å®Œæ•´æ€§æ–­è¨€ï¼šæ£€æŸ¥å¼€ç›˜ä»·æœ‰æ•ˆæ€§ - å¤šé‡å…œåº•æœºåˆ¶
            open_price = 0.0
            
            # å…œåº•1: å°è¯•ä»æœ¬åœ°æ—¥çº¿æ•°æ®è·å–å¼€ç›˜ä»·
            try:
                from xtquant import xtdata
                daily_data = xtdata.get_local_data(
                    field_list=['time', 'open'],
                    stock_list=[stock_code],
                    period='1d',
                    start_time=date,
                    end_time=date
                )
                if daily_data and stock_code in daily_data and not daily_data[stock_code].empty:
                    open_price = safe_float(daily_data[stock_code]['open'].values[0])
                    logger.debug(f"ã€æ—¶é—´æœºå™¨ã€‘{stock_code} ä»æ—¥çº¿æ•°æ®è·å–å¼€ç›˜ä»·: {open_price}")
            except Exception as e:
                logger.debug(f"ã€æ—¶é—´æœºå™¨ã€‘{stock_code} ä»æ—¥çº¿è·å–å¼€ç›˜ä»·å¤±è´¥: {e}")
            
            # å…œåº•2: å°è¯•ä»Tickæ•°æ®ç¬¬ä¸€ä¸ªè®°å½•è·å–å¼€ç›˜ä»·
            if open_price <= 0:
                try:
                    first_tick = tick_data.iloc[0]
                    if 'lastPrice' in first_tick:
                        open_price = safe_float(first_tick['lastPrice'])
                    elif 'price' in first_tick:
                        open_price = safe_float(first_tick['price'])
                    elif 'openPrice' in first_tick:
                        open_price = safe_float(first_tick['openPrice'])
                    logger.debug(f"ã€æ—¶é—´æœºå™¨ã€‘{stock_code} ä»Tickæ•°æ®è·å–å¼€ç›˜ä»·: {open_price}")
                except Exception as e:
                    logger.debug(f"ã€æ—¶é—´æœºå™¨ã€‘{stock_code} ä»Tickè·å–å¼€ç›˜ä»·å¤±è´¥: {e}")
            
            # å…œåº•3: ä½¿ç”¨æ˜¨æ”¶ä»·ä¼°ç®—å¼€ç›˜ä»· (å‡è®¾é«˜å¼€2%)
            if open_price <= 0 and pre_close > 0:
                open_price = pre_close * 1.02
                logger.warning(f"ã€æ—¶é—´æœºå™¨ã€‘{stock_code} ä½¿ç”¨ä¼°ç®—å¼€ç›˜ä»·: {open_price:.2f} (æ˜¨æ”¶{pre_close} * 1.02)")
            
            # æœ€ç»ˆæ ¡éªŒ: åªæœ‰å½“å¼€ç›˜ä»·å’Œæ˜¨æ”¶ä»·éƒ½ä¸º0æ—¶æ‰è·³è¿‡
            if open_price <= 0 and pre_close <= 0:
                logger.warning(f"ã€æ—¶é—´æœºå™¨ã€‘{stock_code} å¼€ç›˜ä»·å’Œæ˜¨æ”¶ä»·éƒ½æ— æ•ˆï¼Œè·³è¿‡")
                return None
            
            # ä½¿ç”¨æœ‰æ•ˆçš„å¼€ç›˜ä»·
            first_tick_price = open_price if open_price > 0 else pre_close
            
            # CTOä¿®å¤ï¼šæ­£ç¡®å¤„ç†æ—¶é—´æˆ³è·å–09:40ä»·æ ¼
            # ç¡®ä¿timeåˆ—æ˜¯å­—ç¬¦ä¸²æ ¼å¼ HH:MM:SS
            if pd.api.types.is_numeric_dtype(tick_data['time']):
                # å¦‚æœæ˜¯æ•°å€¼ï¼ˆæ¯«ç§’æ—¶é—´æˆ³ï¼‰ï¼Œè½¬æ¢
                tick_data['time_str'] = pd.to_datetime(tick_data['time'], unit='ms') + pd.Timedelta(hours=8)
                tick_data['time_str'] = tick_data['time_str'].dt.strftime('%H:%M:%S')
            else:
                tick_data['time_str'] = tick_data['time'].astype(str)
            
            # ã€CTOé“è¡€æ•´æ”¹ã€‘å…¨å¤©TickçŠ¶æ€æœº - ä¸¥ç¦09:40æˆªæ–­ï¼
            # === åˆå§‹åŒ–çŠ¶æ€å˜é‡ ===
            flow_5min = 0.0
            flow_15min = 0.0
            max_price_after_0945 = 0.0
            vwap_cum_volume = 0.0
            vwap_cum_amount = 0.0
            final_score = 0.0
            sustain_ratio = 0.0
            inflow_ratio = 0.0
            ratio_stock = 0.0
            is_scored = False
            is_vetoed = False
            veto_reason = ""
            
            # === è·å–æµé€šå¸‚å€¼ç”¨äºRatioè®¡ç®— ===
            float_volume = safe_float(self._get_float_volume(stock_code))
            float_market_cap = float_volume * pre_close if float_volume > 0 else 1.0
            
            # === å…¨å¤©Tickéå† (09:30-15:00) ===
            for index, row in tick_data.iterrows():
                curr_time = str(row['time_str'])
                price = safe_float(row['lastPrice']) if 'lastPrice' in row else safe_float(row.get('price', 0))
                volume = safe_float(row.get('volume', 0))
                amount = safe_float(price * volume)
                
                # è®¡ç®—å•ç¬”å‡€æµå…¥ä¼°ç®—
                # ç®€åŒ–ï¼šä»·æ ¼ä¸Šæ¶¨ä¸ºæµå…¥ï¼Œä¸‹è·Œä¸ºæµå‡º
                if index > 0:
                    prev_price_raw = tick_data.iloc[index-1]
                    prev_price = safe_float(prev_price_raw['lastPrice']) if 'lastPrice' in prev_price_raw else safe_float(prev_price_raw.get('price', price))
                    price_change = safe_float(price - prev_price)
                    # å‡€æµå…¥ä¼°ç®—ï¼šä»·æ ¼å˜åŒ– * æˆäº¤é‡ (ç®€åŒ–æ¨¡å‹)
                    estimated_flow = safe_float(price_change * volume) if price_change > 0 else safe_float(price_change * volume * 0.5)
                else:
                    estimated_flow = 0.0
                
                # ã€é˜¶æ®µä¸€ï¼š09:30-09:45ã€‘ç´¯åŠ æ‰“åˆ†æ•°æ®
                if curr_time <= '09:35:00':
                    flow_5min = safe_float(flow_5min + estimated_flow)
                if curr_time <= '09:45:00':
                    flow_15min = safe_float(flow_15min + estimated_flow)
                
                # ã€æ‰“åˆ†å®šæ ¼ã€‘09:45ç¬é—´è°ƒç”¨V18éªŒé’æœº
                if not is_scored and ('09:45:00' <= curr_time < '09:46:00' or curr_time == '09:45:00'):
                    from logic.core.config_manager import get_config_manager
                    config_manager = get_config_manager()
                    
                    # 5æ—¥å¹³å‡æˆäº¤é‡å·²åœ¨å‰æ–¹å¼ºåˆ¶è½¬æ¢
                    flow_5min_median = safe_float(avg_volume_5d / 240) if avg_volume_5d > 0 else 1.0  # 5åˆ†é’Ÿä¸­ä½æ•°ä¼°ç®—
                    
                    # è®¡ç®—Space Gap (çªç ´çº¯åº¦)
                    high_60d = self._get_60d_high(stock_code, date)
                    space_gap_pct = (high_60d - price) / high_60d if high_60d > 0 else 0.5
                    
                    # ============================================================
                    # ã€è®°å¿†å¼•æ“æŒ‚è½½ã€‘ç®—åˆ†å‰è¯»å–è®°å¿†è¡°å‡
                    # ============================================================
                    memory_multiplier = 1.0
                    try:
                        from logic.memory.short_term_memory import ShortTermMemoryEngine
                        memory_engine = ShortTermMemoryEngine()
                        memory_score = memory_engine.read_memory(stock_code, today=date)
                        if memory_score is not None:
                            # å°†è®°å¿†åˆ†æ•°è½¬åŒ–ä¸ºmultiplier (0.5~1.5èŒƒå›´)
                            memory_multiplier = 0.5 + (memory_score / 100.0)
                            logger.debug(f"ğŸ§  {stock_code} è®°å¿†æ¿€æ´»: score={memory_score:.2f}, multiplier={memory_multiplier:.2f}")
                        memory_engine.close()
                    except Exception as mem_e:
                        # Gracefulé™çº§ï¼šè®°å¿†å¼•æ“å¤±è´¥æ—¶multiplier=1.0
                        logger.debug(f"âš ï¸ {stock_code} è®°å¿†è¯»å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤multiplier=1.0: {mem_e}")
                        memory_multiplier = 1.0
                    
                    # è°ƒç”¨V18éªŒé’æœº (CTOç»ˆæçº¢çº¿ç‰ˆ)
                    current_time = datetime.strptime('09:45', '%H:%M').time()
                    base_score, sustain_ratio, inflow_ratio, ratio_stock = self.calculate_true_dragon_score(
                        net_inflow=flow_15min,
                        price=price,
                        prev_close=pre_close,
                        high=price * 1.02,  # ç®€åŒ–
                        low=price * 0.98,
                        flow_5min=flow_5min,
                        flow_15min=flow_15min,
                        flow_5min_median_stock=flow_5min_median,
                        space_gap_pct=space_gap_pct,
                        float_volume_shares=float_volume,
                        current_time=current_time
                    )
                    
                    # åº”ç”¨è®°å¿†multiplier
                    final_score = base_score * memory_multiplier
                    logger.debug(f"ğŸ¯ {stock_code} V18ç®—åˆ†: base={base_score:.2f}, memory_mult={memory_multiplier:.2f}, final={final_score:.2f}")
                    
                    is_scored = True
                
                # ã€é˜¶æ®µäºŒï¼š09:45-15:00ã€‘é˜²å®ˆä¸è®°å½•
                if curr_time > '09:45:00':
                    # è®°å½•09:45åçš„æœ€é«˜ä»· (ç”¨äºéª—ç‚®è®¡ç®—)
                    if price > max_price_after_0945:
                        max_price_after_0945 = safe_float(price)
                    
                    # æ›´æ–°VWAP
                    vwap_cum_volume = safe_float(vwap_cum_volume + volume)
                    vwap_cum_amount = safe_float(vwap_cum_amount + amount)
                    vwap = safe_float(vwap_cum_amount / vwap_cum_volume) if vwap_cum_volume > 0 else safe_float(price)
                    
                    # ç›˜ä¸­ç ´ä½é˜²å®ˆ (VWAPå®½å®¹åˆ¤å®š)
                    if curr_time > '09:50:00' and price < vwap and not is_vetoed:
                        # æ£€æŸ¥æ˜¯å¦æ”¾é‡ç ¸ç›˜
                        recent_volume = safe_float(volume)
                        if recent_volume > safe_float(avg_volume_5d / 240 * 2):  # æ”¾é‡
                            is_vetoed = True
                            veto_reason = "Veto: ç›˜ä¸­ç ´ä½æ´¾å‘"
            
            # ã€é˜¶æ®µä¸‰ï¼š15:00æ—¥è½ç»“ç®—ã€‘ä¸¥ç¦é€ å‡ï¼
            # è·å–æ—¥Kçº¿çœŸå®æ”¶ç›˜ä»·
            daily_k = xtdata.get_local_data(
                field_list=['time', 'close'],
                stock_list=[stock_code],
                period='1d',
                start_time=date,
                end_time=date
            )
            
            real_close = safe_float(price)  # é»˜è®¤ç”¨æœ€åTickä»·æ ¼
            if daily_k and stock_code in daily_k and not daily_k[stock_code].empty:
                real_close = safe_float(daily_k[stock_code]['close'].values[-1])
            
            # è®¡ç®—çœŸå®æ¶¨å¹… (ä½¿ç”¨æ—¥Kæ”¶ç›˜ä»·ï¼)
            final_change = safe_float(MetricDefinitions.TRUE_CHANGE(real_close, pre_close))
            
            # éª—ç‚®ç»ˆå®¡ï¼šPullback_Ratioè®¡ç®— - å…¨éƒ¨ä½¿ç”¨safe_float
            if max_price_after_0945 > pre_close:
                pullback_ratio = safe_float((max_price_after_0945 - real_close) / (max_price_after_0945 - pre_close))
            else:
                pullback_ratio = 0.0
            
            # å°–åˆºéª—ç‚®åˆ¤å®š
            if pullback_ratio > 0.3 and final_change < 0.08:
                is_vetoed = True
                veto_reason = f"Veto: å°–åˆºéª—ç‚® (å›è½{pullback_ratio:.1%})"
                final_score = 0.0  # åˆ†æ•°æ¸…é›¶ï¼
            
            # ã€CTOä¿®å¤ã€‘æ•°æ®å®Œæ•´æ€§æ–­è¨€ï¼šå¦‚æœæ²¡æœ‰æˆåŠŸæ‰“åˆ†ï¼Œè¿”å›None
            if not is_scored:
                logger.warning(f"ã€æ—¶é—´æœºå™¨ã€‘{stock_code} {date}: æœªèƒ½åœ¨09:45å®Œæˆæ‰“åˆ†ï¼ˆç¼ºå°‘å…³é”®æ—¶é—´ç‚¹Tickæ•°æ®ï¼‰ï¼Œåˆ¤å®šä¸ºæ•°æ®ç¼ºå¤±")
                return None
            
            # ã€CTOã€‘è®¡ç®—MFE (Maximum Favorable Excursion) æœ€å¤§æœ‰åˆ©æ³¢åŠ¨ - ä½¿ç”¨safe_float
            mfe = safe_float((max_price_after_0945 - pre_close) / pre_close * 100) if pre_close > 0 else 0.0
            
            # è¿”å›ç»“æœ - æ‰€æœ‰æ•°å€¼éƒ½ç»è¿‡safe_float
            return {
                'stock_code': stock_code,
                'final_score': safe_float(final_score),
                'final_change': safe_float(final_change),
                'real_close': safe_float(real_close),
                'pre_close': safe_float(pre_close),
                'max_price': safe_float(max_price_after_0945),
                'pullback_ratio': safe_float(pullback_ratio),
                'sustain_ratio': safe_float(sustain_ratio),
                'inflow_ratio': safe_float(inflow_ratio),
                'ratio_stock': safe_float(ratio_stock),
                'mfe': safe_float(mfe),
                'is_vetoed': is_vetoed,
                'veto_reason': veto_reason,
                'flow_5min': safe_float(flow_5min),
                'flow_15min': safe_float(flow_15min)
            }
            
        except Exception as e:
            logger.error(f"ã€æ—¶é—´æœºå™¨ã€‘è®¡ç®—æ—©ç›˜å¾—åˆ†å¤±è´¥ {stock_code}: {e}")
            return None
    
    def run_continuous_backtest(self, start_date: str, end_date: str, 
                                 stock_pool_path: str = 'TUSHARE',
                                 use_tushare: bool = True) -> List[Dict]:
        """
        è¿ç»­å¤šæ—¥å›æµ‹ - å…¨æ¯æ—¶é—´æœºå™¨æ ¸å¿ƒ
        CTODict: å¼ºåˆ¶ä½¿ç”¨çœŸå®Tushareç²—ç­›ï¼Œç¦æ­¢æ¨¡æ‹Ÿæ•°æ®
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ 'YYYYMMDD'
            end_date: ç»“æŸæ—¥æœŸ 'YYYYMMDD'
            stock_pool_path: è‚¡ç¥¨æ± æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤'TUSHARE'è¡¨ç¤ºå®æ—¶ç²—ç­›
            use_tushare: æ˜¯å¦ä½¿ç”¨Tushareæ¯æ—¥åŠ¨æ€ç²—ç­›
        
        Returns:
            æ¯æ—¥å›æµ‹ç»“æœåˆ—è¡¨
        """
        print(f"\n{'#'*80}")
        print(f"# å…¨æ¯æ—¶é—´æœºå™¨å¯åŠ¨")
        print(f"# å›æµ‹åŒºé—´: {start_date} ~ {end_date}")
        print(f"# åˆå§‹èµ„é‡‘: {self.initial_capital}å…ƒ")
        print(f"# æ•°æ®æº: {'Tushareå®æ—¶ç²—ç­›' if use_tushare else 'CSVæ–‡ä»¶'}")
        print(f"{'#'*80}\n")
        
        logger.info(f"ã€æ—¶é—´æœºå™¨ã€‘å¯åŠ¨è¿ç»­å›æµ‹: {start_date} ~ {end_date}")
        logger.info(f"ã€æ—¶é—´æœºå™¨ã€‘æ•°æ®æº: {'Tushareå®æ—¶ç²—ç­›' if use_tushare else 'CSVæ–‡ä»¶'}")
        
        # ==========================================
        # CTOå¼ºåˆ¶æ¤å…¥ï¼šå¹´åº¦å‘è½¦å‰çš„"è„‘ç™½é‡‘"æ¸…æ´—ä»ªå¼
        # ==========================================
        memory_file = PathResolver.get_data_dir() / 'memory' / 'ShortTermMemory.json'
        if memory_file.exists():
            logger.warning("ã€CTOå¼ºåˆ¶æ¸…æ´—ã€‘æ£€æµ‹åˆ°æ®‹ç•™çš„è·¨æ—¥è®°å¿†ï¼Œæ­£åœ¨ç‰©ç†æŠ¹é™¤ä»¥é˜²æ­¢æœªæ¥å‡½æ•°æ±¡æŸ“...")
            print("ğŸ§  ã€CTOæ¸…æ´—ã€‘æ£€æµ‹åˆ°æ®‹ç•™è®°å¿†ï¼Œæ‰§è¡Œç‰©ç†æŠ¹é™¤...")
            # å¼ºåˆ¶æ¸…ç©ºï¼Œè®©æ—¶é—´æœºå™¨ä»¥çº¯æ´çš„çŠ¶æ€å›åˆ°è¿‡å»ï¼
            with open(memory_file, 'w', encoding='utf-8') as f:
                json.dump({"date": "19700101", "memory": {}}, f)
            print("âœ… ã€CTOæ¸…æ´—ã€‘è®°å¿†åº“å·²æ¸…ç©ºï¼Œç³»ç»Ÿçº¯æ´æ€å¯åŠ¨ï¼")
        
        logger.info("ã€ç³»ç»Ÿå·²å°±ç»ªã€‘è®°å¿†åº“å·²æ¸…ç©ºï¼Œå‡†å¤‡å¼€å§‹è¿è´¯ç©¿è¶Šï¼")
        # ==========================================
        
        # 2. è·å–äº¤æ˜“æ—¥
        trade_dates = self.get_trade_dates(start_date, end_date)
        print(f"ğŸ“… äº¤æ˜“æ—¥: {len(trade_dates)} å¤©")
        logger.info(f"äº¤æ˜“æ—¥: {len(trade_dates)} å¤©")
        
        # 3. é€æ—¥å›æµ‹
        all_results = []
        
        for i, date in enumerate(trade_dates, 1):
            print(f"\nğŸ“Œ è¿›åº¦: [{i}/{len(trade_dates)}] {date}")
            
            # CTODict: æ¯æ—¥åŠ¨æ€ç²—ç­› (Tushareæ¨¡å¼)
            if use_tushare:
                try:
                    stock_pool = self._load_stock_pool('TUSHARE', date)
                    print(f"  ğŸ“Š å½“æ—¥ç²—ç­›: {len(stock_pool)} åª")
                except Exception as e:
                    error_msg = str(e)
                    # CTOä¿®å¤ï¼šæ£€æµ‹æ˜¯å¦ä¸ºèŠ‚å‡æ—¥ï¼ˆTushareè¿”å›ç©ºï¼‰
                    if 'ç²—ç­›è¿”å›ç©ºè‚¡ç¥¨æ± ' in error_msg or 'Empty' in error_msg:
                        logger.warning(f"ã€æ—¶é—´æœºå™¨ã€‘{date} å¯èƒ½æ˜¯èŠ‚å‡æ—¥ï¼Œè·³è¿‡")
                        print(f"  â­ï¸  {date} èŠ‚å‡æ—¥/éäº¤æ˜“æ—¥ï¼Œè·³è¿‡")
                        all_results.append({
                            'date': date,
                            'status': 'holiday_skipped',
                            'error': 'èŠ‚å‡æ—¥æˆ–éäº¤æ˜“æ—¥'
                        })
                    else:
                        logger.error(f"ã€æ—¶é—´æœºå™¨ã€‘{date} ç²—ç­›å¤±è´¥: {e}")
                        print(f"  âŒ {date} ç²—ç­›å¤±è´¥: {e}")
                        all_results.append({
                            'date': date,
                            'status': 'coarse_filter_failed',
                            'error': error_msg
                        })
                    continue
            
            daily_result = self.run_daily_backtest(date, stock_pool)
            all_results.append(daily_result)
            
            # ä¿å­˜æ¯æ—¥ç»“æœ
            self._save_daily_result(date, daily_result)
            
            # æ¸…ç†ç¼“å­˜
            self.results_cache.clear()
        
        # 4. ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        self._generate_summary_report(all_results, start_date, end_date)
        
        # ç»Ÿè®¡ç»“æœ
        success_count = len([r for r in all_results if r['status'] == 'success'])
        
        print(f"\n{'#'*80}")
        print(f"# å…¨æ¯æ—¶é—´æœºå™¨å®Œæˆ")
        print(f"# æˆåŠŸ: {success_count}/{len(all_results)}")
        print(f"{'#'*80}\n")
        
        logger.info(f"ã€æ—¶é—´æœºå™¨ã€‘è¿ç»­å›æµ‹å®Œæˆ: {success_count}/{len(all_results)} æˆåŠŸ")
        
        return all_results
    
        def _load_stock_pool(self, path: str, date: str = None) -> List[str]:
            """
            åŠ è½½è‚¡ç¥¨æ±  - CTODict: ç¦æ­¢æ¨¡æ‹Ÿæ•°æ®ï¼Œå¼ºåˆ¶çœŸå®ç²—ç­›
            
            Args:
                path: è‚¡ç¥¨æ± æ–‡ä»¶è·¯å¾„ æˆ– 'TUSHARE' è¡¨ç¤ºå®æ—¶ç²—ç­›
                date: æ—¥æœŸ 'YYYYMMDD' (ç”¨äºTushareç²—ç­›)
            
            Returns:
                è‚¡ç¥¨ä»£ç åˆ—è¡¨ (çº¦500åª)
            
            Raises:
                RuntimeError: æ— æ³•è·å–çœŸå®æ•°æ®æ—¶æŠ›å‡ºè‡´å‘½å¼‚å¸¸ (Fail Fast)
            """
            # å¦‚æœä½¿ç”¨Tushareå®æ—¶ç²—ç­›
            if path.upper() == 'TUSHARE' or path == '':
                if not date:
                    raise ValueError("ä½¿ç”¨Tushareç²—ç­›æ—¶å¿…é¡»æä¾›dateå‚æ•°")
                
                logger.info(f"ã€æ—¶é—´æœºå™¨ã€‘ä½¿ç”¨UniverseBuilderè·å–è‚¡ç¥¨æ± : {date}")
                try:
                    # UniverseBuilderå†…éƒ¨ä½¿ç”¨æ­£ç¡®çš„ç»å¯¹é˜ˆå€¼3.0
                    builder = UniverseBuilder()
                    logger.info(f"ã€æ—¶é—´æœºå™¨ã€‘å¼€å§‹è°ƒç”¨get_daily_universe...")
                    stock_pool = builder.get_daily_universe(date)
                    
                    logger.info(f"ã€æ—¶é—´æœºå™¨ã€‘UniverseBuilderè¿”å›: {len(stock_pool)} åªè‚¡ç¥¨")
                    
                    if not stock_pool:
                        logger.error(f"ã€æ—¶é—´æœºå™¨ã€‘ UniverseBuilderè¿”å›ç©ºè‚¡ç¥¨æ± : {date}")
                        # ã€CTOä¿®å¤ã€‘è¿”å›ç©ºåˆ—è¡¨è€Œä¸æ˜¯æŠ¥é”™ï¼Œè®©ä¸Šå±‚å¤„ç†
                        return []
                    
                    logger.info(f"ã€æ—¶é—´æœºå™¨ã€‘è‚¡ç¥¨æ± è·å–å®Œæˆ: {len(stock_pool)} åª")
                    return stock_pool
                    
                except Exception as e:
                    logger.error(f"ã€æ—¶é—´æœºå™¨ã€‘Tushareç²—ç­›å¤±è´¥: {e}")
                    raise RuntimeError(f"æ— æ³•è·å–çœŸå®è‚¡ç¥¨æ± : {e}") from e
                
            # å¦‚æœæä¾›CSVæ–‡ä»¶è·¯å¾„
            full_path = PathResolver.resolve_path(path)
            
            if not full_path.exists():
                logger.error(f"ã€æ—¶é—´æœºå™¨ã€‘è‚¡ç¥¨æ± æ–‡ä»¶ä¸å­˜åœ¨: {path}")
                raise FileNotFoundError(f"è‚¡ç¥¨æ± æ–‡ä»¶ä¸å­˜åœ¨: {path}ã€‚è¯·æä¾›æœ‰æ•ˆCSVæ–‡ä»¶æˆ–ä½¿ç”¨'TUSHARE'è¿›è¡Œå®æ—¶ç²—ç­›")
            
            try:
                df = pd.read_csv(full_path)
                if 'ts_code' in df.columns:
                    return df['ts_code'].tolist()
                elif 'stock_code' in df.columns:
                    return df['stock_code'].tolist()
                elif 'code' in df.columns:
                    return df['code'].tolist()
                else:
                    # å‡è®¾ç¬¬ä¸€åˆ—æ˜¯è‚¡ç¥¨ä»£ç 
                    return df.iloc[:, 0].tolist()
            except Exception as e:
                logger.error(f"ã€æ—¶é—´æœºå™¨ã€‘åŠ è½½è‚¡ç¥¨æ± å¤±è´¥: {e}")
                raise RuntimeError(f"æ— æ³•åŠ è½½è‚¡ç¥¨æ± æ–‡ä»¶: {e}") from e    
    def _save_daily_result(self, date: str, result: Dict):
        """
        ä¿å­˜æ¯æ—¥ç»“æœ
        
        Args:
            date: æ—¥æœŸ 'YYYYMMDD'
            result: å½“æ—¥å›æµ‹ç»“æœ
        """
        try:
            output_dir = PathResolver.get_data_dir() / 'backtest_out' / 'time_machine'
            PathResolver.ensure_dir(output_dir)
            
            output_file = output_dir / f'time_machine_{date}.json'
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ã€æ—¶é—´æœºå™¨ã€‘ç»“æœå·²ä¿å­˜: {output_file}")
        except Exception as e:
            logger.error(f"ä¿å­˜æ¯æ—¥ç»“æœå¤±è´¥: {e}")
    
    def _generate_summary_report(self, results: List[Dict], start_date: str, end_date: str):
        """
        ç”Ÿæˆæ€»ç»“æŠ¥å‘Š - CTODict: ä¿®å¤success_daysç»Ÿè®¡ï¼Œæ‰©å®¹è‡³Top 20
        
        Args:
            results: æ‰€æœ‰å›æµ‹ç»“æœ
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
        """
        try:
            # ç»Ÿè®¡å„çŠ¶æ€å¤©æ•°
            success_results = [r for r in results if r.get('status') == 'success']
            insufficient_results = [r for r in results if r.get('status') == 'insufficient_data']
            error_results = [r for r in results if r.get('status') == 'error']
            coarse_failed_results = [r for r in results if r.get('status') == 'coarse_filter_failed']
            
            report = {
                'start_date': start_date,
                'end_date': end_date,
                'total_days': len(results),
                'success_days': len(success_results),
                'insufficient_data_days': len(insufficient_results),
                'error_days': len(error_results),
                'coarse_filter_failed_days': len(coarse_failed_results),
                'statistics_by_date': {
                    r['date']: {
                        'status': r.get('status'),
                        'valid_stocks': r.get('valid_stocks', 0),
                        'top1_score': r.get('top20', [{}])[0].get('final_score', 0) if r.get('top20') else 0
                    }
                    for r in results
                },
                'daily_top20': [
                    {
                        'date': r['date'],
                        'top20': r.get('top20', []),
                        'valid_stocks': r.get('valid_stocks', 0)
                    } 
                    for r in success_results
                ]
            }
            
            output_dir = PathResolver.get_data_dir() / 'backtest_out' / 'time_machine'
            PathResolver.ensure_dir(output_dir)
            
            output_file = output_dir / f'time_machine_summary_{start_date}_{end_date}.json'
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            print(f"\n  ğŸ“„ æ€»ç»“æŠ¥å‘Šå·²ä¿å­˜: {output_file}")
            logger.info(f"ã€æ—¶é—´æœºå™¨ã€‘æ€»ç»“æŠ¥å‘Šå·²ä¿å­˜: {output_file}")
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ€»ç»“æŠ¥å‘Šå¤±è´¥: {e}")
    
    def get_backtest_summary(self, start_date: str, end_date: str) -> Optional[Dict]:
        """
        è·å–å›æµ‹æ€»ç»“æŠ¥å‘Š
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
        
        Returns:
            æŠ¥å‘Šå­—å…¸æˆ–None
        """
        try:
            output_file = (
                PathResolver.get_data_dir() / 'backtest_out' / 'time_machine' / 
                f'time_machine_summary_{start_date}_{end_date}.json'
            )
            
            if output_file.exists():
                with open(output_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            
            return None
        except Exception as e:
            logger.error(f"è¯»å–æ€»ç»“æŠ¥å‘Šå¤±è´¥: {e}")
            return None
    
    # ==================== è®°å¿†è¡°å‡æœºåˆ¶ ====================
    
    def _load_memory(self) -> Dict[str, Dict]:
        """
        åŠ è½½çŸ­æœŸè®°å¿† - è‡ªåŠ¨è¡¥å……ç¼ºå¤±å­—æ®µ
        
        Returns:
            è®°å¿†å­—å…¸ {stock_code: memory_item}
        """
        try:
            if self.MEMORY_FILE.exists():
                with open(self.MEMORY_FILE, 'r', encoding='utf-8') as f:
                    memory = json.load(f)
                
                # è‡ªåŠ¨è¡¥å……ç¼ºå¤±çš„å­—æ®µï¼ˆå‘åå…¼å®¹æ—§æ•°æ®ç»“æ„ï¼‰
                for stock_code, mem_item in memory.items():
                    if 'absent_days' not in mem_item:
                        mem_item['absent_days'] = 0
                        logger.debug(f"ã€è®°å¿†è¡°å‡ã€‘{stock_code} è¡¥å…… absent_days=0")
                    if 'last_decay_date' not in mem_item:
                        mem_item['last_decay_date'] = mem_item.get('date', '')
                        logger.debug(f"ã€è®°å¿†è¡°å‡ã€‘{stock_code} è¡¥å…… last_decay_date")
                
                return memory
            return {}
        except Exception as e:
            logger.error(f"ã€è®°å¿†è¡°å‡ã€‘åŠ è½½è®°å¿†å¤±è´¥: {e}")
            return {}
    
    def _save_memory(self, memory: Dict[str, Dict]) -> bool:
        """
        ä¿å­˜çŸ­æœŸè®°å¿†
        
        Args:
            memory: è®°å¿†å­—å…¸
        
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            self.MEMORY_FILE.parent.mkdir(parents=True, exist_ok=True)
            
            with open(self.MEMORY_FILE, 'w', encoding='utf-8') as f:
                json.dump(memory, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ã€è®°å¿†è¡°å‡ã€‘è®°å¿†å·²ä¿å­˜: {len(memory)} æ¡")
            return True
        except Exception as e:
            logger.error(f"ã€è®°å¿†è¡°å‡ã€‘ä¿å­˜è®°å¿†å¤±è´¥: {e}")
            return False
    
    def _apply_memory_decay(self, current_date: str, today_top20: List[Dict]) -> Dict[str, Dict]:
        """
        æ‰§è¡Œè®°å¿†è¡°å‡ - æ ¸å¿ƒé€»è¾‘
        
        è§„åˆ™:
        1. æ–°è®°å¿†åˆ† = è€è®°å¿†åˆ† * 0.5
        2. è¿ç»­2æ—¥ä¸ä¸Šæ¦œ -> åˆ é™¤
        3. è¡°å‡åscore < 10 -> åˆ é™¤
        
        Args:
            current_date: å½“å‰æ—¥æœŸ 'YYYYMMDD'
            today_top20: ä»Šæ—¥Top20åˆ—è¡¨ [{'stock_code': str, 'final_score': float, ...}]
        
        Returns:
            æ›´æ–°åçš„è®°å¿†å­—å…¸
        """
        # 1. åŠ è½½æ—§è®°å¿†
        memory = self._load_memory()
        
        # 2. è·å–ä»Šæ—¥ä¸Šæ¦œè‚¡ç¥¨ä»£ç 
        today_top_codes: Set[str] = {item['stock_code'] for item in today_top20}
        
        # 3. æ›´æ–°è®°å¿†ä¸­æ¯åªè‚¡ç¥¨
        new_memory = {}
        decay_stats = {'decayed': 0, 'removed_absent': 0, 'removed_low_score': 0, 'new_added': 0}
        
        for stock_code, mem_item in memory.items():
            # è·å–å½“å‰åˆ†æ•°
            old_score = mem_item.get('score', 0)
            
            # è¡°å‡åˆ†æ•°
            new_score = old_score * MEMORY_DECAY_FACTOR
            
            # æ£€æŸ¥æ˜¯å¦åœ¨ä»Šæ—¥Top20ä¸­
            if stock_code in today_top_codes:
                # ä»Šæ—¥ä¸Šæ¦œï¼Œé‡ç½®ç¼ºå¸­å¤©æ•°
                mem_item['absent_days'] = 0
                decay_stats['decayed'] += 1
                logger.debug(f"ã€è®°å¿†è¡°å‡ã€‘{stock_code} ä»Šæ—¥ä¸Šæ¦œï¼Œé‡ç½®ç¼ºå¸­å¤©æ•°")
            else:
                # æœªä¸Šæ¦œï¼Œå¢åŠ ç¼ºå¸­å¤©æ•°
                absent_days = mem_item.get('absent_days', 0) + 1
                mem_item['absent_days'] = absent_days
                
                # æ£€æŸ¥æ˜¯å¦è¿ç»­ç¼ºå¸­è¶…è¿‡é˜ˆå€¼
                if absent_days >= MEMORY_MAX_ABSENCE_DAYS:
                    decay_stats['removed_absent'] += 1
                    logger.info(f"ã€è®°å¿†è¡°å‡ã€‘{stock_code} è¿ç»­{absent_days}æ—¥ä¸ä¸Šæ¦œï¼Œåˆ é™¤")
                    continue
            
            # æ£€æŸ¥åˆ†æ•°æ˜¯å¦ä½äºé˜ˆå€¼
            if new_score < MEMORY_MIN_SCORE:
                decay_stats['removed_low_score'] += 1
                logger.info(f"ã€è®°å¿†è¡°å‡ã€‘{stock_code} åˆ†æ•°{new_score:.1f} < {MEMORY_MIN_SCORE}ï¼Œåˆ é™¤")
                continue
            
            # æ›´æ–°åˆ†æ•°å’Œæ—¥æœŸ
            mem_item['score'] = round(new_score, 2)
            mem_item['last_decay_date'] = current_date
            new_memory[stock_code] = mem_item
            decay_stats['decayed'] += 1
        
        # 4. æ·»åŠ ä»Šæ—¥æ–°ä¸Šæ¦œè‚¡ç¥¨ï¼ˆä¸åœ¨è®°å¿†ä¸­çš„ï¼‰
        for item in today_top20:
            stock_code = item['stock_code']
            if stock_code not in new_memory:
                new_memory[stock_code] = {
                    'stock_code': stock_code,
                    'date': current_date,
                    'score': item.get('final_score', 70.0),
                    'absent_days': 0,
                    'last_decay_date': current_date,
                    'close_price': item.get('price_0940', 0),
                    'change_pct': item.get('change_0940', 0),
                    'status': item.get('status', 'unknown')
                }
                decay_stats['new_added'] += 1
                logger.debug(f"ã€è®°å¿†è¡°å‡ã€‘{stock_code} æ–°ä¸Šæ¦œï¼ŒåŠ å…¥è®°å¿†")
        
        # 5. ä¿å­˜æ›´æ–°åçš„è®°å¿†
        self._save_memory(new_memory)
        
        # 6. æ‰“å°ç»Ÿè®¡
        print(f"\n  ğŸ“‰ è®°å¿†è¡°å‡ç»Ÿè®¡:")
        print(f"     åŸæœ‰è®°å¿†: {len(memory)} æ¡")
        print(f"     è¡°å‡ä¿ç•™: {decay_stats['decayed']} æ¡")
        print(f"     æ–°å¢è®°å¿†: {decay_stats['new_added']} æ¡")
        print(f"     åˆ é™¤(ç¼ºå¸­): {decay_stats['removed_absent']} æ¡")
        print(f"     åˆ é™¤(ä½åˆ†): {decay_stats['removed_low_score']} æ¡")
        print(f"     å½“å‰è®°å¿†: {len(new_memory)} æ¡")
        
        logger.info(f"ã€è®°å¿†è¡°å‡ã€‘ç»Ÿè®¡: åŸæœ‰{len(memory)}, ä¿ç•™{decay_stats['decayed']}, "
                   f"æ–°å¢{decay_stats['new_added']}, åˆ é™¤ç¼ºå¸­{decay_stats['removed_absent']}, "
                   f"åˆ é™¤ä½åˆ†{decay_stats['removed_low_score']}, å½“å‰{len(new_memory)}")
        
        return new_memory

    # ==================== Step6: æ—¶ç©ºå¯¹é½ä¸å…¨æ¯å›æ¼”UIçœ‹æ¿ ====================
    
    

    def calculate_time_slice_flows(self, stock_code: str, date: str) -> Optional[Dict]:
        """
        ã€CTOç»ˆæçº¢çº¿ï¼šæ—¶ç©ºç»å¯¹å¯¹é½ã€‘è®¡ç®—çœŸå®æ—¶é—´åˆ‡ç‰‡èµ„é‡‘æµ
        
        æ ¸å¿ƒè¦æ±‚ï¼š
        1. ç»ä¸å…è®¸ç”¨å…¨å¤©æ•°æ®ä¼°ç®—åˆ‡ç‰‡ï¼å¿…é¡»é€šè¿‡ get_local_data(period='tick'/'1m') çœŸå®æ‹‰å–æ—¥å†…å†å²æµ
        2. æˆªå– 09:30-09:35 è®¡ç®—çœŸå® flow_5min
        3. æˆªå– 09:30-09:45 è®¡ç®—çœŸå® flow_15min
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            date: æ—¥æœŸ 'YYYYMMDD'
            
        Returns:
            Dict: åŒ…å«flow_5min, flow_15minçš„å­—å…¸ï¼Œæˆ–Noneï¼ˆæ•°æ®ä¸è¶³ï¼‰
        """
        try:
            from xtquant import xtdata
            
            # æ ‡å‡†åŒ–ä»£ç 
            normalized_code = self._normalize_stock_code(stock_code)
            
            # ã€æ ¸å¿ƒã€‘çœŸå®æ‹‰å–æ—¥å†…å†å²Tickæµ - ä¸¥ç¦ç”¨å…¨å¤©æ•°æ®ä¼°ç®—ï¼
            tick_data = xtdata.get_local_data(
                field_list=['time', 'lastPrice', 'volume', 'amount'],
                stock_list=[normalized_code],
                period='tick',
                start_time=date,
                end_time=date
            )
            
            if not tick_data or normalized_code not in tick_data:
                logger.warning(f"âš ï¸ {stock_code} æ— Tickæ•°æ®")
                return None
            
            df = tick_data[normalized_code]
            if df.empty or len(df) < 10:
                logger.warning(f"âš ï¸ {stock_code} Tickæ•°æ®ä¸è¶³")
                return None
            
            # è½¬æ¢æ—¶é—´æˆ³ä¸ºå¯è¯»æ—¶é—´
            if 'time' in df.columns:
                if pd.api.types.is_numeric_dtype(df['time']):
                    df['datetime'] = pd.to_datetime(df['time'], unit='ms') + pd.Timedelta(hours=8)
                    df['time_str'] = df['datetime'].dt.strftime('%H:%M:%S')
                else:
                    df['time_str'] = df['time'].astype(str)
            
            # ã€æ—¶ç©ºåˆ‡ç‰‡1ã€‘æˆªå– 09:30-09:35 è®¡ç®—çœŸå® flow_5min
            df_5min = df[(df['time_str'] >= '09:30:00') & (df['time_str'] <= '09:35:00')].copy()
            if df_5min.empty:
                logger.warning(f"âš ï¸ {stock_code} 09:30-09:35 æ— æ•°æ®")
                return None
            
            # è®¡ç®—5åˆ†é’Ÿèµ„é‡‘æµå…¥ï¼ˆç®€åŒ–ï¼šç”¨amountå¢é‡ï¼‰
            if 'amount' in df_5min.columns:
                flow_5min = df_5min['amount'].sum()
            else:
                # å¦‚æœæ²¡æœ‰amountï¼Œç”¨ price * volume * 100 ä¼°ç®—
                flow_5min = (df_5min['lastPrice'] * df_5min['volume'] * 100).sum()
            
            # ã€æ—¶ç©ºåˆ‡ç‰‡2ã€‘æˆªå– 09:30-09:45 è®¡ç®—çœŸå® flow_15min
            df_15min = df[(df['time_str'] >= '09:30:00') & (df['time_str'] <= '09:45:00')].copy()
            if df_15min.empty:
                logger.warning(f"âš ï¸ {stock_code} 09:30-09:45 æ— æ•°æ®")
                return None
            
            if 'amount' in df_15min.columns:
                flow_15min = df_15min['amount'].sum()
            else:
                flow_15min = (df_15min['lastPrice'] * df_15min['volume'] * 100).sum()
            
            logger.debug(f"âœ… {stock_code} æ—¶ç©ºåˆ‡ç‰‡: 5min={flow_5min/1e8:.2f}äº¿, 15min={flow_15min/1e8:.2f}äº¿")
            
            return {
                'flow_5min': float(flow_5min),
                'flow_15min': float(flow_15min),
                'tick_count_5min': len(df_5min),
                'tick_count_15min': len(df_15min)
            }
            
        except Exception as e:
            logger.error(f"âŒ {stock_code} æ—¶ç©ºåˆ‡ç‰‡è®¡ç®—å¤±è´¥: {e}")
            return None

    

    


# CLIå…¥å£
if __name__ == '__main__':
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # åˆ›å»ºå¼•æ“
    engine = TimeMachineEngine(initial_capital=20000.0)
    
    # æµ‹è¯•ï¼šå›æµ‹1.5æ—¥å‰å10å¤©
    results = engine.run_continuous_backtest(
        start_date='20251231',
        end_date='20260110',
        stock_pool_path='data/cleaned_candidates_66.csv'
    )
    
    # æ‰“å°æœ€ç»ˆç»“æœ
    print("\n" + "="*80)
    print("å›æµ‹å®Œæˆ!")
    print(f"æ€»äº¤æ˜“æ—¥: {len(results)}")
    print(f"æˆåŠŸ: {len([r for r in results if r['status']=='success'])}")
    print("="*80)
