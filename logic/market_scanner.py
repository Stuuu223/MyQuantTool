#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å…¨å¸‚åœºæ‰¹é‡æ‰«æå™¨ï¼ˆä¸‰é˜¶æ®µæ¸è¿›å¼ç­›é€‰ï¼‰

ç›®æ ‡ï¼š
- æ‰«æå…¨Aè‚¡5000+è‚¡ç¥¨
- è¯†åˆ«ç–‘ä¼¼è¯±å¤šè‚¡ç¥¨ï¼ˆTOP 20-50ï¼‰
- æ‰§è¡Œæ—¶é—´ï¼š<10åˆ†é’Ÿ

ä¸‰é˜¶æ®µç­›é€‰ï¼š
1. é¢„ç­›é€‰ï¼ˆ1åˆ†é’Ÿï¼‰ï¼š5000è‚¡ â†’ 200-400è‚¡ï¼ˆç¡¬æ€§æ¡ä»¶ï¼‰
2. å››ç»´åˆç­›ï¼ˆ3åˆ†é’Ÿï¼‰ï¼š200-400è‚¡ â†’ 50-100è‚¡ï¼ˆç®€åŒ–QPSTï¼‰
3. ç²¾å‡†QPSTï¼ˆ5åˆ†é’Ÿï¼‰ï¼š50-100è‚¡ â†’ 20-50è‚¡ï¼ˆå®Œæ•´åˆ†æï¼‰

Author: MyQuantTool Team
Date: 2026-02-11
Version: Phase 2
"""

import time
import json
from pathlib import Path
from typing import List, Dict, Optional
from datetime import datetime
import pandas as pd
from multiprocessing import Pool, cpu_count

try:
    from xtquant import xtdata
    QMT_AVAILABLE = True
except ImportError:
    QMT_AVAILABLE = False

from logic.batch_qpst_analyzer import BatchQPSTAnalyzer
from logic.logger import get_logger

logger = get_logger(__name__)


class MarketScanner:
    """
    å…¨å¸‚åœºæ‰¹é‡æ‰«æå™¨
    
    ç‰¹æ€§ï¼š
    - ä¸‰é˜¶æ®µæ¸è¿›å¼ç­›é€‰ï¼ˆç²—ç­›â†’åˆç­›â†’ç²¾ç­›ï¼‰
    - æ™ºèƒ½å¹¶è¡Œï¼ˆ<100è‚¡å•è¿›ç¨‹ï¼Œ>100è‚¡å¤šè¿›ç¨‹ï¼‰
    - QMTå®æ—¶æ•°æ® + CSVå¤‡ä»½æœºåˆ¶
    - å†…å­˜ä¼˜åŒ–ï¼ˆåªä¿ç•™å¿…è¦æ•°æ®ï¼‰
    """
    
    def __init__(self, equity_info_path: str = 'data/equity_info.json'):
        """
        åˆå§‹åŒ–å¸‚åœºæ‰«æå™¨
        
        Args:
            equity_info_path: è‚¡æœ¬ä¿¡æ¯æ–‡ä»¶è·¯å¾„
        """
        if not QMT_AVAILABLE:
            raise RuntimeError("âš ï¸ xtquant æœªå®‰è£…ï¼ŒMarketScanner ä¸å¯ç”¨")
        
        # åŠ è½½è‚¡æœ¬ä¿¡æ¯
        self.equity_info = self._load_equity_info(equity_info_path)
        
        # åˆå§‹åŒ–æ‰¹é‡åˆ†æå™¨
        self.analyzer = BatchQPSTAnalyzer(self.equity_info)
        
        # CSVç¼“å­˜ç›®å½•
        self.cache_dir = Path('data/kline_cache')
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info("âœ… MarketScanner åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   - è‚¡æœ¬ä¿¡æ¯: {len(self.equity_info)} åªè‚¡ç¥¨")
        logger.info(f"   - ç¼“å­˜ç›®å½•: {self.cache_dir}")
    
    def _load_equity_info(self, path: str) -> dict:
        """åŠ è½½è‚¡æœ¬ä¿¡æ¯"""
        try:
            with open(path, 'r', encoding='utf-8') as f:
                equity_info = json.load(f)
            logger.debug(f"âœ… åŠ è½½è‚¡æœ¬ä¿¡æ¯: {len(equity_info)} åªè‚¡ç¥¨")
            return equity_info
        except Exception as e:
            logger.warning(f"âš ï¸ åŠ è½½è‚¡æœ¬ä¿¡æ¯å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨ç©ºå­—å…¸")
            return {}
    
    def scan(self, stock_list: List[str], scan_time: str = 'auto') -> List[dict]:
        """
        æ‰«æå…¨å¸‚åœº
        
        Args:
            stock_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆå¦‚ ['300997.SZ', '603697.SH', ...]ï¼‰
            scan_time: æ‰«ææ—¶é—´èŠ‚ç‚¹ï¼ˆ'09:35' | '10:00' | '14:00' | 'auto'ï¼‰
        
        Returns:
            TOP 20-50 è¯±å¤šæ¦œå•
        """
        start_time = time.time()
        
        logger.info("="*80)
        logger.info("ğŸš€ å…¨å¸‚åœºæ‰«æå¯åŠ¨")
        logger.info("="*80)
        logger.info(f"æ‰«æèŒƒå›´: {len(stock_list)} åªè‚¡ç¥¨")
        logger.info(f"æ‰«ææ—¶é—´: {scan_time}")
        logger.info(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info("="*80)
        
        # ===== é˜¶æ®µ1: é¢„ç­›é€‰ï¼ˆç¡¬æ€§æ¡ä»¶ï¼‰ =====
        logger.info("\nğŸ“Š é˜¶æ®µ1: é¢„ç­›é€‰ï¼ˆç¡¬æ€§æ¡ä»¶ï¼‰")
        phase1_start = time.time()
        candidates = self._phase1_pre_filter(stock_list)
        phase1_time = time.time() - phase1_start
        logger.info(f"âœ… é˜¶æ®µ1å®Œæˆ: {len(stock_list)} â†’ {len(candidates)} åªè‚¡ç¥¨ (è€—æ—¶ {phase1_time:.1f}ç§’)")
        
        if not candidates:
            logger.warning("âš ï¸ é¢„ç­›é€‰åæ— å€™é€‰è‚¡ç¥¨ï¼Œç»ˆæ­¢æ‰«æ")
            return []
        
        # ===== é˜¶æ®µ2: å››ç»´åˆç­›ï¼ˆç®€åŒ–QPSTï¼‰ =====
        logger.info("\nğŸ“Š é˜¶æ®µ2: å››ç»´åˆç­›ï¼ˆç®€åŒ–QPSTï¼‰")
        phase2_start = time.time()
        potentials = self._phase2_qpst_lite(candidates)
        phase2_time = time.time() - phase2_start
        logger.info(f"âœ… é˜¶æ®µ2å®Œæˆ: {len(candidates)} â†’ {len(potentials)} åªè‚¡ç¥¨ (è€—æ—¶ {phase2_time:.1f}ç§’)")
        
        if not potentials:
            logger.warning("âš ï¸ å››ç»´åˆç­›åæ— å€™é€‰è‚¡ç¥¨ï¼Œç»ˆæ­¢æ‰«æ")
            return []
        
        # ===== é˜¶æ®µ3: ç²¾å‡†QPSTï¼ˆå®Œæ•´åˆ†æï¼‰ =====
        logger.info("\nğŸ“Š é˜¶æ®µ3: ç²¾å‡†QPSTï¼ˆå®Œæ•´åˆ†æï¼‰")
        phase3_start = time.time()
        trap_list = self._phase3_qpst_full(potentials)
        phase3_time = time.time() - phase3_start
        logger.info(f"âœ… é˜¶æ®µ3å®Œæˆ: {len(potentials)} â†’ {len(trap_list)} åªè‚¡ç¥¨ (è€—æ—¶ {phase3_time:.1f}ç§’)")
        
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        trap_list.sort(key=lambda x: x['confidence'], reverse=True)
        
        total_time = time.time() - start_time
        logger.info("\n" + "="*80)
        logger.info(f"ğŸ¯ æ‰«æå®Œæˆï¼Œå…±è€—æ—¶ {total_time:.1f}ç§’")
        logger.info(f"ğŸ“‹ è¾“å‡ºæ¦œå•: TOP {len(trap_list[:50])} ç–‘ä¼¼è¯±å¤šè‚¡ç¥¨")
        logger.info("="*80)
        
        return trap_list[:50]  # TOP 50
    
    def _phase1_pre_filter(self, stock_list: List[str]) -> List[str]:
        """
        é˜¶æ®µ1: é¢„ç­›é€‰ï¼ˆç¡¬æ€§æ¡ä»¶ï¼‰
        
        ç›®æ ‡: 5000è‚¡ â†’ 200-400è‚¡ï¼ˆ1åˆ†é’Ÿå†…å®Œæˆï¼‰
        
        æ¡ä»¶:
        1. æ¶¨å¹… > 2%
        2. æ¢æ‰‹ç‡ > 3%ï¼ˆ10åˆ†é’Ÿï¼‰
        3. æ”¾é‡ > 1.3å€
        """
        candidates = []
        
        try:
            # æ‰¹é‡è·å–æœ€æ–°10æ ¹åˆ†é’ŸKï¼ˆä¸€æ¬¡æ€§è·å–æ‰€æœ‰è‚¡ç¥¨ï¼‰
            logger.info("   æ­£åœ¨æ‰¹é‡è·å–åˆ†é’ŸKæ•°æ®...")
            kline_data = xtdata.get_market_data_ex(
                field_list=['close', 'volume'],
                stock_list=stock_list,
                period='1m',
                count=10
            )
            
            for code in stock_list:
                if code not in kline_data:
                    continue
                
                df = kline_data[code]
                if len(df) < 10:
                    continue
                
                # è®¡ç®—æ¶¨å¹…
                price_change = (df['close'].iloc[-1] - df['close'].iloc[0]) / df['close'].iloc[0]
                
                # è®¡ç®—é‡æ¯”
                volumes = df['volume'].values
                recent_vol = volumes[-3:].mean()
                earlier_vol = volumes[:-3].mean()
                volume_ratio = recent_vol / earlier_vol if earlier_vol > 0 else 0
                
                # è®¡ç®—æ¢æ‰‹ç‡ï¼ˆéœ€è¦è‚¡æœ¬ä¿¡æ¯ï¼‰
                float_shares = self.equity_info.get(code, {}).get('float_shares', 0)
                if float_shares > 0:
                    turnover = df['volume'].sum() / float_shares
                else:
                    turnover = 0
                
                # ç¡¬æ€§ç­›é€‰æ¡ä»¶
                if price_change > 0.02 and turnover > 0.03 and volume_ratio > 1.3:
                    candidates.append(code)
                    logger.debug(f"   âœ“ {code}: æ¶¨å¹…{price_change:.2%}, æ¢æ‰‹{turnover:.2%}, é‡æ¯”{volume_ratio:.2f}")
        
        except Exception as e:
            logger.error(f"âŒ é˜¶æ®µ1ç­›é€‰å¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())
        
        return candidates
    
    def _phase2_qpst_lite(self, candidates: List[str]) -> List[str]:
        """
        é˜¶æ®µ2: å››ç»´åˆç­›ï¼ˆç®€åŒ–QPSTï¼‰
        
        ç›®æ ‡: 200-400è‚¡ â†’ 50-100è‚¡ï¼ˆ3åˆ†é’Ÿå†…å®Œæˆï¼‰
        
        åªè®¡ç®—å…³é”®æŒ‡æ ‡ï¼Œä¸åšå®Œæ•´åˆ†æ
        """
        potentials = []
        
        try:
            # æ‰¹é‡è·å–åˆ†é’ŸKæ•°æ®
            logger.info("   æ­£åœ¨æ‰¹é‡è·å–åˆ†é’ŸKæ•°æ®...")
            kline_data = xtdata.get_market_data_ex(
                field_list=['close', 'high', 'low', 'volume'],
                stock_list=candidates,
                period='1m',
                count=10
            )
            
            for code in candidates:
                if code not in kline_data:
                    continue
                
                df = kline_data[code]
                if len(df) < 10:
                    continue
                
                # å¿«é€Ÿå››ç»´åˆ¤æ–­ï¼ˆç®€åŒ–ç‰ˆï¼‰
                abnormal_count = 0
                
                # é‡èƒ½å¼‚å¸¸
                volumes = df['volume'].values
                recent_vol = volumes[-3:].mean()
                earlier_vol = volumes[:-3].mean()
                if earlier_vol > 0 and recent_vol / earlier_vol > 2.5:
                    abnormal_count += 1
                
                # ä»·æ ¼å¼‚å¸¸ï¼ˆæŒ¯å¹…è¿‡å¤§ï¼‰
                amplitudes = (df['high'] - df['low']) / df['close']
                if amplitudes.mean() > 0.025:
                    abnormal_count += 1
                
                # æ¢æ‰‹ç‡å¼‚å¸¸
                float_shares = self.equity_info.get(code, {}).get('float_shares', 0)
                if float_shares > 0:
                    turnover = df['volume'].sum() / float_shares
                    if turnover > 0.02:  # 10åˆ†é’Ÿæ¢æ‰‹>2%
                        abnormal_count += 1
                
                # è‡³å°‘2ä¸ªç»´åº¦å¼‚å¸¸æ‰è¿›å…¥ä¸‹ä¸€é˜¶æ®µ
                if abnormal_count >= 2:
                    potentials.append(code)
                    logger.debug(f"   âœ“ {code}: {abnormal_count}ä¸ªç»´åº¦å¼‚å¸¸")
        
        except Exception as e:
            logger.error(f"âŒ é˜¶æ®µ2ç­›é€‰å¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())
        
        return potentials
    
    def _phase3_qpst_full(self, potentials: List[str]) -> List[dict]:
        """
        é˜¶æ®µ3: ç²¾å‡†QPSTï¼ˆå®Œæ•´åˆ†æï¼‰
        
        ç›®æ ‡: 50-100è‚¡ â†’ 20-50è‚¡ï¼ˆ5åˆ†é’Ÿå†…å®Œæˆï¼‰
        
        æ‰§è¡Œå®Œæ•´çš„å››ç»´åˆ†æ + åè¯±å¤šæ£€æµ‹
        """
        trap_list = []
        
        try:
            # æ‰¹é‡è·å–æ›´é•¿æ—¶é—´çš„åˆ†é’ŸKï¼ˆç”¨äºå®Œæ•´åˆ†æï¼‰
            logger.info("   æ­£åœ¨æ‰¹é‡è·å–åˆ†é’ŸKæ•°æ®...")
            kline_data = xtdata.get_market_data_ex(
                field_list=['time', 'open', 'high', 'low', 'close', 'volume', 'amount'],
                stock_list=potentials,
                period='1m',
                count=30  # æœ€è¿‘30æ ¹Kçº¿
            )
            
            # æ™ºèƒ½é€‰æ‹©å•è¿›ç¨‹æˆ–å¤šè¿›ç¨‹
            if len(potentials) < 100:
                # å•è¿›ç¨‹å¤„ç†ï¼ˆ<100è‚¡ï¼‰
                logger.info("   ä½¿ç”¨å•è¿›ç¨‹æ¨¡å¼...")
                for code in potentials:
                    if code not in kline_data:
                        continue
                    
                    result = self._analyze_single_stock(code, kline_data[code])
                    if result and result['final_signal'] == 'TRAP_WARNING':
                        trap_list.append(result)
            
            else:
                # å¤šè¿›ç¨‹å¤„ç†ï¼ˆ>100è‚¡ï¼‰
                logger.info(f"   ä½¿ç”¨å¤šè¿›ç¨‹æ¨¡å¼ï¼ˆ{cpu_count()}æ ¸å¿ƒï¼‰...")
                tasks = [(code, kline_data[code]) for code in potentials if code in kline_data]
                
                with Pool(processes=min(cpu_count(), 8)) as pool:
                    results = pool.starmap(self._analyze_single_stock, tasks)
                
                for result in results:
                    if result and result['final_signal'] == 'TRAP_WARNING':
                        trap_list.append(result)
        
        except Exception as e:
            logger.error(f"âŒ é˜¶æ®µ3ç­›é€‰å¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())
        
        return trap_list
    
    def _analyze_single_stock(self, code: str, kline_df: pd.DataFrame) -> Optional[dict]:
        """
        å•è‚¡ç¥¨å®Œæ•´QPSTåˆ†æ
        
        Args:
            code: è‚¡ç¥¨ä»£ç 
            kline_df: åˆ†é’ŸKæ•°æ®
        
        Returns:
            åˆ†æç»“æœï¼ˆå¦‚æœæ— æ•ˆåˆ™è¿”å›Noneï¼‰
        """
        if len(kline_df) < 20:
            return None
        
        try:
            # æ‰§è¡Œå®Œæ•´å››ç»´åˆ†æ
            result = self.analyzer.analyze(code, kline_df)
            return result
        
        except Exception as e:
            logger.debug(f"âš ï¸ åˆ†æ{code}å¤±è´¥: {e}")
            return None
    
    def _save_to_cache(self, code: str, kline_df: pd.DataFrame):
        """
        ä¿å­˜Kçº¿æ•°æ®åˆ°CSVç¼“å­˜
        
        Args:
            code: è‚¡ç¥¨ä»£ç 
            kline_df: åˆ†é’ŸKæ•°æ®
        """
        try:
            date_str = datetime.now().strftime('%Y%m%d')
            cache_file = self.cache_dir / date_str / f"{code.replace('.', '_')}_1min.csv"
            cache_file.parent.mkdir(parents=True, exist_ok=True)
            
            kline_df.to_csv(cache_file, index=False, encoding='utf-8')
            logger.debug(f"âœ… ç¼“å­˜æ•°æ®: {cache_file}")
        
        except Exception as e:
            logger.debug(f"âš ï¸ ç¼“å­˜æ•°æ®å¤±è´¥ {code}: {e}")
    
    def _load_from_cache(self, code: str) -> Optional[pd.DataFrame]:
        """
        ä»CSVç¼“å­˜åŠ è½½Kçº¿æ•°æ®
        
        Args:
            code: è‚¡ç¥¨ä»£ç 
        
        Returns:
            åˆ†é’ŸKæ•°æ®ï¼ˆå¦‚æœç¼“å­˜ä¸å­˜åœ¨åˆ™è¿”å›Noneï¼‰
        """
        try:
            date_str = datetime.now().strftime('%Y%m%d')
            cache_file = self.cache_dir / date_str / f"{code.replace('.', '_')}_1min.csv"
            
            if cache_file.exists():
                df = pd.read_csv(cache_file, encoding='utf-8')
                logger.debug(f"âœ… åŠ è½½ç¼“å­˜: {cache_file}")
                return df
        
        except Exception as e:
            logger.debug(f"âš ï¸ åŠ è½½ç¼“å­˜å¤±è´¥ {code}: {e}")
        
        return None
