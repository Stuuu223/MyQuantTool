#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å…¨å¸‚åœºæ‰«æå¼•æ“

ä¸‰é˜¶æ®µæ¸è¿›å¼ç­›é€‰ï¼š
1. é¢„ç­›é€‰ï¼šç¡¬æ€§æ¡ä»¶å¿«é€Ÿè¿‡æ»¤
2. å››ç»´åˆç­›ï¼šç®€åŒ–QPSTè¯†åˆ«å¼‚å¸¸
3. ç²¾å‡†QPSTï¼šå®Œæ•´åˆ†æè¾“å‡ºæ¦œå•

Author: MyQuantTool Team
Date: 2026-02-11
Version: Phase 2
"""

import time
import json
from pathlib import Path
from typing import List, Dict, Optional
from datetime import datetime
import pandas as pd
from multiprocessing import Pool, cpu_count

try:
    from xtquant import xtdata
    QMT_AVAILABLE = True
except ImportError:
    QMT_AVAILABLE = False

from logic.batch_qpst_analyzer import BatchQPSTAnalyzer
from logic.logger import get_logger

logger = get_logger(__name__)


class MarketScanner:
    """
    å…¨å¸‚åœºæ‰«æå™¨
    
    ä¸‰é˜¶æ®µæ¸è¿›å¼ç­›é€‰ï¼Œè¾“å‡ºTOP 20-50è¯±å¤šæ¦œå•
    """
    
    def __init__(self, use_cache: bool = True, cache_dir: str = 'data/kline_cache'):
        """
        åˆå§‹åŒ–æ‰«æå™¨
        
        Args:
            use_cache: æ˜¯å¦ä½¿ç”¨æœ¬åœ°CSVç¼“å­˜ä½œä¸ºå¤‡ä»½
            cache_dir: ç¼“å­˜ç›®å½•è·¯å¾„
        """
        if not QMT_AVAILABLE:
            raise RuntimeError("âš ï¸ xtquant æœªå®‰è£…ï¼ŒMarketScanner ä¸å¯ç”¨")
        
        self.use_cache = use_cache
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–æ‰¹é‡åˆ†æå™¨
        self.analyzer = BatchQPSTAnalyzer()
        
        # å¤±è´¥è®°å½•
        self.failed_codes = []
        
        logger.info("âœ… MarketScanner åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   - ç¼“å­˜ç›®å½•: {self.cache_dir}")
        logger.info(f"   - ç¼“å­˜å¤‡ä»½: {' å¯ç”¨' if use_cache else 'ç¦ç”¨'}")
    
    def scan(self, stock_list: List[str], scan_time: str = None) -> List[Dict]:
        """
        æ‰§è¡Œå…¨å¸‚åœºæ‰«æ
        
        Args:
            stock_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            scan_time: æ‰«ææ—¶é—´èŠ‚ç‚¹ï¼ˆ'09:35' | '10:00' | '14:00'ï¼‰
        
        Returns:
            TOP 20-50 è¯±å¤šæ¦œå•
        """
        if scan_time is None:
            scan_time = datetime.now().strftime('%H:%M')
        
        logger.info("="*80)
        logger.info(f"ğŸš€ å¼€å§‹å…¨å¸‚åœºæ‰«æ - {scan_time}")
        logger.info("="*80)
        logger.info(f"å¾…æ‰«æè‚¡ç¥¨æ•°é‡: {len(stock_list)}")
        
        start_time = time.time()
        
        # é‡ç½®å¤±è´¥è®°å½•
        self.failed_codes = []
        
        # ===== é˜¶æ®µ1: é¢„ç­›é€‰ =====
        candidates = self._phase1_pre_filter(stock_list)
        logger.info(f"\nâœ… é˜¶æ®µ1å®Œæˆ: {len(stock_list)} â†’ {len(candidates)} åªè‚¡ç¥¨")
        
        if not candidates:
            logger.warning("âš ï¸ é¢„ç­›é€‰åæ— å€™é€‰è‚¡ç¥¨ï¼Œæ‰«æç»“æŸ")
            return []
        
        # ===== é˜¶æ®µ2: å››ç»´åˆç­› =====
        potentials = self._phase2_qpst_lite(candidates)
        logger.info(f"âœ… é˜¶æ®µ2å®Œæˆ: {len(candidates)} â†’ {len(potentials)} åªè‚¡ç¥¨")
        
        if not potentials:
            logger.warning("âš ï¸ å››ç»´åˆç­›åæ— å€™é€‰è‚¡ç¥¨ï¼Œæ‰«æç»“æŸ")
            return []
        
        # ===== é˜¶æ®µ3: ç²¾å‡†QPST =====
        trap_list = self._phase3_qpst_full(potentials)
        logger.info(f"âœ… é˜¶æ®µ3å®Œæˆ: {len(potentials)} â†’ {len(trap_list)} åªè‚¡ç¥¨")
        
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        trap_list.sort(key=lambda x: x['confidence'], reverse=True)
        
        # ç»Ÿè®¡ä¿¡æ¯
        elapsed = time.time() - start_time
        logger.info("="*80)
        logger.info(f"ğŸ“Š æ‰«æå®Œæˆ - è€—æ—¶ {elapsed:.1f}ç§’")
        logger.info(f"   - æ€»æ‰«æ: {len(stock_list)} åª")
        logger.info(f"   - é¢„ç­›é€‰: {len(candidates)} åª")
        logger.info(f"   - åˆç­›é€‰: {len(potentials)} åª")
        logger.info(f"   - æœ€ç»ˆæ¦œå•: {len(trap_list)} åª")
        logger.info(f"   - å¤±è´¥è‚¡ç¥¨: {len(self.failed_codes)} åª")
        logger.info("="*80)
        
        return trap_list[:50]  # TOP 50
    
    def _phase1_pre_filter(self, stock_list: List[str]) -> List[str]:
        """
        é˜¶æ®µ1: é¢„ç­›é€‰ï¼ˆç¡¬æ€§æ¡ä»¶ï¼‰
        
        ç›®æ ‡: 5000è‚¡ â†’ 200-400è‚¡ï¼ˆ1åˆ†é’Ÿå†…å®Œæˆï¼‰
        
        ç­›é€‰æ¡ä»¶:
        1. æ¶¨å¹… > 2%
        2. æ¢æ‰‹ç‡ > 3%ï¼ˆ10åˆ†é’Ÿï¼‰
        3. æ”¾é‡ > 1.3å€
        """
        logger.info("\nğŸ” é˜¶æ®µ1: é¢„ç­›é€‰ï¼ˆç¡¬æ€§æ¡ä»¶ï¼‰")
        logger.info("-" * 80)
        
        candidates = []
        
        # æ‰¹é‡è·å–åˆ†é’ŸKæ•°æ®ï¼ˆQMTæ¥å£ï¼‰
        logger.info("æ­£åœ¨æ‰¹é‡è·å–åˆ†é’ŸKæ•°æ®...")
        kline_data = self._get_kline_batch(stock_list, count=10)
        
        logger.info(f"æˆåŠŸè·å– {len(kline_data)} åªè‚¡ç¥¨çš„Kçº¿æ•°æ®")
        
        for code in stock_list:
            try:
                if code not in kline_data:
                    continue
                
                df = kline_data[code]
                
                if len(df) < 10:
                    continue
                
                # è®¡ç®—æ¶¨å¹…
                price_change = (df['close'].iloc[-1] - df['close'].iloc[0]) / df['close'].iloc[0]
                
                # è®¡ç®—é‡æ¯”
                recent_vol = df['volume'].iloc[-3:].mean()
                earlier_vol = df['volume'].iloc[:-3].mean()
                volume_ratio = recent_vol / earlier_vol if earlier_vol > 0 else 0
                
                # è®¡ç®—æ¢æ‰‹ç‡
                float_shares = self.analyzer.equity_info.get(code, {}).get('float_shares', 0)
                if float_shares > 0:
                    turnover = df['volume'].sum() / float_shares
                else:
                    turnover = 0
                
                # ç¡¬æ€§ç­›é€‰æ¡ä»¶
                if price_change > 0.02 and turnover > 0.03 and volume_ratio > 1.3:
                    candidates.append(code)
                    logger.debug(f"  âœ“ {code}: æ¶¨å¹…={price_change:.2%}, æ¢æ‰‹={turnover:.2%}, é‡æ¯”={volume_ratio:.2f}")
            
            except Exception as e:
                logger.debug(f"  âœ— {code}: é¢„ç­›é€‰å¤±è´¥ - {e}")
                self.failed_codes.append(code)
        
        return candidates
    
    def _phase2_qpst_lite(self, candidates: List[str]) -> List[str]:
        """
        é˜¶æ®µ2: å››ç»´åˆç­›ï¼ˆç®€åŒ–QPSTï¼‰
        
        ç›®æ ‡: 200-400è‚¡ â†’ 50-100è‚¡ï¼ˆ3åˆ†é’Ÿå†…å®Œæˆï¼‰
        """
        logger.info("\nğŸ” é˜¶æ®µ2: å››ç»´åˆç­›ï¼ˆç®€åŒ–QPSTï¼‰")
        logger.info("-" * 80)
        
        potentials = []
        
        # æ‰¹é‡è·å–åˆ†é’ŸKæ•°æ®
        logger.info("æ­£åœ¨æ‰¹é‡è·å–åˆ†é’ŸKæ•°æ®...")
        kline_data = self._get_kline_batch(candidates, count=10)
        
        for code in candidates:
            try:
                if code not in kline_data:
                    continue
                
                df = kline_data[code]
                
                if len(df) < 10:
                    continue
                
                # å¿«é€Ÿå››ç»´åˆ¤æ–­
                signals = self.analyzer.analyze_lite(df, code)
                
                # ç»Ÿè®¡å¼‚å¸¸ç»´åº¦æ•°é‡
                abnormal_count = sum(1 for sig in signals.values() if sig == 'ABNORMAL')
                
                # è‡³å°‘2ä¸ªç»´åº¦å¼‚å¸¸æ‰è¿›å…¥ä¸‹ä¸€é˜¶æ®µ
                if abnormal_count >= 2:
                    potentials.append(code)
                    logger.debug(f"  âœ“ {code}: {abnormal_count}/4 ç»´åº¦å¼‚å¸¸ - {signals}")
            
            except Exception as e:
                logger.debug(f"  âœ— {code}: åˆç­›å¤±è´¥ - {e}")
                self.failed_codes.append(code)
        
        return potentials
    
    def _phase3_qpst_full(self, potentials: List[str]) -> List[Dict]:
        """
        é˜¶æ®µ3: ç²¾å‡†QPSTï¼ˆå®Œæ•´åˆ†æï¼‰
        
        ç›®æ ‡: 50-100è‚¡ â†’ 20-50è‚¡ï¼ˆ5åˆ†é’Ÿå†…å®Œæˆï¼‰
        """
        logger.info("\nğŸ” é˜¶æ®µ3: ç²¾å‡†QPSTï¼ˆå®Œæ•´åˆ†æï¼‰")
        logger.info("-" * 80)
        
        # æ™ºèƒ½é€‰æ‹©å•è¿›ç¨‹ vs å¤šè¿›ç¨‹
        if len(potentials) < 100:
            logger.info(f"ä½¿ç”¨å•è¿›ç¨‹æ¨¡å¼ï¼ˆ{len(potentials)} åªè‚¡ç¥¨ï¼‰")
            results = [self._analyze_single_stock(code) for code in potentials]
        else:
            logger.info(f"ä½¿ç”¨å¤šè¿›ç¨‹æ¨¡å¼ï¼ˆ{len(potentials)} åªè‚¡ç¥¨ï¼Œ{cpu_count()} æ ¸å¿ƒï¼‰")
            with Pool(processes=min(8, cpu_count())) as pool:
                results = pool.map(self._analyze_single_stock, potentials)
        
        # è¿‡æ»¤å‡ºè¯±å¤šé¢„è­¦
        trap_list = []
        for result in results:
            if result and result['final_signal'] == 'TRAP_WARNING':
                trap_list.append(result)
                logger.info(f"  âš ï¸  {result['code']}: {result['reason']} (ç½®ä¿¡åº¦: {result['confidence']:.0%})")
        
        return trap_list
    
    def _analyze_single_stock(self, code: str) -> Optional[Dict]:
        """
        å•è‚¡ç¥¨å®Œæ•´QPSTåˆ†æ
        
        Args:
            code: è‚¡ç¥¨ä»£ç 
        
        Returns:
            åˆ†æç»“æœå­—å…¸ æˆ– Noneï¼ˆå¤±è´¥ï¼‰
        """
        try:
            # è·å–æ›´é•¿æ—¶é—´çš„åˆ†é’ŸKï¼ˆ30æ ¹ï¼‰
            df = self._get_kline_single(code, count=30)
            
            if df is None or len(df) < 20:
                return None
            
            # æ‰§è¡Œå®Œæ•´å››ç»´åˆ†æ
            result = self.analyzer.analyze_full(df, code)
            
            # æ·»åŠ è‚¡ç¥¨ä»£ç å’Œæ—¶é—´æˆ³
            result['code'] = code
            result['timestamp'] = datetime.now().strftime('%H:%M:%S')
            
            return result
        
        except Exception as e:
            logger.debug(f"  âœ— {code}: å®Œæ•´åˆ†æå¤±è´¥ - {e}")
            self.failed_codes.append(code)
            return None
    
    # ========== æ•°æ®è·å–å±‚ï¼ˆQMTä¸»åŠ› + CSVå¤‡ä»½ï¼‰ ==========
    
    def _get_kline_batch(self, stock_list: List[str], count: int = 10) -> Dict[str, pd.DataFrame]:
        """
        æ‰¹é‡è·å–åˆ†é’ŸKæ•°æ®ï¼ˆQMTæ¥å£ï¼‰
        
        Args:
            stock_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            count: Kçº¿æ ¹æ•°
        
        Returns:
            {code: DataFrame, ...}
        """
        try:
            # ä½¿ç”¨QMTæ‰¹é‡è·å–
            kline_data = xtdata.get_market_data_ex(
                field_list=['open', 'high', 'low', 'close', 'volume', 'amount'],
                stock_list=stock_list,
                period='1m',
                count=count,
                dividend_type='none'
            )
            
            # æ·»åŠ æ—¶é—´åˆ—ï¼ˆæ–¹ä¾¿å°¾ç›˜åˆ¤æ–­ï¼‰
            for code, df in kline_data.items():
                if not df.empty and df.index.name == 'time':
                    df['time'] = df.index.strftime('%H:%M')
            
            return kline_data
        
        except Exception as e:
            logger.error(f"âŒ QMTæ‰¹é‡è·å–å¤±è´¥: {e}")
            
            # é™çº§åˆ°CSVç¼“å­˜
            if self.use_cache:
                logger.warning("âš ï¸ é™çº§ä½¿ç”¨CSVç¼“å­˜")
                return self._load_from_cache_batch(stock_list, count)
            
            return {}
    
    def _get_kline_single(self, code: str, count: int = 30) -> Optional[pd.DataFrame]:
        """
        è·å–å•ä¸ªè‚¡ç¥¨çš„åˆ†é’ŸKæ•°æ®
        
        Args:
            code: è‚¡ç¥¨ä»£ç 
            count: Kçº¿æ ¹æ•°
        
        Returns:
            DataFrame æˆ– None
        """
        try:
            # ä½¿ç”¨QMTè·å–
            kline_data = xtdata.get_market_data_ex(
                field_list=['open', 'high', 'low', 'close', 'volume', 'amount'],
                stock_list=[code],
                period='1m',
                count=count,
                dividend_type='none'
            )
            
            if code in kline_data:
                df = kline_data[code]
                if not df.empty and df.index.name == 'time':
                    df['time'] = df.index.strftime('%H:%M')
                return df
            
            return None
        
        except Exception as e:
            logger.debug(f"QMTè·å–{code}å¤±è´¥: {e}")
            
            # é™çº§åˆ°CSVç¼“å­˜
            if self.use_cache:
                return self._load_from_cache_single(code, count)
            
            return None
    
    def _load_from_cache_batch(self, stock_list: List[str], count: int) -> Dict[str, pd.DataFrame]:
        """
        ä»CSVç¼“å­˜æ‰¹é‡åŠ è½½ï¼ˆå¤‡ä»½æ–¹æ¡ˆï¼‰
        
        Args:
            stock_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            count: Kçº¿æ ¹æ•°
        
        Returns:
            {code: DataFrame, ...}
        """
        result = {}
        for code in stock_list:
            df = self._load_from_cache_single(code, count)
            if df is not None:
                result[code] = df
        return result
    
    def _load_from_cache_single(self, code: str, count: int) -> Optional[pd.DataFrame]:
        """
        ä»CSVç¼“å­˜åŠ è½½å•ä¸ªè‚¡ç¥¨æ•°æ®
        
        Args:
            code: è‚¡ç¥¨ä»£ç 
            count: Kçº¿æ ¹æ•°
        
        Returns:
            DataFrame æˆ– None
        """
        try:
            # æ„å»ºç¼“å­˜æ–‡ä»¶è·¯å¾„
            today = datetime.now().strftime('%Y%m%d')
            cache_file = self.cache_dir / today / f"{code.replace('.', '_')}_1min.csv"
            
            if not cache_file.exists():
                return None
            
            # è¯»å–CSV
            df = pd.read_csv(cache_file, parse_dates=['time'])
            
            # å–æœ€è¿‘countæ ¹Kçº¿
            if len(df) > count:
                df = df.tail(count)
            
            # æ·»åŠ æ—¶é—´åˆ—
            df['time'] = pd.to_datetime(df['time']).dt.strftime('%H:%M')
            
            return df
        
        except Exception as e:
            logger.debug(f"CSVåŠ è½½{code}å¤±è´¥: {e}")
            return None
    
    def get_failed_codes(self) -> List[str]:
        """
        è·å–å¤±è´¥çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨
        
        Returns:
            å¤±è´¥è‚¡ç¥¨ä»£ç åˆ—è¡¨
        """
        return list(set(self.failed_codes))  # å»é‡
