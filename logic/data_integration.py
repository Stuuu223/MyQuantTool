"""
çœŸå®é¾™è™æ¦œæ•°æ®é›†æˆæ¨¡å—
å±æ€§ï¼š
- akshare å®æ—¶æ•°æ®æ¥å…¥
- æœ¬åœ° SQLite æ•°æ®åº“ä¸Šä¸š
- æ•°æ®æµç»¯åŒ–å¤„ç†
- é”™è¯¯é‡è¯•æœºåˆ¶
"""

import akshare as ak
import pandas as pd
import sqlite3
import logging
from datetime import datetime, timedelta
from typing import Optional, Dict, List, Tuple
from pathlib import Path
import time
import json
from collections import deque

logger = logging.getLogger(__name__)


class RealTimeDataLoader:
    """
    å®æ—¶é¾™è™æ¦œæ•°æ®åŠ è½½å™¨
    """
    
    def __init__(
        self,
        db_path: str = 'data/production.db',
        max_retries: int = 3,
        retry_delay: float = 2.0
    ):
        """
        Args:
            db_path: SQLite æ•°æ®åº“è·¯å¾„
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            retry_delay: é‡è¯•å»¶è¿Ÿ (ç§’)
        """
        self.db_path = db_path
        self.max_retries = max_retries
        self.retry_delay = retry_delay
        self.error_log = deque(maxlen=100)  # ä¿æŒæœ€è§’100æ¡é”™è¯¯
        
        Path(self.db_path).parent.mkdir(parents=True, exist_ok=True)
        self._init_db()
    
    def _init_db(self) -> None:
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨"""
        with sqlite3.connect(self.db_path) as conn:
            # é¾™è™æ¦œè¡¨
            conn.execute("""
                CREATE TABLE IF NOT EXISTS lhb_realtime (
                    id INTEGER PRIMARY KEY,
                    date TEXT NOT NULL,
                    stock_code TEXT NOT NULL,
                    stock_name TEXT,
                    capital_name TEXT NOT NULL,
                    direction TEXT,  -- 'ä¹°' æˆ– 'å–'
                    amount REAL,  -- æˆäº¤é¢ (ä¸‡å…ƒ)
                    price REAL,
                    rank INTEGER,  -- é¾™è™æ¦œæ’å
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(date, stock_code, capital_name, direction),
                    FOREIGN KEY (stock_code) REFERENCES stock_meta(code)
                )
            """)
            
            # è‚¡ç¥¨å…ƒæ•°æ®è¡¨
            conn.execute("""
                CREATE TABLE IF NOT EXISTS stock_meta (
                    code TEXT PRIMARY KEY,
                    name TEXT,
                    industry TEXT,
                    last_update DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # çµ¢è¨ˆæ•°æ®è¡¨ (ç”¨äºè¿‡æ»¤)
            conn.execute("""
                CREATE TABLE IF NOT EXISTS lhb_stats (
                    id INTEGER PRIMARY KEY,
                    date TEXT NOT NULL UNIQUE,
                    total_records INTEGER,
                    total_stocks INTEGER,
                    total_capitals INTEGER,
                    total_amount REAL,
                    processed_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # åˆ›å»ºç´¢å¼•
            conn.execute("CREATE INDEX IF NOT EXISTS idx_date ON lhb_realtime(date)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_stock ON lhb_realtime(stock_code)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_capital ON lhb_realtime(capital_name)")
            conn.commit()
    
    def fetch_lhb_with_retry(
        self,
        date_str: str,
        attempt: int = 1
    ) -> Optional[pd.DataFrame]:
        """
        å¸¦é‡è¯•æ©œåˆ¶çš„ LHB æ•°æ®è·å–
        
        Args:
            date_str: æ—¥æœŸ 'YYYY-MM-DD'
            attempt: å½“å‰å°è¯•æ¬¡æ•°
        
        Returns:
            DataFrame æˆ– None
        """
        try:
            logger.info(f"â­ æ­£åœ¨è·å– {date_str} é¾™è™æ¦œæ•°æ®...")
            df = ak.stock_lgb_daily(date=date_str)
            
            if df is None or len(df) == 0:
                logger.warning(f"âš ï¸  {date_str} æ— æ•°æ® (å¯èƒ½æ˜¯èŠ‚å‡æ—¥)")
                return None
            
            logger.info(f"âœ… æˆåŠŸè·å– {len(df)} æ¡è®°å½•")
            return df
        
        except Exception as e:
            error_msg = f"{date_str} è·å–å¤±è´¥: {str(e)}"
            self.error_log.append((datetime.now(), error_msg))
            
            if attempt < self.max_retries:
                logger.warning(f"âš ï¸  {error_msg}. å³å°†éœ€è¦ {self.retry_delay}s åç¬¬ {attempt+1} æ¬¡æ°«è¯•...")
                time.sleep(self.retry_delay)
                return self.fetch_lhb_with_retry(date_str, attempt + 1)
            else:
                logger.error(f"âŒ {error_msg} (è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°)")
                return None
    
    def preprocess_lhb_data(
        self,
        df_raw: pd.DataFrame,
        date_str: str
    ) -> pd.DataFrame:
        """
        é¢„å¤„ç†é¾™è™æ¦œæ•°æ®
        
        å¤„ç†æ‰¥ç­¥ï¼š
        - åˆ—é‡å‘½å
        - æ•°æ®ç±»å‹è½¬æ¢
        - ç¼ºå¤±å€¼å¤„ç†
        - é‡å¤å€¼å¤„ç†
        """
        df = df_raw.copy()
        
        # åˆ—é‡å‘½å
        rename_map = {
            'ä»£ç ': 'stock_code',
            'åç§°': 'stock_name',
            'æ¸¸èµ„åç§°': 'capital_name',
            'æ“ä½œæ–¹å‘': 'direction',
            'æˆäº¤é¢': 'amount',  # å•ä½ï¼šä¸‡å…ƒ
            'æœ€æ–°ä»·': 'price',
        }
        df.rename(columns=rename_map, inplace=True)
        
        # æ•°æ®ç±»å‹è½¬æ¢
        df['amount'] = pd.to_numeric(df['amount'], errors='coerce')
        df['price'] = pd.to_numeric(df['price'], errors='coerce')
        df['date'] = date_str
        
        # ç¼ºå¤±å€¼å¤„ç†
        df.dropna(subset=['stock_code', 'capital_name', 'amount'], inplace=True)
        
        # é‡å¤å€¼å¤„ç† (å–ç¬¬ä¸€æ¡)
        df.drop_duplicates(subset=['stock_code', 'capital_name', 'direction'], 
                          keep='first', inplace=True)
        
        # è¡¥å……é¾™è™æ¦œæ’å
        if 'æ’å' not in df.columns:
            df['rank'] = df.groupby('stock_code').cumcount() + 1
        else:
            df.rename(columns={'æ’å': 'rank'}, inplace=True)
        
        return df
    
    def upsert_to_db(
        self,
        df_processed: pd.DataFrame
    ) -> Dict[str, int]:
        """
        æ’å…¥/æ›´æ–°æ•°æ®åº“
        
        Returns:
            {
                'inserted': int,
                'updated': int,
                'skipped': int,
                'errors': int
            }
        """
        stats = {'inserted': 0, 'updated': 0, 'skipped': 0, 'errors': 0}
        
        with sqlite3.connect(self.db_path) as conn:
            for _, row in df_processed.iterrows():
                try:
                    # å…ˆæ›´æ–°æ ªæå–æ‰¹
                    cursor = conn.execute("""
                        INSERT OR REPLACE INTO lhb_realtime
                        (date, stock_code, stock_name, capital_name, direction, amount, price, rank)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                        row['date'],
                        row['stock_code'],
                        row.get('stock_name', ''),
                        row['capital_name'],
                        row.get('direction', ''),
                        row['amount'],
                        row.get('price', None),
                        row.get('rank', 0)
                    ))
                    
                    if cursor.rowcount > 0:
                        stats['inserted'] += 1
                    else:
                        stats['updated'] += 1
                
                except sqlite3.IntegrityError:
                    stats['skipped'] += 1
                except Exception as e:
                    logger.error(f"æ’å…¥æ•°æ®å¤±è´¥: {str(e)}")
                    stats['errors'] += 1
            
            conn.commit()
        
        return stats
    
    def load_daily_data(
        self,
        date_str: str = None
    ) -> Tuple[Optional[pd.DataFrame], Dict]:
        """
        ä¸€ä½“åŒ–åŠ è½½æ—¥å¸¸æ•°æ®çš„æ ‡å‡†æµç¨‹
        
        Returns:
            (DataFrame, å¤„ç†ç»Ÿè®¡)
        """
        if date_str is None:
            date_str = datetime.now().strftime('%Y-%m-%d')
        
        logger.info(f"ğŸ“„ å¼€å§‹åŠ è½½ {date_str} æ•°æ®...")
        
        # æ­¥éª¤ 1: è·å–åŸå§‹æ•°æ®
        df_raw = self.fetch_lhb_with_retry(date_str)
        if df_raw is None:
            return None, {'status': 'failed', 'reason': 'no_data'}
        
        # æ­¥éª¤ 2: é¢„å¤„ç†
        df_processed = self.preprocess_lhb_data(df_raw, date_str)
        logger.info(f"âœ… é¢„å¤„ç†å®Œæˆ: {len(df_processed)} æ¡æœ‰æ•ˆè®°å½•")
        
        # æ­¥éª¤ 3: å…¥åº“
        db_stats = self.upsert_to_db(df_processed)
        logger.info(f"ğŸ’¾ å…¥åº“å®Œæˆ: æ–°å¢ {db_stats['inserted']}, æˆ‰ä½ {db_stats['skipped']}, æ”™è¯¯ {db_stats['errors']}")
        
        # æ­¥éª¤ 4: ç»Ÿè®¡æ•°æ®
        self._update_stats(date_str, df_processed)
        
        return df_processed, db_stats
    
    def _update_stats(
        self,
        date_str: str,
        df: pd.DataFrame
    ) -> None:
        """æ›´æ–°çµ¢è¨ˆæ•°æ®"""
        stats = {
            'total_records': len(df),
            'total_stocks': df['stock_code'].nunique(),
            'total_capitals': df['capital_name'].nunique(),
            'total_amount': df['amount'].sum()
        }
        
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                INSERT OR REPLACE INTO lhb_stats
                (date, total_records, total_stocks, total_capitals, total_amount)
                VALUES (?, ?, ?, ?, ?)
            """, (date_str, stats['total_records'], stats['total_stocks'],
                   stats['total_capitals'], stats['total_amount']))
            conn.commit()
        
        logger.info(f"ğŸ“Š ç»Ÿè®¡: {stats['total_stocks']}åªè‚¡, {stats['total_capitals']}ä¸ªæ¸¸èµ„, ç»Ÿè®¡æˆäº¤é¢ {stats['total_amount']:.2f}ä¸‡å…ƒ")
    
    def batch_load(
        self,
        start_date: str,
        end_date: str,
        skip_weekends: bool = True
    ) -> Dict:
        """
        æ‰¹é‡åŠ è½½å†å²æ•°æ®
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ 'YYYY-MM-DD'
            end_date: ç»“æŸæ—¥æœŸ 'YYYY-MM-DD'
            skip_weekends: æ˜¯å¦è·³è¿‡å‘¨æœ«
        
        Returns:
            {
                'total_days': int,
                'successful_days': int,
                'failed_days': int,
                'total_records': int
            }
        """
        start = datetime.strptime(start_date, '%Y-%m-%d')
        end = datetime.strptime(end_date, '%Y-%m-%d')
        
        total_records = 0
        successful_days = 0
        failed_days = 0
        
        current = start
        while current <= end:
            # è·³è¿‡å‘¨æœ«
            if skip_weekends and current.weekday() >= 5:
                current += timedelta(days=1)
                continue
            
            date_str = current.strftime('%Y-%m-%d')
            df, stats = self.load_daily_data(date_str)
            
            if df is not None and len(df) > 0:
                successful_days += 1
                total_records += len(df)
            else:
                failed_days += 1
            
            current += timedelta(days=1)
            time.sleep(0.5)  # ä¸ºäº†ä¸ä½ ä¾¿æœåŠ¡å™¨ï¼Œæ¨è¿Ÿè¯·æ±‚
        
        return {
            'total_days': (end - start).days + 1,
            'successful_days': successful_days,
            'failed_days': failed_days,
            'total_records': total_records
        }
    
    def query_realtime(
        self,
        date_str: str = None
    ) -> pd.DataFrame:
        """
        æŸ¥è¯¢æŒ‡å®šæ—¥æ—¥çš„æ•°æ®
        """
        if date_str is None:
            date_str = datetime.now().strftime('%Y-%m-%d')
        
        with sqlite3.connect(self.db_path) as conn:
            query = f"""
                SELECT * FROM lhb_realtime 
                WHERE date = '{date_str}'
                ORDER BY amount DESC
            """
            return pd.read_sql(query, conn)
    
    def get_error_log(self) -> List[Tuple]:
        """è·å–é”™è¯¯æ—¥å¿—"""
        return list(self.error_log)
