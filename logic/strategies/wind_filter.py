#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
V12.1.0 æ¿å—å…±æŒ¯è¿‡æ»¤å™¨

æ‹’ç»"å­¤å†›æ·±å…¥"ï¼Œåªæœ‰"ä¸ªè‚¡å¼º + æ¿å—å…±æŒ¯"æ‰æ˜¯çœŸé¾™

æ ¸å¿ƒé€»è¾‘ï¼š
- æ¡ä»¶A: æ¿å—å†…æ¶¨åœè‚¡ â‰¥ 3åª
- æ¡ä»¶B: æ¿å—å†…ä¸Šæ¶¨è‚¡ç¥¨å æ¯” â‰¥ 35%
- æ¡ä»¶C: æ¿å—æŒ‡æ•°è¿ç»­3æ—¥èµ„é‡‘å‡€æµå…¥
- æ»¡è¶³è‡³å°‘2ä¸ªæ¡ä»¶æ‰è¿”å›True

Author: iFlow CLI
Version: V12.1.0
Date: 2026-02-14
"""

import json
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple

from logic.utils.logger import get_logger
from logic.utils.code_converter import CodeConverter
from logic.data_providers.data_source_manager import get_smart_data_manager
from logic.data_providers.cache_manager import CacheManager

logger = get_logger(__name__)


class WindFilter:
    """
    æ¿å—å…±æŒ¯è¿‡æ»¤å™¨
    
    åŠŸèƒ½ï¼š
    1. æ£€æŸ¥ä¸ªè‚¡æ‰€å±æ¿å—çš„æ•´ä½“æ´»è·ƒåº¦
    2. è¯†åˆ«æ¿å—å…±æŒ¯ä¿¡å·ï¼ˆæ¶¨åœè‚¡æ•°/ä¸Šæ¶¨å æ¯”/èµ„é‡‘æµå…¥ï¼‰
    3. æ‹’ç»"å­¤å†›æ·±å…¥"çš„ä¸ªè‚¡
    4. æä¾›æ¿å—å…±æŒ¯è¯„åˆ†ï¼ˆ0-1ï¼‰
    
    æ•°æ®æºï¼š
    - æ¿å—æ˜ å°„: data/stock_sector_map.json
    - QMT Tickæ•°æ®: å®æ—¶æ¶¨åœè‚¡ç»Ÿè®¡
    - Tushareæ•°æ®: æ¿å—æŒ‡æ•°èµ„é‡‘æµ
    """

    # é…ç½®å‚æ•°
    SECTOR_MAP_PATH = Path("data/sector_map/stock_sector_map.json")
    MIN_LIMIT_UP_COUNT = 3  # æ¡ä»¶A: æœ€å°‘æ¶¨åœè‚¡æ•°
    MIN_RISE_RATIO = 0.35  # æ¡ä»¶B: æœ€å°‘ä¸Šæ¶¨æ¯”ä¾‹ (35%)
    SUSTAINED_INFLOW_DAYS = 3  # æ¡ä»¶C: è¿ç»­æµå…¥å¤©æ•°
    
    # ç¼“å­˜æ—¶é—´ï¼ˆç§’ï¼‰
    CACHE_TTL_LIMIT_UP = 60  # æ¶¨åœè‚¡ç»Ÿè®¡ç¼“å­˜60ç§’
    CACHE_TTL_SECTOR_PERFORMANCE = 60  # æ¿å—è¡¨ç°ç¼“å­˜60ç§’
    CACHE_TTL_CAPITAL_FLOW = 600  # èµ„é‡‘æµç¼“å­˜10åˆ†é’Ÿï¼ˆAPIè°ƒç”¨æ…¢ï¼Œéœ€è¦æ›´é•¿ç¼“å­˜ï¼‰

    def __init__(self):
        """åˆå§‹åŒ–æ¿å—å…±æŒ¯è¿‡æ»¤å™¨"""
        self.converter = CodeConverter()
        self.data_manager = get_smart_data_manager()
        self.cache = CacheManager()

        # åŠ è½½æ¿å—æ˜ å°„
        self.sector_map = self._load_sector_map()

        # å…¨å±€è¡Œä¸šèµ„é‡‘æµç¼“å­˜ï¼ˆä¸€æ¬¡æ€§è·å–æ‰€æœ‰è¡Œä¸šæ•°æ®ï¼‰
        self._global_capital_flow_cache = None
        self._global_capital_flow_timestamp = 0

        # å…¨å±€å®æ—¶ä»·æ ¼ç¼“å­˜
        self._global_price_cache = None
        self._global_price_timestamp = 0

        logger.info("âœ… [æ¿å—å…±æŒ¯è¿‡æ»¤å™¨] åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   - æ¶¨åœè‚¡é˜ˆå€¼: â‰¥ {self.MIN_LIMIT_UP_COUNT} åª")
        logger.info(f"   - ä¸Šæ¶¨å æ¯”é˜ˆå€¼: â‰¥ {self.MIN_RISE_RATIO*100:.0f}%")
        logger.info(f"   - è¿ç»­æµå…¥å¤©æ•°: â‰¥ {self.SUSTAINED_INFLOW_DAYS} å¤©")
    
    def _load_sector_map(self) -> Dict:
        """
        åŠ è½½æ¿å—æ˜ å°„
        
        Returns:
            dict: è‚¡ç¥¨ä»£ç  -> æ¿å—ä¿¡æ¯
        """
        try:
            if self.SECTOR_MAP_PATH.exists():
                with open(self.SECTOR_MAP_PATH, 'r', encoding='utf-8') as f:
                    return json.load(f)
            else:
                logger.warning(f"âš ï¸ [æ¿å—å…±æŒ¯] æ¿å—æ˜ å°„æ–‡ä»¶ä¸å­˜åœ¨: {self.SECTOR_MAP_PATH}")
                return {}
        except Exception as e:
            logger.error(f"âŒ [æ¿å—å…±æŒ¯] åŠ è½½æ¿å—æ˜ å°„å¤±è´¥: {e}")
            return {}
    
    def get_stock_sector(self, stock_code: str) -> Optional[Dict]:
        """
        è·å–è‚¡ç¥¨æ‰€å±æ¿å—
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
        
        Returns:
            dict: {
                'industry': str,  # è¡Œä¸š
                'concepts': list,  # æ¦‚å¿µåˆ—è¡¨
            }
        """
        try:
            # è½¬æ¢ä¸ºæ ‡å‡†ä»£ç 
            standard_code = self.converter.to_standard(stock_code)
            
            if standard_code in self.sector_map:
                return self.sector_map[standard_code]
            
            return None
        except Exception as e:
            logger.warning(f"âš ï¸ [æ¿å—å…±æŒ¯] è·å–è‚¡ç¥¨æ¿å—å¤±è´¥: {stock_code}, {e}")
            return None
    
    def get_sector_stocks(self, industry: str) -> List[str]:
        """
        è·å–æ¿å—å†…æ‰€æœ‰è‚¡ç¥¨
        
        Args:
            industry: è¡Œä¸šåç§°
        
        Returns:
            list: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        """
        try:
            stocks = []
            for code, info in self.sector_map.items():
                if info.get('industry') == industry:
                    stocks.append(code)
            
            return stocks
        except Exception as e:
            logger.warning(f"âš ï¸ [æ¿å—å…±æŒ¯] è·å–æ¿å—è‚¡ç¥¨å¤±è´¥: {industry}, {e}")
            return []
    
    def count_limit_up_stocks(self, industry: str) -> int:
        """
        ç»Ÿè®¡æ¿å—å†…æ¶¨åœè‚¡ç¥¨æ•°é‡

        ç­–ç•¥ï¼š
        1. è·å–æ¿å—å†…æ‰€æœ‰è‚¡ç¥¨
        2. è·å–å®æ—¶ä»·æ ¼æ•°æ®
        3. ç»Ÿè®¡æ¶¨å¹… >= 9.8% çš„è‚¡ç¥¨æ•°

        Args:
            industry: è¡Œä¸šåç§°

        Returns:
            int: æ¶¨åœè‚¡ç¥¨æ•°é‡
        """
        try:
            # å°è¯•ä»ç¼“å­˜è·å–
            cache_key = f"limit_up_count_{industry}"
            cached_data = self.cache.get(cache_key)
            if cached_data is not None:
                return cached_data

            # è·å–æ¿å—è‚¡ç¥¨
            stocks = self.get_sector_stocks(industry)
            if not stocks:
                return 0

            # é™åˆ¶æ£€æŸ¥æ•°é‡ï¼ˆé¿å…æ€§èƒ½é—®é¢˜ï¼‰
            stocks = stocks[:100]

            # è·å–å®æ—¶æ•°æ®
            limit_up_count = 0

            # ä¼˜å…ˆä½¿ç”¨æé€Ÿå±‚
            try:
                realtime_data = self.data_manager.get_realtime_price_fast(stocks)

                for code in stocks:
                    if code in realtime_data:
                        info = realtime_data[code]
                        price = info.get('price', 0)
                        yesterday_close = info.get('close', 0)

                        if yesterday_close > 0:
                            change_pct = (price - yesterday_close) / yesterday_close * 100

                            # æ¶¨åœåˆ¤å®šï¼šæ¶¨å¹… >= 9.8%
                            if change_pct >= 9.8:
                                limit_up_count += 1

            except Exception as e:
                logger.debug(f"âš ï¸ [æ¿å—å…±æŒ¯] è·å–å®æ—¶æ•°æ®å¤±è´¥: {e}")

                # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨å¢å¼ºå±‚
                try:
                    import akshare as ak

                    # è·å–æ¿å—è¡Œæƒ…
                    sector_df = ak.stock_board_industry_cons_em(symbol=industry)

                    if not sector_df.empty:
                        limit_up_count = len(sector_df[sector_df['æ¶¨è·Œå¹…'] >= 9.8])

                except Exception as e2:
                    logger.debug(f"âš ï¸ [æ¿å—å…±æŒ¯] å¤‡ç”¨æ–¹æ¡ˆä¹Ÿå¤±è´¥: {e2}")

            # ç¼“å­˜ç»“æœ
            self.cache.set(cache_key, limit_up_count, ttl=self.CACHE_TTL_LIMIT_UP)

            return limit_up_count

        except Exception as e:
            logger.error(f"âŒ [æ¿å—å…±æŒ¯] ç»Ÿè®¡æ¶¨åœè‚¡å¤±è´¥: {industry}, {e}")
            return 0
    
    def calculate_rise_breadth(self, industry: str) -> float:
        """
        è®¡ç®—æ¿å—ä¸Šæ¶¨æ¯”ä¾‹ï¼ˆå¹¿åº¦ï¼‰
        
        Args:
            industry: è¡Œä¸šåç§°
        
        Returns:
            float: ä¸Šæ¶¨æ¯”ä¾‹ (0-1)
        """
        try:
            # å°è¯•ä»ç¼“å­˜è·å–
            cache_key = f"rise_breadth_{industry}"
            cached_data = self.cache.get(cache_key)
            if cached_data is not None:
                return cached_data
            
            # è·å–æ¿å—è‚¡ç¥¨
            stocks = self.get_sector_stocks(industry)
            if not stocks:
                return 0.0
            
            # é™åˆ¶æ£€æŸ¥æ•°é‡
            stocks = stocks[:100]
            
            # è·å–å®æ—¶æ•°æ®
            rise_count = 0
            total_count = 0
            
            try:
                realtime_data = self.data_manager.get_realtime_price_fast(stocks)
                
                for code in stocks:
                    if code in realtime_data:
                        info = realtime_data[code]
                        price = info.get('price', 0)
                        yesterday_close = info.get('close', 0)
                        
                        if yesterday_close > 0:
                            change_pct = (price - yesterday_close) / yesterday_close * 100
                            total_count += 1
                            
                            # ä¸Šæ¶¨åˆ¤å®šï¼šæ¶¨å¹… > 0%
                            if change_pct > 0:
                                rise_count += 1
                
            except Exception as e:
                logger.warning(f"âš ï¸ [æ¿å—å…±æŒ¯] è·å–å®æ—¶æ•°æ®å¤±è´¥: {e}")
            
            # è®¡ç®—ä¸Šæ¶¨æ¯”ä¾‹
            rise_ratio = rise_count / total_count if total_count > 0 else 0.0
            
            # ç¼“å­˜ç»“æœ
            self.cache.set(cache_key, rise_ratio, ttl=self.CACHE_TTL_SECTOR_PERFORMANCE)
            
            return rise_ratio
            
        except Exception as e:
            logger.error(f"âŒ [æ¿å—å…±æŒ¯] è®¡ç®—ä¸Šæ¶¨æ¯”ä¾‹å¤±è´¥: {industry}, {e}")
            return 0.0
    
    def check_sustained_capital_inflow(self, industry: str) -> bool:
        """
        æ£€æŸ¥æ¿å—æŒ‡æ•°è¿ç»­èµ„é‡‘å‡€æµå…¥

        ç­–ç•¥ï¼š
        1. è·å–æ¿å—æŒ‡æ•°çš„èµ„é‡‘æµæ•°æ®ï¼ˆè¿‡å»Nå¤©ï¼‰
        2. åˆ¤æ–­æ˜¯å¦è¿ç»­Næ—¥å‡€æµå…¥

        Args:
            industry: è¡Œä¸šåç§°

        Returns:
            bool: æ˜¯å¦è¿ç»­æµå…¥
        """
        try:
            # å°è¯•ä»ç¼“å­˜è·å–
            cache_key = f"sustained_inflow_{industry}"
            cached_data = self.cache.get(cache_key)
            if cached_data is not None:
                return cached_data

            # æ£€æŸ¥å…¨å±€ç¼“å­˜æ˜¯å¦è¿‡æœŸï¼ˆ10åˆ†é’Ÿï¼‰
            current_time = time.time()
            if (self._global_capital_flow_cache is None or
                current_time - self._global_capital_flow_timestamp > 600):

                # ä¸€æ¬¡æ€§è·å–æ‰€æœ‰è¡Œä¸šçš„èµ„é‡‘æµæ•°æ®
                try:
                    import akshare as ak
                    logger.debug("ğŸ”„ [æ¿å—å…±æŒ¯] æ›´æ–°å…¨å±€è¡Œä¸šèµ„é‡‘æµæ•°æ®...")
                    self._global_capital_flow_cache = ak.stock_fund_flow_industry(symbol='å³æ—¶')
                    self._global_capital_flow_timestamp = current_time
                    logger.debug("âœ… [æ¿å—å…±æŒ¯] å…¨å±€è¡Œä¸šèµ„é‡‘æµæ•°æ®æ›´æ–°å®Œæˆ")
                except Exception as e:
                    logger.warning(f"âš ï¸ [æ¿å—å…±æŒ¯] è·å–èµ„é‡‘æµæ•°æ®å¤±è´¥: {e}")
                    return False

            # ä»å…¨å±€ç¼“å­˜ä¸­æŸ¥æ‰¾å¯¹åº”è¡Œä¸š
            if self._global_capital_flow_cache is not None and not self._global_capital_flow_cache.empty:
                # æŸ¥æ‰¾å¯¹åº”è¡Œä¸šï¼ˆä½¿ç”¨'è¡Œä¸š'åˆ—ï¼‰
                industry_row = self._global_capital_flow_cache[
                    self._global_capital_flow_cache['è¡Œä¸š'] == industry
                ]

                if not industry_row.empty:
                    # æ£€æŸ¥ä»Šæ—¥æ˜¯å¦å‡€æµå…¥ï¼ˆä½¿ç”¨'å‡€é¢'åˆ—ï¼‰
                    net_inflow = industry_row['å‡€é¢'].values[0]

                    # ç®€åŒ–åˆ¤æ–­ï¼šä»Šæ—¥å‡€æµå…¥ > 0
                    sustained_inflow = net_inflow > 0

                    # ç¼“å­˜ç»“æœ
                    self.cache.set(cache_key, sustained_inflow, ttl=self.CACHE_TTL_CAPITAL_FLOW)

                    return sustained_inflow

            # é»˜è®¤è¿”å›False
            return False

        except Exception as e:
            logger.error(f"âŒ [æ¿å—å…±æŒ¯] æ£€æŸ¥æŒç»­æµå…¥å¤±è´¥: {industry}, {e}")
            return False
    
    def check_sector_resonance(self, stock_code: str) -> Dict:
        """
        æ£€æŸ¥æ¿å—å…±æŒ¯çŠ¶æ€
        
        æ ¸å¿ƒé€»è¾‘ï¼š
        - æ¡ä»¶A: æ¿å—å†…æ¶¨åœè‚¡ â‰¥ 3åª
        - æ¡ä»¶B: æ¿å—å†…ä¸Šæ¶¨è‚¡ç¥¨å æ¯” â‰¥ 35%
        - æ¡ä»¶C: æ¿å—æŒ‡æ•°è¿ç»­3æ—¥èµ„é‡‘å‡€æµå…¥
        - æ»¡è¶³è‡³å°‘2ä¸ªæ¡ä»¶æ‰è¿”å›True
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
        
        Returns:
            dict: {
                'is_resonance': bool,  # æ˜¯å¦å…±æŒ¯
                'limit_up_count': int,  # æ¶¨åœè‚¡æ•°
                'breadth': float,  # ä¸Šæ¶¨æ¯”ä¾‹ (0-1)
                'sustained_inflow': bool,  # æŒç»­æµå…¥
                'resonance_score': float,  # å…±æŒ¯åˆ†æ•° (0-1)
                'passed_conditions': list,  # é€šè¿‡çš„æ¡ä»¶åˆ—è¡¨
                'industry': str,  # è¡Œä¸šåç§°
                'details': dict  # è¯¦ç»†ä¿¡æ¯
            }
        """
        start_time = time.time()
        
        try:
            # 1. è·å–è‚¡ç¥¨æ‰€å±æ¿å—
            sector_info = self.get_stock_sector(stock_code)
            
            if not sector_info:
                logger.warning(f"âš ï¸ [æ¿å—å…±æŒ¯] æ— æ³•è·å–æ¿å—ä¿¡æ¯: {stock_code}")
                return {
                    'is_resonance': False,
                    'limit_up_count': 0,
                    'breadth': 0.0,
                    'sustained_inflow': False,
                    'resonance_score': 0.0,
                    'passed_conditions': [],
                    'industry': '',
                    'details': {'reason': 'æ— æ³•è·å–æ¿å—ä¿¡æ¯'}
                }
            
            industry = sector_info.get('industry', '')
            
            if not industry:
                logger.warning(f"âš ï¸ [æ¿å—å…±æŒ¯] æ— è¡Œä¸šä¿¡æ¯: {stock_code}")
                return {
                    'is_resonance': False,
                    'limit_up_count': 0,
                    'breadth': 0.0,
                    'sustained_inflow': False,
                    'resonance_score': 0.0,
                    'passed_conditions': [],
                    'industry': '',
                    'details': {'reason': 'æ— è¡Œä¸šä¿¡æ¯'}
                }
            
            # 2. æ£€æŸ¥ä¸‰ä¸ªæ¡ä»¶
            passed_conditions = []
            
            # æ¡ä»¶A: æ¶¨åœè‚¡æ•°
            limit_up_count = self.count_limit_up_stocks(industry)
            condition_a_passed = limit_up_count >= self.MIN_LIMIT_UP_COUNT
            if condition_a_passed:
                passed_conditions.append('A')
            
            # æ¡ä»¶B: ä¸Šæ¶¨æ¯”ä¾‹
            breadth = self.calculate_rise_breadth(industry)
            condition_b_passed = breadth >= self.MIN_RISE_RATIO
            if condition_b_passed:
                passed_conditions.append('B')
            
            # æ¡ä»¶C: æŒç»­æµå…¥
            sustained_inflow = self.check_sustained_capital_inflow(industry)
            condition_c_passed = sustained_inflow
            if condition_c_passed:
                passed_conditions.append('C')
            
            # 3. åˆ¤æ–­æ˜¯å¦å…±æŒ¯ï¼ˆæ»¡è¶³è‡³å°‘2ä¸ªæ¡ä»¶ï¼‰
            is_resonance = len(passed_conditions) >= 2
            
            # 4. è®¡ç®—å…±æŒ¯åˆ†æ•° (0-1)
            # åˆ†æ•° = (é€šè¿‡çš„æ¡ä»¶çš„æƒé‡å’Œ) / æ€»æƒé‡
            # æƒé‡: A=0.4, B=0.35, C=0.25
            weights = {'A': 0.4, 'B': 0.35, 'C': 0.25}
            score = sum(weights.get(c, 0) for c in passed_conditions)
            resonance_score = min(1.0, score)
            
            # 5. è®¡ç®—è€—æ—¶
            elapsed_time = (time.time() - start_time) * 1000  # æ¯«ç§’
            
            # 6. æ„å»ºç»“æœ
            result = {
                'is_resonance': is_resonance,
                'limit_up_count': limit_up_count,
                'breadth': breadth,
                'sustained_inflow': sustained_inflow,
                'resonance_score': resonance_score,
                'passed_conditions': passed_conditions,
                'industry': industry,
                'details': {
                    'condition_a': {
                        'name': 'æ¶¨åœè‚¡æ•°',
                        'threshold': self.MIN_LIMIT_UP_COUNT,
                        'value': limit_up_count,
                        'passed': condition_a_passed
                    },
                    'condition_b': {
                        'name': 'ä¸Šæ¶¨å æ¯”',
                        'threshold': self.MIN_RISE_RATIO,
                        'value': breadth,
                        'passed': condition_b_passed
                    },
                    'condition_c': {
                        'name': 'æŒç»­æµå…¥',
                        'threshold': self.SUSTAINED_INFLOW_DAYS,
                        'value': 'æ˜¯' if sustained_inflow else 'å¦',
                        'passed': condition_c_passed
                    },
                    'elapsed_time_ms': elapsed_time,
                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
            }
            
            # 7. æ—¥å¿—è®°å½•
            if is_resonance:
                logger.info(
                    f"âœ… [æ¿å—å…±æŒ¯] {stock_code} ({industry}) å…±æŒ¯ç¡®è®¤ "
                    f"[{','.join(passed_conditions)}] "
                    f"æ¶¨åœ={limit_up_count} ä¸Šæ¶¨={breadth*100:.1f}% "
                    f"åˆ†æ•°={resonance_score:.2f} "
                    f"è€—æ—¶={elapsed_time:.1f}ms"
                )
            else:
                logger.debug(
                    f"âš ï¸ [æ¿å—å…±æŒ¯] {stock_code} ({industry}) æœªå…±æŒ¯ "
                    f"[{','.join(passed_conditions) if passed_conditions else 'æ— '}] "
                    f"æ¶¨åœ={limit_up_count} ä¸Šæ¶¨={breadth*100:.1f}% "
                    f"åˆ†æ•°={resonance_score:.2f}"
                )
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ [æ¿å—å…±æŒ¯] æ£€æŸ¥å¤±è´¥: {stock_code}, {e}")
            return {
                'is_resonance': False,
                'limit_up_count': 0,
                'breadth': 0.0,
                'sustained_inflow': False,
                'resonance_score': 0.0,
                'passed_conditions': [],
                'industry': '',
                'details': {'reason': f'æ£€æŸ¥å¤±è´¥: {e}'}
            }
    
    def batch_check_resonance(self, stock_codes: List[str]) -> Dict[str, Dict]:
        """
        æ‰¹é‡æ£€æŸ¥æ¿å—å…±æŒ¯çŠ¶æ€
        
        Args:
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        
        Returns:
            dict: {stock_code: resonance_result}
        """
        results = {}
        
        for code in stock_codes:
            results[code] = self.check_sector_resonance(code)
        
        return results
    
    def get_cache_info(self) -> Dict:
        """
        è·å–ç¼“å­˜ä¿¡æ¯
        
        Returns:
            dict: ç¼“å­˜ç»Ÿè®¡
        """
        cache_info = self.cache.get_cache_info()
        
        # ç»Ÿè®¡æ¿å—ç›¸å…³çš„ç¼“å­˜
        sector_cache_keys = [
            k for k in cache_info.get('ç¼“å­˜é”®åˆ—è¡¨', [])
            if k.startswith('limit_up_count_') or 
               k.startswith('rise_breadth_') or 
               k.startswith('sustained_inflow_')
        ]
        
        return {
            'æ€»ç¼“å­˜æ•°': cache_info.get('ç¼“å­˜æ•°é‡', 0),
            'æ¿å—ç›¸å…³ç¼“å­˜æ•°': len(sector_cache_keys),
            'æ¿å—ç¼“å­˜é”®åˆ—è¡¨': sector_cache_keys
        }


# ==================== å…¨å±€å®ä¾‹ ====================

_wind_filter: Optional[WindFilter] = None


def get_wind_filter() -> WindFilter:
    """è·å–æ¿å—å…±æŒ¯è¿‡æ»¤å™¨å•ä¾‹"""
    global _wind_filter
    if _wind_filter is None:
        _wind_filter = WindFilter()
    return _wind_filter


# ==================== æµ‹è¯•ä»£ç  ====================

if __name__ == "__main__":
    # æµ‹è¯•æ¿å—å…±æŒ¯è¿‡æ»¤å™¨
    print("=" * 60)
    print("æ¿å—å…±æŒ¯è¿‡æ»¤å™¨æµ‹è¯•")
    print("=" * 60)
    
    wind_filter = get_wind_filter()
    
    # æµ‹è¯•è‚¡ç¥¨
    test_stocks = ['000001', '000002', '600519', '000858']
    
    print("\næµ‹è¯•è‚¡ç¥¨åˆ—è¡¨:", test_stocks)
    print("\nå¼€å§‹æ£€æŸ¥æ¿å—å…±æŒ¯çŠ¶æ€...\n")
    
    for code in test_stocks:
        result = wind_filter.check_sector_resonance(code)
        
        print(f"\nè‚¡ç¥¨: {code}")
        print(f"è¡Œä¸š: {result['industry']}")
        print(f"æ˜¯å¦å…±æŒ¯: {'âœ… æ˜¯' if result['is_resonance'] else 'âŒ å¦'}")
        print(f"å…±æŒ¯åˆ†æ•°: {result['resonance_score']:.2f}")
        print(f"é€šè¿‡æ¡ä»¶: {', '.join(result['passed_conditions']) if result['passed_conditions'] else 'æ— '}")
        print(f"æ¶¨åœè‚¡æ•°: {result['limit_up_count']}")
        print(f"ä¸Šæ¶¨å æ¯”: {result['breadth']*100:.1f}%")
        print(f"æŒç»­æµå…¥: {'æ˜¯' if result['sustained_inflow'] else 'å¦'}")
        print(f"è€—æ—¶: {result['details']['elapsed_time_ms']:.1f}ms")
    
    print("\n" + "=" * 60)
    print("ç¼“å­˜ä¿¡æ¯:")
    print("=" * 60)
    cache_info = wind_filter.get_cache_info()
    print(f"æ€»ç¼“å­˜æ•°: {cache_info['æ€»ç¼“å­˜æ•°']}")
    print(f"æ¿å—ç›¸å…³ç¼“å­˜æ•°: {cache_info['æ¿å—ç›¸å…³ç¼“å­˜æ•°']}")