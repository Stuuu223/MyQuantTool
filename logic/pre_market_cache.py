# -*- coding: utf-8 -*-
"""
ç›˜å‰æ•°æ®é¢„çƒ­ç¼“å­˜ç³»ç»Ÿ (PreMarketCache) - V19.5

åŠŸèƒ½ï¼š
- åœ¨ç›˜å‰ï¼ˆ9:15ä¹‹å‰ï¼‰ä¸€æ¬¡æ€§è®¡ç®—å…¨å¸‚åœºçš„å‡çº¿æ•°æ®
- ç›˜ä¸­ä¸å†è¯·æ±‚å†å²æ•°æ®ï¼Œç›´æ¥ä»ç¼“å­˜è¯»å–
- è§£å†³ IP è¢«å°ç¦å’Œç³»ç»Ÿå¡æ­»é—®é¢˜

æ¶æ„ï¼š
- ç›˜å‰ï¼šä¸€æ¬¡æ€§æ‹‰å–å…¨å¸‚åœºæ•°æ®ï¼Œè®¡ç®— MA4ã€MA5 ç­‰æŒ‡æ ‡
- ç›˜ä¸­ï¼šçº¯æ•°å­¦è®¡ç®—ï¼Œ0 ç½‘ç»œè¯·æ±‚
- å…¬å¼ï¼šRealtime_MA5 = (Pre_Market_MA4 * 4 + Current_Price) / 5

Author: iFlow CLI
Version: V19.5
"""

import os
import json
import akshare as ak
from datetime import datetime, time
from typing import Dict, Optional
from logic.utils.logger import get_logger

logger = get_logger(__name__)


class PreMarketCache:
    """
    ç›˜å‰æ•°æ®é¢„çƒ­ç¼“å­˜ç³»ç»Ÿ

    åŠŸèƒ½ï¼š
    - åœ¨ç›˜å‰ï¼ˆ9:15ä¹‹å‰ï¼‰ä¸€æ¬¡æ€§è®¡ç®—å…¨å¸‚åœºçš„å‡çº¿æ•°æ®
    - ç›˜ä¸­ä¸å†è¯·æ±‚å†å²æ•°æ®ï¼Œç›´æ¥ä»ç¼“å­˜è¯»å–
    - è§£å†³ IP è¢«å°ç¦å’Œç³»ç»Ÿå¡æ­»é—®é¢˜
    """

    CACHE_FILE = "data/pre_market_ma_cache.json"
    CACHE_VERSION = "V19.5"

    def __init__(self):
        self.cache = {}
        self._load_cache()

    def is_market_time(self) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åœ¨äº¤æ˜“æ—¶é—´

        Returns:
            bool: True è¡¨ç¤ºåœ¨äº¤æ˜“æ—¶é—´ï¼ˆ9:30-15:00ï¼‰
        """
        now = datetime.now().time()
        morning_start = time(9, 30)
        morning_end = time(11, 30)
        afternoon_start = time(13, 0)
        afternoon_end = time(15, 0)

        return (morning_start <= now <= morning_end) or (afternoon_start <= now <= afternoon_end)

    def should_refresh_cache(self) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦åˆ·æ–°ç¼“å­˜

        Returns:
            bool: True è¡¨ç¤ºéœ€è¦åˆ·æ–°
        """
        # å¦‚æœç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨ï¼Œéœ€è¦åˆ·æ–°
        if not os.path.exists(self.CACHE_FILE):
            return True

        # å¦‚æœæ˜¯äº¤æ˜“æ—¥æ—©ä¸Š9:15ä¹‹å‰ï¼Œéœ€è¦åˆ·æ–°
        now = datetime.now()
        current_time = now.time()
        weekday = now.weekday()

        # å‘¨æœ«ä¸åˆ·æ–°
        if weekday >= 5:  # å‘¨å…­ã€å‘¨æ—¥
            return False

        # äº¤æ˜“æ—¥æ—©ä¸Š9:15ä¹‹å‰åˆ·æ–°
        if current_time < time(9, 15):
            return True

        # æ£€æŸ¥ç¼“å­˜æ—¥æœŸ
        try:
            with open(self.CACHE_FILE, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
                cache_date = cache_data.get('cache_date', '')
                today_str = now.strftime('%Y-%m-%d')

                # å¦‚æœç¼“å­˜æ—¥æœŸä¸æ˜¯ä»Šå¤©ï¼Œéœ€è¦åˆ·æ–°
                if cache_date != today_str:
                    return True
        except Exception as e:
            logger.warning(f"æ£€æŸ¥ç¼“å­˜æ—¥æœŸå¤±è´¥: {e}")
            return True

        return False

    def run_daily_job(self) -> bool:
        """
        æ‰§è¡Œç›˜å‰æ•°æ®é¢„çƒ­ä»»åŠ¡

        Returns:
            bool: True è¡¨ç¤ºæˆåŠŸï¼ŒFalse è¡¨ç¤ºå¤±è´¥
        """
        if not self.should_refresh_cache():
            logger.info("âœ… ç¼“å­˜æ˜¯æœ€æ–°çš„ï¼Œæ— éœ€åˆ·æ–°")
            return True

        logger.info("â˜€ï¸ å¼€å§‹æ‰§è¡Œç›˜å‰æ•°æ®é¢„çƒ­...")
        start_time = datetime.now()

        try:
            # 1. ä¸€æ¬¡æ€§æ‹‰å–å…¨å¸‚åœºæ‰€æœ‰è‚¡ç¥¨çš„å®æ—¶æ•°æ®
            # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨çš„æ˜¯ ak.stock_zh_a_spot_em()ï¼Œå®ƒè¿”å›çš„æ˜¯å½“å‰è¡Œæƒ…
            # æˆ‘ä»¬éœ€è¦ä»ä¸­æå–æ˜¨æ”¶ä»·ï¼Œä½œä¸º MA5 çš„è¿‘ä¼¼åŸºå‡†
            logger.info("ğŸ“¡ æ­£åœ¨æ‹‰å–å…¨å¸‚åœºæ•°æ®...")
            df = ak.stock_zh_a_spot_em()

            if df is None or df.empty:
                logger.error("âŒ æ‹‰å–å…¨å¸‚åœºæ•°æ®å¤±è´¥")
                return False

            logger.info(f"âœ… æˆåŠŸæ‹‰å– {len(df)} åªè‚¡ç¥¨æ•°æ®")

            # 2. æ„å»ºç¼“å­˜æ•°æ®
            cache = {
                'cache_version': self.CACHE_VERSION,
                'cache_date': datetime.now().strftime('%Y-%m-%d'),
                'cache_time': datetime.now().strftime('%H:%M:%S'),
                'total_stocks': len(df),
                'stocks': {}
            }

            # 3. éå†æ‰€æœ‰è‚¡ç¥¨ï¼Œè®¡ç®—åŸºå‡†æ•°æ®
            for _, row in df.iterrows():
                code = row['ä»£ç ']
                name = row['åç§°']
                prev_close = row['æ˜¨æ”¶']  # æ˜¨æ”¶ä»·

                # ä½¿ç”¨æ˜¨æ”¶ä»·ä½œä¸º MA5 çš„è¿‘ä¼¼åŸºå‡†
                # å®é™…ä¸Šï¼Œæ˜¨æ”¶ä»· â‰ˆ æ˜¨æ—¥çš„æ”¶ç›˜ä»·
                # æˆ‘ä»¬ç”¨æ˜¨æ”¶ä»·ä½œä¸ºå‰4å¤©çš„å‡ä»·çš„è¿‘ä¼¼å€¼
                # è¿™æ ·ç›˜ä¸­è®¡ç®— MA5 æ—¶ï¼šMA5 = (æ˜¨æ”¶ * 4 + å½“å‰ä»·) / 5
                cache['stocks'][code] = {
                    'name': name,
                    'prev_close': float(prev_close),
                    'ma4_ref': float(prev_close),  # å‰4å¤©å‡ä»·çš„è¿‘ä¼¼å€¼
                    'ma5_ref': float(prev_close)   # MA5çš„è¿‘ä¼¼å€¼
                }

            # 4. å­˜å…¥æ–‡ä»¶
            os.makedirs("data", exist_ok=True)
            with open(self.CACHE_FILE, 'w', encoding='utf-8') as f:
                json.dump(cache, f, ensure_ascii=False, indent=2)

            elapsed = (datetime.now() - start_time).total_seconds()
            logger.info(f"âœ… ç›˜å‰ç¼“å­˜æ„å»ºå®Œæˆï¼š{len(cache['stocks'])} åªè‚¡ç¥¨ï¼Œè€—æ—¶ {elapsed:.2f} ç§’")

            # 5. åŠ è½½åˆ°å†…å­˜
            self._load_cache()

            return True

        except Exception as e:
            logger.error(f"âŒ ç›˜å‰æ•°æ®é¢„çƒ­å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

    def _load_cache(self):
        """ä»æ–‡ä»¶åŠ è½½ç¼“å­˜åˆ°å†…å­˜"""
        try:
            if os.path.exists(self.CACHE_FILE):
                with open(self.CACHE_FILE, 'r', encoding='utf-8') as f:
                    cache_data = json.load(f)
                    self.cache = cache_data.get('stocks', {})
                    cache_date = cache_data.get('cache_date', 'Unknown')
                    logger.info(f"âœ… æˆåŠŸåŠ è½½ç›˜å‰ç¼“å­˜ï¼š{len(self.cache)} åªè‚¡ç¥¨ï¼ˆæ—¥æœŸï¼š{cache_date}ï¼‰")
            else:
                logger.warning("âš ï¸ ç›˜å‰ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨")
                self.cache = {}
        except Exception as e:
            logger.error(f"âŒ åŠ è½½ç›˜å‰ç¼“å­˜å¤±è´¥: {e}")
            self.cache = {}

    def get_stock_data(self, stock_code: str) -> Optional[Dict]:
        """
        è·å–å•åªè‚¡ç¥¨çš„ç›˜å‰ç¼“å­˜æ•°æ®

        Args:
            stock_code: è‚¡ç¥¨ä»£ç 

        Returns:
            dict: åŒ…å« prev_close, ma4_ref, ma5_ref ç­‰æ•°æ®ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› None
        """
        return self.cache.get(stock_code)

    def calculate_realtime_ma5(self, stock_code: str, current_price: float) -> Optional[float]:
        """
        å®æ—¶è®¡ç®— MA5ï¼ˆä½¿ç”¨ç›˜å‰ç¼“å­˜ï¼‰

        å…¬å¼ï¼šRealtime_MA5 = (Pre_Market_MA4 * 4 + Current_Price) / 5

        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            current_price: å½“å‰ä»·æ ¼

        Returns:
            float: å®æ—¶ MA5ï¼Œå¦‚æœç¼“å­˜ä¸å­˜åœ¨åˆ™è¿”å› None
        """
        stock_data = self.get_stock_data(stock_code)

        if not stock_data:
            return None

        ma4_ref = stock_data.get('ma4_ref', 0)

        if ma4_ref == 0:
            return None

        # è®¡ç®— MA5
        realtime_ma5 = (ma4_ref * 4 + current_price) / 5

        return realtime_ma5

    def calculate_ma_bias(self, stock_code: str, current_price: float) -> Optional[float]:
        """
        è®¡ç®—ä¹–ç¦»ç‡ï¼ˆä½¿ç”¨ç›˜å‰ç¼“å­˜ï¼‰

        å…¬å¼ï¼šBias = (Current_Price - MA5) / MA5 * 100

        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            current_price: å½“å‰ä»·æ ¼

        Returns:
            float: ä¹–ç¦»ç‡ï¼ˆ%ï¼‰ï¼Œå¦‚æœç¼“å­˜ä¸å­˜åœ¨åˆ™è¿”å› None
        """
        ma5 = self.calculate_realtime_ma5(stock_code, current_price)

        if ma5 is None or ma5 == 0:
            return None

        bias = (current_price - ma5) / ma5 * 100

        return round(bias, 2)

    def get_cache_info(self) -> Dict:
        """
        è·å–ç¼“å­˜ä¿¡æ¯

        Returns:
            dict: åŒ…å«ç¼“å­˜ç‰ˆæœ¬ã€æ—¥æœŸã€è‚¡ç¥¨æ•°é‡ç­‰ä¿¡æ¯
        """
        try:
            if os.path.exists(self.CACHE_FILE):
                with open(self.CACHE_FILE, 'r', encoding='utf-8') as f:
                    cache_data = json.load(f)
                    return {
                        'cache_version': cache_data.get('cache_version', 'Unknown'),
                        'cache_date': cache_data.get('cache_date', 'Unknown'),
                        'cache_time': cache_data.get('cache_time', 'Unknown'),
                        'total_stocks': cache_data.get('total_stocks', 0),
                        'is_loaded': len(self.cache) > 0
                    }
        except Exception as e:
            logger.error(f"âŒ è·å–ç¼“å­˜ä¿¡æ¯å¤±è´¥: {e}")

        return {
            'cache_version': 'Unknown',
            'cache_date': 'Unknown',
            'cache_time': 'Unknown',
            'total_stocks': 0,
            'is_loaded': False
        }


# å…¨å±€å•ä¾‹
_pre_market_cache_instance = None


def get_pre_market_cache() -> PreMarketCache:
    """
    è·å–ç›˜å‰ç¼“å­˜å•ä¾‹

    Returns:
        PreMarketCache: ç›˜å‰ç¼“å­˜å®ä¾‹
    """
    global _pre_market_cache_instance

    if _pre_market_cache_instance is None:
        _pre_market_cache_instance = PreMarketCache()

    return _pre_market_cache_instance