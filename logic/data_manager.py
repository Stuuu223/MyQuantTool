import akshare as ak
try:
    import easyquotation
except ImportError:
    easyquotation = None
import pandas as pd
import sqlite3
import os
from datetime import datetime, timedelta
from typing import Optional, Dict, Any
from logic.logger import get_logger
from logic.error_handler import handle_errors, DataError, NetworkError, ValidationError

logger = get_logger(__name__)

class DataManager:
    _instance = None
    _initialized = False
    
    def __new__(cls, db_path: str = 'data/stock_data.db'):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self, db_path: str = 'data/stock_data.db') -> None:
        # é¿å…é‡å¤åˆå§‹åŒ–
        if DataManager._initialized:
            return
        
        logger.info(f"åˆå§‹åŒ– DataManagerï¼Œæ•°æ®åº“è·¯å¾„: {db_path}")
        os.makedirs(os.path.dirname(db_path), exist_ok=True)
        
        # ä½¿ç”¨ WAL æ¨¡å¼æå‡å¹¶å‘æ€§èƒ½
        self.conn = sqlite3.connect(db_path, check_same_thread=False, timeout=30.0)
        self.conn.execute('PRAGMA journal_mode=WAL')
        self.conn.execute('PRAGMA synchronous=NORMAL')
        self.conn.execute('PRAGMA cache_size=-64000')  # 64MB ç¼“å­˜
        
        # å»¶è¿Ÿåˆå§‹åŒ–æ•°æ®åº“ç»“æ„ï¼ˆé¦–æ¬¡ä½¿ç”¨æ—¶æ‰åˆå§‹åŒ–ï¼‰
        self._db_initialized = False
        self._db_path = db_path
        
        # å®æ—¶æ•°æ®ç¼“å­˜ï¼š{symbol: {'data': {...}, 'timestamp': datetime}}
        self.realtime_cache: Dict[str, Dict[str, Any]] = {}
        self.cache_expire_seconds: int = 60  # ç¼“å­˜60ç§’
        
        # ğŸ†• V9.9 æ–°å¢ï¼šKçº¿ç£ç›˜ç¼“å­˜ï¼ˆæ‡’åŠ è½½ï¼‰
        self.kline_cache_dir = "data/kline_cache"
        os.makedirs(self.kline_cache_dir, exist_ok=True)
        self.kline_cache_expire_hours: int = 2  # Kçº¿ç¼“å­˜2å°æ—¶
        
        # ğŸ”¥ğŸ”¥ğŸ”¥ æ¿€æ´» Easyquotation æé€Ÿè¡Œæƒ…å¼•æ“ ğŸ”¥ğŸ”¥ğŸ”¥
        if easyquotation is not None:
            try:
                logger.info("æ­£åœ¨å¯åŠ¨æé€Ÿè¡Œæƒ…å¼•æ“ Easyquotation...")
                # ä½¿ç”¨æ–°æµªæ¥å£ï¼ˆæœ€å¿«ï¼Œå¸¦ä¹°ä¸€å–ä¸€é‡ï¼‰
                self.quotation = easyquotation.use('sina')
                logger.info("âœ… Easyquotation å¯åŠ¨æˆåŠŸï¼")
            except Exception as e:
                logger.warning(f"âŒ Easyquotation å¯åŠ¨å¤±è´¥: {e}ï¼Œå°†å›é€€åˆ° Akshare")
                self.quotation = None
        else:
            logger.warning("âŒ Easyquotation æœªå®‰è£…ï¼Œå°†ä½¿ç”¨ Akshare")
            self.quotation = None
        
        # ğŸ†• V9.2 æ–°å¢ï¼šç«ä»·å¿«ç…§ç®¡ç†å™¨
        self.auction_snapshot_manager = None
        try:
            from logic.auction_snapshot_manager import AuctionSnapshotManager
            self.auction_snapshot_manager = AuctionSnapshotManager(self)
            logger.info("âœ… ç«ä»·å¿«ç…§ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸ ç«ä»·å¿«ç…§ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # ğŸ†• V9.3.7 æ–°å¢ï¼šé™æ€æ•°æ®ç¼“å­˜ï¼ˆè¡Œä¸šä¿¡æ¯ï¼‰
        self.static_cache_file = "data/industry_cache.json"
        self.industry_cache = {}
        self._load_industry_cache()
        
        DataManager._initialized = True
        logger.info("DataManager åˆå§‹åŒ–å®Œæˆ")
    
    def _ensure_connection_open(self):
        """ç¡®ä¿æ•°æ®åº“è¿æ¥æ˜¯æ‰“å¼€çš„ï¼Œå¦‚æœå·²å…³é—­åˆ™é‡æ–°è¿æ¥"""
        try:
            # å°è¯•æ‰§è¡Œä¸€ä¸ªç®€å•çš„æŸ¥è¯¢æ¥æµ‹è¯•è¿æ¥
            self.conn.execute("SELECT 1")
        except sqlite3.ProgrammingError:
            # è¿æ¥å·²å…³é—­ï¼Œé‡æ–°è¿æ¥
            logger.warning("æ•°æ®åº“è¿æ¥å·²å…³é—­ï¼Œæ­£åœ¨é‡æ–°è¿æ¥...")
            self.conn = sqlite3.connect(self._db_path, check_same_thread=False, timeout=30.0)
            self.conn.execute('PRAGMA journal_mode=WAL')
            self.conn.execute('PRAGMA synchronous=NORMAL')
            self.conn.execute('PRAGMA cache_size=-64000')
            logger.info("æ•°æ®åº“è¿æ¥å·²é‡æ–°å»ºç«‹")

    def _ensure_db_initialized(self):
        """ç¡®ä¿æ•°æ®åº“å·²åˆå§‹åŒ–ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰"""
        self._ensure_connection_open()
        if not self._db_initialized:
            self.init_db()
            self.update_db_schema()
            self._db_initialized = True

    def init_db(self) -> None:
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„
        
        åˆ›å»º daily_bars è¡¨ï¼Œå¦‚æœä¸å­˜åœ¨çš„è¯ã€‚
        è¡¨ç»“æ„åŒ…å«ï¼šsymbol, date, open, high, low, close, volume, turnover_rate
        åŒæ—¶åˆ›å»ºç´¢å¼•ä»¥ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½ã€‚
        """
        query = '''
        CREATE TABLE IF NOT EXISTS daily_bars (
            symbol TEXT,
            date TEXT,
            open REAL,
            high REAL,
            low REAL,
            close REAL,
            volume REAL,
            turnover_rate REAL,
            PRIMARY KEY (symbol, date)
        )
        '''
        self.conn.execute(query)
        
        # åˆ›å»ºç´¢å¼•ä»¥ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½
        try:
            self.conn.execute('CREATE INDEX IF NOT EXISTS idx_symbol_date ON daily_bars(symbol, date)')
            self.conn.commit()
            logger.info("æ•°æ®åº“ç´¢å¼•åˆ›å»ºæˆåŠŸ")
        except Exception as e:
            logger.warning(f"æ•°æ®åº“ç´¢å¼•åˆ›å»ºå¤±è´¥: {e}")
        query = '''
        CREATE TABLE IF NOT EXISTS daily_bars (
            symbol TEXT,
            date TEXT,
            open REAL,
            high REAL,
            low REAL,
            close REAL,
            volume REAL,
            turnover_rate REAL,
            PRIMARY KEY (symbol, date)
        )
        '''
        self.conn.execute(query)
        self.conn.commit()
    
    def update_db_schema(self) -> None:
        """æ›´æ–°æ•°æ®åº“è¡¨ç»“æ„ï¼Œæ·»åŠ æ¢æ‰‹ç‡åˆ—
        
        æ£€æŸ¥ daily_bars è¡¨æ˜¯å¦æœ‰ turnover_rate åˆ—ï¼Œå¦‚æœæ²¡æœ‰åˆ™æ·»åŠ ã€‚
        """
        try:
            # æ£€æŸ¥è¡¨æ˜¯å¦æœ‰ turnover_rate åˆ—
            cursor = self.conn.execute("PRAGMA table_info(daily_bars)")
            columns = [column[1] for column in cursor.fetchall()]
            
            if 'turnover_rate' not in columns:
                # æ·»åŠ  turnover_rate åˆ—
                self.conn.execute("ALTER TABLE daily_bars ADD COLUMN turnover_rate REAL")
                self.conn.commit()
                print("æ•°æ®åº“è¡¨ç»“æ„å·²æ›´æ–°ï¼Œæ·»åŠ äº† turnover_rate åˆ—")
        except Exception as e:
            print(f"æ›´æ–°æ•°æ®åº“è¡¨ç»“æ„å¤±è´¥: {e}")

    def _get_kline_cache_path(self, symbol: str) -> str:
        """ğŸ†• V9.9ï¼šè·å–Kçº¿ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        return os.path.join(self.kline_cache_dir, f"{symbol}_kline.pkl")
    
    def _get_kline_cache_ttl(self) -> int:
        """
        ğŸ†• V9.10.1 ä¼˜åŒ–ï¼šæ ¹æ®äº¤æ˜“æ—¶æ®µåŠ¨æ€è·å–ç¼“å­˜TTL
        
        é˜²æ­¢"æ—¶æ•ˆæ€§é™·é˜±"å’Œ"åˆä¼‘æµªè´¹"ï¼š
        - é›†åˆç«ä»· (09:15-09:30)ï¼šåªç¼“å­˜10ç§’ï¼Œæ•°æ®å˜åŒ–æå¿«
        - äº¤æ˜“æ—¶é—´ (09:30-11:30, 13:00-15:00)ï¼šåªç¼“å­˜1åˆ†é’Ÿï¼Œä¿è¯æ•°æ®é²œåº¦
        - åˆé—´ä¼‘ç›˜ (11:30-13:00)ï¼šç¼“å­˜1å°æ—¶ï¼Œæ•°æ®é™æ­¢ï¼Œæ— éœ€åˆ·æ–°
        - ç›˜å (15:00-æ¬¡æ—¥9:00)ï¼šç¼“å­˜2å°æ—¶ï¼Œç”¨äºå¤ç›˜
        
        Returns:
            ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆç§’ï¼‰
        """
        try:
            from logic.market_status import get_market_status_checker
            market_checker = get_market_status_checker()
            
            current_time = market_checker.get_current_time()
            
            # 1. é›†åˆç«ä»·æœŸé—´ï¼ˆ09:15-09:30ï¼‰ï¼šæ•°æ®å˜åŒ–æå¿«ï¼Œ10ç§’åˆ·æ–°
            if market_checker.MORNING_START <= current_time < time(9, 30):
                return 10  # 10ç§’
            
            # 2. â˜•ï¸ åˆé—´ä¼‘ç›˜ï¼ˆ11:30-13:00ï¼‰ï¼šæ•°æ®é™æ­¢ï¼Œç¼“å­˜1å°æ—¶
            elif market_checker.is_noon_break(current_time):
                return 3600  # 1å°æ—¶
            
            # 3. äº¤æ˜“æ—¶é—´ï¼šåªç¼“å­˜1åˆ†é’Ÿ
            elif market_checker.is_trading_time():
                return 60  # 1åˆ†é’Ÿ
            
            # 4. ç›˜ååŠä¼‘å¸‚ï¼šç¼“å­˜2å°æ—¶
            else:
                return self.kline_cache_expire_hours * 3600  # 2å°æ—¶
        except Exception as e:
            logger.warning(f"è·å–åŠ¨æ€TTLå¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            return self.kline_cache_expire_hours * 3600
    
    def _save_kline_to_cache(self, symbol: str, kline_data: pd.DataFrame) -> None:
        """ğŸ†• V9.9ï¼šä¿å­˜Kçº¿æ•°æ®åˆ°ç£ç›˜ç¼“å­˜"""
        try:
            cache_path = self._get_kline_cache_path(symbol)
            cache_info = {
                'kline': kline_data,
                'timestamp': datetime.now().isoformat()
            }
            
            import pickle
            with open(cache_path, 'wb') as f:
                pickle.dump(cache_info, f)
            
            logger.debug(f"âœ… Kçº¿æ•°æ®å·²ç¼“å­˜: {symbol}")
        except Exception as e:
            logger.warning(f"Kçº¿ç¼“å­˜ä¿å­˜å¤±è´¥ {symbol}: {e}")
    
    def _load_kline_from_cache(self, symbol: str) -> Optional[pd.DataFrame]:
        """ğŸ†• V9.9ï¼šä»ç£ç›˜ç¼“å­˜åŠ è½½Kçº¿æ•°æ®"""
        try:
            cache_path = self._get_kline_cache_path(symbol)
            
            if not os.path.exists(cache_path):
                return None
            
            import pickle
            with open(cache_path, 'rb') as f:
                cache_info = pickle.load(f)
            
            # ğŸ†• V9.10 ä¿®å¤ï¼šä½¿ç”¨åŠ¨æ€TTLæ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
            cache_time = datetime.fromisoformat(cache_info['timestamp'])
            cache_age = (datetime.now() - cache_time).total_seconds()
            
            # è·å–åŠ¨æ€TTLï¼ˆç›˜ä¸­1åˆ†é’Ÿï¼Œç›˜å2å°æ—¶ï¼‰
            cache_ttl = self._get_kline_cache_ttl()
            
            if cache_age > cache_ttl:
                logger.debug(f"âš ï¸ Kçº¿ç¼“å­˜å·²è¿‡æœŸ: {symbol}")
                return None
            
            logger.debug(f"âœ… ä»ç¼“å­˜åŠ è½½Kçº¿: {symbol} (ç¼“å­˜æ—¶é—´: {cache_info['timestamp']})")
            return cache_info['kline']
        except Exception as e:
            logger.warning(f"Kçº¿ç¼“å­˜åŠ è½½å¤±è´¥ {symbol}: {e}")
            return None
    
    def _is_kline_cache_valid(self, symbol: str) -> bool:
        """ğŸ†• V9.9ï¼šæ£€æŸ¥Kçº¿ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        cache_path = self._get_kline_cache_path(symbol)
        
        if not os.path.exists(cache_path):
            return False
        
        try:
            import pickle
            with open(cache_path, 'rb') as f:
                cache_info = pickle.load(f)
            
            cache_time = datetime.fromisoformat(cache_info['timestamp'])
            cache_age = (datetime.now() - cache_time).total_seconds()
            
            # ğŸ†• V9.10 ä¿®å¤ï¼šä½¿ç”¨åŠ¨æ€TTL
            cache_ttl = self._get_kline_cache_ttl()
            
            return cache_age <= cache_ttl
        except Exception as e:
            return False
    
    @handle_errors(show_user_message=False)
    def get_history_data(self, symbol: str, start_date: str = "20240101", end_date: str = "20251231") -> pd.DataFrame:
        """è·å–è‚¡ç¥¨å†å²æ•°æ®

        ä»æœ¬åœ°æ•°æ®åº“è·å–å†å²æ•°æ®ï¼Œå¦‚æœç¼“å­˜æœªå‘½ä¸­åˆ™ä» akshare è·å–å¹¶ç¼“å­˜ã€‚
        ä½¿ç”¨å†…å­˜ç¼“å­˜åŠ é€Ÿé‡å¤æŸ¥è¯¢ã€‚

        Args:
            symbol: è‚¡ç¥¨ä»£ç ï¼ˆ6ä½æ•°å­—ï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ YYYYMMDDï¼Œé»˜è®¤ 20240101
            end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ YYYYMMDDï¼Œé»˜è®¤ 20251231

        Returns:
            åŒ…å«å†å²æ•°æ®çš„ DataFrameï¼ŒåŒ…å«åˆ—ï¼šsymbol, date, open, high, low, close, volume, turnover_rate

        Raises:
            ValidationError: è‚¡ç¥¨ä»£ç æ ¼å¼é”™è¯¯
            DataError: è·å–æ•°æ®å¤±è´¥

        Example:
            >>> db = DataManager()
            >>> df = db.get_history_data('600519', '20240101', '20241231')
            >>> print(df.head())
        """
        try:
            # ğŸš€ å…ˆæ£€æŸ¥å†…å­˜ç¼“å­˜
            from logic.history_cache import get_history_cache
            cache = get_history_cache()
            cached_df = cache.get(symbol)
            if cached_df is not None and not cached_df.empty:
                return cached_df

            # å»¶è¿Ÿåˆå§‹åŒ–æ•°æ®åº“
            self._ensure_db_initialized()
            # éªŒè¯è‚¡ç¥¨ä»£ç 
            if not symbol or len(symbol) != 6:
                raise ValidationError(f"è‚¡ç¥¨ä»£ç æ ¼å¼é”™è¯¯: {symbol}")

            df = pd.read_sql(f"SELECT * FROM daily_bars WHERE symbol='{symbol}'", self.conn)

            # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°è·å–æ•°æ®
            need_fetch = False
            if df.empty or len(df) < 5:
                need_fetch = True
            elif 'turnover_rate' not in df.columns:
                need_fetch = True
            elif df['turnover_rate'].isna().all():
                need_fetch = True

            if need_fetch:
                logger.info(f"æœ¬åœ°ç¼“å­˜æœªå‘½ä¸­ï¼Œæ­£åœ¨ä¸‹è½½ {symbol} ...")
                df_api = ak.stock_zh_a_hist(symbol=symbol, period="daily", start_date=start_date, end_date=end_date, adjust="qfq")

                if df_api.empty:
                    raise DataError(f"è·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {symbol}")

                df_api = df_api.rename(columns={
                    'æ—¥æœŸ': 'date', 'å¼€ç›˜': 'open', 'æœ€é«˜': 'high',
                    'æœ€ä½': 'low', 'æ”¶ç›˜': 'close', 'æˆäº¤é‡': 'volume', 'æ¢æ‰‹ç‡': 'turnover_rate'
                })
                df_api['symbol'] = symbol

                # åˆ é™¤æ—§æ•°æ®
                self.conn.execute(f"DELETE FROM daily_bars WHERE symbol='{symbol}'")
                self.conn.commit()

                # æ’å…¥æ–°æ•°æ®
                cols = ['symbol', 'date', 'open', 'high', 'low', 'close', 'volume', 'turnover_rate']
                df_api[cols].to_sql('daily_bars', self.conn, if_exists='append', index=False)
                df = df_api

            # ğŸš€ å­˜å…¥å†…å­˜ç¼“å­˜
            if not df.empty:
                cache.set(symbol, df)

            return df
        except Exception as e:
            logger.error(f"æ•°æ®è·å–å¼‚å¸¸: {e}", exc_info=True)
            return pd.DataFrame()

    def get_multiple_stocks(self, symbols: list) -> Dict[str, pd.DataFrame]:
        """æ‰¹é‡è·å–å¤šåªè‚¡ç¥¨æ•°æ®
        
        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            
        Returns:
            è‚¡ç¥¨ä»£ç åˆ° DataFrame çš„å­—å…¸
        """
        try:
            if not symbols:
                return {}
            
            symbols_str = "','".join(symbols)
            query = f"SELECT * FROM daily_bars WHERE symbol IN ('{symbols_str}') ORDER BY symbol, date"
            df = pd.read_sql(query, self.conn)
            
            if df.empty:
                return {}
            
            # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„
            result = {}
            for symbol in symbols:
                symbol_df = df[df['symbol'] == symbol].copy()
                if not symbol_df.empty:
                    result[symbol] = symbol_df
            
            return result
        except Exception as e:
            logger.error(f"æ‰¹é‡è·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {e}", exc_info=True)
            return {}

    def get_realtime_data(self, symbol: str) -> Optional[Dict[str, Any]]:
        """è·å–å®æ—¶è¡Œæƒ…æ•°æ®ï¼ˆä½¿ç”¨1åˆ†é’ŸKçº¿ï¼Œå¸¦60ç§’ç¼“å­˜ï¼‰
        
        æ ¹æ®å½“å‰æ—¶é—´è‡ªåŠ¨é€‰æ‹©æ•°æ®æºï¼š
        - äº¤æ˜“æ—¶é—´å†…ï¼ˆ9:30-11:30, 13:00-15:00ï¼‰ï¼šä½¿ç”¨1åˆ†é’ŸKçº¿æ•°æ®
        - éäº¤æ˜“æ—¶é—´ï¼šä½¿ç”¨æ—¥çº¿æ•°æ®
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç ï¼ˆ6ä½æ•°å­—ï¼‰
            
        Returns:
            å®æ—¶æ•°æ®å­—å…¸ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
            - symbol: è‚¡ç¥¨ä»£ç 
            - price: æœ€æ–°ä»·æ ¼
            - change_percent: æ¶¨è·Œå¹…ï¼ˆç™¾åˆ†æ¯”ï¼‰
            - volume: æˆäº¤é‡
            - turnover_rate: æ¢æ‰‹ç‡
            - high: æœ€é«˜ä»·
            - low: æœ€ä½ä»·
            - open: å¼€ç›˜ä»·
            - pre_close: æ˜¨æ”¶ä»·
            - timestamp: æ•°æ®æ—¶é—´æˆ³
            
            å¤±è´¥è¿”å› None
            
        Note:
            æ•°æ®ç¼“å­˜60ç§’ï¼Œ60ç§’å†…é‡å¤æŸ¥è¯¢ä¼šè¿”å›ç¼“å­˜æ•°æ®
        """
        try:
            # å»¶è¿Ÿåˆå§‹åŒ–æ•°æ®åº“
            self._ensure_db_initialized()
            
            import time

            # æ£€æŸ¥ç¼“å­˜
            if symbol in self.realtime_cache:
                cache_data = self.realtime_cache[symbol]
                # ğŸ†• V9.9 ä¿®å¤ï¼šç¡®ä¿datetimeå¯¹è±¡æ—¶åŒºä¸€è‡´
                from logic.market_status import get_market_status_checker
                market_checker = get_market_status_checker()
                now = datetime.now(market_checker.timezone)
                cache_timestamp = cache_data['timestamp']
                
                # å¦‚æœç¼“å­˜æ—¶é—´æˆ³æ˜¯æ—¶åŒºæ— å…³çš„ï¼Œè½¬æ¢ä¸ºæ—¶åŒºæ„ŸçŸ¥çš„
                if cache_timestamp.tzinfo is None:
                    cache_timestamp = cache_timestamp.replace(tzinfo=market_checker.timezone)
                
                cache_age = (now - cache_timestamp).total_seconds()
                if cache_age < self.cache_expire_seconds:
                    print(f"[CACHE] ä½¿ç”¨ç¼“å­˜æ•°æ® (å‰©ä½™æœ‰æ•ˆæ—¶é—´: {self.cache_expire_seconds - cache_age:.1f}ç§’)")
                    return cache_data['data']

            # ğŸ†• V9.6 ä¼˜åŒ–ï¼šä¼˜å…ˆä½¿ç”¨ Easyquotation æé€Ÿè¡Œæƒ…å¼•æ“
            if self.quotation:
                try:
                    # è½¬æ¢ä»£ç æ ¼å¼ (easyquotation éœ€è¦ sh/sz å‰ç¼€)
                    if symbol.startswith('6'):
                        prefix = 'sh'
                    elif symbol.startswith('8') or symbol.startswith('4'):
                        prefix = 'bj'
                    else:
                        prefix = 'sz'
                    
                    full_code = f"{prefix}{symbol}"
                    
                    # ğŸ†• V9.8 ä¿®å¤ï¼šæ·»åŠ è¶…æ—¶æœºåˆ¶ï¼Œé¿å… Easyquotation å¡æ­»
                    import signal
                    import threading
                    
                    result_container = {'data': None, 'error': None}
                    
                    def fetch_with_timeout():
                        try:
                            result_container['data'] = self.quotation.stocks([full_code])
                        except Exception as e:
                            result_container['error'] = e
                    
                    # åˆ›å»ºè¶…æ—¶çº¿ç¨‹ï¼ˆ3ç§’è¶…æ—¶ï¼‰
                    fetch_thread = threading.Thread(target=fetch_with_timeout)
                    fetch_thread.daemon = True
                    fetch_thread.start()
                    fetch_thread.join(timeout=3.0)  # 3ç§’è¶…æ—¶
                    
                    if fetch_thread.is_alive():
                        # è¶…æ—¶ï¼Œæ”¾å¼ƒè¿™åªè‚¡ç¥¨
                        logger.warning(f"âš ï¸ Easyquotation è¶…æ—¶ {symbol}ï¼ˆ3ç§’ï¼‰ï¼Œè·³è¿‡")
                        batch_result = None
                    elif result_container['error']:
                        # å‘ç”Ÿé”™è¯¯
                        raise result_container['error']
                    else:
                        batch_result = result_container['data']
                    
                    start_time = time.time()
                    elapsed = time.time() - start_time
                    
                    if batch_result and full_code in batch_result:
                        stock_data = batch_result[full_code]
                        
                        # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
                        result = {
                            'symbol': symbol,
                            'price': float(stock_data.get('now', 0)),
                            'change_percent': round((float(stock_data.get('now', 0)) - float(stock_data.get('close', 0))) / float(stock_data.get('close', 1)) * 100, 2) if stock_data.get('close', 0) != 0 else 0.0,
                            'volume': float(stock_data.get('volume', 0)) / 100,  # è½¬æ¢ä¸ºæ‰‹
                            'turnover_rate': 0.0,
                            'high': float(stock_data.get('high', 0)),
                            'low': float(stock_data.get('low', 0)),
                            'open': float(stock_data.get('open', 0)),
                            'pre_close': float(stock_data.get('close', 0)),
                            'timestamp': stock_data.get('time', datetime.now().strftime('%H:%M:%S')),
                            'is_trading': True,
                            # ğŸ†• V9.9 æ–°å¢ï¼šæ•°æ®ä¸€è‡´æ€§æ ¡éªŒå­—æ®µ
                            'data_timestamp': stock_data.get('time', datetime.now().strftime('%H:%M:%S')),  # å¿«ç…§æ—¶é—´
                            'fetch_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),  # æ•°æ®è·å–æ—¶é—´
                            'data_age_seconds': 0  # æ•°æ®æ–°é²œåº¦ï¼ˆç§’ï¼‰
                        }
                        
                        # å­˜å…¥ç¼“å­˜
                        self.realtime_cache[symbol] = {
                            'data': result,
                            'timestamp': datetime.now()
                        }
                        
                        logger.info(f"âœ… Easyquotation è·å–æˆåŠŸ: {symbol} (è€—æ—¶: {elapsed:.3f}ç§’)")
                        return result
                except Exception as e:
                    logger.warning(f"Easyquotation è·å–å¤±è´¥ {symbol}: {e}ï¼Œå›é€€åˆ° Akshare")

            # ğŸ†• V9.6: ä½¿ç”¨æ ‡å‡†åŒ–çš„å¸‚åœºçŠ¶æ€åˆ¤æ–­é€»è¾‘ï¼ˆæ”¯æŒæ—¶åŒºï¼‰
            from logic.market_status import get_market_status_checker
            market_checker = get_market_status_checker()
            is_trading_time = market_checker.is_trading_time()
            is_weekday = market_checker.is_weekday()
            now = datetime.now(market_checker.timezone)

            start_time = time.time()

            if is_trading_time and is_weekday:
                # äº¤æ˜“æ—¶é—´å†…ï¼Œä½¿ç”¨1åˆ†é’ŸKçº¿
                # ğŸ†• V9.9 æ–°å¢ï¼šå…ˆæ£€æŸ¥ç£ç›˜ç¼“å­˜ï¼ˆæ‡’åŠ è½½ï¼‰
                cached_kline = self._load_kline_from_cache(symbol)
                if cached_kline is not None and not cached_kline.empty:
                    logger.info(f"âœ… ä½¿ç”¨ç¼“å­˜çš„1åˆ†é’ŸKçº¿æ•°æ®: {symbol}")
                    df = cached_kline
                    # ç»§ç»­å¤„ç†ç¼“å­˜æ•°æ®...
                else:
                    # ç¼“å­˜æœªå‘½ä¸­ï¼Œä»ç½‘ç»œè·å–
                    logger.info(f"æ­£åœ¨è·å–1åˆ†é’ŸKçº¿æ•°æ®: {symbol}...")
                    end_date = now.strftime("%Y-%m-%d %H:%M:%S")
                    start_date = (now - timedelta(days=3)).strftime("%Y-%m-%d %H:%M:%S")

                    df = ak.stock_zh_a_hist_min_em(symbol=symbol, period="1", start_date=start_date, end_date=end_date, adjust="qfq")
                    elapsed = time.time() - start_time
                    logger.info(f"1åˆ†é’ŸKçº¿æ•°æ®è·å–è€—æ—¶: {elapsed:.2f}ç§’")
                    
                    # ğŸ†• V9.9 æ–°å¢ï¼šä¿å­˜åˆ°ç£ç›˜ç¼“å­˜
                    if not df.empty:
                        self._save_kline_to_cache(symbol, df)

                if not df.empty:
                    # å–æœ€åä¸€æ ¹Kçº¿ï¼ˆæœ€æ–°çš„æ•°æ®ï¼‰
                    latest = df.iloc[-1]

                    # è·å–å½“æ—¥å¼€ç›˜ä»·ï¼ˆæ‰¾åˆ°9:30-9:31çš„Kçº¿ï¼‰
                    df['æ—¶é—´'] = pd.to_datetime(df['æ—¶é—´'])
                    today_open_df = df[df['æ—¶é—´'].dt.time <= datetime.strptime("09:31", "%H:%M").time()]
                    if not today_open_df.empty:
                        day_open = today_open_df.iloc[0]['å¼€ç›˜']
                    else:
                        day_open = latest['å¼€ç›˜']

                    # è®¡ç®—æ¶¨è·Œå¹…ï¼ˆå¯¹æ¯”å½“æ—¥å¼€ç›˜ä»·ï¼Œåæ˜ å½“æ—¥æ€»æ¶¨è·Œå¹…ï¼‰
                    # é˜²æ­¢é™¤ä»¥é›¶
                    if day_open != 0:
                        change_pct = (latest['æ”¶ç›˜'] - day_open) / day_open * 100
                    else:
                        change_pct = 0.0

                    result = {
                        'symbol': symbol,
                        'price': float(latest['æ”¶ç›˜']),
                        'change_percent': round(change_pct, 2),
                        'volume': float(latest['æˆäº¤é‡']),
                        'turnover_rate': 0.0,
                        'high': float(latest['æœ€é«˜']),
                        'low': float(latest['æœ€ä½']),
                        'open': float(latest['å¼€ç›˜']),
                        'pre_close': float(day_open),  # ä½¿ç”¨å½“æ—¥å¼€ç›˜ä»·ä½œä¸ºåŸºå‡†
                        'timestamp': now.strftime('%Y-%m-%d %H:%M:%S'),
                        'is_trading': True,
                        # ğŸ†• V9.9 æ–°å¢ï¼šæ•°æ®ä¸€è‡´æ€§æ ¡éªŒå­—æ®µ
                        'data_timestamp': str(latest['æ—¶é—´']) if 'æ—¶é—´' in latest else now.strftime('%Y-%m-%d %H:%M:%S'),  # Kçº¿å®é™…æ—¶é—´
                        'fetch_timestamp': now.strftime('%Y-%m-%d %H:%M:%S'),  # æ•°æ®è·å–æ—¶é—´
                        'data_age_seconds': 0  # æ•°æ®æ–°é²œåº¦ï¼ˆç§’ï¼‰
                    }

                    self.realtime_cache[symbol] = {
                        'data': result,
                        'timestamp': now
                    }
                    print(f"[SUCCESS] 1åˆ†é’ŸKçº¿æ•°æ®è·å–æˆåŠŸ: {result}")
                    return result
            else:
                # éäº¤æ˜“æ—¶é—´ï¼Œä½¿ç”¨æ—¥çº¿æ•°æ®ï¼ˆæ˜¨å¤©çš„æ”¶ç›˜ä»·ï¼‰
                # ğŸ†• V9.9 æ–°å¢ï¼šå…ˆæ£€æŸ¥ç£ç›˜ç¼“å­˜ï¼ˆæ‡’åŠ è½½ï¼‰
                cached_kline = self._load_kline_from_cache(symbol)
                if cached_kline is not None and not cached_kline.empty:
                    logger.info(f"âœ… ä½¿ç”¨ç¼“å­˜çš„æ—¥çº¿æ•°æ®: {symbol}")
                    df = cached_kline
                    # ç»§ç»­å¤„ç†ç¼“å­˜æ•°æ®...
                else:
                    # ç¼“å­˜æœªå‘½ä¸­ï¼Œä»ç½‘ç»œè·å–
                    logger.info(f"éäº¤æ˜“æ—¶é—´ï¼Œè·å–æ—¥çº¿æ•°æ®: {symbol}...")
                    end_date = now.strftime("%Y%m%d")
                    start_date = (now - timedelta(days=10)).strftime("%Y%m%d")

                    df = ak.stock_zh_a_hist(symbol=symbol, period="daily", start_date=start_date, end_date=end_date, adjust="qfq")
                    elapsed = time.time() - start_time
                    logger.info(f"æ—¥çº¿æ•°æ®è·å–è€—æ—¶: {elapsed:.2f}ç§’")
                    
                    # ğŸ†• V9.9 æ–°å¢ï¼šä¿å­˜åˆ°ç£ç›˜ç¼“å­˜
                    if not df.empty:
                        self._save_kline_to_cache(symbol, df)

                if not df.empty:
                    # å–æœ€åä¸€æ ¹Kçº¿ï¼ˆæ˜¨å¤©çš„æ”¶ç›˜ä»·ï¼‰
                    latest = df.iloc[-1]

                    # è®¡ç®—æ¶¨è·Œå¹…ï¼ˆå¯¹æ¯”å‰ä¸€æ ¹Kçº¿çš„æ”¶ç›˜ä»·ï¼‰
                    if len(df) >= 2:
                        prev_close = df.iloc[-2]['æ”¶ç›˜']
                        # é˜²æ­¢é™¤ä»¥é›¶
                        if prev_close != 0:
                            change_pct = (latest['æ”¶ç›˜'] - prev_close) / prev_close * 100
                        else:
                            change_pct = 0.0
                    else:
                        prev_close = latest['å¼€ç›˜']
                        change_pct = 0.0

                    result = {
                        'symbol': symbol,
                        'price': float(latest['æ”¶ç›˜']),
                        'change_percent': round(change_pct, 2),
                        'volume': float(latest['æˆäº¤é‡']),
                        'turnover_rate': float(latest.get('æ¢æ‰‹ç‡', 0)),
                        'high': float(latest['æœ€é«˜']),
                        'low': float(latest['æœ€ä½']),
                        'open': float(latest['å¼€ç›˜']),
                        'pre_close': float(prev_close),
                        'timestamp': now.strftime('%Y-%m-%d %H:%M:%S'),
                        'is_trading': False,
                        # ğŸ†• V9.9 æ–°å¢ï¼šæ•°æ®ä¸€è‡´æ€§æ ¡éªŒå­—æ®µ
                        'data_timestamp': str(latest['æ—¥æœŸ']) if 'æ—¥æœŸ' in latest else now.strftime('%Y-%m-%d'),  # Kçº¿å®é™…æ—¥æœŸ
                        'fetch_timestamp': now.strftime('%Y-%m-%d %H:%M:%S'),  # æ•°æ®è·å–æ—¶é—´
                        'data_age_seconds': 0  # æ•°æ®æ–°é²œåº¦ï¼ˆç§’ï¼‰
                    }

                    self.realtime_cache[symbol] = {
                        'data': result,
                        'timestamp': now
                    }
                    logger.info(f"[SUCCESS] æ—¥çº¿æ•°æ®è·å–æˆåŠŸ: {result}")
                    return result

            logger.warning(f"[WARNING] æœªæ‰¾åˆ°è‚¡ç¥¨æ•°æ®: {symbol}")
            return None

        except Exception as e:
            print(f"[ERROR] è·å–æ•°æ®å¤±è´¥: {type(e).__name__}: {str(e)}")
            return None

    def close(self) -> None:
        """å…³é—­æ•°æ®åº“è¿æ¥
        
        é‡Šæ”¾æ•°æ®åº“èµ„æºï¼Œåº”åœ¨åº”ç”¨é€€å‡ºæ—¶è°ƒç”¨ã€‚
        """
        self.conn.close()
    
    def get_fast_price(self, stock_list: list, max_retries: int = 3) -> dict:
        """
        æé€Ÿæ‰¹é‡è·å–è¡Œæƒ… (ä¸“é—¨ç»™é¾™å¤´æ‰«æç”¨) - V6.1 å¢å¼ºç‰ˆ

        ä¼˜å…ˆä½¿ç”¨ Easyquotation æ‰¹é‡è·å–å®æ—¶è¡Œæƒ…ï¼Œä¸€æ¬¡ç½‘ç»œè¯·æ±‚å¯è·å–æ•°ç™¾åªè‚¡ç¥¨æ•°æ®ï¼Œ
        è€—æ—¶ä»…éœ€ 0.5-1 ç§’ï¼Œç›¸æ¯”é€ä¸ªè°ƒç”¨ Akshare å¿« 100 å€ä»¥ä¸Šã€‚
        
        ğŸ†• V6.1 æ•°æ®æºé™çº§ç­–ç•¥ï¼š
        1. ä¸»å¤‡åˆ‡æ¢ï¼šEasyquotation (Sina) -> Akshare (Eastmoney) -> æ ·æœ¬ä¼°ç®—
        2. å¤šæ¬¡é‡è¯•ï¼šç½‘ç»œå¤±è´¥æ—¶è‡ªåŠ¨é‡è¯•
        3. æ ·æœ¬ä¼°ç®—ï¼šå…¨å¸‚åœºæ•°æ®è·å–å¤±è´¥æ—¶ï¼Œä½¿ç”¨æ ·æœ¬è‚¡ç¥¨ä¼°ç®—å¸‚åœºæƒ…ç»ª
        4. ç¼“å­˜æœºåˆ¶ï¼š60ç§’å†…é‡å¤æŸ¥è¯¢ä½¿ç”¨ç¼“å­˜æ•°æ®

        Args:
            stock_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œå¦‚ ['300063', '000001', '600519']
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤3æ¬¡ï¼‰

        Returns:
            å­—å…¸ï¼Œkey ä¸ºå¸¦å‰ç¼€çš„è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ 'sz300063'ï¼‰ï¼Œvalue ä¸ºè¡Œæƒ…æ•°æ®å­—å…¸

            è¡Œæƒ…æ•°æ®åŒ…å«ï¼š
            - name: è‚¡ç¥¨åç§°
            - open: å¼€ç›˜ä»·
            - close: æ˜¨æ”¶ä»·
            - now: æœ€æ–°ä»·
            - high: æœ€é«˜ä»·
            - low: æœ€ä½ä»·
            - bid1_volume: ä¹°ä¸€é‡ï¼ˆè‚¡æ•°ï¼‰
            - ask1_volume: å–ä¸€é‡ï¼ˆè‚¡æ•°ï¼‰
            - volume: æˆäº¤é‡ï¼ˆæ‰‹ï¼‰
            - turnover: æ¢æ‰‹ç‡

        Note:
            å¦‚æœæ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥ï¼Œä¼šè¿”å›æ ·æœ¬ä¼°ç®—æ•°æ®æˆ–ç©ºå­—å…¸

        Example:
            >>> db = DataManager()
            >>> data = db.get_fast_price(['300063', '000001'])
            >>> print(data['sz300063']['name'])
        """
        if not stock_list:
            return {}

        # ğŸ†• V7.0: åˆ¤æ–­æ˜¯å¦åœ¨äº¤æ˜“æ—¶é—´å†…
        # ğŸ†• V9.6: ä½¿ç”¨æ ‡å‡†åŒ–çš„å¸‚åœºçŠ¶æ€åˆ¤æ–­é€»è¾‘ï¼ˆæ”¯æŒæ—¶åŒºï¼‰
        from logic.market_status import get_market_status_checker
        market_checker = get_market_status_checker()
        current_time = market_checker.get_current_time()
        is_trading_time = market_checker.is_trading_time()
        is_weekday = market_checker.is_weekday()

        # ğŸ†• V7.0: éäº¤æ˜“æ—¶é—´ï¼Œä½¿ç”¨ç¼“å­˜æ•°æ®ï¼ˆä¸Šæ¬¡æ”¶ç›˜ï¼‰
        if not (is_trading_time and is_weekday):
            cache_key = f"fast_price_{len(stock_list)}_{hash(tuple(sorted(stock_list)))}"
            if cache_key in self.realtime_cache:
                cache_data = self.realtime_cache[cache_key]
                logger.info(f"[OFF-HOURS] ä½¿ç”¨ä¸Šæ¬¡æ”¶ç›˜æ•°æ® (ç¼“å­˜æ—¶é—´: {cache_data['timestamp'].strftime('%H:%M:%S')})")
                return cache_data['data']
            else:
                logger.warning("[OFF-HOURS] æ— ç¼“å­˜æ•°æ®ï¼Œå°è¯•è·å–æœ€æ–°æ•°æ®")

        # ğŸ†• V6.1: æ£€æŸ¥ç¼“å­˜ï¼ˆäº¤æ˜“æ—¶é—´å†…ï¼‰
        cache_key = f"fast_price_{len(stock_list)}_{hash(tuple(sorted(stock_list)))}"
        if cache_key in self.realtime_cache:
            cache_data = self.realtime_cache[cache_key]
            cache_age = (datetime.now() - cache_data['timestamp']).total_seconds()
            if cache_age < self.cache_expire_seconds:
                logger.info(f"[CACHE] ä½¿ç”¨ç¼“å­˜æ•°æ® (å‰©ä½™æœ‰æ•ˆæ—¶é—´: {self.cache_expire_seconds - cache_age:.1f}ç§’)")
                return cache_data['data']

        # ğŸ†• V6.1: å¤šæ¬¡é‡è¯•æœºåˆ¶
        for retry in range(max_retries):
            result = self._try_get_fast_price(stock_list, retry)
            
            if result and len(result) > 0:
                # ğŸ†• V6.1: å­˜å…¥ç¼“å­˜ï¼ˆéäº¤æ˜“æ—¶é—´ç¼“å­˜æ—¶é—´å»¶é•¿ï¼‰
                cache_duration = 86400 if not (is_trading_time and is_weekday) else self.cache_expire_seconds
                self.realtime_cache[cache_key] = {
                    'data': result,
                    'timestamp': datetime.now(),
                    'cache_duration': cache_duration
                }
                return result
            
            if retry < max_retries - 1:
                logger.warning(f"ç¬¬ {retry + 1} æ¬¡å°è¯•å¤±è´¥ï¼Œç­‰å¾… 2 ç§’åé‡è¯•...")
                import time
                time.sleep(2)

        # ğŸ†• V6.1: æ‰€æœ‰å°è¯•éƒ½å¤±è´¥ï¼Œä½¿ç”¨æ ·æœ¬ä¼°ç®—
        logger.error("æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æ ·æœ¬ä¼°ç®—...")
        return self._get_sample_estimation(stock_list)
    
    def _try_get_fast_price(self, stock_list: list, retry: int) -> dict:
        """
        å°è¯•è·å–è¡Œæƒ…æ•°æ®ï¼ˆå•æ¬¡å°è¯•ï¼‰

        Args:
            stock_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            retry: å½“å‰é‡è¯•æ¬¡æ•°

        Returns:
            dict: è¡Œæƒ…æ•°æ®å­—å…¸
        """
        # ä¼˜å…ˆä½¿ç”¨ Easyquotation
        if self.quotation:
            try:
                return self._get_price_from_easyquotation(stock_list)
            except Exception as e:
                logger.error(f"Easyquotation è·å–å¤±è´¥ (å°è¯• {retry + 1}): {e}")
        
        # å›é€€æ–¹æ¡ˆï¼šä½¿ç”¨ Akshare
        try:
            return self._get_price_from_akshare(stock_list)
        except Exception as e:
            logger.error(f"Akshare è·å–å¤±è´¥ (å°è¯• {retry + 1}): {e}")
        
        return {}
    
    def _get_price_from_easyquotation(self, stock_list: list) -> dict:
        """
        ä½¿ç”¨ Easyquotation è·å–è¡Œæƒ…
        
        Args:
            stock_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        
        Returns:
            dict: è¡Œæƒ…æ•°æ®å­—å…¸
        """
        # ğŸ†• V8.4: å¯¼å…¥æ•°æ®æ¶ˆæ¯’å™¨
        from logic.data_sanitizer import DataSanitizer
        
        # ğŸ†• V9.6 ä¿®å¤ï¼šå¯¼å…¥ time æ¨¡å—
        from datetime import time as dt_time
        
        # ğŸ†• V9.2: åˆ¤æ–­å½“å‰æ—¶é—´
        # ğŸ†• V9.6: ä½¿ç”¨æ ‡å‡†åŒ–çš„å¸‚åœºçŠ¶æ€åˆ¤æ–­é€»è¾‘ï¼ˆæ”¯æŒæ—¶åŒºï¼‰
        from logic.market_status import get_market_status_checker
        market_checker = get_market_status_checker()
        current_time = market_checker.get_current_time()
        
        # ä½¿ç”¨ market_status æ¨¡å—ä¸­çš„æ—¶é—´å¸¸é‡
        is_auction_time = (
            current_time >= market_checker.MORNING_START and
            current_time < dt_time(9, 30)  # ç«ä»·æ—¶é—´ï¼š9:15-9:30
        )
        is_after_market = current_time >= dt_time(9, 30)        
        # è½¬æ¢ä»£ç æ ¼å¼ (easyquotation éœ€è¦ sh/sz å‰ç¼€)
        full_codes = []
        for code in stock_list:
            if code.startswith('6'):
                prefix = 'sh'
            elif code.startswith('8') or code.startswith('4'):
                prefix = 'bj'
            else:
                prefix = 'sz'
            full_codes.append(f"{prefix}{code}")

        # ğŸš€ æ‰¹é‡è·å–ï¼Œé¿å…ä¸€æ¬¡è¯·æ±‚è¿‡å¤šè‚¡ç¥¨å¯¼è‡´è¿æ¥å¤±è´¥
        result = {}
        batch_size = 500  # æ¯æ¬¡æœ€å¤š 500 åªè‚¡ç¥¨
        total_batches = (len(full_codes) + batch_size - 1) // batch_size

        logger.info(f"æ­£åœ¨ä½¿ç”¨ Easyquotation æé€Ÿè·å– {len(full_codes)} åªè‚¡ç¥¨çš„å®æ—¶è¡Œæƒ…ï¼ˆåˆ† {total_batches} æ‰¹ï¼‰...")

        for i in range(0, len(full_codes), batch_size):
            batch = full_codes[i:i + batch_size]
            batch_num = i // batch_size + 1
            try:
                logger.info(f"æ­£åœ¨è·å–ç¬¬ {batch_num}/{total_batches} æ‰¹æ•°æ® ({len(batch)} åªè‚¡ç¥¨)...")
                
                # ğŸ†• V9.8 ä¿®å¤ï¼šæ·»åŠ è¶…æ—¶æœºåˆ¶ï¼Œé¿å… Easyquotation å¡æ­»
                import threading
                result_container = {'data': None, 'error': None}
                
                def fetch_with_timeout():
                    try:
                        result_container['data'] = self.quotation.stocks(batch)
                    except Exception as e:
                        result_container['error'] = e
                
                # åˆ›å»ºè¶…æ—¶çº¿ç¨‹ï¼ˆ5ç§’è¶…æ—¶ï¼Œæ‰¹é‡è¯·æ±‚å¯ä»¥ç¨å¾®é•¿ä¸€ç‚¹ï¼‰
                fetch_thread = threading.Thread(target=fetch_with_timeout)
                fetch_thread.daemon = True
                fetch_thread.start()
                fetch_thread.join(timeout=5.0)  # 5ç§’è¶…æ—¶
                
                if fetch_thread.is_alive():
                    # è¶…æ—¶ï¼Œè·³è¿‡è¿™ä¸€æ‰¹
                    logger.warning(f"âš ï¸ Easyquotation è¶…æ—¶ï¼ˆç¬¬ {batch_num}/{total_batches} æ‰¹ï¼‰ï¼Œè·³è¿‡")
                    continue
                elif result_container['error']:
                    # å‘ç”Ÿé”™è¯¯
                    raise result_container['error']
                else:
                    batch_result = result_container['data']
                
                # ğŸ†• V8.4: æ•°æ®æ¶ˆæ¯’ - åœ¨æ•°æ®è¿›å…¥ç³»ç»Ÿçš„é‚£ä¸€åˆ»è¿›è¡Œæ¸…æ´—
                # ğŸ†• V9.2: ç«ä»·å¿«ç…§ä¿å­˜å’Œæ¢å¤
                sanitized_batch = {}
                for stock_code, stock_data in batch_result.items():
                    # æå–çº¯è‚¡ç¥¨ä»£ç ï¼ˆå»æ‰å‰ç¼€ï¼‰
                    code = stock_code[2:]  # 'sh600058' -> '600058'
                    
                    # ä½¿ç”¨ DataSanitizer æ¸…æ´—æ•°æ®
                    sanitized_data = DataSanitizer.sanitize_realtime_data(
                        stock_data, 
                        source_type='easyquotation',
                        code=stock_code
                    )
                    
                    # ğŸ†• V9.2: ç«ä»·å¿«ç…§é€»è¾‘
                    if self.auction_snapshot_manager:
                        # åœºæ™¯ A: ç«ä»·æ—¶é—´ï¼ˆ9:25-9:30ï¼‰â†’ ä¿å­˜ç«ä»·æ•°æ®
                        if is_auction_time:
                            auction_volume = sanitized_data.get('volume', 0)  # æ­¤æ—¶ volume å°±æ˜¯ç«ä»·é‡
                            auction_amount = sanitized_data.get('turnover', 0)
                            
                            if auction_volume > 0:
                                # ä¿å­˜ç«ä»·å¿«ç…§
                                self.auction_snapshot_manager.save_auction_snapshot(code, {
                                    'auction_volume': auction_volume,
                                    'auction_amount': auction_amount,
                                    'timestamp': datetime.now(market_checker.timezone).timestamp()
                                })
                        
                        # åœºæ™¯ B: ç›˜ä¸­/ç›˜åï¼ˆ9:30 ä»¥åï¼‰â†’ å°è¯•æ¢å¤ç«ä»·æ•°æ®
                        elif is_after_market:
                            # ä» Redis æ¢å¤ç«ä»·æ•°æ®
                            snapshot = self.auction_snapshot_manager.load_auction_snapshot(code)
                            
                            if snapshot:
                                # âœ… æˆåŠŸæ¢å¤ç«ä»·æ•°æ®
                                sanitized_data['ç«ä»·é‡'] = snapshot.get('auction_volume', 0)
                                sanitized_data['ç«ä»·é‡‘é¢'] = snapshot.get('auction_amount', 0)
                                logger.debug(f"âœ… [ç«ä»·æ¢å¤] {code} ç«ä»·æ•°æ®å·²ä» Redis æ¢å¤")
                            else:
                                # âŒ Redis ä¹Ÿæ²¡æœ‰ï¼Œæ ‡è®°ä¸ºç¼ºå¤±
                                sanitized_data['ç«ä»·é‡'] = 0
                                sanitized_data['ç«ä»·é‡‘é¢'] = 0
                                logger.debug(f"âš ï¸ [ç«ä»·ç¼ºå¤±] {code} æ— ç«ä»·å¿«ç…§æ•°æ®")
                    
                    sanitized_batch[stock_code] = sanitized_data
                
                result.update(sanitized_batch)
                logger.info(f"âœ… ç¬¬ {batch_num} æ‰¹è·å–å®Œæˆï¼Œè·å–åˆ° {len(batch_result)} åªè‚¡ç¥¨")
            except Exception as e:
                logger.warning(f"ç¬¬ {batch_num} æ‰¹è·å–å¤±è´¥: {e}ï¼Œç»§ç»­ä¸‹ä¸€æ‰¹")
                continue

        logger.info(f"âœ… Easyquotation æé€Ÿè·å–å®Œæˆï¼Œå…±è·å– {len(result)} åªè‚¡ç¥¨")
        return result
    
    def _get_price_from_akshare(self, stock_list: list) -> dict:
        """
        ä½¿ç”¨ Akshare è·å–è¡Œæƒ…

        Args:
            stock_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨

        Returns:
            dict: è¡Œæƒ…æ•°æ®å­—å…¸
        """
        result = {}

        # ä½¿ç”¨ Akshare è·å–å®æ—¶è¡Œæƒ…
        import time
        start_time = time.time()

        # ğŸ†• V9.8 ä¿®å¤ï¼šåœ¨å¾ªç¯å¤–è°ƒç”¨ä¸€æ¬¡ï¼Œè·å–å…¨å¸‚åœºæ•°æ®ï¼Œç„¶ååœ¨å†…å­˜ä¸­æŸ¥æ‰¾
        # ä¸è¦åœ¨å¾ªç¯ä¸­è°ƒç”¨ï¼Œå¦åˆ™æ‰«æ 5000 åªè‚¡ç¥¨ä¼šè°ƒç”¨ 5000 æ¬¡ï¼Œæå…¶ä½æ•ˆï¼
        import akshare as ak
        logger.info(f"æ­£åœ¨ä½¿ç”¨ Akshare è·å–å…¨å¸‚åœºå®æ—¶è¡Œæƒ…...")
        stock_info = ak.stock_zh_a_spot_em()
        logger.info(f"âœ… Akshare å…¨å¸‚åœºæ•°æ®è·å–å®Œæˆï¼Œå…± {len(stock_info)} åªè‚¡ç¥¨")

        # æ‰¹é‡å¤„ç†ï¼Œæ¯æ¬¡æœ€å¤š 300 åªè‚¡ç¥¨
        batch_size = 300
        for i in range(0, len(stock_list), batch_size):
            batch = stock_list[i:i + batch_size]
            logger.info(f"æ­£åœ¨å¤„ç†ç¬¬ {i//batch_size + 1} æ‰¹æ•°æ® ({len(batch)} åªè‚¡ç¥¨)...")

            for code in batch:
                try:
                    # ğŸ†• V9.8 ä¿®å¤ï¼šç›´æ¥ä»å†…å­˜ä¸­æŸ¥æ‰¾ï¼Œä¸å†é‡å¤è°ƒç”¨ API
                    # æŸ¥æ‰¾è‚¡ç¥¨æ•°æ®
                    stock_data = stock_info[stock_info['ä»£ç '] == code]
                    
                    if not stock_data.empty:
                        stock_row = stock_data.iloc[0]
                        full_code = f"sh{code}" if code.startswith('6') else f"sz{code}"
                        
                        # è®¡ç®—æ¶¨è·Œå¹…
                        price = float(stock_row['æœ€æ–°ä»·'])
                        pre_close = float(stock_row['æ˜¨æ”¶'])
                        change_pct = ((price - pre_close) / pre_close * 100) if pre_close > 0 else 0.0
                        
                        result[full_code] = {
                            'name': stock_row['åç§°'],
                            'open': float(stock_row['ä»Šå¼€']),
                            'close': pre_close,
                            'now': price,
                            'high': float(stock_row['æœ€é«˜']),
                            'low': float(stock_row['æœ€ä½']),
                            'volume': float(stock_row['æˆäº¤é‡']) / 100,  # è½¬æ¢ä¸ºæ‰‹
                            'turnover': float(stock_row['æ¢æ‰‹ç‡']),
                            'bid1_volume': 0,  # Akshare å®æ—¶æ•°æ®ä¸åŒ…å«ç›˜å£æ•°æ®
                            'ask1_volume': 0,
                            'bid1': 0,
                            'ask1': 0
                        }
                except Exception as e:
                    logger.warning(f"è·å–è‚¡ç¥¨ {code} æ•°æ®å¤±è´¥: {e}")
                    continue

        elapsed = time.time() - start_time
        logger.info(f"âœ… Akshare è·å–å®Œæˆï¼Œå…± {len(result)} åªè‚¡ç¥¨ï¼Œè€—æ—¶ {elapsed:.2f}ç§’")
        return result
    
    def _get_sample_estimation(self, stock_list: list) -> dict:
        """
        ğŸ†• V6.1: ä½¿ç”¨æ ·æœ¬ä¼°ç®—å¸‚åœºæƒ…ç»ªï¼ˆé™çº§æ–¹æ¡ˆï¼‰
        ğŸ†• V6.2: å‡çº§ä¸ºåˆ†å±‚æŠ½æ ·ï¼Œé¿å…æ ·æœ¬åå·®

        å½“å…¨å¸‚åœºæ•°æ®è·å–å¤±è´¥æ—¶ï¼Œä½¿ç”¨åˆ†å±‚æŠ½æ ·çš„æ ·æœ¬è‚¡ç¥¨ï¼ˆ100åªï¼‰æ¥ä¼°ç®—å¸‚åœºæƒ…ç»ªã€‚
        ç¡®ä¿æ ·æœ¬è¦†ç›–ï¼šæƒé‡è‚¡ã€äººæ°”å¦–è‚¡ã€è·Œå¹…æ¦œå¸¸å®¢ã€éšæœºä¸­å°ç›˜ã€‚

        Args:
            stock_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨

        Returns:
            dict: æ ·æœ¬ä¼°ç®—æ•°æ®
        """
        logger.warning("ä½¿ç”¨æ ·æœ¬ä¼°ç®—æ¨¡å¼ï¼ˆåˆ†å±‚æŠ½æ ·100åªè‚¡ç¥¨ï¼‰")
        
        # ğŸ†• V6.2: ä½¿ç”¨åˆ†å±‚æŠ½æ ·ï¼Œè€Œä¸æ˜¯éšæœºå–å‰100åª
        sample_stocks = self._get_stratified_sample()
        
        if not sample_stocks:
            # å¦‚æœåˆ†å±‚æŠ½æ ·å¤±è´¥ï¼Œå›é€€åˆ°å–å‰100åª
            logger.warning("åˆ†å±‚æŠ½æ ·å¤±è´¥ï¼Œå›é€€åˆ°éšæœºæŠ½æ ·")
            sample_stocks = stock_list[:100]
        
        result = {}
        try:
            # å°è¯•è·å–æ ·æœ¬æ•°æ®
            sample_data = self._get_price_from_akshare(sample_stocks)
            
            if sample_data:
                # è®¡ç®—æ ·æœ¬ç»Ÿè®¡ä¿¡æ¯
                total_count = len(sample_data)
                up_count = sum(1 for data in sample_data.values() if data.get('now', 0) > data.get('close', 0))
                down_count = sum(1 for data in sample_data.values() if data.get('now', 0) < data.get('close', 0))
                
                logger.info(f"ğŸ“Š åˆ†å±‚æ ·æœ¬ç»Ÿè®¡ï¼šå…± {total_count} åªï¼Œä¸Šæ¶¨ {up_count} åªï¼Œä¸‹è·Œ {down_count} åª")
                logger.info(f"ğŸ“Š æ¶¨è·Œæ¯”ï¼š{up_count/total_count:.1%}ï¼Œåˆ†å±‚æŠ½æ ·ä»£è¡¨å¤§ç›˜æƒ…ç»ª")
                
                return sample_data
            else:
                logger.error("æ ·æœ¬æ•°æ®è·å–ä¹Ÿå¤±è´¥")
                return {}
        
        except Exception as e:
            logger.error(f"æ ·æœ¬ä¼°ç®—å¤±è´¥: {e}")
            return {}
    
    def _get_stratified_sample(self) -> list:
        """
        ğŸ†• V6.2: è·å–åˆ†å±‚æŠ½æ ·æ ·æœ¬
        
        ä»balanced_monitor_list.jsonä¸­è¯»å–é¢„å­˜çš„100åªä»£è¡¨æ€§è‚¡ç¥¨ï¼Œ
        ç¡®ä¿è¦†ç›–å„ä¸ªå¸‚åœºå±‚çº§ã€‚
        
        Returns:
            list: 100åªåˆ†å±‚æŠ½æ ·çš„è‚¡ç¥¨ä»£ç 
        """
        try:
            import json
            import os
            
            config_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 
                                       'config', 'balanced_monitor_list.json')
            
            if not os.path.exists(config_path):
                logger.warning(f"åˆ†å±‚æŠ½æ ·é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
                return []
            
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            # æå–æ‰€æœ‰å±‚çš„è‚¡ç¥¨
            sample_stocks = []
            for layer_name, layer_info in config.get('layers', {}).items():
                stocks = layer_info.get('stocks', [])
                sample_stocks.extend(stocks)
                logger.info(f"ğŸ“Š åˆ†å±‚æŠ½æ · - {layer_name}: {len(stocks)} åª")
            
            # ç¡®ä¿æ€»æ•°æ˜¯100åª
            if len(sample_stocks) != 100:
                logger.warning(f"åˆ†å±‚æŠ½æ ·æ€»æ•°ä¸æ˜¯100åªï¼Œå®é™…: {len(sample_stocks)} åª")
            
            logger.info(f"âœ… åˆ†å±‚æŠ½æ ·å®Œæˆï¼Œå…± {len(sample_stocks)} åª")
            return sample_stocks
            
        except Exception as e:
            logger.error(f"è·å–åˆ†å±‚æŠ½æ ·å¤±è´¥: {e}")
            return []
    
    def _load_industry_cache(self):
        """ä»æœ¬åœ°JSONæ–‡ä»¶åŠ è½½è¡Œä¸šç¼“å­˜"""
        import json
        import os
        
        if os.path.exists(self.static_cache_file):
            try:
                with open(self.static_cache_file, 'r', encoding='utf-8') as f:
                    self.industry_cache = json.load(f)
                logger.info(f"âœ… ä»ç£ç›˜åŠ è½½è¡Œä¸šç¼“å­˜æˆåŠŸï¼Œå…± {len(self.industry_cache)} ä¸ªæ¿å—")
            except Exception as e:
                logger.warning(f"è¯»å–è¡Œä¸šç¼“å­˜å¤±è´¥: {e}ï¼Œå°†é‡æ–°è·å–")
                self.industry_cache = {}
                self._update_industry_cache()
        else:
            logger.info("è¡Œä¸šç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º...")
            self._update_industry_cache()
    
    def _update_industry_cache(self):
        """ä»AkShareæ›´æ–°è¡Œä¸šç¼“å­˜å¹¶ä¿å­˜åˆ°ç£ç›˜"""
        import akshare as ak
        import json
        
        try:
            logger.info("æ­£åœ¨ä»AkShareè·å–è¡Œä¸šä¿¡æ¯...")
            industry_df = ak.stock_board_industry_name_em()
            
            # æ„å»ºæ¿å—ä»£ç åˆ°æ¿å—åç§°çš„æ˜ å°„
            self.industry_cache = {}
            for _, row in industry_df.iterrows():
                self.industry_cache[row['æ¿å—ä»£ç ']] = row['æ¿å—åç§°']
            
            # ä¿å­˜åˆ°ç£ç›˜
            with open(self.static_cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.industry_cache, f, ensure_ascii=False, indent=2)
            
            logger.info(f"âœ… è¡Œä¸šç¼“å­˜æ›´æ–°æˆåŠŸï¼Œå…± {len(self.industry_cache)} ä¸ªæ¿å—")
            
        except Exception as e:
            logger.error(f"æ›´æ–°è¡Œä¸šç¼“å­˜å¤±è´¥: {e}")
            self.industry_cache = {}
    
    def get_industry_cache(self):
        """è·å–è¡Œä¸šç¼“å­˜"""
        return self.industry_cache
    
    def get_stock_status(self, code: str, days: int = 5) -> Dict[str, Any]:
        """
        ğŸ†• V9.13 è·å–è‚¡ç¥¨çš„ã€èº«ä½ã€‘å’Œã€å½¢æ€ã€‘
        
        è®¡ç®—è¿æ¿æ•°å’Œæ˜¨æ—¥çŠ¶æ€ï¼Œç”¨äºè¯†åˆ«å¼±è½¬å¼ºå’Œè¿æ¿æº¢ä»·ã€‚
        
        Args:
            code: è‚¡ç¥¨ä»£ç 
            days: è·å–å†å²å¤©æ•°ï¼ˆé»˜è®¤5å¤©ï¼‰
        
        Returns:
            dict: {
                'lianban_count': è¿æ¿æ•°,
                'yesterday_status': æ˜¨æ—¥çŠ¶æ€ï¼ˆæ¶¨åœ/çƒ‚æ¿/éæ¶¨åœï¼‰,
                'yesterday_pct': æ˜¨æ—¥æ¶¨è·Œå¹…,
                'limit_threshold': æ¶¨åœé˜ˆå€¼
            }
        """
        from datetime import datetime, timedelta
        import pandas as pd
        
        try:
            # è·å–æœ€è¿‘Nå¤©çš„æ—¥çº¿æ•°æ®
            end_date = datetime.now().strftime("%Y%m%d")
            start_date = (datetime.now() - timedelta(days=days+10)).strftime("%Y%m%d")  # å¤šå–å‡ å¤©ç¡®ä¿æœ‰æ•°æ®
            
            from logic.akshare_data_loader import AKShareDataLoader
            klines = AKShareDataLoader.get_stock_daily(code, start_date, end_date, adjust="")
            
            if klines is None or len(klines) < 2:
                return {
                    'lianban_count': 0,
                    'yesterday_status': 'æœªçŸ¥',
                    'yesterday_pct': 0,
                    'limit_threshold': 9.5
                }
            
            # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰é¢ï¼‰
            klines = klines.sort_values('æ—¥æœŸ', ascending=False)
            
            # 1. è®¡ç®—è¿æ¿æ•°ï¼ˆå€’åºéå†ï¼‰
            boards = 0
            limit_threshold = 9.5  # é»˜è®¤ä¸»æ¿é˜ˆå€¼
            
            # åˆ¤æ–­æ˜¯å¦ä¸º 20cm æ ‡çš„ (åˆ›ä¸šæ¿ 30/ç§‘åˆ›æ¿ 68)
            if code.startswith(('30', '68')):
                limit_threshold = 19.5
            elif 'ST' in str(code):
                limit_threshold = 4.8
            
            for _, k in klines.iterrows():
                pct = k.get('æ¶¨è·Œå¹…', 0)
                
                # åˆ¤æ–­æ˜¯å¦æ¶¨åœ
                if pct >= limit_threshold:
                    boards += 1
                else:
                    # ä¸€æ—¦æ–­æ¿ï¼Œåœæ­¢è®¡ç®—
                    break
            
            # 2. åˆ¤æ–­æ˜¨æ—¥çŠ¶æ€ï¼ˆç”¨äºè¯†åˆ«å¼±è½¬å¼ºï¼‰
            if len(klines) >= 2:
                yesterday = klines.iloc[1]  # æ˜¨å¤©çš„æ•°æ®
                yesterday_pct = yesterday.get('æ¶¨è·Œå¹…', 0)
                
                # åˆ¤æ–­æ˜¨æ—¥çŠ¶æ€
                if yesterday_pct >= limit_threshold:
                    yesterday_status = 'æ¶¨åœ'
                elif yesterday_pct > 5 and yesterday_pct < limit_threshold:
                    yesterday_status = 'çƒ‚æ¿'  # å¤§æ¶¨ä½†æœªæ¶¨åœ
                elif yesterday_pct < -5:
                    yesterday_status = 'å¤§è·Œ'
                else:
                    yesterday_status = 'éæ¶¨åœ'
            else:
                yesterday_pct = 0
                yesterday_status = 'æœªçŸ¥'
            
            return {
                'lianban_count': boards,
                'yesterday_status': yesterday_status,
                'yesterday_pct': yesterday_pct,
                'limit_threshold': limit_threshold
            }
            
        except Exception as e:
            logger.warning(f"è·å–è‚¡ç¥¨ {code} çŠ¶æ€å¤±è´¥: {e}")
            return {
                'lianban_count': 0,
                'yesterday_status': 'æœªçŸ¥',
                'yesterday_pct': 0,
                'limit_threshold': 9.5
            }
    
    def warm_up_stock_status(self, stock_list: list) -> Dict[str, Any]:
        """
        ğŸ”¥ V9.13.1 ç›˜å‰é¢„çƒ­ï¼šæå‰æŠŠè¿æ¿æ•°å’Œæ˜¨æ—¥çŠ¶æ€ç®—å¥½ï¼Œå­˜å…¥å†…å­˜
        
        å»ºè®®åœ¨ 9:15 ä¹‹å‰è¿è¡Œï¼Œé¢„çƒ­ç›‘æ§æ± çš„è‚¡ç¥¨èº«ä½æ•°æ®ã€‚
        è¿™æ ·åœ¨ 9:25 ç«ä»·æ—¶ï¼Œget_stock_status ä¼šç›´æ¥ä»ç¼“å­˜è¯»å–ï¼Œè€—æ—¶ä» 0.35s é™è‡³ 0.0001sã€‚
        
        Args:
            stock_list: è‚¡ç¥¨åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« 'code' å­—æ®µ
        
        Returns:
            dict: é¢„çƒ­ç»“æœç»Ÿè®¡
        """
        import time
        from datetime import datetime
        
        start_time = time.time()
        success_count = 0
        fail_count = 0
        
        logger.info(f"ğŸ”¥ å¼€å§‹ç›˜å‰é¢„çƒ­ {len(stock_list)} åªè‚¡ç¥¨çš„èº«ä½æ•°æ®...")
        
        for stock in stock_list:
            code = stock.get('code', '')
            if not code:
                continue
                
            try:
                # è°ƒç”¨ get_stock_status ä¼šä¸‹è½½ K çº¿å¹¶ç¼“å­˜
                # å› ä¸ºæ•°æ®æ˜¯é™æ€çš„ï¼ŒDataManager çš„ç¼“å­˜æœºåˆ¶ä¼šç”Ÿæ•ˆ
                self.get_stock_status(code)
                success_count += 1
            except Exception as e:
                logger.warning(f"é¢„çƒ­è‚¡ç¥¨ {code} å¤±è´¥: {e}")
                fail_count += 1
        
        elapsed_time = time.time() - start_time
        
        result = {
            'total': len(stock_list),
            'success': success_count,
            'failed': fail_count,
            'elapsed_time': round(elapsed_time, 2),
            'timestamp': datetime.now().strftime("%H:%M:%S")
        }
        
        logger.info(f"âœ… ç›˜å‰é¢„çƒ­å®Œæˆï¼æˆåŠŸ {success_count} åªï¼Œå¤±è´¥ {fail_count} åªï¼Œè€—æ—¶ {elapsed_time:.2f} ç§’")
        logger.info(f"ğŸ’¡ 9:25 ç«ä»·æ—¶å°†ç›´æ¥è¯»å–ç¼“å­˜ï¼Œé¢„è®¡è€—æ—¶ < 0.1 ç§’")
        
        return result
