#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
V11 æ ¸å¿ƒç»„ä»¶ï¼šå¤ç›˜ç®¡ç†å™¨ (Review Manager)
è´Ÿè´£ç®¡ç†'éš”æ—¥è®°å¿†'ï¼Œè®¡ç®—è¿æ¿é«˜åº¦å’Œæ˜¨æ—¥æº¢ä»·
V18.7: æ–°å¢é«˜ä»·å€¼æ¡ˆä¾‹è‡ªåŠ¨æ•è·æœºåˆ¶
"""

import pandas as pd
import json
import os
from datetime import datetime
from logic.database_manager import get_db_manager
from logic.logger import get_logger
import akshare as ak

logger = get_logger(__name__)


class ReviewManager:
    """
    V11 æ ¸å¿ƒç»„ä»¶ï¼šå¤ç›˜ç®¡ç†å™¨
    è´Ÿè´£ç®¡ç†'éš”æ—¥è®°å¿†'ï¼Œè®¡ç®—è¿æ¿é«˜åº¦å’Œæ˜¨æ—¥æº¢ä»·
    V18.7: æ–°å¢é«˜ä»·å€¼æ¡ˆä¾‹è‡ªåŠ¨æ•è·æœºåˆ¶
    """
    
    def __init__(self):
        self.db = get_db_manager()
        self._init_tables()
    
    def _init_tables(self):
        """åˆå§‹åŒ–å¤ç›˜æ•°æ®è¡¨ (SQLite)"""
        # åˆ›å»ºæ¯æ—¥å¸‚åœºæ¦‚å†µè¡¨ (Metadata)
        sql_summary = """
        CREATE TABLE IF NOT EXISTS market_summary (
            date TEXT PRIMARY KEY,
            highest_board INTEGER,      -- æœ€é«˜è¿æ¿æ•°
            limit_up_count INTEGER,     -- æ¶¨åœå®¶æ•°
            limit_down_count INTEGER,   -- è·Œåœå®¶æ•°
            limit_up_list TEXT,         -- æ¶¨åœè‚¡åå• (JSON)
            top_sectors TEXT,           -- [V13 æ–°å¢] å­˜å‚¨å½“æ—¥é¢†æ¶¨æ¿å— (JSON åˆ—è¡¨)
            created_at TEXT
        )
        """
        self.db.sqlite_execute(sql_summary)
        
        # [V13 æ–°å¢] æ•°æ®åº“è¿ç§»ï¼šæ·»åŠ  top_sectors å­—æ®µï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        try:
            # æ£€æŸ¥å­—æ®µæ˜¯å¦å­˜åœ¨
            check_sql = "PRAGMA table_info(market_summary)"
            columns = self.db.sqlite_query(check_sql)
            column_names = [col[1] for col in columns]
            
            if 'top_sectors' not in column_names:
                # æ·»åŠ æ–°å­—æ®µ
                alter_sql = "ALTER TABLE market_summary ADD COLUMN top_sectors TEXT"
                self.db.sqlite_execute(alter_sql)
                logger.info("âœ… V13 æ•°æ®åº“è¿ç§»å®Œæˆï¼šå·²æ·»åŠ  top_sectors å­—æ®µ")
            else:
                logger.info("âœ… V13 å¤ç›˜æ•°æ®åº“è¡¨ç»“æ„å·²å°±ç»ª (å«æ¿å—è®°å¿†å­—æ®µ top_sectors)")
        except Exception as e:
            logger.warning(f"âš ï¸ æ•°æ®åº“è¿ç§»å¤±è´¥: {e}")
    
    def run_daily_review(self, date=None):
        """
        æ‰§è¡Œæ¯æ—¥å¤ç›˜ (å»ºè®®æ¯æ—¥ 15:30 è¿è¡Œ)
        è·å–å½“æ—¥æ¶¨åœæ•°æ®å¹¶å­˜å…¥ DB
        [V13 æ–°å¢] è‡ªåŠ¨æŠ“å–å½“æ—¥è¡¨ç°æœ€å¼ºçš„è¡Œä¸šæ¿å—
        """
        if date is None:
            date = datetime.now().strftime("%Y%m%d")
        
        logger.info(f"ğŸ”„ å¼€å§‹æ‰§è¡Œ {date} æ¯æ—¥å¤ç›˜å½’æ¡£...")
        
        try:
            # 1. è·å–å½“æ—¥æ¶¨åœæ±  (æ¥è‡ª AkShare)
            df = ak.stock_zt_pool_em(date=date)
            
            if df is None or df.empty:
                logger.warning(f"âš ï¸ {date} æ²¡æœ‰è·å–åˆ°æ¶¨åœæ•°æ® (å¯èƒ½æ˜¯ä¼‘å¸‚æˆ–æ•°æ®æœªæ›´æ–°)")
                return False
            
            # 2. æå–æ ¸å¿ƒæ•°æ®
            # è¿æ¿é«˜åº¦ (è¿æ¿æ•°é‚£ä¸€åˆ—çš„æœ€å¤§å€¼)
            highest_board = int(df['è¿æ¿æ•°'].max()) if 'è¿æ¿æ•°' in df.columns else 1
            limit_up_count = len(df)
            
            # æå–æ¶¨åœåå• (åªå­˜ä»£ç ï¼ŒèŠ‚çœç©ºé—´)
            # æ ¼å¼: ["000001", "600519", ...]
            limit_up_list = df['ä»£ç '].tolist()
            
            # [V13 æ–°å¢] è·å–ä»Šæ—¥é¢†æ¶¨æ¿å—
            top_sectors = []
            try:
                # è·å–è¡Œä¸šæ¿å—è¡Œæƒ…
                sector_df = ak.stock_board_industry_name_em()
                # å–æ¶¨å¹…å‰ 3 çš„æ¿å—åç§°
                if not sector_df.empty and 'æ¶¨è·Œå¹…' in sector_df.columns:
                    top_3_sectors = sector_df.nlargest(3, 'æ¶¨è·Œå¹…')['æ¿å—åç§°'].tolist()
                    top_sectors = top_3_sectors
                    logger.info(f"ğŸ† ä»Šæ—¥æ ¸å¿ƒä¸»çº¿é¢„é€‰: {top_sectors}")
                else:
                    logger.warning("âš ï¸ æ¿å—æ•°æ®æ ¼å¼å¼‚å¸¸ï¼Œæ— æ³•æå–é¢†æ¶¨æ¿å—")
            except Exception as e:
                logger.error(f"è·å–é¢†æ¶¨æ¿å—å¤±è´¥: {e}")
                top_sectors = []
            
            # 3. å­˜å…¥æ•°æ®åº“
            sql = """
            INSERT OR REPLACE INTO market_summary 
            (date, highest_board, limit_up_count, limit_down_count, limit_up_list, top_sectors, created_at)
            VALUES (?, ?, ?, ?, ?, ?, ?)
            """
            
            self.db.sqlite_execute(sql, (
                date, 
                highest_board, 
                limit_up_count, 
                0,  # è·Œåœæ•°æš‚æ—¶å¡«0ï¼Œåç»­å¯æ‰©å……
                json.dumps(limit_up_list), 
                json.dumps(top_sectors),  # âœ… å­˜å…¥ JSON åŒ–çš„æ¿å—åˆ—è¡¨
                datetime.now().isoformat()
            ))
            
            logger.info(f"âœ… å¤ç›˜å½’æ¡£å®Œæˆ! æ—¥æœŸ: {date}, æœ€é«˜æ¿: {highest_board}, æ¶¨åœ: {limit_up_count}å®¶, é¢†æ¶¨æ¿å—: {top_sectors}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ å¤ç›˜å½’æ¡£å¤±è´¥: {e}")
            return False
    
    def get_yesterday_stats(self):
        """
        è·å–æ˜¨æ—¥å¸‚åœºçŠ¶æ€ (ä¾›ä»Šæ—¥å®ç›˜ä½¿ç”¨)
        [V13 æ–°å¢] è¿”å›é¢†æ¶¨æ¿å—æ•°æ®
        """
        # è·å–æœ€è¿‘çš„ä¸€ä¸ªäº¤æ˜“æ—¥è®°å½•
        sql = "SELECT * FROM market_summary ORDER BY date DESC LIMIT 1"
        results = self.db.sqlite_query(sql)
        
        if not results:
            return None
        
        row = results[0]
        # è§£ææ•°æ®
        stats = {
            'date': row[0],
            'highest_board': row[1],
            'limit_up_count': row[2],
            'limit_up_list': json.loads(row[4]) if row[4] else []  # è¿™æ˜¯ä¸€ä¸ªä»£ç åˆ—è¡¨
        }
        
        # [V13 æ–°å¢] è§£æé¢†æ¶¨æ¿å—
        if len(row) > 5 and row[5]:
            try:
                stats['top_sectors'] = json.loads(row[5])
            except:
                stats['top_sectors'] = []
        else:
            stats['top_sectors'] = []
        
        return stats
    
    def capture_golden_cases(self, date_str=None):
        """
        ğŸš€ [V18.7 æ–°å¢] é«˜ä»·å€¼æ¡ˆä¾‹è‡ªåŠ¨æ•è·æœºåˆ¶
        è‡ªåŠ¨ç­›é€‰ï¼šæ ‡å‡†çœŸé¾™ã€æƒ¨æ¡ˆå¤§å‘ã€å¼±è½¬å¼º
        
        Args:
            date_str: æ—¥æœŸå­—ç¬¦ä¸²ï¼Œæ ¼å¼ YYYYMMDDï¼Œé»˜è®¤ä¸ºä»Šå¤©
        
        Returns:
            dict: é«˜ä»·å€¼æ¡ˆä¾‹æ•°æ®ï¼ŒåŒ…å«ï¼š
                - date: æ—¥æœŸ
                - dragons: æ ‡å‡†çœŸé¾™åˆ—è¡¨
                - traps: æƒ¨æ¡ˆå¤§å‘åˆ—è¡¨
                - reversals: å¼±è½¬å¼º/åæ ¸åˆ—è¡¨
                - market_score: å¸‚åœºæƒ…ç»ªè¯„åˆ† (0-100)
        """
        if date_str is None:
            date_str = datetime.now().strftime("%Y%m%d")
        
        logger.info(f"ğŸ¦ æ­£åœ¨æ•è· {date_str} çš„é«˜ä»·å€¼å¤ç›˜æ¡ˆä¾‹...")
        
        cases = {
            "date": date_str,
            "dragons": [],      # æ ‡å‡†ç­”æ¡ˆ
            "traps": [],        # é¿å‘æŒ‡å—
            "reversals": [],    # å¼±è½¬å¼º/åæ ¸
            "market_score": 0   # å¸‚åœºæƒ…ç»ªè¯„åˆ†
        }
        
        try:
            # 1. è·å–å½“æ—¥æ¶¨åœæ±  (çœŸé¾™æºå¤´)
            df_zt = ak.stock_zt_pool_em(date=date_str)
            if df_zt is not None and not df_zt.empty:
                # ç­›é€‰è§„åˆ™ï¼šè¿æ¿é«˜åº¦æœ€é«˜ Or å°æ¿èµ„é‡‘æœ€å¤§
                # æŒ‰è¿æ¿æ•°é™åºï¼Œå°æ¿èµ„é‡‘é™åº
                df_zt['å°æ¿èµ„é‡‘'] = df_zt['å°æ¿èµ„é‡‘'].astype(float)
                top_dragons = df_zt.sort_values(by=['è¿æ¿æ•°', 'å°æ¿èµ„é‡‘'], ascending=[False, False]).head(3)
                
                for _, row in top_dragons.iterrows():
                    cases['dragons'].append({
                        "code": row['ä»£ç '],
                        "name": row['åç§°'],
                        "reason": f"ğŸ”¥ å¸‚åœºæœ€é«˜æ ‡: {row['è¿æ¿æ•°']}è¿æ¿, å°å•{int(row['å°æ¿èµ„é‡‘']/10000)}ä¸‡",
                        "type": "SPACE_DRAGON", # ç©ºé—´é¾™
                        "limit_board": int(row['è¿æ¿æ•°']),
                        "seal_amount": float(row['å°æ¿èµ„é‡‘'])
                    })
                
                # è®¡ç®—å¸‚åœºæƒ…ç»ªè¯„åˆ† (0-100)
                cases['market_score'] = int(len(df_zt) / 50 * 100)
            else:
                # å¦‚æœæ²¡æœ‰æ¶¨åœæ•°æ®ï¼Œå¸‚åœºæƒ…ç»ªè¯„åˆ†è®¾ä¸º 20
                cases['market_score'] = 20
            
            # 2. è·å–å½“æ—¥è·Œå¹…æ¦œ (å¤§å‘æºå¤´) - ä½¿ç”¨è¶…æ—¶å¤„ç†
            # æ³¨æ„ï¼šakshare è·å–å®æ—¶è¡Œæƒ…æŒ‰è·Œå¹…æ’åº
            try:
                import signal
                
                def timeout_handler(signum, frame):
                    raise TimeoutError("è·å–è·Œå¹…æ¦œè¶…æ—¶")
                
                # è®¾ç½® 30 ç§’è¶…æ—¶
                signal.signal(signal.SIGALRM, timeout_handler)
                signal.alarm(30)
                
                df_market = ak.stock_zh_a_spot_em()
                
                # å–æ¶ˆè¶…æ—¶
                signal.alarm(0)
                
                # ç­›é€‰è·Œå¹…å‰3ä¸”æˆäº¤é¢ä¸ä¸º0çš„
                df_drop = df_market[df_market['æˆäº¤é¢'] > 0].sort_values(by='æ¶¨è·Œå¹…').head(3)
                
                for _, row in df_drop.iterrows():
                    # è¿‡æ»¤æ‰ ST å’Œé€€å¸‚è‚¡ (å¦‚æœä¸ç©åƒåœ¾è‚¡çš„è¯)
                    if 'ST' not in row['åç§°'] and 'é€€' not in row['åç§°']:
                        cases['traps'].append({
                            "code": row['ä»£ç '],
                            "name": row['åç§°'],
                            "reason": f"ğŸ’€ æ ¸æŒ‰é’®æƒ¨æ¡ˆ: è·Œå¹… {row['æ¶¨è·Œå¹…']}%, æˆäº¤{int(row['æˆäº¤é¢']/10000)}ä¸‡",
                            "type": "FATAL_TRAP",
                            "change_pct": float(row['æ¶¨è·Œå¹…']),
                            "amount": float(row['æˆäº¤é¢'])
                        })
            except (TimeoutError, Exception) as e:
                logger.warning(f"âš ï¸ è·å–è·Œå¹…æ¦œå¤±è´¥æˆ–è¶…æ—¶: {e}")
            
            # 3. (å¯é€‰) è¯†åˆ«å½“æ—¥"ç‚¸æ¿å¤§é¢" (æ›¾ç»æ¶¨åœï¼Œæ”¶ç›˜å¤§è·Œ)
            try:
                df_zha = ak.stock_zt_pool_zbgc_em(date=date_str) # ç‚¸æ¿è‚¡æ± 
                if df_zha is not None and not df_zha.empty:
                    worst_zha = df_zha.sort_values(by='æ¶¨è·Œå¹…').head(1) # ç‚¸å¾—æœ€æƒ¨çš„
                    for _, row in worst_zha.iterrows():
                        cases['traps'].append({
                            "code": row['ä»£ç '],
                            "name": row['åç§°'],
                            "reason": f"ğŸ©¸ ç‚¸æ¿å¤§é¢: æ¶¨åœè¢«ç ¸è‡³ {row['æ¶¨è·Œå¹…']}%, ä¹Ÿå°±æ˜¯æ‰€è°“çš„'å¤©åœ°æ¿'é£é™©",
                            "type": "FAILED_DRAGON",
                            "change_pct": float(row['æ¶¨è·Œå¹…'])
                        })
            except Exception as e:
                logger.warning(f"âš ï¸ è·å–ç‚¸æ¿è‚¡å¤±è´¥: {e}")
            
            # 4. ä¿å­˜æ¡ˆä¾‹é›†
            save_dir = "data/review_cases/golden_cases"
            if not os.path.exists(save_dir):
                os.makedirs(save_dir)
            
            file_path = f"{save_dir}/cases_{date_str}.json"
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(cases, f, ensure_ascii=False, indent=4)
            
            logger.info(f"âœ… é«˜ä»·å€¼æ¡ˆä¾‹å·²å½’æ¡£: {file_path}")
            logger.info(f"   - çœŸé¾™: {len(cases['dragons'])} åª")
            logger.info(f"   - å¤§å‘: {len(cases['traps'])} åª")
            logger.info(f"   - ç‚¸æ¿: {len([t for t in cases['traps'] if t['type'] == 'FAILED_DRAGON'])} åª")
            logger.info(f"   - å¸‚åœºæƒ…ç»ªè¯„åˆ†: {cases['market_score']}")
            
            return cases
        
        except Exception as e:
            logger.error(f"âŒ æ¡ˆä¾‹æ•è·å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None


# å•ä¾‹æµ‹è¯•
if __name__ == "__main__":
    rm = ReviewManager()
    # å°è¯•è·‘ä¸€ä¸‹æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥çš„æ•°æ® (æ³¨æ„ï¼šå¦‚æœæ˜¯å‘¨æœ«å¯èƒ½å–ä¸åˆ°ä»Šå¤©çš„ï¼Œakshareé€šå¸¸å»¶è¿Ÿ)
    # æˆ‘ä»¬å¯ä»¥å°è¯•å–ä¸Šå‘¨äº”çš„æ•°æ®æµ‹è¯•
    rm.run_daily_review(date='20260116')
    
    # è¯»å–æµ‹è¯•
    stats = rm.get_yesterday_stats()
    print("è¯»å–åˆ°çš„æ˜¨æ—¥çŠ¶æ€:", stats)
    
    # æµ‹è¯•é«˜ä»·å€¼æ¡ˆä¾‹æ•è·
    print("\n" + "="*60)
    print("æµ‹è¯•é«˜ä»·å€¼æ¡ˆä¾‹æ•è·")
    print("="*60)
    golden_cases = rm.capture_golden_cases(date='20260116')
    if golden_cases:
        print(f"âœ… æ•è·æˆåŠŸ!")
        print(f"   - æ—¥æœŸ: {golden_cases['date']}")
        print(f"   - çœŸé¾™: {len(golden_cases['dragons'])} åª")
        print(f"   - å¤§å‘: {len(golden_cases['traps'])} åª")
        print(f"   - ç‚¸æ¿: {len([t for t in golden_cases['traps'] if t['type'] == 'FAILED_DRAGON'])} åª")
    else:
        print("âŒ æ•è·å¤±è´¥")