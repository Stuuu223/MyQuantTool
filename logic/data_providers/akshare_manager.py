#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AkShareæ•°æ®ç®¡ç†å™¨ (V16.2 - ç¼“å­˜+é¢„çƒ­æ¶æ„)

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. å¼ºåˆ¶ç¼“å­˜ï¼šæ‰€æœ‰æ¥å£è°ƒç”¨å‰å…ˆæŸ¥ç£ç›˜ç¼“å­˜
2. åŒæ¨¡å¼æ§åˆ¶ï¼šwarmupæ¨¡å¼ï¼ˆå…è®¸è”ç½‘ï¼‰/readonlyæ¨¡å¼ï¼ˆåªè¯»ç¼“å­˜ï¼‰
3. é™é€Ÿä¿æŠ¤ï¼šä¸¥æ ¼éµå®ˆ200æ¬¡/å°æ—¶é™åˆ¶
4. TTLç®¡ç†ï¼šä¸åŒæ•°æ®ç±»å‹æœ‰ä¸åŒçš„æœ‰æ•ˆæœŸ

æ•°æ®ç±»å‹ï¼š
1. ä¸ªè‚¡èµ„é‡‘æµ - stock_individual_fund_flowï¼ˆè¿‘100æ—¥ä¸»åŠ›/è¶…å¤§å•ï¼‰
2. é¾™è™æ¦œ - stock_lhb_detail_emï¼ˆæ¯æ—¥è¯¦æƒ…ï¼‰
3. åŸºæœ¬é¢æŒ‡æ ‡ - stock_financial_analysis_indicatorï¼ˆè´¢åŠ¡æŒ‡æ ‡ï¼‰
4. æ˜¨æ—¥æ¶¨åœæ±  - stock_zt_pool_previous_emï¼ˆæ˜¨æ—¥æ¶¨åœï¼‰

V16.3å˜æ›´ï¼š
- âŒ å·²ç§»é™¤ï¼šä¸ªè‚¡æ–°é—»ï¼ˆstock_news_emï¼‰- æ ¹æ®"èµ„é‡‘ä¸ºç‹ï¼Œæ‹’ç»å™ªéŸ³"åŸåˆ™

Usage:
    # ç›˜å‰é¢„çƒ­æ¨¡å¼
    manager = AkShareDataManager(mode='warmup')
    manager.warmup_all()
    
    # ç›˜ä¸­åªè¯»æ¨¡å¼
    manager = AkShareDataManager(mode='readonly')
    data = manager.get_fund_flow('600519')

Architecture:
    ç›˜å‰é¢„çƒ­ï¼ˆ08:30-09:25ï¼‰: å…è®¸è”ç½‘æ‹‰æ•°æ® â†’ å†™å…¥ç¼“å­˜
    ç›˜ä¸­æ‰«æï¼ˆ09:30-15:00ï¼‰: åªè¯»ç¼“å­˜ï¼Œç»ä¸è”ç½‘
    ç›˜åå¤ç›˜ï¼ˆ17:00-20:00ï¼‰: å…è®¸è”ç½‘æ‹‰æ•°æ® â†’ æ›´æ–°ç¼“å­˜

Author: MyQuantTool Team
Date: 2026-02-16
Version: V16.2
"""

import sys
import os
import time
import json
import hashlib
from pathlib import Path
from datetime import datetime as dt_datetime, date as dt_date, timedelta as dt_timedelta
from typing import Optional, Dict, List, Any
from concurrent.futures import ThreadPoolExecutor, as_completed

# Windowsç¼–ç å«å£«
if sys.platform == 'win32':
    try:
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    except Exception:
        pass

try:
    import akshare as ak
    AKSHARE_AVAILABLE = True
except ImportError:
    AKSHARE_AVAILABLE = False
    print("[AkShareDataManager] âš ï¸ akshare æœªå®‰è£…ï¼Œç¼“å­˜æ¨¡å¼å°†æ— æ³•ä½¿ç”¨")

try:
    import pandas as pd
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False
    print("[AkShareDataManager] âš ï¸ pandas æœªå®‰è£…ï¼Œç¼“å­˜æ¨¡å¼å°†æ— æ³•ä½¿ç”¨")

from logic.utils.logger import get_logger
from logic.core.rate_limiter import get_rate_limiter
import random

logger = get_logger(__name__)


class PandasJSONEncoder(json.JSONEncoder):
    """è‡ªå®šä¹‰JSONç¼–ç å™¨ï¼Œå¤„ç†pandas DataFrameå’Œdateå¯¹è±¡"""

    def default(self, obj):
        if hasattr(obj, 'to_dict'):
            # pandas DataFrameæˆ–Series
            return obj.to_dict()
        elif hasattr(pd, 'NaT') and obj is pd.NaT:
            # pandas NaT
            return None
        elif hasattr(pd, 'Timestamp') and isinstance(obj, pd.Timestamp):
            # pandas Timestamp
            if pd.isna(obj):
                return None
            return obj.strftime('%Y-%m-%d %H:%M:%S')
        elif isinstance(obj, (dt_date, dt_datetime)):
            # Python dateæˆ–datetimeå¯¹è±¡
            return obj.strftime('%Y-%m-%d %H:%M:%S')
        elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes)):
            # å¯è¿­ä»£å¯¹è±¡ï¼ˆéå­—ç¬¦ä¸²/å­—èŠ‚ï¼‰
            try:
                return list(obj)
            except TypeError:
                return str(obj)
        else:
            # å…¶ä»–ç±»å‹ä½¿ç”¨é»˜è®¤å¤„ç†
            return super().default(obj)


class AkShareDataManager:
    """
    AkShareæ•°æ®ç®¡ç†å™¨ï¼ˆç¼“å­˜+é¢„çƒ­æ¶æ„ï¼‰
    
    æ ¸å¿ƒåŸåˆ™ï¼š
    1. ç›˜ä¸­åªè¯»ç¼“å­˜ï¼Œç»ä¸è”ç½‘
    2. ç›˜å‰é¢„çƒ­æ¨¡å¼ï¼Œå…è®¸è”ç½‘
    3. é™é€Ÿä¿æŠ¤ï¼Œé˜²æ­¢å°IP
    4. TTLç®¡ç†ï¼Œæ•°æ®æœ‰æ•ˆæ€§æ§åˆ¶
    
    æ¨¡å¼ï¼š
    - warmup: é¢„çƒ­æ¨¡å¼ï¼Œå…è®¸è”ç½‘æ‹‰æ•°æ®
    - readonly: åªè¯»æ¨¡å¼ï¼Œåªè¯»ç¼“å­˜
    """
    
    def __init__(self, mode: str = 'readonly', cache_dir: str = 'data/ak_cache'):
        """
        åˆå§‹åŒ–AkShareæ•°æ®ç®¡ç†å™¨

        Args:
            mode: è¿è¡Œæ¨¡å¼ï¼ˆ'warmup'æˆ–'readonly'ï¼‰
            cache_dir: ç¼“å­˜ç›®å½•
        """
        self.mode = mode
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)

        # V16.4.0: ä½¿ç”¨å…¨å±€é™æµå™¨ï¼ˆæ›¿ä»£åœŸåˆ¶é™é€Ÿï¼‰
        self.limiter = get_rate_limiter()
        # æ›´æ–°é™é€Ÿå‚æ•°ï¼ˆé’ˆå¯¹AkShareä¼˜åŒ–ï¼‰
        self.limiter.update_limits(
            max_requests_per_minute=60,
            max_requests_per_hour=2000,
            min_request_interval=0.1
        )

        # TTLé…ç½®ï¼ˆç§’ï¼‰
        self.ttl_config = {
            'fund_flow': 8 * 3600,  # 8å°æ—¶ï¼ˆå½“æ—¥æ”¶ç›˜å‰ï¼‰
            'lhb_detail': 24 * 3600,  # 24å°æ—¶ï¼ˆæ¬¡æ—¥æ”¶ç›˜å‰ï¼‰
            'financial_indicator': 7 * 24 * 3600,  # 7å¤©
            'limit_up_pool': 8 * 3600,  # 8å°æ—¶ï¼ˆå½“æ—¥æ”¶ç›˜å‰ï¼‰
        }

        print(f"[AkShareDataManager] âœ… åˆå§‹åŒ–å®Œæˆï¼Œæ¨¡å¼: {self.mode}, ç¼“å­˜ç›®å½•: {self.cache_dir}")
    
    def _check_rate_limit(self) -> None:
        """
        æ£€æŸ¥å¹¶æ‰§è¡Œé™é€Ÿä¿æŠ¤ï¼ˆV16.4.0: ä½¿ç”¨RateLimiterï¼‰

        åŠŸèƒ½ï¼š
        1. éšæœºå»¶è¿Ÿï¼ˆé˜²WAFæŒ‡çº¹è¯†åˆ«ï¼‰
        2. é™æµå™¨æ£€æŸ¥ï¼ˆè‡ªåŠ¨ç­‰å¾…ï¼‰
        3. è®°å½•è¯·æ±‚
        """
        if self.mode == 'readonly':
            return  # åªè¯»æ¨¡å¼ä¸é™é€Ÿ

        # V16.4.0: 1. å¼ºåˆ¶éšæœºå»¶è¿Ÿï¼ˆé˜²WAFæŒ‡çº¹è¯†åˆ«ï¼‰
        time.sleep(random.uniform(0.1, 0.3))

        # V16.4.0: 2. é™æµå™¨æ£€æŸ¥ï¼ˆè‡ªåŠ¨ç­‰å¾…ï¼‰
        self.limiter.wait_if_needed(url="akshare")
        self.limiter.record_request(url="akshare")
    
    def _get_cache_key(self, data_type: str, code: str, **kwargs) -> str:
        """
        ç”Ÿæˆç¼“å­˜é”®
        
        Args:
            data_type: æ•°æ®ç±»å‹
            code: è‚¡ç¥¨ä»£ç 
            **kwargs: å…¶ä»–å‚æ•°
        
        Returns:
            str: ç¼“å­˜é”®
        """
        # ç»„åˆæ‰€æœ‰å‚æ•°
        params = f"{data_type}_{code}"
        for k, v in sorted(kwargs.items()):
            params += f"_{k}_{v}"
        
        # ç”Ÿæˆå“ˆå¸Œ
        return hashlib.md5(params.encode('utf-8')).hexdigest()
    
    def _get_cache_file(self, cache_key: str) -> Path:
        """
        è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„
        
        Args:
            cache_key: ç¼“å­˜é”®
        
        Returns:
            Path: ç¼“å­˜æ–‡ä»¶è·¯å¾„
        """
        return self.cache_dir / f"{cache_key}.json"
    
    def _read_cache(self, cache_key: str) -> Optional[Dict]:
        """
        è¯»å–ç¼“å­˜
        
        Args:
            cache_key: ç¼“å­˜é”®
        
        Returns:
            Optional[Dict]: ç¼“å­˜æ•°æ®ï¼Œå¦‚æœä¸å­˜åœ¨æˆ–è¿‡æœŸè¿”å›None
        """
        cache_file = self._get_cache_file(cache_key)
        
        if not cache_file.exists():
            return None
        
        try:
            with open(cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            # æ£€æŸ¥TTL
            fetch_time = cache_data.get('fetch_time', 0)
            data_type = cache_data.get('data_type', '')
            ttl = self.ttl_config.get(data_type, 3600)
            
            if time.time() - fetch_time > ttl:
                logger.debug(f"[AkShareDataManager] ç¼“å­˜è¿‡æœŸ: {cache_key}")
                return None
            
            return cache_data
        except Exception as e:
            logger.warning(f"[AkShareDataManager] è¯»å–ç¼“å­˜å¤±è´¥: {e}")
            return None
    
    def _write_cache(self, cache_key: str, data_type: str, data: Any) -> None:
        """
        å†™å…¥ç¼“å­˜

        Args:
            cache_key: ç¼“å­˜é”®
            data_type: æ•°æ®ç±»å‹
            data: æ•°æ®
        """
        cache_file = self._get_cache_file(cache_key)

        try:
            cache_data = {
                'data_type': data_type,
                'fetch_time': time.time(),
                'data': data,
                'cache_key': cache_key
            }

            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2, cls=PandasJSONEncoder)

            logger.debug(f"[AkShareDataManager] ç¼“å­˜å†™å…¥æˆåŠŸ: {cache_key}")
        except Exception as e:
            logger.error(f"[AkShareDataManager] å†™å…¥ç¼“å­˜å¤±è´¥: {e} (file: {cache_file})")
    
    def get_fund_flow(self, code: str, days: int = 100) -> Optional[Dict]:
        """
        è·å–ä¸ªè‚¡èµ„é‡‘æµï¼ˆå¸¦ç¼“å­˜ï¼‰

        Args:
            code: è‚¡ç¥¨ä»£ç 
            days: å¤©æ•°

        Returns:
            Optional[Dict]: èµ„é‡‘æµæ•°æ®ï¼Œå¦‚æœç¼“å­˜ä¸å­˜åœ¨è¿”å›None
        """
        cache_key = self._get_cache_key('fund_flow', code, days=days)

        # å°è¯•è¯»å–ç¼“å­˜
        cached_data = self._read_cache(cache_key)
        if cached_data is not None:
            return cached_data['data']

        # åªè¯»æ¨¡å¼ï¼šç¼“å­˜ä¸å­˜åœ¨è¿”å›None
        if self.mode == 'readonly':
            logger.debug(f"[AkShareDataManager] åªè¯»æ¨¡å¼ï¼šèµ„é‡‘æµç¼“å­˜ä¸å­˜åœ¨ {code}")
            return None

        # é¢„çƒ­æ¨¡å¼ï¼šè”ç½‘æ‹‰å–
        if not AKSHARE_AVAILABLE:
            logger.warning("[AkShareDataManager] akshare æœªå®‰è£…")
            return None

        try:
            self._check_rate_limit()

            # è§£æè‚¡ç¥¨ä»£ç å’Œå¸‚åœº
            # codeæ ¼å¼: "600000.SH" æˆ– "000001.SZ"
            if '.' in code:
                stock_code, market = code.split('.')
                market = market.lower()  # sh, sz
            else:
                # å¦‚æœæ²¡æœ‰åç¼€ï¼Œé»˜è®¤ä¸ºsh
                stock_code = code
                market = 'sh'

            # æ‹‰å–æ•°æ®ï¼ˆæ­£ç¡®çš„APIç­¾åï¼‰
            df = ak.stock_individual_fund_flow(stock=stock_code, market=market)

            # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
            if df is None or df.empty:
                logger.warning(f"[AkShareDataManager] èµ„é‡‘æµæ•°æ®ä¸ºç©º: {code}")
                return None

            # å†™å…¥ç¼“å­˜
            self._write_cache(cache_key, 'fund_flow', df)

            return df.to_dict()
        except Exception as e:
            logger.warning(f"[AkShareDataManager] è·å–èµ„é‡‘æµå¤±è´¥ {code}: {e}")
            return None
    
    def get_lhb_detail(self, date: str = None) -> Optional[List[Dict]]:
        """
        è·å–é¾™è™æ¦œè¯¦æƒ…ï¼ˆå¸¦ç¼“å­˜å’Œæ•°æ®æ¸…æ´—ï¼‰

        æ•°æ®æ¸…æ´—ï¼šæå–æ ¸å¿ƒå­—æ®µï¼Œè¿‡æ»¤æ— å…³ä¿¡æ¯

        Args:
            date: æ—¥æœŸï¼ˆYYYYMMDDï¼‰ï¼Œé»˜è®¤ä¸ºæœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥

        Returns:
            Optional[List[Dict]]: æ¸…æ´—åçš„é¾™è™æ¦œæ•°æ®ï¼Œå¦‚æœç¼“å­˜ä¸å­˜åœ¨è¿”å›None
        """
        if date is None:
            date = (dt_datetime.now() - dt_timedelta(days=1)).strftime('%Y%m%d')

        cache_key = self._get_cache_key('lhb_detail', date)

        # å°è¯•è¯»å–ç¼“å­˜
        cached_data = self._read_cache(cache_key)
        if cached_data is not None:
            return cached_data['data']

        # åªè¯»æ¨¡å¼ï¼šç¼“å­˜ä¸å­˜åœ¨è¿”å›None
        if self.mode == 'readonly':
            logger.debug(f"[AkShareDataManager] åªè¯»æ¨¡å¼ï¼šé¾™è™æ¦œç¼“å­˜ä¸å­˜åœ¨ {date}")
            return None

        # é¢„çƒ­æ¨¡å¼ï¼šè”ç½‘æ‹‰å–
        if not AKSHARE_AVAILABLE:
            logger.warning("[AkShareDataManager] akshare æœªå®‰è£…")
            return None

        try:
            self._check_rate_limit()

            # æ‹‰å–æ•°æ®ï¼ˆæ­£ç¡®çš„APIç­¾åï¼šä½¿ç”¨start_dateå’Œend_dateï¼‰
            df = ak.stock_lhb_detail_em(start_date=date, end_date=date)

            # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
            if df is None or df.empty:
                logger.warning(f"[AkShareDataManager] é¾™è™æ¦œæ•°æ®ä¸ºç©º: {date}")
                return None

            # ========== æ•°æ®æ¸…æ´—ï¼šæå–æ ¸å¿ƒå­—æ®µ ==========
            # æ ¸å¿ƒå­—æ®µåˆ—è¡¨ï¼ˆæ ¹æ®CTOè¦æ±‚ï¼‰
            core_columns = [
                'ä»£ç ',           # è‚¡ç¥¨ä»£ç 
                'åç§°',           # è‚¡ç¥¨åç§°
                'ä¸Šæ¦œæ—¥',         # ä¸Šæ¦œæ—¥æœŸ
                'è§£è¯»',           # è§£è¯»åˆ†æ
                'é¾™è™æ¦œå‡€ä¹°é¢',   # å‡€ä¹°å…¥é¢
                'é¾™è™æ¦œä¹°å…¥é¢',   # ä¹°å…¥é¢
                'é¾™è™æ¦œå–å‡ºé¢',   # å–å‡ºé¢
                'é¾™è™æ¦œæˆäº¤é¢',   # æˆäº¤é¢
                'ä¸Šæ¦œåŸå› ',       # ä¸Šæ¦œåŸå› 
                'ä¸Šæ¦œå1æ—¥',      # å1æ—¥è¡¨ç°
                'ä¸Šæ¦œå2æ—¥',      # å2æ—¥è¡¨ç°
                'ä¸Šæ¦œå5æ—¥',      # å5æ—¥è¡¨ç°
                'ä¸Šæ¦œå10æ—¥'      # å10æ—¥è¡¨ç°
            ]

            # æ£€æŸ¥æ ¸å¿ƒå­—æ®µæ˜¯å¦å­˜åœ¨
            available_columns = [col for col in core_columns if col in df.columns]
            if len(available_columns) < len(core_columns):
                missing = set(core_columns) - set(available_columns)
                logger.warning(f"[AkShareDataManager] é¾™è™æ¦œæ•°æ®å­—æ®µç¼ºå¤±: {missing}")

            # åªä¿ç•™æ ¸å¿ƒå­—æ®µ
            df_cleaned = df[available_columns].copy()

            # å†™å…¥ç¼“å­˜
            self._write_cache(cache_key, 'lhb_detail', df_cleaned)

            logger.info(f"[AkShareDataManager] âœ… é¾™è™æ¦œæ•°æ®è·å–æˆåŠŸ: {date}, {len(df_cleaned)}åªè‚¡ç¥¨, {len(available_columns)}ä¸ªæ ¸å¿ƒå­—æ®µ")

            return df_cleaned.to_dict()
        except Exception as e:
            logger.warning(f"[AkShareDataManager] è·å–é¾™è™æ¦œå¤±è´¥ {date}: {e}")
            return None
    
    def get_financial_indicator(self, code: str) -> Optional[Dict]:
        """
        è·å–åŸºæœ¬é¢æŒ‡æ ‡ï¼ˆå¸¦ç¼“å­˜å’Œé™çº§ç­–ç•¥ï¼‰

        é™çº§ç­–ç•¥ï¼š
        1. ä¼˜å…ˆä½¿ç”¨ stock_financial_analysis_indicatorï¼ˆè¯¦ç»†æŒ‡æ ‡ï¼‰
        2. å¤±è´¥æ—¶é™çº§åˆ° stock_financial_abstractï¼ˆç®€ç•¥æŒ‡æ ‡ï¼‰
        3. ä¸¤è€…éƒ½å¤±è´¥æ—¶è¿”å› Noneï¼Œå¹¶æ ‡è®°æ•°æ®ç¼ºå¤±

        Args:
            code: è‚¡ç¥¨ä»£ç 

        Returns:
            Optional[Dict]: åŸºæœ¬é¢æ•°æ®ï¼ŒåŒ…å« data_source æ ‡è¯†æ¥æº
        """
        cache_key = self._get_cache_key('financial_indicator', code)

        # å°è¯•è¯»å–ç¼“å­˜
        cached_data = self._read_cache(cache_key)
        if cached_data is not None:
            return cached_data['data']

        # åªè¯»æ¨¡å¼ï¼šç¼“å­˜ä¸å­˜åœ¨è¿”å›None
        if self.mode == 'readonly':
            logger.debug(f"[AkShareDataManager] åªè¯»æ¨¡å¼ï¼šåŸºæœ¬é¢ç¼“å­˜ä¸å­˜åœ¨ {code}")
            return None

        # é¢„çƒ­æ¨¡å¼ï¼šè”ç½‘æ‹‰å–
        if not AKSHARE_AVAILABLE:
            logger.warning("[AkShareDataManager] akshare æœªå®‰è£…")
            return None

        # æå–çº¯æ•°å­—ä»£ç ï¼ˆç§»é™¤å¸‚åœºåç¼€ï¼‰
        symbol = code.split('.')[0] if '.' in code else code

        # ========== ç­–ç•¥1ï¼šå°è¯•è·å–è¯¦ç»†æŒ‡æ ‡ ==========
        try:
            self._check_rate_limit()
            df = ak.stock_financial_analysis_indicator(symbol=symbol)

            if df is not None and not df.empty:
                # æ·»åŠ æ•°æ®æ¥æºæ ‡è¯†
                result = df.to_dict()
                result['_metadata'] = {
                    'data_source': 'stock_financial_analysis_indicator',
                    'symbol': symbol,
                    'timestamp': dt_datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
                self._write_cache(cache_key, 'financial_indicator', df)
                logger.info(f"[AkShareDataManager] âœ… åŸºæœ¬é¢æŒ‡æ ‡è·å–æˆåŠŸï¼ˆè¯¦ç»†æ¨¡å¼ï¼‰: {code}")
                return result
        except Exception as e:
            logger.warning(f"[AkShareDataManager] âš ï¸ è¯¦ç»†æŒ‡æ ‡è·å–å¤±è´¥ï¼Œå¯ç”¨é™çº§ç­–ç•¥: {code} - {e}")

        # ========== ç­–ç•¥2ï¼šé™çº§åˆ°ç®€ç•¥æŒ‡æ ‡ ==========
        try:
            self._check_rate_limit()
            df = ak.stock_financial_abstract(symbol=symbol)

            if df is not None and not df.empty:
                # æ·»åŠ æ•°æ®æ¥æºæ ‡è¯†
                result = df.to_dict()
                result['_metadata'] = {
                    'data_source': 'stock_financial_abstract (é™çº§æ¨¡å¼)',
                    'symbol': symbol,
                    'timestamp': dt_datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'warning': 'ä½¿ç”¨é™çº§æ•°æ®æºï¼ŒæŒ‡æ ‡å¯èƒ½ä¸å®Œæ•´'
                }
                self._write_cache(cache_key, 'financial_indicator', df)
                logger.info(f"[AkShareDataManager] âœ… åŸºæœ¬é¢æŒ‡æ ‡è·å–æˆåŠŸï¼ˆé™çº§æ¨¡å¼ï¼‰: {code}")
                return result
            else:
                logger.warning(f"[AkShareDataManager] âš ï¸ é™çº§æ•°æ®æºè¿”å›ç©º: {code}")
        except Exception as e:
            logger.error(f"[AkShareDataManager] âŒ é™çº§æ•°æ®æºä¹Ÿå¤±è´¥: {code} - {e}")

        # ========== ç­–ç•¥3ï¼šæ•°æ®ç¼ºå¤±è­¦å‘Š ==========
        logger.error(f"[AkShareDataManager] â›” FUNDAMENTAL DATA MISSING: {code} - æ‰€æœ‰æ•°æ®æºå‡å¤±è´¥")
        return None
    
    def get_limit_up_pool(self, date: str = None) -> Optional[List[str]]:
        """
        è·å–æ˜¨æ—¥æ¶¨åœæ± ï¼ˆå¸¦ç¼“å­˜ï¼‰

        Args:
            date: æ—¥æœŸï¼ˆYYYYMMDDï¼‰ï¼Œé»˜è®¤ä¸ºæ˜¨æ—¥

        Returns:
            Optional[List[str]]: æ¶¨åœè‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œå¦‚æœç¼“å­˜ä¸å­˜åœ¨è¿”å›None
        """
        if date is None:
            date = (dt_datetime.now() - dt_timedelta(days=1)).strftime('%Y%m%d')

        cache_key = self._get_cache_key('limit_up_pool', date)
        
        # å°è¯•è¯»å–ç¼“å­˜
        cached_data = self._read_cache(cache_key)
        if cached_data is not None:
            return cached_data['data']
        
        # åªè¯»æ¨¡å¼ï¼šç¼“å­˜ä¸å­˜åœ¨è¿”å›None
        if self.mode == 'readonly':
            logger.debug(f"[AkShareDataManager] åªè¯»æ¨¡å¼ï¼šæ¶¨åœæ± ç¼“å­˜ä¸å­˜åœ¨ {date}")
            return None
        
        # é¢„çƒ­æ¨¡å¼ï¼šè”ç½‘æ‹‰å–
        if not AKSHARE_AVAILABLE:
            logger.warning("[AkShareDataManager] akshare æœªå®‰è£…")
            return None
        
        try:
            self._check_rate_limit()
            
            # æ‹‰å–æ•°æ®
            df = ak.stock_zt_pool_previous_em(date=date)
            
            if not df.empty:
                codes = df['ä»£ç '].tolist()
                self._write_cache(cache_key, 'limit_up_pool', codes)
                return codes
            
            return None
        except Exception as e:
            logger.warning(f"[AkShareDataManager] è·å–æ¶¨åœæ± å¤±è´¥ {date}: {e}")
            return None
    
    def warmup_all(self, stock_list: List[str] = None) -> Dict[str, Any]:
        """
        é¢„çƒ­æ‰€æœ‰æ•°æ®ï¼ˆç›˜å‰è°ƒç”¨ï¼‰
        
        Args:
            stock_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆç”¨äºé¢„çƒ­ä¸ªè‚¡æ•°æ®ï¼‰
        
        Returns:
            Dict: é¢„çƒ­æŠ¥å‘Š
        """
        print("[AkShareDataManager] ğŸš€ å¼€å§‹é¢„çƒ­æ‰€æœ‰æ•°æ®...")
        
        report = {
            'fund_flow': {'success': 0, 'failed': 0},
            'lhb_detail': {'success': 0, 'failed': 0},
            'financial_indicator': {'success': 0, 'failed': 0},
            'limit_up_pool': {'success': 0, 'failed': 0},
        }
        
        # é¢„çƒ­æ¶¨åœæ± 
        print("[AkShareDataManager] 1ï¸âƒ£ é¢„çƒ­æ¶¨åœæ± ...")
        if self.get_limit_up_pool() is not None:
            report['limit_up_pool']['success'] = 1
        else:
            report['limit_up_pool']['failed'] = 1
        
        # é¢„çƒ­é¾™è™æ¦œ
        print("[AkShareDataManager] 2ï¸âƒ£ é¢„çƒ­é¾™è™æ¦œ...")
        if self.get_lhb_detail() is not None:
            report['lhb_detail']['success'] = 1
        else:
            report['lhb_detail']['failed'] = 1
        
        # é¢„çƒ­ä¸ªè‚¡æ•°æ®ï¼ˆå¦‚æœæœ‰è‚¡ç¥¨åˆ—è¡¨ï¼‰
        if stock_list:
            print(f"[AkShareDataManager] 3ï¸âƒ£ é¢„çƒ­ä¸ªè‚¡æ•°æ®ï¼ˆ{len(stock_list)}åªè‚¡ç¥¨ï¼‰...")
            
            # ğŸ”¥ [V16.2.1 ä¿®å¤] åˆ é™¤ç¡¬ç¼–ç é™åˆ¶ï¼Œé¢„çƒ­æ‰€æœ‰è‚¡ç¥¨
            # å¢åŠ è¿›åº¦æ˜¾ç¤º
            total = len(stock_list)
            for i, code in enumerate(stock_list, 1):
                # æ¯å¤„ç†10åªè‚¡ç¥¨æ‰“å°ä¸€æ¬¡è¿›åº¦
                if i % 10 == 0:
                    print(f"[AkShareDataManager] è¿›åº¦: {i}/{total} ({i/total*100:.0f}%)")
                
                # é¢„çƒ­èµ„é‡‘æµ
                if self.get_fund_flow(code) is not None:
                    report['fund_flow']['success'] += 1
                else:
                    report['fund_flow']['failed'] += 1
                
                # é¢„çƒ­åŸºæœ¬é¢
                if self.get_financial_indicator(code) is not None:
                    report['financial_indicator']['success'] += 1
                else:
                    report['financial_indicator']['failed'] += 1
            
            print(f"[AkShareDataManager] âœ… ä¸ªè‚¡æ•°æ®é¢„çƒ­å®Œæˆ: {total}åªè‚¡ç¥¨")
        
        # ä¿å­˜é¢„çƒ­æŠ¥å‘Š
        report_file = self.cache_dir / 'warmup_report.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"[AkShareDataManager] âœ… é¢„çƒ­å®Œæˆï¼ŒæŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        return report


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("=" * 80)
    print("AkShareDataManager æµ‹è¯•")
    print("=" * 80)
    
    # 1. é¢„çƒ­æ¨¡å¼æµ‹è¯•
    print("\nğŸš€ é¢„çƒ­æ¨¡å¼æµ‹è¯•:")
    manager = AkShareDataManager(mode='warmup')
    
    # é¢„çƒ­æ¶¨åœæ± 
    limit_up_pool = manager.get_limit_up_pool()
    if limit_up_pool:
        print(f"  âœ… æ¶¨åœæ± : {len(limit_up_pool)}åªè‚¡ç¥¨")
    else:
        print(f"  âŒ æ¶¨åœæ± : è·å–å¤±è´¥")
    
    # 2. åªè¯»æ¨¡å¼æµ‹è¯•
    print("\nğŸ”’ åªè¯»æ¨¡å¼æµ‹è¯•:")
    manager = AkShareDataManager(mode='readonly')
    
    # è¯»å–æ¶¨åœæ± ï¼ˆä»ç¼“å­˜ï¼‰
    limit_up_pool = manager.get_limit_up_pool()
    if limit_up_pool:
        print(f"  âœ… æ¶¨åœæ± ï¼ˆç¼“å­˜ï¼‰: {len(limit_up_pool)}åªè‚¡ç¥¨")
    else:
        print(f"  âŒ æ¶¨åœæ± ï¼ˆç¼“å­˜ï¼‰: ç¼“å­˜ä¸å­˜åœ¨")
    
    print("\n" + "=" * 80)
    print("âœ… æµ‹è¯•å®Œæˆ")
    print("=" * 80)
