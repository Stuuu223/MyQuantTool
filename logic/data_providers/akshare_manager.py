#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AkShareæ•°æ®ç®¡ç†å™¨ (V16.2 - ç¼“å­˜+é¢„çƒ­æ¶æ„)

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. å¼ºåˆ¶ç¼“å­˜ï¼šæ‰€æœ‰æ¥å£è°ƒç”¨å‰å…ˆæŸ¥ç£ç›˜ç¼“å­˜
2. åŒæ¨¡å¼æ§åˆ¶ï¼šwarmupæ¨¡å¼ï¼ˆå…è®¸è”ç½‘ï¼‰/readonlyæ¨¡å¼ï¼ˆåªè¯»ç¼“å­˜ï¼‰
3. é™é€Ÿä¿æŠ¤ï¼šä¸¥æ ¼éµå®ˆ200æ¬¡/å°æ—¶é™åˆ¶
4. TTLç®¡ç†ï¼šä¸åŒæ•°æ®ç±»å‹æœ‰ä¸åŒçš„æœ‰æ•ˆæœŸ

æ•°æ®ç±»å‹ï¼š
1. ä¸ªè‚¡èµ„é‡‘æµ - stock_individual_fund_flowï¼ˆè¿‘100æ—¥ä¸»åŠ›/è¶…å¤§å•ï¼‰
2. ä¸ªè‚¡æ–°é—» - stock_news_emï¼ˆæœ€è¿‘20æ¡ï¼‰
3. é¾™è™æ¦œ - stock_lhb_detail_emï¼ˆæ¯æ—¥è¯¦æƒ…ï¼‰
4. åŸºæœ¬é¢æŒ‡æ ‡ - stock_financial_analysis_indicatorï¼ˆè´¢åŠ¡æŒ‡æ ‡ï¼‰
5. æ˜¨æ—¥æ¶¨åœæ±  - stock_zt_pool_previous_emï¼ˆæ˜¨æ—¥æ¶¨åœï¼‰

Usage:
    # ç›˜å‰é¢„çƒ­æ¨¡å¼
    manager = AkShareDataManager(mode='warmup')
    manager.warmup_all()
    
    # ç›˜ä¸­åªè¯»æ¨¡å¼
    manager = AkShareDataManager(mode='readonly')
    data = manager.get_fund_flow('600519')

Architecture:
    ç›˜å‰é¢„çƒ­ï¼ˆ08:30-09:25ï¼‰: å…è®¸è”ç½‘æ‹‰æ•°æ® â†’ å†™å…¥ç¼“å­˜
    ç›˜ä¸­æ‰«æï¼ˆ09:30-15:00ï¼‰: åªè¯»ç¼“å­˜ï¼Œç»ä¸è”ç½‘
    ç›˜åå¤ç›˜ï¼ˆ17:00-20:00ï¼‰: å…è®¸è”ç½‘æ‹‰æ•°æ® â†’ æ›´æ–°ç¼“å­˜

Author: MyQuantTool Team
Date: 2026-02-16
Version: V16.2
"""

import sys
import os
import time
import json
import hashlib
from pathlib import Path
from datetime import datetime as dt_datetime, date as dt_date, timedelta as dt_timedelta
from typing import Optional, Dict, List, Any
from concurrent.futures import ThreadPoolExecutor, as_completed

# Windowsç¼–ç å«å£«
if sys.platform == 'win32':
    try:
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    except Exception:
        pass

try:
    import akshare as ak
    AKSHARE_AVAILABLE = True
except ImportError:
    AKSHARE_AVAILABLE = False
    print("[AkShareDataManager] âš ï¸ akshare æœªå®‰è£…ï¼Œç¼“å­˜æ¨¡å¼å°†æ— æ³•ä½¿ç”¨")

try:
    import pandas as pd
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False
    print("[AkShareDataManager] âš ï¸ pandas æœªå®‰è£…ï¼Œç¼“å­˜æ¨¡å¼å°†æ— æ³•ä½¿ç”¨")

from logic.utils.logger import get_logger

logger = get_logger(__name__)


class PandasJSONEncoder(json.JSONEncoder):
    """è‡ªå®šä¹‰JSONç¼–ç å™¨ï¼Œå¤„ç†pandas DataFrameå’Œdateå¯¹è±¡"""

    def default(self, obj):
        if hasattr(obj, 'to_dict'):
            # pandas DataFrameæˆ–Series
            return obj.to_dict()
        elif hasattr(pd, 'NaT') and obj is pd.NaT:
            # pandas NaT
            return None
        elif hasattr(pd, 'Timestamp') and isinstance(obj, pd.Timestamp):
            # pandas Timestamp
            if pd.isna(obj):
                return None
            return obj.strftime('%Y-%m-%d %H:%M:%S')
        elif isinstance(obj, (dt_date, dt_datetime)):
            # Python dateæˆ–datetimeå¯¹è±¡
            return obj.strftime('%Y-%m-%d %H:%M:%S')
        elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes)):
            # å¯è¿­ä»£å¯¹è±¡ï¼ˆéå­—ç¬¦ä¸²/å­—èŠ‚ï¼‰
            try:
                return list(obj)
            except TypeError:
                return str(obj)
        else:
            # å…¶ä»–ç±»å‹ä½¿ç”¨é»˜è®¤å¤„ç†
            return super().default(obj)


class AkShareDataManager:
    """
    AkShareæ•°æ®ç®¡ç†å™¨ï¼ˆç¼“å­˜+é¢„çƒ­æ¶æ„ï¼‰
    
    æ ¸å¿ƒåŸåˆ™ï¼š
    1. ç›˜ä¸­åªè¯»ç¼“å­˜ï¼Œç»ä¸è”ç½‘
    2. ç›˜å‰é¢„çƒ­æ¨¡å¼ï¼Œå…è®¸è”ç½‘
    3. é™é€Ÿä¿æŠ¤ï¼Œé˜²æ­¢å°IP
    4. TTLç®¡ç†ï¼Œæ•°æ®æœ‰æ•ˆæ€§æ§åˆ¶
    
    æ¨¡å¼ï¼š
    - warmup: é¢„çƒ­æ¨¡å¼ï¼Œå…è®¸è”ç½‘æ‹‰æ•°æ®
    - readonly: åªè¯»æ¨¡å¼ï¼Œåªè¯»ç¼“å­˜
    """
    
    def __init__(self, mode: str = 'readonly', cache_dir: str = 'data/ak_cache'):
        """
        åˆå§‹åŒ–AkShareæ•°æ®ç®¡ç†å™¨
        
        Args:
            mode: è¿è¡Œæ¨¡å¼ï¼ˆ'warmup'æˆ–'readonly'ï¼‰
            cache_dir: ç¼“å­˜ç›®å½•
        """
        self.mode = mode
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # é™é€Ÿä¿æŠ¤ï¼š200æ¬¡/å°æ—¶
        self.rate_limit = 200
        self.rate_window = 3600  # 1å°æ—¶
        self.request_times = []
        
        # TTLé…ç½®ï¼ˆç§’ï¼‰
        self.ttl_config = {
            'fund_flow': 8 * 3600,  # 8å°æ—¶ï¼ˆå½“æ—¥æ”¶ç›˜å‰ï¼‰
            'news': 4 * 3600,  # 4å°æ—¶
            'lhb_detail': 24 * 3600,  # 24å°æ—¶ï¼ˆæ¬¡æ—¥æ”¶ç›˜å‰ï¼‰
            'financial_indicator': 7 * 24 * 3600,  # 7å¤©
            'limit_up_pool': 8 * 3600,  # 8å°æ—¶ï¼ˆå½“æ—¥æ”¶ç›˜å‰ï¼‰
        }
        
        print(f"[AkShareDataManager] âœ… åˆå§‹åŒ–å®Œæˆï¼Œæ¨¡å¼: {self.mode}, ç¼“å­˜ç›®å½•: {self.cache_dir}")
    
    def _check_rate_limit(self) -> None:
        """
        æ£€æŸ¥å¹¶æ‰§è¡Œé™é€Ÿä¿æŠ¤
        
        Raises:
            RuntimeError: è¶…è¿‡é™é€Ÿé˜ˆå€¼
        """
        if self.mode == 'readonly':
            return  # åªè¯»æ¨¡å¼ä¸é™é€Ÿ
        
        now = time.time()
        
        # æ¸…ç†è¿‡æœŸè®°å½•
        self.request_times = [t for t in self.request_times if now - t < self.rate_window]
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™é€Ÿ
        if len(self.request_times) >= self.rate_limit:
            raise RuntimeError(
                f"[AkShareDataManager] âš ï¸ è¶…è¿‡é™é€Ÿé˜ˆå€¼ï¼"
                f"å½“å‰è¯·æ±‚: {len(self.request_times)}, é™åˆ¶: {self.rate_limit}/{self.rate_window}ç§’"
            )
        
        # è®°å½•æœ¬æ¬¡è¯·æ±‚
        self.request_times.append(now)
    
    def _get_cache_key(self, data_type: str, code: str, **kwargs) -> str:
        """
        ç”Ÿæˆç¼“å­˜é”®
        
        Args:
            data_type: æ•°æ®ç±»å‹
            code: è‚¡ç¥¨ä»£ç 
            **kwargs: å…¶ä»–å‚æ•°
        
        Returns:
            str: ç¼“å­˜é”®
        """
        # ç»„åˆæ‰€æœ‰å‚æ•°
        params = f"{data_type}_{code}"
        for k, v in sorted(kwargs.items()):
            params += f"_{k}_{v}"
        
        # ç”Ÿæˆå“ˆå¸Œ
        return hashlib.md5(params.encode('utf-8')).hexdigest()
    
    def _get_cache_file(self, cache_key: str) -> Path:
        """
        è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„
        
        Args:
            cache_key: ç¼“å­˜é”®
        
        Returns:
            Path: ç¼“å­˜æ–‡ä»¶è·¯å¾„
        """
        return self.cache_dir / f"{cache_key}.json"
    
    def _read_cache(self, cache_key: str) -> Optional[Dict]:
        """
        è¯»å–ç¼“å­˜
        
        Args:
            cache_key: ç¼“å­˜é”®
        
        Returns:
            Optional[Dict]: ç¼“å­˜æ•°æ®ï¼Œå¦‚æœä¸å­˜åœ¨æˆ–è¿‡æœŸè¿”å›None
        """
        cache_file = self._get_cache_file(cache_key)
        
        if not cache_file.exists():
            return None
        
        try:
            with open(cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            # æ£€æŸ¥TTL
            fetch_time = cache_data.get('fetch_time', 0)
            data_type = cache_data.get('data_type', '')
            ttl = self.ttl_config.get(data_type, 3600)
            
            if time.time() - fetch_time > ttl:
                logger.debug(f"[AkShareDataManager] ç¼“å­˜è¿‡æœŸ: {cache_key}")
                return None
            
            return cache_data
        except Exception as e:
            logger.warning(f"[AkShareDataManager] è¯»å–ç¼“å­˜å¤±è´¥: {e}")
            return None
    
    def _write_cache(self, cache_key: str, data_type: str, data: Any) -> None:
        """
        å†™å…¥ç¼“å­˜

        Args:
            cache_key: ç¼“å­˜é”®
            data_type: æ•°æ®ç±»å‹
            data: æ•°æ®
        """
        cache_file = self._get_cache_file(cache_key)

        try:
            cache_data = {
                'data_type': data_type,
                'fetch_time': time.time(),
                'data': data,
                'cache_key': cache_key
            }

            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2, cls=PandasJSONEncoder)

            logger.debug(f"[AkShareDataManager] ç¼“å­˜å†™å…¥æˆåŠŸ: {cache_key}")
        except Exception as e:
            logger.error(f"[AkShareDataManager] å†™å…¥ç¼“å­˜å¤±è´¥: {e} (file: {cache_file})")
    
    def get_fund_flow(self, code: str, days: int = 100) -> Optional[Dict]:
        """
        è·å–ä¸ªè‚¡èµ„é‡‘æµï¼ˆå¸¦ç¼“å­˜ï¼‰

        Args:
            code: è‚¡ç¥¨ä»£ç 
            days: å¤©æ•°

        Returns:
            Optional[Dict]: èµ„é‡‘æµæ•°æ®ï¼Œå¦‚æœç¼“å­˜ä¸å­˜åœ¨è¿”å›None
        """
        cache_key = self._get_cache_key('fund_flow', code, days=days)

        # å°è¯•è¯»å–ç¼“å­˜
        cached_data = self._read_cache(cache_key)
        if cached_data is not None:
            return cached_data['data']

        # åªè¯»æ¨¡å¼ï¼šç¼“å­˜ä¸å­˜åœ¨è¿”å›None
        if self.mode == 'readonly':
            logger.debug(f"[AkShareDataManager] åªè¯»æ¨¡å¼ï¼šèµ„é‡‘æµç¼“å­˜ä¸å­˜åœ¨ {code}")
            return None

        # é¢„çƒ­æ¨¡å¼ï¼šè”ç½‘æ‹‰å–
        if not AKSHARE_AVAILABLE:
            logger.warning("[AkShareDataManager] akshare æœªå®‰è£…")
            return None

        try:
            self._check_rate_limit()

            # è§£æè‚¡ç¥¨ä»£ç å’Œå¸‚åœº
            # codeæ ¼å¼: "600000.SH" æˆ– "000001.SZ"
            if '.' in code:
                stock_code, market = code.split('.')
                market = market.lower()  # sh, sz
            else:
                # å¦‚æœæ²¡æœ‰åç¼€ï¼Œé»˜è®¤ä¸ºsh
                stock_code = code
                market = 'sh'

            # æ‹‰å–æ•°æ®ï¼ˆæ­£ç¡®çš„APIç­¾åï¼‰
            df = ak.stock_individual_fund_flow(stock=stock_code, market=market)

            # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
            if df is None or df.empty:
                logger.warning(f"[AkShareDataManager] èµ„é‡‘æµæ•°æ®ä¸ºç©º: {code}")
                return None

            # å†™å…¥ç¼“å­˜
            self._write_cache(cache_key, 'fund_flow', df)

            return df.to_dict()
        except Exception as e:
            logger.warning(f"[AkShareDataManager] è·å–èµ„é‡‘æµå¤±è´¥ {code}: {e}")
            return None
    
    def get_news(self, code: str) -> Optional[List[Dict]]:
        """
        è·å–ä¸ªè‚¡æ–°é—»ï¼ˆå¸¦ç¼“å­˜ï¼‰
        
        Args:
            code: è‚¡ç¥¨ä»£ç 
        
        Returns:
            Optional[List[Dict]]: æ–°é—»åˆ—è¡¨ï¼Œå¦‚æœç¼“å­˜ä¸å­˜åœ¨è¿”å›None
        """
        cache_key = self._get_cache_key('news', code)
        
        # å°è¯•è¯»å–ç¼“å­˜
        cached_data = self._read_cache(cache_key)
        if cached_data is not None:
            return cached_data['data']
        
        # åªè¯»æ¨¡å¼ï¼šç¼“å­˜ä¸å­˜åœ¨è¿”å›None
        if self.mode == 'readonly':
            logger.debug(f"[AkShareDataManager] åªè¯»æ¨¡å¼ï¼šæ–°é—»ç¼“å­˜ä¸å­˜åœ¨ {code}")
            return None
        
        # é¢„çƒ­æ¨¡å¼ï¼šè”ç½‘æ‹‰å–
        if not AKSHARE_AVAILABLE:
            logger.warning("[AkShareDataManager] akshare æœªå®‰è£…")
            return None
        
        try:
            self._check_rate_limit()

            # æå–çº¯æ•°å­—ä»£ç ï¼ˆç§»é™¤å¸‚åœºåç¼€ï¼‰
            # codeæ ¼å¼: "600000.SH" â†’ "600000"
            symbol = code.split('.')[0] if '.' in code else code

            # æ‹‰å–æ•°æ®ï¼ˆæ­£ç¡®çš„APIç­¾åï¼‰
            df = ak.stock_news_em(symbol=symbol)

            # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
            if df is None or df.empty:
                logger.warning(f"[AkShareDataManager] æ–°é—»æ•°æ®ä¸ºç©º: {code}")
                return None

            # åªå–æœ€è¿‘20æ¡
            df = df.head(20)

            # å†™å…¥ç¼“å­˜
            self._write_cache(cache_key, 'news', df)

            return df.to_dict()
        except Exception as e:
            logger.warning(f"[AkShareDataManager] è·å–æ–°é—»å¤±è´¥ {code}: {e}")
            return None
    
    def get_lhb_detail(self, date: str = None) -> Optional[List[Dict]]:
        """
        è·å–é¾™è™æ¦œè¯¦æƒ…ï¼ˆå¸¦ç¼“å­˜ï¼‰

        Args:
            date: æ—¥æœŸï¼ˆYYYYMMDDï¼‰ï¼Œé»˜è®¤ä¸ºæœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥

        Returns:
            Optional[List[Dict]]: é¾™è™æ¦œæ•°æ®ï¼Œå¦‚æœç¼“å­˜ä¸å­˜åœ¨è¿”å›None
        """
        if date is None:
            date = (dt_datetime.now() - dt_timedelta(days=1)).strftime('%Y%m%d')

        cache_key = self._get_cache_key('lhb_detail', date)
        
        # å°è¯•è¯»å–ç¼“å­˜
        cached_data = self._read_cache(cache_key)
        if cached_data is not None:
            return cached_data['data']
        
        # åªè¯»æ¨¡å¼ï¼šç¼“å­˜ä¸å­˜åœ¨è¿”å›None
        if self.mode == 'readonly':
            logger.debug(f"[AkShareDataManager] åªè¯»æ¨¡å¼ï¼šé¾™è™æ¦œç¼“å­˜ä¸å­˜åœ¨ {date}")
            return None
        
        # é¢„çƒ­æ¨¡å¼ï¼šè”ç½‘æ‹‰å–
        if not AKSHARE_AVAILABLE:
            logger.warning("[AkShareDataManager] akshare æœªå®‰è£…")
            return None
        
        try:
            self._check_rate_limit()

            # æ‹‰å–æ•°æ®ï¼ˆæ­£ç¡®çš„APIç­¾åï¼šä½¿ç”¨start_dateå’Œend_dateï¼‰
            df = ak.stock_lhb_detail_em(start_date=date, end_date=date)

            # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
            if df is None or df.empty:
                logger.warning(f"[AkShareDataManager] é¾™è™æ¦œæ•°æ®ä¸ºç©º: {date}")
                return None

            # å†™å…¥ç¼“å­˜
            self._write_cache(cache_key, 'lhb_detail', df)

            return df.to_dict()
        except Exception as e:
            logger.warning(f"[AkShareDataManager] è·å–é¾™è™æ¦œå¤±è´¥ {date}: {e}")
            return None
    
    def get_financial_indicator(self, code: str) -> Optional[Dict]:
        """
        è·å–åŸºæœ¬é¢æŒ‡æ ‡ï¼ˆå¸¦ç¼“å­˜ï¼‰
        
        Args:
            code: è‚¡ç¥¨ä»£ç 
        
        Returns:
            Optional[Dict]: åŸºæœ¬é¢æ•°æ®ï¼Œå¦‚æœç¼“å­˜ä¸å­˜åœ¨è¿”å›None
        """
        cache_key = self._get_cache_key('financial_indicator', code)
        
        # å°è¯•è¯»å–ç¼“å­˜
        cached_data = self._read_cache(cache_key)
        if cached_data is not None:
            return cached_data['data']
        
        # åªè¯»æ¨¡å¼ï¼šç¼“å­˜ä¸å­˜åœ¨è¿”å›None
        if self.mode == 'readonly':
            logger.debug(f"[AkShareDataManager] åªè¯»æ¨¡å¼ï¼šåŸºæœ¬é¢ç¼“å­˜ä¸å­˜åœ¨ {code}")
            return None
        
        # é¢„çƒ­æ¨¡å¼ï¼šè”ç½‘æ‹‰å–
        if not AKSHARE_AVAILABLE:
            logger.warning("[AkShareDataManager] akshare æœªå®‰è£…")
            return None
        
        try:
            self._check_rate_limit()

            # æå–çº¯æ•°å­—ä»£ç ï¼ˆç§»é™¤å¸‚åœºåç¼€ï¼‰
            # codeæ ¼å¼: "600000.SH" â†’ "600000"
            symbol = code.split('.')[0] if '.' in code else code

            # æ‹‰å–æ•°æ®ï¼ˆæ­£ç¡®çš„APIç­¾åï¼‰
            df = ak.stock_financial_analysis_indicator(symbol=symbol)

            # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
            if df is None or df.empty:
                logger.warning(f"[AkShareDataManager] åŸºæœ¬é¢æŒ‡æ ‡æ•°æ®ä¸ºç©º: {code}")
                return None

            # å†™å…¥ç¼“å­˜
            self._write_cache(cache_key, 'financial_indicator', df)

            return df.to_dict()
        except Exception as e:
            logger.warning(f"[AkShareDataManager] è·å–åŸºæœ¬é¢æŒ‡æ ‡å¤±è´¥ {code}: {e}")
            return None
    
    def get_limit_up_pool(self, date: str = None) -> Optional[List[str]]:
        """
        è·å–æ˜¨æ—¥æ¶¨åœæ± ï¼ˆå¸¦ç¼“å­˜ï¼‰

        Args:
            date: æ—¥æœŸï¼ˆYYYYMMDDï¼‰ï¼Œé»˜è®¤ä¸ºæ˜¨æ—¥

        Returns:
            Optional[List[str]]: æ¶¨åœè‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œå¦‚æœç¼“å­˜ä¸å­˜åœ¨è¿”å›None
        """
        if date is None:
            date = (dt_datetime.now() - dt_timedelta(days=1)).strftime('%Y%m%d')

        cache_key = self._get_cache_key('limit_up_pool', date)
        
        # å°è¯•è¯»å–ç¼“å­˜
        cached_data = self._read_cache(cache_key)
        if cached_data is not None:
            return cached_data['data']
        
        # åªè¯»æ¨¡å¼ï¼šç¼“å­˜ä¸å­˜åœ¨è¿”å›None
        if self.mode == 'readonly':
            logger.debug(f"[AkShareDataManager] åªè¯»æ¨¡å¼ï¼šæ¶¨åœæ± ç¼“å­˜ä¸å­˜åœ¨ {date}")
            return None
        
        # é¢„çƒ­æ¨¡å¼ï¼šè”ç½‘æ‹‰å–
        if not AKSHARE_AVAILABLE:
            logger.warning("[AkShareDataManager] akshare æœªå®‰è£…")
            return None
        
        try:
            self._check_rate_limit()
            
            # æ‹‰å–æ•°æ®
            df = ak.stock_zt_pool_previous_em(date=date)
            
            if not df.empty:
                codes = df['ä»£ç '].tolist()
                self._write_cache(cache_key, 'limit_up_pool', codes)
                return codes
            
            return None
        except Exception as e:
            logger.warning(f"[AkShareDataManager] è·å–æ¶¨åœæ± å¤±è´¥ {date}: {e}")
            return None
    
    def warmup_all(self, stock_list: List[str] = None) -> Dict[str, Any]:
        """
        é¢„çƒ­æ‰€æœ‰æ•°æ®ï¼ˆç›˜å‰è°ƒç”¨ï¼‰
        
        Args:
            stock_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆç”¨äºé¢„çƒ­ä¸ªè‚¡æ•°æ®ï¼‰
        
        Returns:
            Dict: é¢„çƒ­æŠ¥å‘Š
        """
        print("[AkShareDataManager] ğŸš€ å¼€å§‹é¢„çƒ­æ‰€æœ‰æ•°æ®...")
        
        report = {
            'fund_flow': {'success': 0, 'failed': 0},
            'news': {'success': 0, 'failed': 0},
            'lhb_detail': {'success': 0, 'failed': 0},
            'financial_indicator': {'success': 0, 'failed': 0},
            'limit_up_pool': {'success': 0, 'failed': 0},
        }
        
        # é¢„çƒ­æ¶¨åœæ± 
        print("[AkShareDataManager] 1ï¸âƒ£ é¢„çƒ­æ¶¨åœæ± ...")
        if self.get_limit_up_pool() is not None:
            report['limit_up_pool']['success'] = 1
        else:
            report['limit_up_pool']['failed'] = 1
        
        # é¢„çƒ­é¾™è™æ¦œ
        print("[AkShareDataManager] 2ï¸âƒ£ é¢„çƒ­é¾™è™æ¦œ...")
        if self.get_lhb_detail() is not None:
            report['lhb_detail']['success'] = 1
        else:
            report['lhb_detail']['failed'] = 1
        
        # é¢„çƒ­ä¸ªè‚¡æ•°æ®ï¼ˆå¦‚æœæœ‰è‚¡ç¥¨åˆ—è¡¨ï¼‰
        if stock_list:
            print(f"[AkShareDataManager] 3ï¸âƒ£ é¢„çƒ­ä¸ªè‚¡æ•°æ®ï¼ˆ{len(stock_list)}åªè‚¡ç¥¨ï¼‰...")
            
            # ğŸ”¥ [V16.2.1 ä¿®å¤] åˆ é™¤ç¡¬ç¼–ç é™åˆ¶ï¼Œé¢„çƒ­æ‰€æœ‰è‚¡ç¥¨
            # å¢åŠ è¿›åº¦æ˜¾ç¤º
            total = len(stock_list)
            for i, code in enumerate(stock_list, 1):
                # æ¯å¤„ç†10åªè‚¡ç¥¨æ‰“å°ä¸€æ¬¡è¿›åº¦
                if i % 10 == 0:
                    print(f"[AkShareDataManager] è¿›åº¦: {i}/{total} ({i/total*100:.0f}%)")
                
                # é¢„çƒ­èµ„é‡‘æµ
                if self.get_fund_flow(code) is not None:
                    report['fund_flow']['success'] += 1
                else:
                    report['fund_flow']['failed'] += 1
                
                # é¢„çƒ­æ–°é—»
                if self.get_news(code) is not None:
                    report['news']['success'] += 1
                else:
                    report['news']['failed'] += 1
                
                # é¢„çƒ­åŸºæœ¬é¢
                if self.get_financial_indicator(code) is not None:
                    report['financial_indicator']['success'] += 1
                else:
                    report['financial_indicator']['failed'] += 1
            
            print(f"[AkShareDataManager] âœ… ä¸ªè‚¡æ•°æ®é¢„çƒ­å®Œæˆ: {total}åªè‚¡ç¥¨")
        
        # ä¿å­˜é¢„çƒ­æŠ¥å‘Š
        report_file = self.cache_dir / 'warmup_report.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"[AkShareDataManager] âœ… é¢„çƒ­å®Œæˆï¼ŒæŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        return report


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("=" * 80)
    print("AkShareDataManager æµ‹è¯•")
    print("=" * 80)
    
    # 1. é¢„çƒ­æ¨¡å¼æµ‹è¯•
    print("\nğŸš€ é¢„çƒ­æ¨¡å¼æµ‹è¯•:")
    manager = AkShareDataManager(mode='warmup')
    
    # é¢„çƒ­æ¶¨åœæ± 
    limit_up_pool = manager.get_limit_up_pool()
    if limit_up_pool:
        print(f"  âœ… æ¶¨åœæ± : {len(limit_up_pool)}åªè‚¡ç¥¨")
    else:
        print(f"  âŒ æ¶¨åœæ± : è·å–å¤±è´¥")
    
    # 2. åªè¯»æ¨¡å¼æµ‹è¯•
    print("\nğŸ”’ åªè¯»æ¨¡å¼æµ‹è¯•:")
    manager = AkShareDataManager(mode='readonly')
    
    # è¯»å–æ¶¨åœæ± ï¼ˆä»ç¼“å­˜ï¼‰
    limit_up_pool = manager.get_limit_up_pool()
    if limit_up_pool:
        print(f"  âœ… æ¶¨åœæ± ï¼ˆç¼“å­˜ï¼‰: {len(limit_up_pool)}åªè‚¡ç¥¨")
    else:
        print(f"  âŒ æ¶¨åœæ± ï¼ˆç¼“å­˜ï¼‰: ç¼“å­˜ä¸å­˜åœ¨")
    
    print("\n" + "=" * 80)
    print("âœ… æµ‹è¯•å®Œæˆ")
    print("=" * 80)
