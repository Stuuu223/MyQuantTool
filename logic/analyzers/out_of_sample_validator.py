"""
æ ·æœ¬å¤–æ£€éªŒæ¨¡å— - æ£€æµ‹è¿‡æ‹Ÿåˆ
"""

import pandas as pd
import numpy as np
from typing import Tuple, Dict
import logging

logger = logging.getLogger(__name__)


class OutOfSampleValidator:
    """
    æ ·æœ¬å¤–æ£€éªŒå™¨
    
    ç”¨äºæ£€æµ‹ç­–ç•¥æ˜¯å¦è¿‡æ‹Ÿåˆ
    """
    
    def __init__(self, train_ratio: float = 0.8):
        """
        åˆå§‹åŒ–æ ·æœ¬å¤–æ£€éªŒå™¨
        
        Args:
            train_ratio: è®­ç»ƒé›†æ¯”ä¾‹ (é»˜è®¤ 0.8)
        """
        self.train_ratio = train_ratio
    
    def split_data(
        self,
        df: pd.DataFrame
    ) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        åˆ†å‰²æ•°æ®ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†
        
        Args:
            df: åŸå§‹æ•°æ®
        
        Returns:
            (è®­ç»ƒé›†, æµ‹è¯•é›†)
        """
        train_size = int(len(df) * self.train_ratio)
        
        df_train = df[:train_size].copy()
        df_test = df[train_size:].copy()
        
        logger.info(f"æ•°æ®åˆ†å‰²: è®­ç»ƒé›† {len(df_train)} å¤©, æµ‹è¯•é›† {len(df_test)} å¤©")
        
        return df_train, df_test
    
    def validate_overfitting(
        self,
        train_metrics: Dict,
        test_metrics: Dict
    ) -> Tuple[bool, str]:
        """
        æ£€æµ‹è¿‡æ‹Ÿåˆ
        
        Args:
            train_metrics: è®­ç»ƒé›†æŒ‡æ ‡
            test_metrics: æµ‹è¯•é›†æŒ‡æ ‡
        
        Returns:
            (æ˜¯å¦è¿‡æ‹Ÿåˆ, æ£€æµ‹ç»“æœæ¶ˆæ¯)
        """
        issues = []
        
        # 1. å¤æ™®æ¯”ç‡æ£€æŸ¥
        train_sharpe = train_metrics.get('sharpe_ratio', 0)
        test_sharpe = test_metrics.get('sharpe_ratio', 0)
        
        if test_sharpe < train_sharpe * 0.7:
            issues.append(f"å¤æ™®æ¯”ç‡ä¸‹é™ {((train_sharpe - test_sharpe) / train_sharpe * 100):.1f}%")
        elif test_sharpe < train_sharpe * 0.85:
            issues.append(f"å¤æ™®æ¯”ç‡è½»å¾®ä¸‹é™ {((train_sharpe - test_sharpe) / train_sharpe * 100):.1f}%")
        
        # 2. æ”¶ç›Šç‡æ£€æŸ¥
        train_return = train_metrics.get('annual_return', 0)
        test_return = test_metrics.get('annual_return', 0)
        
        if test_return < train_return * 0.7:
            issues.append(f"å¹´åŒ–æ”¶ç›Šä¸‹é™ {((train_return - test_return) / train_return * 100):.1f}%")
        elif test_return < train_return * 0.85:
            issues.append(f"å¹´åŒ–æ”¶ç›Šè½»å¾®ä¸‹é™ {((train_return - test_return) / train_return * 100):.1f}%")
        
        # 3. æœ€å¤§å›æ’¤æ£€æŸ¥
        train_dd = train_metrics.get('max_drawdown', 0)
        test_dd = test_metrics.get('max_drawdown', 0)
        
        if abs(test_dd) > abs(train_dd) * 1.3:
            issues.append(f"æœ€å¤§å›æ’¤æ‰©å¤§ {((abs(test_dd) - abs(train_dd)) / abs(train_dd) * 100):.1f}%")
        
        # 4. èƒœç‡æ£€æŸ¥
        train_winrate = train_metrics.get('win_rate', 0)
        test_winrate = test_metrics.get('win_rate', 0)
        
        if test_winrate < train_winrate * 0.8:
            issues.append(f"èƒœç‡ä¸‹é™ {((train_winrate - test_winrate) / train_winrate * 100):.1f}%")
        
        # åˆ¤æ–­æ˜¯å¦è¿‡æ‹Ÿåˆ
        is_overfitted = len(issues) >= 2 or any("ä¸‹é™" in issue and float(issue.split()[1]) > 30 for issue in issues)
        
        if is_overfitted:
            return True, "âš ï¸ æ£€æµ‹åˆ°å¼ºçƒˆè¿‡æ‹Ÿåˆ: " + "; ".join(issues)
        elif len(issues) > 0:
            return False, "âš ï¸ è½»å¾®æ€§èƒ½ä¸‹é™: " + "; ".join(issues)
        else:
            return False, "âœ… æ ·æœ¬å¤–è¡¨ç°è‰¯å¥½ï¼Œæ— æ˜æ˜¾è¿‡æ‹Ÿåˆ"
    
    def cross_validation(
        self,
        df: pd.DataFrame,
        backtest_func,
        n_folds: int = 5
    ) -> Dict:
        """
        äº¤å‰éªŒè¯
        
        Args:
            df: åŸå§‹æ•°æ®
            backtest_func: å›æµ‹å‡½æ•°
            n_folds: æŠ˜å æ•°
        
        Returns:
            äº¤å‰éªŒè¯ç»“æœ
        """
        fold_size = len(df) // n_folds
        results = []
        
        for i in range(n_folds):
            # æµ‹è¯•é›†
            test_start = i * fold_size
            test_end = (i + 1) * fold_size if i < n_folds - 1 else len(df)
            df_test = df.iloc[test_start:test_end].copy()
            
            # è®­ç»ƒé›† (å…¶ä»–æ‰€æœ‰æ•°æ®)
            df_train = pd.concat([df.iloc[:test_start], df.iloc[test_end:]]).copy()
            
            # è¿è¡Œå›æµ‹
            try:
                result = backtest_func(df_train, df_test)
                results.append(result)
            except Exception as e:
                logger.error(f"ç¬¬ {i+1} æŠ˜äº¤å‰éªŒè¯å¤±è´¥: {e}")
                results.append(None)
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        valid_results = [r for r in results if r is not None]
        
        if not valid_results:
            return {}
        
        avg_metrics = {}
        for key in valid_results[0].keys():
            values = [r[key] for r in valid_results if key in r]
            if values and all(isinstance(v, (int, float)) for v in values):
                avg_metrics[key] = np.mean(values)
        
        logger.info(f"äº¤å‰éªŒè¯å®Œæˆ: {len(valid_results)}/{n_folds} æŠ˜æˆåŠŸ")
        
        return avg_metrics
    
    def get_validation_report(
        self,
        train_metrics: Dict,
        test_metrics: Dict
    ) -> str:
        """
        è·å–éªŒè¯æŠ¥å‘Š
        
        Args:
            train_metrics: è®­ç»ƒé›†æŒ‡æ ‡
            test_metrics: æµ‹è¯•é›†æŒ‡æ ‡
        
        Returns:
            æ ¼å¼åŒ–çš„éªŒè¯æŠ¥å‘Š
        """
        is_overfitted, message = self.validate_overfitting(train_metrics, test_metrics)
        
        report = f"""
ğŸ”¬ æ ·æœ¬å¤–æ£€éªŒæŠ¥å‘Š
================

ğŸ“Š è®­ç»ƒé›†æŒ‡æ ‡:
  - å¤æ™®æ¯”ç‡: {train_metrics.get('sharpe_ratio', 0):.2f}
  - å¹´åŒ–æ”¶ç›Š: {train_metrics.get('annual_return', 0):.2%}
  - æœ€å¤§å›æ’¤: {train_metrics.get('max_drawdown', 0):.2%}
  - èƒœç‡: {train_metrics.get('win_rate', 0):.2%}

ğŸ“Š æµ‹è¯•é›†æŒ‡æ ‡:
  - å¤æ™®æ¯”ç‡: {test_metrics.get('shrpe_ratio', 0):.2f}
  - å¹´åŒ–æ”¶ç›Š: {test_metrics.get('annual_return', 0):.2%}
  - æœ€å¤§å›æ’¤: {test_metrics.get('max_drawdown', 0):.2%}
  - èƒœç‡: {test_metrics.get('win_rate', 0):.2%}

ğŸ¯ æ£€éªŒç»“æœ:
{message}
"""
        return report