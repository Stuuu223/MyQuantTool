# -*- coding: utf-8 -*-
"""
è‚¡ç¥¨æ± æ„å»ºå™¨ V2.0 - CTO Phase 6.2 é‡æ„ç‰ˆ

èŒè´£ï¼š
1. Tushareäº‘ç«¯ä¸‰å±‚æ¼æ–—ç­›é€‰ï¼ˆ5000â†’200ï¼‰
2. é¡½ä¸»ç²¾é€‰è‚¡ç¥¨æ± æ„å»º
3. ç»Ÿä¸€çš„è‚¡ç¥¨æ± æ„å»ºæ¥å£

é‡æ„ç›®æ ‡ï¼š
- æ•´åˆ tasks/tushare_market_filter.py
- æä¾›æ¨¡å—åŒ–APIæ¥å£
- å®Œæ•´é”™è¯¯å¤„ç†å’Œç±»å‹æ³¨è§£

ä¸‰å±‚æ¼æ–—æ¶æ„ï¼š
- Layer 1: é™æ€è¿‡æ»¤ï¼ˆST/åŒ—äº¤æ‰€/åœç‰Œï¼‰
- Layer 2: æˆäº¤é¢è¿‡æ»¤ï¼ˆ5æ—¥æ—¥å‡>3000ä¸‡ï¼‰
- Layer 3: é‡æ¯”è¿‡æ»¤ï¼ˆé‡æ¯”>3ï¼Œå–Top200ï¼‰

ä½¿ç”¨ç¤ºä¾‹:
    >>> from logic.analyzers.universe_builder import UniverseBuilder
    >>> builder = UniverseBuilder()
    >>> universe_df = builder.build_universe(trade_date='20251231')
    >>> top_73 = builder.get_top_candidates(n=73)
"""

import json
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Optional, Tuple, Any
from dataclasses import dataclass, field

import pandas as pd

try:
    import tushare as ts
    TUSHARE_AVAILABLE = True
except ImportError:
    TUSHARE_AVAILABLE = False
    ts = None

from logic.utils.logger import get_logger

logger = get_logger(__name__)


@dataclass
class FilterResult:
    """è¿‡æ»¤ç»“æœæ•°æ®ç»“æ„"""
    layer: int
    name: str
    input_count: int
    output_count: int
    duration_ms: float
    params: Dict[str, Any] = field(default_factory=dict)
    
    @property
    def filter_ratio(self) -> float:
        """è¿‡æ»¤æ¯”ç‡ (0.0-1.0)"""
        if self.input_count == 0:
            return 0.0
        return 1 - (self.output_count / self.input_count)
    
    def __str__(self) -> str:
        return (f"Layer {self.layer} [{self.name}]: "
                f"{self.input_count} â†’ {self.output_count} "
                f"(è¿‡æ»¤ {self.filter_ratio*100:.1f}%)")


@dataclass
class UniverseBuildReport:
    """è‚¡ç¥¨æ± æ„å»ºæŠ¥å‘Š"""
    trade_date: str
    total_stocks: int
    final_count: int
    filter_results: List[FilterResult] = field(default_factory=list)
    duration_seconds: float = 0.0
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'trade_date': self.trade_date,
            'total_stocks': self.total_stocks,
            'final_count': self.final_count,
            'duration_seconds': self.duration_seconds,
            'filters': [
                {
                    'layer': f.layer,
                    'name': f.name,
                    'input': f.input_count,
                    'output': f.output_count,
                    'filter_ratio': f.filter_ratio
                }
                for f in self.filter_results
            ]
        }


class UniverseBuilder:
    """
    è‚¡ç¥¨æ± æ„å»ºå™¨ï¼ˆTushareä¸‰å±‚æ¼æ–—ï¼‰
    
    æ•´åˆTushareäº‘ç«¯ç²—ç­›èƒ½åŠ›ï¼Œæä¾›æ ‡å‡†åŒ–çš„è‚¡ç¥¨æ± æ„å»ºæµç¨‹ã€‚
    
    Attributes:
        tushare_token: Tushare API Token
        min_avg_amount: 5æ—¥å¹³å‡æˆäº¤é¢é˜ˆå€¼ï¼ˆä¸‡å…ƒï¼‰
        volume_ratio_threshold: é‡æ¯”é˜ˆå€¼
        max_output: æœ€å¤§è¾“å‡ºæ•°é‡
        api_delay: APIè°ƒç”¨é—´éš”ï¼ˆç§’ï¼‰
    
    Example:
        >>> builder = UniverseBuilder(tushare_token="your_token")
        >>> df = builder.build_universe('20251231')
        >>> print(f"ç­›é€‰ç»“æœ: {len(df)}åªè‚¡ç¥¨")
    """
    
    # é»˜è®¤é…ç½®ï¼ˆä»CTOé…ç½®ä¸­æå–ï¼‰
    DEFAULT_MIN_AVG_AMOUNT = 3000  # ä¸‡å…ƒ
    DEFAULT_VOLUME_RATIO_THRESHOLD = 3.0
    DEFAULT_MAX_OUTPUT = 200
    DEFAULT_API_DELAY = 0.5
    DEFAULT_TUSHARE_TOKEN = '1430dca9cc3419b91928e162935065bcd3531fa82976fee8355d550b'
    
    def __init__(
        self,
        tushare_token: Optional[str] = None,
        min_avg_amount: float = DEFAULT_MIN_AVG_AMOUNT,
        volume_ratio_threshold: float = DEFAULT_VOLUME_RATIO_THRESHOLD,
        max_output: int = DEFAULT_MAX_OUTPUT,
        api_delay: float = DEFAULT_API_DELAY
    ):
        """
        åˆå§‹åŒ–è‚¡ç¥¨æ± æ„å»ºå™¨
        
        Args:
            tushare_token: Tushare API Token
            min_avg_amount: 5æ—¥å¹³å‡æˆäº¤é¢é˜ˆå€¼ï¼ˆä¸‡å…ƒï¼‰
            volume_ratio_threshold: é‡æ¯”é˜ˆå€¼
            max_output: æœ€å¤§è¾“å‡ºæ•°é‡
            api_delay: APIè°ƒç”¨é—´éš”ï¼ˆç§’ï¼‰
        """
        self.tushare_token = tushare_token or self._load_tushare_token()
        self.min_avg_amount = min_avg_amount
        self.volume_ratio_threshold = volume_ratio_threshold
        self.max_output = max_output
        self.api_delay = api_delay
        self._pro = None
        self._filter_results: List[FilterResult] = []
        self._last_result: Optional[pd.DataFrame] = None
        
        logger.info(f"[UniverseBuilder] åˆå§‹åŒ–å®Œæˆ | æˆäº¤é¢>{min_avg_amount}ä¸‡ | é‡æ¯”>{volume_ratio_threshold}")
    
    def _load_tushare_token(self) -> str:
        """ä»é…ç½®æ–‡ä»¶åŠ è½½Tushare Token"""
        try:
            token_file = Path(__file__).parent.parent.parent / 'config' / 'tushare_token.txt'
            if token_file.exists():
                token = token_file.read_text().strip()
                if token and not token.startswith('æ›¿æ¢'):
                    return token
        except Exception as e:
            logger.warning(f"[UniverseBuilder] åŠ è½½Tokenæ–‡ä»¶å¤±è´¥: {e}")
        
        logger.info("[UniverseBuilder] ä½¿ç”¨é»˜è®¤Tushare Token")
        return self.DEFAULT_TUSHARE_TOKEN
    
    def init_tushare(self) -> bool:
        """
        åˆå§‹åŒ–Tushare Pro API
        
        Returns:
            æ˜¯å¦åˆå§‹åŒ–æˆåŠŸ
        """
        if not TUSHARE_AVAILABLE:
            logger.error("[UniverseBuilder] tushareæ¨¡å—æœªå®‰è£…")
            return False
        
        if self._pro is not None:
            return True
        
        try:
            ts.set_token(self.tushare_token)
            self._pro = ts.pro_api()
            logger.info("[UniverseBuilder] Tushare Proåˆå§‹åŒ–æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"[UniverseBuilder] Tushare Proåˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def _get_trade_dates(self, end_date: str, days: int = 5) -> List[str]:
        """
        è·å–å†å²äº¤æ˜“æ—¥åˆ—è¡¨
        
        Args:
            end_date: ç»“æŸæ—¥æœŸ (YYYYMMDD)
            days: éœ€è¦è·å–çš„äº¤æ˜“æ—¥æ•°é‡
        
        Returns:
            äº¤æ˜“æ—¥åˆ—è¡¨ï¼ˆä»æ—§åˆ°æ–°ï¼‰
        """
        try:
            # ä½¿ç”¨trade_calæ¥å£è·å–äº¤æ˜“æ—¥å†
            df = self._pro.trade_cal(
                end_date=end_date,
                is_open='1',
                fields='cal_date'
            )
            if df is None or df.empty:
                # é™çº§ï¼šä½¿ç”¨ç®€å•æ—¥æœŸè®¡ç®—
                return self._calc_trade_dates_fallback(end_date, days)
            
            dates = df['cal_date'].tolist()
            dates.sort()
            return dates[-days:] if len(dates) >= days else dates
            
        except Exception as e:
            logger.warning(f"[UniverseBuilder] è·å–äº¤æ˜“æ—¥å†å¤±è´¥: {e}ï¼Œä½¿ç”¨é™çº§æ–¹æ¡ˆ")
            return self._calc_trade_dates_fallback(end_date, days)
    
    def _calc_trade_dates_fallback(self, end_date: str, days: int) -> List[str]:
        """äº¤æ˜“æ—¥å†é™çº§è®¡ç®—ï¼ˆæ’é™¤å‘¨æœ«ï¼‰"""
        date_obj = datetime.strptime(end_date, '%Y%m%d')
        dates = []
        
        for i in range(1, 20):  # æœ€å¤šå¾€å‰æ‰¾20å¤©
            d = date_obj - timedelta(days=i)
            d_str = d.strftime('%Y%m%d')
            if d.weekday() < 5:  # 0-4æ˜¯å‘¨ä¸€åˆ°å‘¨äº”
                dates.append(d_str)
            if len(dates) >= days:
                break
        
        dates.sort()
        return dates
    
    def filter_layer1_static(self, df_base: Optional[pd.DataFrame] = None) -> pd.DataFrame:
        """
        Layer 1: é™æ€è¿‡æ»¤ï¼ˆ5000â†’çº¦4500ï¼‰
        
        è¿‡æ»¤è§„åˆ™ï¼š
        - å‰”é™¤ST/*ST/é€€å¸‚
        - å‰”é™¤åŒ—äº¤æ‰€ï¼ˆ8/4å¼€å¤´ï¼‰
        - åªä¿ç•™ä¸Šå¸‚çŠ¶æ€ä¸º'L'çš„è‚¡ç¥¨
        
        Args:
            df_base: åŸºç¡€è‚¡ç¥¨åˆ—è¡¨ï¼ŒNoneæ—¶è‡ªåŠ¨è·å–
        
        Returns:
            è¿‡æ»¤åçš„DataFrame
        """
        start_time = time.time()
        
        if not self.init_tushare():
            raise RuntimeError("Tushareæœªåˆå§‹åŒ–")
        
        logger.info("=" * 60)
        logger.info("ã€Layer 1ã€‘Tushareé™æ€è¿‡æ»¤")
        logger.info("=" * 60)
        
        if df_base is not None:
            df = df_base.copy()
            input_count = len(df)
        else:
            # è·å–å…¨å¸‚åœºè‚¡ç¥¨åŸºç¡€ä¿¡æ¯
            df = self._pro.stock_basic(
                exchange='',
                list_status='L',
                fields='ts_code,symbol,name,area,industry,list_date'
            )
            input_count = len(df)
        
        logger.info(f"   å…¨å¸‚åœºè‚¡ç¥¨æ€»æ•°: {len(df)}")
        
        # å‰”é™¤åŒ—äº¤æ‰€ï¼ˆ8/4å¼€å¤´ï¼‰
        df = df[~df['ts_code'].str.startswith(('8', '4'))]
        logger.info(f"   å‰”é™¤åŒ—äº¤æ‰€å: {len(df)}")
        
        # å‰”é™¤STï¼ˆåç§°ä¸­åŒ…å«STï¼‰
        df = df[~df['name'].str.contains('ST', na=False)]
        logger.info(f"   å‰”é™¤STå: {len(df)}")
        
        duration = (time.time() - start_time) * 1000
        result = FilterResult(
            layer=1,
            name='é™æ€è¿‡æ»¤',
            input_count=input_count,
            output_count=len(df),
            duration_ms=duration
        )
        self._filter_results.append(result)
        logger.info(f"   {result}")
        
        return df
    
    def filter_layer2_amount(
        self,
        df_base: pd.DataFrame,
        trade_date: str
    ) -> pd.DataFrame:
        """
        Layer 2: æˆäº¤é¢è¿‡æ»¤ï¼ˆçº¦4500â†’çº¦800ï¼‰
        
        è¿‡æ»¤è§„åˆ™ï¼š
        - è®¡ç®—å‰5æ—¥æ—¥å‡æˆäº¤é¢
        - å‰”é™¤<3000ä¸‡çš„è‚¡ç¥¨
        
        Args:
            df_base: åŸºç¡€è‚¡ç¥¨DataFrame
            trade_date: äº¤æ˜“æ—¥æœŸ (YYYYMMDD)
        
        Returns:
            è¿‡æ»¤åçš„DataFrame
        """
        start_time = time.time()
        
        if not self.init_tushare():
            raise RuntimeError("Tushareæœªåˆå§‹åŒ–")
        
        logger.info("=" * 60)
        logger.info("ã€Layer 2ã€‘Tushareæˆäº¤é¢è¿‡æ»¤")
        logger.info("=" * 60)
        
        # è®¡ç®—å‰5ä¸ªäº¤æ˜“æ—¥
        dates = self._get_trade_dates(trade_date, 5)
        logger.info(f"   åˆ†ææ—¥æœŸèŒƒå›´: {dates[0]} è‡³ {dates[-1]}")
        
        # æ‰¹é‡è·å–æ—¥çº¿æ•°æ®
        all_daily = []
        for date in dates:
            try:
                df_daily = self._pro.daily(trade_date=date, fields='ts_code,amount')
                if df_daily is not None and not df_daily.empty:
                    all_daily.append(df_daily)
                    logger.debug(f"   âœ… {date}: {len(df_daily)}åª")
                time.sleep(self.api_delay)
            except Exception as e:
                logger.warning(f"   âŒ {date}: {e}")
        
        if not all_daily:
            raise ValueError("æ— æ³•è·å–å†å²æ—¥çº¿æ•°æ®")
        
        # åˆå¹¶å¹¶è®¡ç®—5æ—¥å¹³å‡æˆäº¤é¢
        df_all = pd.concat(all_daily, ignore_index=True)
        df_avg = df_all.groupby('ts_code')['amount'].mean().reset_index()
        df_avg.columns = ['ts_code', 'avg_amount_5d']
        
        # åˆå¹¶åˆ°åŸºç¡€æ•°æ®
        df = df_base.merge(df_avg, on='ts_code', how='inner')
        
        # è¿‡æ»¤ï¼šæ—¥å‡æˆäº¤é¢>3000ä¸‡ï¼ˆTushare amountå•ä½æ˜¯åƒå…ƒï¼Œæ‰€ä»¥3000ä¸‡=30000åƒå…ƒï¼‰
        threshold_k = self.min_avg_amount * 10
        df_filtered = df[df['avg_amount_5d'] >= threshold_k].copy()
        
        duration = (time.time() - start_time) * 1000
        result = FilterResult(
            layer=2,
            name='æˆäº¤é¢è¿‡æ»¤',
            input_count=len(df_base),
            output_count=len(df_filtered),
            duration_ms=duration,
            params={'min_amount': self.min_avg_amount}
        )
        self._filter_results.append(result)
        logger.info(f"   5æ—¥æ—¥å‡æˆäº¤>{self.min_avg_amount}ä¸‡: {len(df_filtered)}åª")
        logger.info(f"   {result}")
        
        return df_filtered
    
    def filter_layer3_volume_ratio(
        self,
        df_base: pd.DataFrame,
        trade_date: str
    ) -> pd.DataFrame:
        """
        Layer 3: é‡æ¯”è¿‡æ»¤ï¼ˆçº¦800â†’200ï¼‰
        
        è¿‡æ»¤è§„åˆ™ï¼š
        - è·å–å½“æ—¥é‡æ¯”æ•°æ®
        - ä¿ç•™é‡æ¯”>3çš„è‚¡ç¥¨
        - æŒ‰é‡æ¯”æ’åºï¼Œå–Top N
        
        Args:
            df_base: åŸºç¡€è‚¡ç¥¨DataFrame
            trade_date: äº¤æ˜“æ—¥æœŸ (YYYYMMDD)
        
        Returns:
            è¿‡æ»¤åçš„DataFrame
        """
        start_time = time.time()
        
        if not self.init_tushare():
            raise RuntimeError("Tushareæœªåˆå§‹åŒ–")
        
        logger.info("=" * 60)
        logger.info("ã€Layer 3ã€‘Tushareé‡æ¯”è¿‡æ»¤")
        logger.info("=" * 60)
        
        # è·å–å½“æ—¥æŒ‡æ ‡æ•°æ®
        try:
            df_today = self._pro.daily_basic(
                trade_date=trade_date,
                fields='ts_code,turnover_rate,volume_ratio'
            )
            logger.info(f"   è·å–å½“æ—¥æŒ‡æ ‡: {len(df_today)}åª")
        except Exception as e:
            logger.error(f"   è·å–å½“æ—¥æŒ‡æ ‡å¤±è´¥: {e}")
            # é™çº§ï¼šç›´æ¥è¿”å›å‰Nåª
            df_fallback = df_base.head(self.max_output).copy()
            df_fallback['volume_ratio'] = None
            return df_fallback
        
        # åˆå¹¶æ•°æ®
        df = df_base.merge(df_today, on='ts_code', how='inner')
        
        # è¿‡æ»¤ï¼šé‡æ¯”>é˜ˆå€¼
        df_filtered = df[df['volume_ratio'] >= self.volume_ratio_threshold].copy()
        logger.info(f"   é‡æ¯”>{self.volume_ratio_threshold}: {len(df_filtered)}åª")
        
        # æŒ‰é‡æ¯”æ’åºï¼Œå–å‰N
        df_filtered = df_filtered.sort_values('volume_ratio', ascending=False)
        df_result = df_filtered.head(self.max_output).copy()
        
        duration = (time.time() - start_time) * 1000
        result = FilterResult(
            layer=3,
            name='é‡æ¯”è¿‡æ»¤',
            input_count=len(df_base),
            output_count=len(df_result),
            duration_ms=duration,
            params={'volume_ratio_threshold': self.volume_ratio_threshold, 'max_output': self.max_output}
        )
        self._filter_results.append(result)
        logger.info(f"   Top {self.max_output}: {len(df_result)}åª")
        logger.info(f"   {result}")
        
        return df_result
    
    def build_universe(
        self,
        trade_date: Optional[str] = None,
        df_base: Optional[pd.DataFrame] = None
    ) -> pd.DataFrame:
        """
        æ‰§è¡Œä¸‰å±‚æ¼æ–—å®Œæ•´ç­›é€‰
        
        Args:
            trade_date: äº¤æ˜“æ—¥æœŸ (YYYYMMDD)ï¼Œé»˜è®¤ä»Šå¤©
            df_base: åŸºç¡€è‚¡ç¥¨åˆ—è¡¨ï¼ŒNoneæ—¶è‡ªåŠ¨è·å–
        
        Returns:
            ç­›é€‰ç»“æœDataFrame
        """
        start_time = time.time()
        self._filter_results = []
        
        if trade_date is None:
            trade_date = datetime.now().strftime('%Y%m%d')
        
        logger.info("=" * 60)
        logger.info("ã€è‚¡ç¥¨æ± æ„å»ºã€‘ä¸‰å±‚æ¼æ–—ç­›é€‰")
        logger.info("=" * 60)
        logger.info(f"ç›®æ ‡æ—¥æœŸ: {trade_date}")
        logger.info(f"æˆäº¤é¢åº•çº¿: {self.min_avg_amount}ä¸‡")
        logger.info(f"é‡æ¯”é˜ˆå€¼: {self.volume_ratio_threshold}")
        logger.info("=" * 60)
        
        if not self.init_tushare():
            raise RuntimeError("Tushareåˆå§‹åŒ–å¤±è´¥")
        
        # Layer 1: é™æ€è¿‡æ»¤
        df = self.filter_layer1_static(df_base)
        
        # Layer 2: æˆäº¤é¢è¿‡æ»¤
        df = self.filter_layer2_amount(df, trade_date)
        
        # Layer 3: é‡æ¯”è¿‡æ»¤
        df = self.filter_layer3_volume_ratio(df, trade_date)
        
        # æ·»åŠ æ’ååˆ—
        df['rank'] = range(1, len(df) + 1)
        
        self._last_result = df
        duration = time.time() - start_time
        
        logger.info("=" * 60)
        logger.info("ã€ç­›é€‰ç»“æœæ‘˜è¦ã€‘")
        logger.info("=" * 60)
        logger.info(f"æœ€ç»ˆå…¥é€‰: {len(df)}åª")
        logger.info(f"è€—æ—¶: {duration:.2f}ç§’")
        
        return df
    
    def get_top_candidates(self, n: int = 73) -> List[str]:
        """
        è·å–Top Nå€™é€‰è‚¡ç¥¨ä»£ç 
        
        Args:
            n: è·å–æ•°é‡
        
        Returns:
            è‚¡ç¥¨ä»£ç åˆ—è¡¨
        """
        if self._last_result is None or self._last_result.empty:
            logger.warning("[UniverseBuilder] æ²¡æœ‰å¯ç”¨çš„ç­›é€‰ç»“æœ")
            return []
        
        return self._last_result.head(n)['ts_code'].tolist()
    
    def get_build_report(self) -> UniverseBuildReport:
        """
        è·å–æ„å»ºæŠ¥å‘Š
        
        Returns:
            æ„å»ºæŠ¥å‘Šå¯¹è±¡
        """
        if not self._filter_results:
            return UniverseBuildReport(
                trade_date='',
                total_stocks=0,
                final_count=0
            )
        
        first_filter = self._filter_results[0]
        last_filter = self._filter_results[-1]
        
        return UniverseBuildReport(
            trade_date=datetime.now().strftime('%Y%m%d'),
            total_stocks=first_filter.input_count,
            final_count=last_filter.output_count,
            filter_results=self._filter_results
        )
    
    def save_universe(
        self,
        df: Optional[pd.DataFrame] = None,
        output_dir: Optional[Path] = None,
        trade_date: Optional[str] = None,
        format: str = 'both'
    ) -> Dict[str, Path]:
        """
        ä¿å­˜è‚¡ç¥¨æ± åˆ°æ–‡ä»¶
        
        Args:
            df: è¦ä¿å­˜çš„DataFrameï¼ŒNoneä½¿ç”¨æœ€åä¸€æ¬¡ç»“æœ
            output_dir: è¾“å‡ºç›®å½•
            trade_date: äº¤æ˜“æ—¥æœŸ
            format: æ ¼å¼ ('csv', 'json', 'both')
        
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„å­—å…¸
        """
        if df is None:
            df = self._last_result
        
        if df is None or df.empty:
            logger.warning("[UniverseBuilder] æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
            return {}
        
        if output_dir is None:
            output_dir = Path(__file__).parent.parent.parent / 'data' / 'scan_results'
        
        output_dir.mkdir(parents=True, exist_ok=True)
        
        if trade_date is None:
            trade_date = datetime.now().strftime('%Y%m%d')
        
        saved_files = {}
        base_name = f"{trade_date}_candidates_{len(df)}"
        
        # ä¿å­˜CSV
        if format in ('csv', 'both'):
            csv_path = output_dir / f"{base_name}.csv"
            df.to_csv(csv_path, index=False, encoding='utf-8-sig')
            saved_files['csv'] = csv_path
            logger.info(f"ğŸ’¾ å·²ä¿å­˜CSV: {csv_path}")
        
        # ä¿å­˜JSON
        if format in ('json', 'both'):
            json_path = output_dir / f"{base_name}.json"
            df.to_json(json_path, orient='records', force_ascii=False, indent=2)
            saved_files['json'] = json_path
            logger.info(f"ğŸ’¾ å·²ä¿å­˜JSON: {json_path}")
        
        return saved_files
    
    def check_specific_stock(self, ts_code: str) -> Optional[Dict]:
        """
        æ£€æŸ¥ç‰¹å®šè‚¡ç¥¨æ˜¯å¦åœ¨æœ€åä¸€æ¬¡ç­›é€‰ç»“æœä¸­
        
        Args:
            ts_code: è‚¡ç¥¨ä»£ç 
        
        Returns:
            è‚¡ç¥¨ä¿¡æ¯å­—å…¸ï¼Œæœªæ‰¾åˆ°è¿”å›None
        """
        if self._last_result is None or self._last_result.empty:
            return None
        
        stock = self._last_result[self._last_result['ts_code'] == ts_code]
        if stock.empty:
            return None
        
        row = stock.iloc[0]
        return {
            'ts_code': row['ts_code'],
            'name': row.get('name', ''),
            'rank': int(row.get('rank', 0)),
            'volume_ratio': float(row.get('volume_ratio', 0)),
            'avg_amount_5d': float(row.get('avg_amount_5d', 0))
        }


# ==========================================
# ä¿ç•™åŸæœ‰åŠŸèƒ½ï¼šé¡½ä¸»ç²¾é€‰è‚¡ç¥¨æ± 
# ==========================================

def load_json_config(config_path: Path) -> Dict:
    """åŠ è½½JSONé…ç½®æ–‡ä»¶"""
    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def parse_stock_code(code: str) -> tuple:
    """è§£æè‚¡ç¥¨ä»£ç 
    
    Args:
        code: åŸå§‹ä»£ç ï¼ˆå¦‚ '600519.SH' æˆ– '600519'ï¼‰
    
    Returns:
        (qmt_code, market, full_code)
    """
    if code.endswith('.SH'):
        return code[:-3], 'SH', code
    elif code.endswith('.SZ'):
        return code[:-3], 'SZ', code
    elif code.startswith('6'):
        return code, 'SH', f"{code}.SH"
    elif code.startswith('0') or code.startswith('3'):
        return code, 'SZ', f"{code}.SZ"
    else:
        return code, 'UNKNOWN', code


def build_wanzhu_selected() -> List[Dict]:
    """æ„å»ºé¡½ä¸»ç²¾é€‰150è‚¡ç¥¨æ± ï¼ˆä»CSVï¼‰
    
    ä» data/wanzhu_data/processed/wanzhu_selected_150.csv è¯»å–
    
    Returns:
        æ ‡å‡†åŒ–è‚¡ç¥¨åˆ—è¡¨
    """
    PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent
    csv_path = PROJECT_ROOT / 'data' / 'wanzhu_data' / 'processed' / 'wanzhu_selected_150.csv'
    
    if not csv_path.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°CSVæ–‡ä»¶: {csv_path}")
    
    df = pd.read_csv(csv_path)
    stocks = []
    
    for idx, row in df.iterrows():
        code = str(row['code']).zfill(6)
        qmt_code, market, full_code = parse_stock_code(code)
        
        stocks.append({
            "code": full_code,
            "qmt_code": qmt_code,
            "market": market,
            "name": row.get('name', ''),
            "rank": idx + 1,
            "source": "wanzhu_selected"
        })
    
    return stocks


def save_universe_legacy(universe: List[Dict], output_path: Path, format: str = 'json'):
    """ä¿å­˜è‚¡ç¥¨æ± åˆ°æ–‡ä»¶ï¼ˆæ—§ç‰ˆå…¼å®¹ï¼‰
    
    Args:
        universe: è‚¡ç¥¨åˆ—è¡¨
        output_path: è¾“å‡ºè·¯å¾„
        format: æ ¼å¼ ('json' æˆ– 'csv')
    """
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    if format == 'json':
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(universe, f, ensure_ascii=False, indent=2)
    elif format == 'csv':
        df = pd.DataFrame(universe)
        df.to_csv(output_path, index=False, encoding='utf-8')
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ ¼å¼: {format}")
    
    logger.info(f"âœ… è‚¡ç¥¨æ± å·²ä¿å­˜: {output_path}")
    logger.info(f"   è‚¡ç¥¨æ•°é‡: {len(universe)}")


def get_universe_summary(universe: List[Dict]) -> Dict:
    """è·å–è‚¡ç¥¨æ± æ‘˜è¦ç»Ÿè®¡
    
    Args:
        universe: è‚¡ç¥¨åˆ—è¡¨
    
    Returns:
        ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    """
    sh_count = sum(1 for s in universe if s['market'] == 'SH')
    sz_count = sum(1 for s in universe if s['market'] == 'SZ')
    
    sources = {}
    for s in universe:
        src = s.get('source', 'unknown')
        sources[src] = sources.get(src, 0) + 1
    
    return {
        'total': len(universe),
        'sh_count': sh_count,
        'sz_count': sz_count,
        'sources': sources
    }


if __name__ == '__main__':
    # æµ‹è¯•æ„å»º
    print("=" * 60)
    print("è‚¡ç¥¨æ± æ„å»ºå™¨ V2.0 æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯• Tushare ä¸‰å±‚æ¼æ–—
    print("\næµ‹è¯• Tushare ä¸‰å±‚æ¼æ–—...")
    try:
        builder = UniverseBuilder()
        df = builder.build_universe('20251231')
        top_10 = builder.get_top_candidates(n=10)
        print(f"\nTop 10å€™é€‰:")
        for code in top_10:
            print(f"   {code}")
        
        # æ£€æŸ¥å¿—ç‰¹æ–°æ
        zhite = builder.check_specific_stock('300986.SZ')
        if zhite:
            print(f"\nğŸ¯ å¿—ç‰¹æ–°æ(300986.SZ): æ’å {zhite['rank']}, é‡æ¯” {zhite['volume_ratio']:.2f}")
        else:
            print(f"\nå¿—ç‰¹æ–°æ(300986.SZ): æœªå…¥é€‰")
            
    except Exception as e:
        print(f"Tushareæµ‹è¯•å¤±è´¥: {e}")
    
    # æµ‹è¯•é¡½ä¸»ç²¾é€‰
    print("\n" + "=" * 60)
    print("æµ‹è¯•é¡½ä¸»ç²¾é€‰...")
    try:
        universe = build_wanzhu_selected()
        summary = get_universe_summary(universe)
        print(f"  æ€»æ•°: {summary['total']}")
        print(f"  ä¸Šæµ·: {summary['sh_count']}, æ·±åœ³: {summary['sz_count']}")
        print(f"  æ¥æº: {summary['sources']}")
        print("\nå‰5åªè‚¡ç¥¨:")
        for s in universe[:5]:
            print(f"  {s['rank']:3d}. {s['name']} ({s['code']})")
    except Exception as e:
        print(f"é¡½ä¸»ç²¾é€‰æµ‹è¯•å¤±è´¥: {e}")