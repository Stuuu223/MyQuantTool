#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
äº‹ä»¶ç”Ÿå‘½å‘¨æœŸæœåŠ¡ - Phase 3é€šç”¨åŒ–å°è£…

èŒè´£ï¼š
1. å•ç¥¨å•æ—¥äº‹ä»¶åˆ†æ
2. è®¡ç®—ç»´æŒèƒ½åŠ›åˆ†ã€ç¯å¢ƒåˆ†
3. è¾“å‡ºçœŸèµ·çˆ†/éª—ç‚®é¢„æµ‹

ä½¿ç”¨ï¼š
    service = EventLifecycleService()
    result = service.analyze("300017", "2026-01-26")
    # result = {
    #     'sustain_score': 0.65,      # ç»´æŒèƒ½åŠ›åˆ† (0-1)
    #     'env_score': 0.87,           # ç¯å¢ƒåˆ† (0-1)
    #     'is_true_breakout': True,    # çœŸèµ·çˆ†é¢„æµ‹
    #     'confidence': 0.82,          # ç½®ä¿¡åº¦
    #     'entry_signal': {...}        # å…¥åœºä¿¡å·è¯¦æƒ…
    # }

Author: iFlow CLI
Version: Phase 3.0
Date: 2026-02-21
"""

import json
import sys
from pathlib import Path
from datetime import datetime, timedelta
from typing import Optional, Tuple, Dict, List
from dataclasses import asdict

import pandas as pd
import numpy as np

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from logic.event_lifecycle_analyzer import EventLifecycleAnalyzer, TrueBreakoutEvent, TrapEvent
from logic.services.data_service import data_service
from logic.qmt_historical_provider import QMTHistoricalProvider
from logic.rolling_metrics import RollingFlowCalculator


class EventLifecycleService:
    """
    äº‹ä»¶ç”Ÿå‘½å‘¨æœŸæœåŠ¡ - Phase 3é€šç”¨åŒ–å°è£…
    
    æä¾›å•ç¥¨å•æ—¥çš„äº‹ä»¶åˆ†æã€ç»´æŒèƒ½åŠ›è¯„åˆ†ã€ç¯å¢ƒè¯„åˆ†å’ŒçœŸèµ·çˆ†/éª—ç‚®é¢„æµ‹åŠŸèƒ½ã€‚
    """
    
    def __init__(self):
        """åˆå§‹åŒ–äº‹ä»¶ç”Ÿå‘½å‘¨æœŸæœåŠ¡"""
        self.lifecycle_analyzer = None  # å»¶è¿Ÿåˆå§‹åŒ–
        self._env_cache = {}  # ç¯å¢ƒæ•°æ®ç¼“å­˜
        self._tick_cache = {}  # Tickæ•°æ®ç¼“å­˜ï¼ˆå•æ—¥å†…æœ‰æ•ˆï¼‰
        
    def analyze(self, code: str, date: str) -> dict:
        """
        ä¸»åˆ†ææ¥å£ - åˆ†æå•ç¥¨å•æ—¥çš„äº‹ä»¶ç”Ÿå‘½å‘¨æœŸ
        
        Args:
            code: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ "300017"
            date: æ—¥æœŸï¼Œæ ¼å¼ "2026-01-26"
            
        Returns:
            dict: åˆ†æç»“æœï¼ŒåŒ…å«ç»´æŒèƒ½åŠ›åˆ†ã€ç¯å¢ƒåˆ†ã€çœŸèµ·çˆ†é¢„æµ‹ç­‰
            {
                'code': '300017',
                'date': '2026-01-26',
                'sustain_score': 0.65,           # ç»´æŒèƒ½åŠ›åˆ†
                'sustain_duration_min': 132.4,   # ç»´æŒæ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰
                'env_score': 0.87,               # ç¯å¢ƒåˆ†
                'env_details': {...},            # ç¯å¢ƒè¯¦æƒ…
                'is_true_breakout': True,        # çœŸèµ·çˆ†é¢„æµ‹
                'confidence': 0.82,              # ç½®ä¿¡åº¦
                'entry_signal': {...},           # å…¥åœºä¿¡å·
                'raw_data': {...}                # åŸå§‹æ•°æ®ï¼ˆè°ƒè¯•ç”¨ï¼‰
            }
        """
        try:
            # 1. åŠ è½½Tickæ•°æ®
            df = self._load_tick_data(code, date)
            if df is None or df.empty:
                return {
                    'error': f'æ— æ³•åŠ è½½ {code} åœ¨ {date} çš„Tickæ•°æ®',
                    'code': code,
                    'date': date,
                    'sustain_score': 0.0,
                    'env_score': 0.5,  # ğŸ”¥ P1: é»˜è®¤0.5é˜²0æ±¡æŸ“
                    'is_true_breakout': None,
                    'confidence': 0.0
                }
            
            pre_close = df['pre_close'].iloc[0] if 'pre_close' in df.columns else 0
            if pre_close <= 0:
                return {
                    'error': f'æ— æ³•è·å– {code} åœ¨ {date} çš„æ˜¨æ”¶ä»·',
                    'code': code,
                    'date': date,
                    'sustain_score': 0.0,
                    'env_score': 0.5,  # ğŸ”¥ P1: é»˜è®¤0.5é˜²0æ±¡æŸ“
                    'is_true_breakout': None,
                    'confidence': 0.0
                }
            
            # 2. äº‹ä»¶ç”Ÿå‘½å‘¨æœŸåˆ†æ
            lifecycle = self._analyze_lifecycle(code, df, pre_close)
            
            # 3. è®¡ç®—ç»´æŒèƒ½åŠ›åˆ†
            sustain_score, sustain_duration = self._calculate_sustain_score(lifecycle, df)
            
            # 4. è®¡ç®—ç¯å¢ƒåˆ†
            env_score, env_details = self._calculate_env_score(date, code)
            
            # 5. é¢„æµ‹çœŸèµ·çˆ†/éª—ç‚®
            is_true_breakout, confidence = self._predict_breakout(sustain_score, env_score)
            
            # 6. æå–å…¥åœºä¿¡å·
            entry_signal = self._extract_entry_signal(df, lifecycle, pre_close)
            
            # 7. ç»„è£…ç»“æœ
            result = {
                'code': code,
                'date': date,
                'sustain_score': round(sustain_score, 2),
                'sustain_duration_min': round(sustain_duration, 1),
                'env_score': round(env_score, 2),
                'env_details': env_details,
                'is_true_breakout': is_true_breakout,
                'confidence': round(confidence, 2),
                'entry_signal': entry_signal,
                'raw_data': {
                    'lifecycle': lifecycle,
                    'tick_count': len(df),
                    'pre_close': pre_close,
                    'max_change_pct': df['true_change_pct'].max() if 'true_change_pct' in df.columns else 0,
                }
            }
            
            return result
            
        except Exception as e:
            return {
                'error': f'åˆ†æå¤±è´¥: {str(e)}',
                'code': code,
                'date': date,
                'sustain_score': 0.0,
                'env_score': 0.5,  # ğŸ”¥ P1: é»˜è®¤0.5é˜²0æ±¡æŸ“
                'is_true_breakout': None,
                'confidence': 0.0
            }
    
    def _load_tick_data(self, code: str, date: str) -> Optional[pd.DataFrame]:
        """
        åŠ è½½Tickæ•°æ®
        
        Args:
            code: è‚¡ç¥¨ä»£ç 
            date: æ—¥æœŸ
            
        Returns:
            DataFrameæˆ–Noneï¼ŒåŒ…å«åˆ—ï¼štime, price, true_change_pct, flow_5min, flow_15min, pre_close
        """
        cache_key = f"{code}_{date}"
        if cache_key in self._tick_cache:
            return self._tick_cache[cache_key]
        
        try:
            formatted_code = data_service._format_code(code)
            pre_close = data_service.get_pre_close(code, date)
            
            if pre_close <= 0:
                return None
            
            start_time = date.replace('-', '') + '093000'
            end_time = date.replace('-', '') + '150000'
            
            provider = QMTHistoricalProvider(
                stock_code=formatted_code,
                start_time=start_time,
                end_time=end_time,
                period='tick'
            )
            
            tick_count = provider.get_tick_count()
            if tick_count == 0:
                return None
            
            # è®¡ç®—èµ„é‡‘æµ
            calc = RollingFlowCalculator(windows=[1, 5, 15])
            results = []
            last_tick = None
            
            for tick in provider.iter_ticks():
                metrics = calc.add_tick(tick, last_tick)
                true_change = (tick['lastPrice'] - pre_close) / pre_close * 100
                
                results.append({
                    'time': datetime.fromtimestamp(int(tick['time']) / 1000),
                    'price': tick['lastPrice'],
                    'true_change_pct': true_change,
                    'flow_1min': metrics.flow_1min.total_flow,
                    'flow_5min': metrics.flow_5min.total_flow,
                    'flow_15min': metrics.flow_15min.total_flow,
                    'pre_close': pre_close,
                })
                last_tick = tick
            
            df = pd.DataFrame(results)
            self._tick_cache[cache_key] = df
            return df
            
        except Exception as e:
            print(f"åŠ è½½Tickæ•°æ®å¤±è´¥ {code} {date}: {e}")
            return None
    
    def _analyze_lifecycle(self, code: str, df: pd.DataFrame, pre_close: float) -> dict:
        """
        åˆ†æäº‹ä»¶ç”Ÿå‘½å‘¨æœŸ
        
        Args:
            code: è‚¡ç¥¨ä»£ç 
            df: Tickæ•°æ®DataFrame
            pre_close: æ˜¨æ”¶ä»·
            
        Returns:
            dict: ç”Ÿå‘½å‘¨æœŸåˆ†æç»“æœ
        """
        # åˆå§‹åŒ–åˆ†æå™¨ï¼ˆä½¿ç”¨ratioåŒ–é˜ˆå€¼ï¼‰
        analyzer = EventLifecycleAnalyzer(
            stock_code=code,
            breakout_threshold=4.0,
            trap_reversal_threshold=-1.5,
            max_drawdown_threshold=3.0
        )
        
        events = analyzer.analyze_day(df, pre_close)
        
        lifecycle = {
            'max_change_pct': df['true_change_pct'].max(),
            'min_change_pct': df['true_change_pct'].min(),
            'final_change_pct': df['true_change_pct'].iloc[-1],
            'total_inflow_yi': df['flow_5min'].sum() / 1e8,
            'breakout': None,
            'trap': None,
            'event_type': 'unknown'
        }
        
        # çœŸèµ·çˆ†äº‹ä»¶
        if events['breakouts']:
            evt = events['breakouts'][0]
            if evt.push_phase:
                lifecycle['breakout'] = {
                    't_start': evt.push_phase.t_start,
                    't_end': evt.push_phase.t_end,
                    'warmup_duration': evt.push_phase.duration_minutes,
                    'change_start_pct': evt.push_phase.change_start_pct,
                    'change_end_pct': evt.push_phase.change_end_pct,
                    'change_peak_pct': evt.push_phase.change_peak_pct,
                    'max_drawdown_pct': evt.push_phase.max_drawdown_pct,
                    'total_inflow_yi': evt.push_phase.total_inflow / 1e8,
                    'max_flow_5min_yi': evt.push_phase.max_flow_5min / 1e8,
                    'sustain_ratio': evt.push_phase.sustain_ratio,
                    'efficiency': evt.push_phase.price_efficiency,
                    'is_gradual_push': evt.is_gradual_push,
                }
                lifecycle['event_type'] = 'true_breakout'
        
        # éª—ç‚®äº‹ä»¶
        if events['traps']:
            evt = events['traps'][0]
            if evt.fake_phase:
                lifecycle['trap'] = {
                    't_fake': evt.t_fake,
                    't_peak': evt.t_peak,
                    't_fail': evt.t_fail,
                    'fake_duration': evt.fake_duration,
                    'fake_change_pct': evt.fake_change_pct,
                    'fall_duration': evt.fall_duration,
                    'fall_change_pct': evt.fall_change_pct,
                }
                if lifecycle['event_type'] == 'unknown':
                    lifecycle['event_type'] = 'trap'
        
        return lifecycle
    
    def _calculate_sustain_score(self, lifecycle: dict, df: pd.DataFrame) -> Tuple[float, float]:
        """
        è®¡ç®—ç»´æŒèƒ½åŠ›åˆ† (0-1)
        
        Phase 2éªŒè¯çš„æƒé‡ï¼š
        - æ—¶é—´ç»´åº¦ï¼ˆé«˜ä½ç»´æŒæ—¶é•¿ï¼‰ï¼šæƒé‡50%
        - å¼ºåº¦ç»´åº¦ï¼ˆå¹³å‡èµ„é‡‘æµå…¥ï¼‰ï¼šæƒé‡30%
        - ç¨³å®šæ€§ç»´åº¦ï¼ˆä»·æ ¼æ³¢åŠ¨ç‡ï¼‰ï¼šæƒé‡20%
        
        Args:
            lifecycle: ç”Ÿå‘½å‘¨æœŸåˆ†æç»“æœ
            df: Tickæ•°æ®DataFrame
            
        Returns:
            Tuple[float, float]: (ç»´æŒèƒ½åŠ›åˆ†, ç»´æŒæ—¶é•¿åˆ†é’Ÿ)
        """
        t_breakout = lifecycle.get('breakout', {})
        t_trap = lifecycle.get('trap', {})
        
        if t_breakout:
            # çœŸèµ·çˆ†ï¼šåŸºäºæ¨å‡ç»“æŸç‚¹è®¡ç®—ç»´æŒèƒ½åŠ›
            return self._calculate_true_breakout_sustain(df, t_breakout)
        elif t_trap:
            # éª—ç‚®ï¼šåŸºäºæ¬ºéª—é«˜ç‚¹è®¡ç®—ç»´æŒèƒ½åŠ›
            return self._calculate_trap_sustain(df, t_trap)
        else:
            # æœªè¯†åˆ«åˆ°æ˜ç¡®äº‹ä»¶
            return 0.0, 0.0
    
    def _calculate_true_breakout_sustain(self, df: pd.DataFrame, breakout_info: dict) -> Tuple[float, float]:
        """
        è®¡ç®—çœŸèµ·çˆ†ç»´æŒèƒ½åŠ›
        
        Args:
            df: Tickæ•°æ®DataFrame
            breakout_info: èµ·çˆ†ä¿¡æ¯
            
        Returns:
            Tuple[float, float]: (ç»¼åˆç»´æŒå¾—åˆ†, ç»´æŒæ—¶é•¿åˆ†é’Ÿ)
        """
        push_end_time = breakout_info.get('t_end', '')
        if not push_end_time:
            return 0.0, 0.0
        
        push_end_idx = self._find_time_index(df, push_end_time)
        if push_end_idx >= len(df) - 1:
            return 0.0, 0.0
        
        push_end_price = df.loc[push_end_idx, 'price']
        sustain_threshold = push_end_price * 0.98  # -2%é˜ˆå€¼
        
        sustain_df = df.iloc[push_end_idx:]
        above_threshold = sustain_df[sustain_df['price'] >= sustain_threshold]
        
        if len(above_threshold) == 0:
            return 0.0, 0.0
        
        # æ—¶é—´ç»´åº¦ï¼šé«˜ä½ç»´æŒæ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰
        tick_interval_seconds = 3  # çº¦3ç§’ä¸€æ¡Tick
        sustain_minutes = len(above_threshold) * tick_interval_seconds / 60
        
        # å¼ºåº¦ç»´åº¦ï¼šç»´æŒæœŸé—´å¹³å‡èµ„é‡‘æµå…¥ï¼ˆäº¿å…ƒ/5minï¼‰
        avg_flow = above_threshold['flow_5min'].mean() / 1e8
        
        # ç¨³å®šæ€§ç»´åº¦ï¼šä»·æ ¼æ³¢åŠ¨ç‡ï¼ˆ%ï¼‰
        price_volatility = above_threshold['price'].std() / above_threshold['price'].mean() * 100
        
        # è®¡ç®—ç»¼åˆå¾—åˆ†ï¼ˆ0-1ï¼‰
        duration_score = min(sustain_minutes / 60, 1.0)  # 60åˆ†é’Ÿä¸ºæ»¡åˆ†
        strength_score = min(avg_flow / 0.5, 1.0)  # 0.5äº¿å…ƒ/5minä¸ºæ»¡åˆ†
        stability_score = 1.0 - min(price_volatility / 10.0, 1.0)  # æ³¢åŠ¨ç‡<10%ä¸ºæ»¡åˆ†
        
        composite_score = (
            duration_score * 0.5 + 
            strength_score * 0.3 + 
            stability_score * 0.2
        )
        
        return composite_score, sustain_minutes
    
    def _calculate_trap_sustain(self, df: pd.DataFrame, trap_info: dict) -> Tuple[float, float]:
        """
        è®¡ç®—éª—ç‚®ç»´æŒèƒ½åŠ›ï¼ˆé€šå¸¸å¾ˆçŸ­ï¼‰
        
        Args:
            df: Tickæ•°æ®DataFrame
            trap_info: éª—ç‚®ä¿¡æ¯
            
        Returns:
            Tuple[float, float]: (ç»¼åˆç»´æŒå¾—åˆ†, ç»´æŒæ—¶é•¿åˆ†é’Ÿ)
        """
        peak_time = trap_info.get('t_peak', '')
        if not peak_time:
            return 0.0, 0.0
        
        peak_idx = self._find_time_index(df, peak_time)
        if peak_idx >= len(df) - 1:
            return 0.0, 0.0
        
        peak_price = df.loc[peak_idx, 'price']
        sustain_threshold = peak_price * 0.98
        
        after_peak_df = df.iloc[peak_idx:]
        above_threshold = after_peak_df[after_peak_df['price'] >= sustain_threshold]
        
        if len(above_threshold) == 0:
            return 0.0, 0.0
        
        tick_interval_seconds = 3
        sustain_minutes = len(above_threshold) * tick_interval_seconds / 60
        
        avg_flow = above_threshold['flow_5min'].mean() / 1e8
        price_volatility = above_threshold['price'].std() / above_threshold['price'].mean() * 100
        
        # éª—ç‚®çš„æƒé‡ç•¥æœ‰ä¸åŒ
        duration_score = min(sustain_minutes / 30, 1.0)  # 30åˆ†é’Ÿä¸ºæ»¡åˆ†
        strength_score = min(avg_flow / 0.2, 1.0)  # 0.2äº¿å…ƒ/5minä¸ºæ»¡åˆ†
        stability_score = 1.0 - min(price_volatility / 15.0, 1.0)  # æ³¢åŠ¨ç‡<15%ä¸ºæ»¡åˆ†
        
        composite_score = (
            duration_score * 0.4 + 
            strength_score * 0.3 + 
            stability_score * 0.3
        )
        
        # éª—ç‚®å¾—åˆ†æ‰“æŠ˜æ‰£
        composite_score *= 0.5
        
        return composite_score, sustain_minutes
    
    def _find_time_index(self, df: pd.DataFrame, target_time: str) -> int:
        """
        åœ¨DataFrameä¸­æŸ¥æ‰¾æ—¶é—´ç‚¹ç´¢å¼• - O(1)å‘é‡åŒ–ä¼˜åŒ–
        
        Args:
            df: DataFrame
            target_time: ç›®æ ‡æ—¶é—´ï¼Œæ ¼å¼ "HH:MM:SS"
            
        Returns:
            int: ç´¢å¼•ä½ç½®
        """
        if not target_time or 'time' not in df.columns or len(df) == 0:
            return 0
        
        try:
            # ğŸ”¥ Phase 1.5.3: O(1)å‘é‡åŒ–æŸ¥æ‰¾ï¼Œæ›¿ä»£O(n)é€è¡Œéå†
            # å°†æ—¶é—´åˆ—è½¬ä¸ºå­—ç¬¦ä¸²æ ¼å¼è¿›è¡Œæ¯”è¾ƒ
            time_str = df['time'].dt.strftime('%H:%M:%S') if pd.api.types.is_datetime64_any_dtype(df['time']) else df['time'].astype(str)
            
            # ç²¾ç¡®åŒ¹é…
            exact_match = time_str == target_time
            if exact_match.any():
                return exact_match.idxmax()
            
            # æœ€æ¥è¿‘çš„æ—¶é—´ï¼ˆç¬¬ä¸€ä¸ª>=target_timeçš„ä½ç½®ï¼‰
            future_mask = time_str >= target_time
            if future_mask.any():
                return future_mask.idxmax()
            
            # å¦‚æœéƒ½æ™šäºtarget_timeï¼Œè¿”å›æœ€åä¸€ä¸ª
            return len(df) - 1
            
        except Exception:
            # Fallback: è¿”å›ä¸­é—´ä½ç½®
            return len(df) // 2
    
    def _calculate_env_score(self, date: str, code: str) -> Tuple[float, dict]:
        """
        è®¡ç®—ç¯å¢ƒåˆ† (0-1)
        
        Phase 1æƒé‡ï¼š
        - æ¿å—å…±æŒ¯åˆ†æ•°ï¼šæƒé‡40%
        - å¸‚åœºæƒ…ç»ªåˆ†æ•°ï¼šæƒé‡40%
        - é£é™©è¯„åˆ†ï¼šæƒé‡20%
        
        Args:
            date: æ—¥æœŸ
            code: è‚¡ç¥¨ä»£ç 
            
        Returns:
            Tuple[float, dict]: (ç¯å¢ƒåˆ†, ç¯å¢ƒè¯¦æƒ…)
        """
        cache_key = date
        if cache_key in self._env_cache:
            return self._env_cache[cache_key]
        
        env_details = {
            'resonance_score': 0.5,
            'market_sentiment': 0.5,
            'risk_score': 0.5,
            'resonance_source': 'default',
            'sentiment_source': 'default'
        }
        
        # 1. åŠ è½½æ¿å—å…±æŒ¯åˆ†æ•°ï¼ˆä¼˜å…ˆä½¿ç”¨æ‰‹å·¥å›å¡«æ•°æ®ï¼‰
        resonance_score = 0.5
        resonance_loaded = False
        
        env_path = PROJECT_ROOT / "config" / "event_environment.json"
        if env_path.exists():
            try:
                with open(env_path, 'r', encoding='utf-8') as f:
                    env_data = json.load(f)
                
                env_data_dict = env_data.get('environment_data', {})
                date_formats = [date, date.replace('-', ''), f"{date.replace('-', '')[:8]}"]
                
                for date_fmt in date_formats:
                    if date_fmt in env_data_dict:
                        env_info = env_data_dict[date_fmt]
                        resonance_score = env_info.get('resonance_score', 0.5)
                        env_details['resonance_score'] = resonance_score
                        env_details['resonance_source'] = 'event_environment.json'
                        env_details['resonance_info'] = {
                            'limit_up_count': env_info.get('limit_up_count', 0),
                            'limit_down_count': env_info.get('limit_down_count', 0),
                            'sector_active_stocks': env_info.get('sector_active_stocks', 0),
                            'sector_total_stocks': env_info.get('sector_total_stocks', 45),
                            'description': env_info.get('description', '')
                        }
                        resonance_loaded = True
                        break
                        
            except Exception as e:
                pass
        
        # å¦‚æœæ‰‹å·¥å›å¡«æ•°æ®æœªæ‰¾åˆ°ï¼Œå›é€€åˆ°WindFilterå®æ—¶è®¡ç®—
        if not resonance_loaded:
            try:
                from logic.strategies.wind_filter import WindFilter
                wind_filter = WindFilter()
                resonance_result = wind_filter.check_sector_resonance(code)
                resonance_score = resonance_result.get('resonance_score', 0.5)
                env_details['resonance_score'] = resonance_score
                env_details['resonance_source'] = 'WindFilter'
                env_details['resonance_info'] = resonance_result
            except Exception:
                pass
        
        # 2. åŠ è½½å¸‚åœºæƒ…ç»ªæ•°æ®
        sentiment_score = 0.5
        sentiment_loaded = False
        
        sentiment_path = PROJECT_ROOT / "config" / "market_sentiment.json"
        if sentiment_path.exists():
            try:
                with open(sentiment_path, 'r', encoding='utf-8') as f:
                    sentiment_data = json.load(f)
                
                date_formats = [date, date.replace('-', ''), f"{date.replace('-', '')[:8]}"]
                
                for date_fmt in date_formats:
                    if date_fmt in sentiment_data:
                        sentiment_info = sentiment_data[date_fmt]
                        sentiment_score = sentiment_info.get('sentiment_score', 0.5)
                        env_details['market_sentiment'] = sentiment_score
                        env_details['sentiment_source'] = 'market_sentiment.json'
                        env_details['sentiment_info'] = sentiment_info
                        sentiment_loaded = True
                        break
                
                if not sentiment_loaded and sentiment_data:
                    # ä½¿ç”¨æœ€è¿‘æ—¥æœŸçš„æƒ…ç»ªæ•°æ®ä½œä¸ºå›é€€
                    available_dates = list(sentiment_data.keys())
                    if available_dates:
                        latest_date = max(available_dates)
                        sentiment_info = sentiment_data[latest_date]
                        sentiment_score = sentiment_info.get('sentiment_score', 0.5)
                        env_details['market_sentiment'] = sentiment_score
                        env_details['sentiment_source'] = f'market_sentiment.json({latest_date})'
                        env_details['sentiment_info'] = sentiment_info
                        sentiment_loaded = True
                        
            except Exception as e:
                pass
        
        # 3. é£é™©è¯„åˆ†ï¼ˆå ä½å®ç°ï¼‰
        risk_score = 0.5  # é»˜è®¤ä¸­ç­‰é£é™©
        env_details['risk_score'] = risk_score
        
        # 4. è®¡ç®—ç»¼åˆç¯å¢ƒè¯„åˆ†ï¼ˆ0-1ï¼‰
        # é£é™©åˆ†æ•°éœ€è¦åè½¬ï¼šé£é™©è¶Šé«˜ï¼Œç¯å¢ƒåˆ†è¶Šä½
        risk_adjusted = 1.0 - abs(risk_score - 0.5) * 2
        
        env_score = (
            resonance_score * 0.4 + 
            sentiment_score * 0.4 + 
            risk_adjusted * 0.2
        )
        
        result = (round(env_score, 2), env_details)
        self._env_cache[cache_key] = result
        return result
    
    def _predict_breakout(self, sustain_score: float, env_score: float) -> Tuple[Optional[bool], float]:
        """
        é¢„æµ‹çœŸèµ·çˆ†/éª—ç‚®ï¼Œè¿”å› (is_true_breakout, confidence)
        
        é¢„æµ‹é€»è¾‘ï¼ˆåŸºäºPhase 2éªŒè¯ç»“æœï¼‰ï¼š
        - çœŸèµ·çˆ†å¹³å‡ç»´æŒæ—¶é•¿ 132.4åˆ†é’Ÿï¼Œç¯å¢ƒåˆ†0.62
        - éª—ç‚®å¹³å‡ç»´æŒæ—¶é•¿ 28.7åˆ†é’Ÿï¼Œç¯å¢ƒåˆ†0.21
        - çœŸ/éª—ç‚®æ¯”ç‡ 4.61
        
        é¢„æµ‹è§„åˆ™ï¼š
        - sustain_score >= 0.5 ä¸” env_score >= 0.6 â†’ çœŸèµ·çˆ†
        - sustain_score < 0.3 æˆ– env_score < 0.4 â†’ éª—ç‚®
        - å…¶ä»– â†’ ä¸ç¡®å®š
        
        Args:
            sustain_score: ç»´æŒèƒ½åŠ›åˆ† (0-1)
            env_score: ç¯å¢ƒåˆ† (0-1)
            
        Returns:
            Tuple[Optional[bool], float]: (æ˜¯å¦çœŸèµ·çˆ†, ç½®ä¿¡åº¦)
        """
        if sustain_score >= 0.5 and env_score >= 0.6:
            return True, 0.8
        elif sustain_score < 0.3 or env_score < 0.4:
            return False, 0.7
        else:
            return None, 0.5  # ä¸ç¡®å®š
    
    def _extract_entry_signal(self, df: pd.DataFrame, lifecycle: dict, pre_close: float) -> Optional[dict]:
        """
        æå–å…¥åœºä¿¡å·è¯¦æƒ…
        
        Args:
            df: Tickæ•°æ®DataFrame
            lifecycle: ç”Ÿå‘½å‘¨æœŸåˆ†æç»“æœ
            pre_close: æ˜¨æ”¶ä»·
            
        Returns:
            dictæˆ–None: å…¥åœºä¿¡å·è¯¦æƒ…
        """
        t_breakout = lifecycle.get('breakout', {})
        if not t_breakout:
            return None
        
        trigger_time = t_breakout.get('t_start', '')
        if not trigger_time:
            return None
        
        trigger_idx = self._find_time_index(df, trigger_time)
        if trigger_idx >= len(df):
            return None
        
        entry_price = df.loc[trigger_idx, 'price']
        
        # è®¡ç®—é¢„æœŸæ”¶ç›Šï¼ˆåˆ°æ”¶ç›˜ï¼‰
        exit_price = df['price'].iloc[-1]
        expected_return = (exit_price - entry_price) / entry_price
        
        # è®¡ç®—æœ€å¤§å›æ’¤
        hold_df = df.iloc[trigger_idx:]
        cummax = hold_df['price'].cummax()
        drawdowns = (cummax - hold_df['price']) / cummax
        max_drawdown = drawdowns.max()
        
        return {
            'trigger_time': trigger_time,
            'entry_price': round(entry_price, 2),
            'expected_return': round(expected_return, 3),
            'max_drawdown': round(max_drawdown, 3)
        }
    
    def clear_cache(self):
        """æ¸…é™¤ç¼“å­˜"""
        self._env_cache.clear()
        self._tick_cache.clear()
    
    def _get_market_cap_multiplier(self, code: str) -> float:
        """
        æ ¹æ®æµé€šå¸‚å€¼è·å–é˜ˆå€¼ä¹˜æ•°
        
        ä¼˜å…ˆçº§ï¼š
        1. Tushareå®æ—¶æ•°æ®ï¼ˆåœ¨çº¿ï¼‰
        2. æœ¬åœ°equity_info/market_cap.jsonï¼ˆç¦»çº¿fallbackï¼‰
        3. é»˜è®¤å€¼1.0xï¼ˆä¸­ç›˜ï¼‰
        
        Args:
            code: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ "300017"
            
        Returns:
            float: é˜ˆå€¼ä¹˜æ•° (0.8=å°ç›˜, 1.0=ä¸­ç›˜, 1.2=å¤§ç›˜)
        """
        circ_mv = None
        data_source = "default"
        
        # 1. å°è¯•Tushareå®æ—¶è·å–
        try:
            circ_mv = self._get_circ_mv_from_tushare(code)
            if circ_mv and circ_mv > 0:
                data_source = "tushare"
        except Exception as e:
            print(f"   Tushareè·å–å¸‚å€¼å¤±è´¥ {code}: {e}")
        
        # 2. å°è¯•æœ¬åœ°fallback
        if not circ_mv:
            try:
                circ_mv = self._get_circ_mv_from_local(code)
                if circ_mv and circ_mv > 0:
                    data_source = "local"
            except Exception as e:
                print(f"   æœ¬åœ°å¸‚å€¼æ•°æ®å¤±è´¥ {code}: {e}")
        
        # 3. ä½¿ç”¨é»˜è®¤å€¼
        if not circ_mv:
            circ_mv = 50e9  # é»˜è®¤50äº¿ï¼ˆä¸­ç›˜ï¼‰
            data_source = "default"
        
        # è®¡ç®—ä¹˜æ•°
        if circ_mv < 30e9:       # å°ç›˜<30äº¿
            multiplier = 0.8
            tier = "small"
        elif circ_mv < 80e9:     # ä¸­ç›˜30-80äº¿
            multiplier = 1.0
            tier = "mid"
        else:                    # å¤§ç›˜>80äº¿
            multiplier = 1.2
            tier = "large"
        
        print(f"   å¸‚å€¼åˆ†å±‚: {code} {tier} ({circ_mv/1e9:.1f}äº¿) Ã—{multiplier} [{data_source}]")
        return multiplier
    
    def _get_circ_mv_from_tushare(self, code: str) -> Optional[float]:
        """
        ä»Tushareè·å–æµé€šå¸‚å€¼
        
        Args:
            code: è‚¡ç¥¨ä»£ç 
            
        Returns:
            Optional[float]: æµé€šå¸‚å€¼ï¼ˆå…ƒï¼‰ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            # å°è¯•ä»equity_info_tushare.jsonè¯»å–
            tushare_path = PROJECT_ROOT / "data" / "equity_info" / "equity_info_tushare.json"
            if tushare_path.exists():
                with open(tushare_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # è·å–æœ€æ–°æ—¥æœŸçš„æ•°æ®
                latest_date = data.get('latest_update', '')
                if not latest_date:
                    return None
                    
                date_data = data.get('data', {}).get(latest_date, {})
                
                # å°è¯•å¸¦åç¼€çš„ä»£ç 
                for suffix in ['.SZ', '.SH', '.BJ']:
                    key = f"{code}{suffix}"
                    if key in date_data:
                        float_mv = date_data[key].get('float_mv', 0)
                        # Tushareæ•°æ®å•ä½æ˜¯ä¸‡å…ƒï¼Œè½¬æ¢ä¸ºå…ƒ
                        if float_mv > 0:
                            return float(float_mv) * 10000
                
                # å°è¯•ä¸å¸¦å‰å¯¼é›¶
                if code.startswith('0'):
                    code_no_leading = code.lstrip('0')
                    for suffix in ['.SZ', '.SH', '.BJ']:
                        key = f"{code_no_leading}{suffix}"
                        if key in date_data:
                            float_mv = date_data[key].get('float_mv', 0)
                            if float_mv > 0:
                                return float(float_mv) * 10000
        except Exception as e:
            pass
        
        return None
    
    def _get_circ_mv_from_local(self, code: str) -> Optional[float]:
        """
        ä»æœ¬åœ°JSONåŠ è½½æµé€šå¸‚å€¼ï¼ˆç¦»çº¿fallbackï¼‰
        
        Args:
            code: è‚¡ç¥¨ä»£ç 
            
        Returns:
            Optional[float]: æµé€šå¸‚å€¼ï¼ˆå…ƒï¼‰ï¼Œå¤±è´¥è¿”å›None
        """
        # å°è¯•å¤šä¸ªè·¯å¾„
        paths = [
            PROJECT_ROOT / "data" / "equity_info" / "market_cap.json",
            PROJECT_ROOT / "data" / "equity_info.json",
            PROJECT_ROOT / "config" / "equity_info.json",
        ]
        
        for path in paths:
            if path.exists():
                try:
                    with open(path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    # è·³è¿‡metadata
                    if code in data and not code.startswith('_'):
                        return float(data[code].get('circ_mv', 0))
                    
                    # å°è¯•ä¸å¸¦å‰å¯¼é›¶
                    if code.startswith('0') and code.lstrip('0') in data:
                        return float(data[code.lstrip('0')].get('circ_mv', 0))
                except Exception as e:
                    continue
        
        return None


# ==================== æµ‹è¯•ä»£ç  ====================
if __name__ == "__main__":
    print("="*80)
    print("EventLifecycleService æµ‹è¯•")
    print("="*80)
    
    service = EventLifecycleService()
    
    # æµ‹è¯•ç”¨ä¾‹1: ç½‘å®¿ç§‘æŠ€çœŸèµ·çˆ†æ—¥ (2026-01-26)
    print("\nã€æµ‹è¯•ç”¨ä¾‹1ã€‘ç½‘å®¿ç§‘æŠ€ 2026-01-26 (å·²çŸ¥çœŸèµ·çˆ†)")
    print("-"*80)
    result1 = service.analyze("300017", "2026-01-26")
    
    if 'error' in result1 and result1['error']:
        print(f"âŒ é”™è¯¯: {result1['error']}")
    else:
        print(f"âœ… åˆ†æå®Œæˆ")
        print(f"   ç»´æŒèƒ½åŠ›åˆ†: {result1['sustain_score']}")
        print(f"   ç»´æŒæ—¶é•¿: {result1['sustain_duration_min']:.1f}åˆ†é’Ÿ")
        print(f"   ç¯å¢ƒåˆ†: {result1['env_score']}")
        print(f"   çœŸèµ·çˆ†é¢„æµ‹: {result1['is_true_breakout']}")
        print(f"   ç½®ä¿¡åº¦: {result1['confidence']}")
        if result1['entry_signal']:
            print(f"   å…¥åœºä¿¡å·: {result1['entry_signal']['trigger_time']} @ {result1['entry_signal']['entry_price']}")
    
    # æµ‹è¯•ç”¨ä¾‹2: ç½‘å®¿ç§‘æŠ€éª—ç‚®æ—¥ (2026-02-13)
    print("\nã€æµ‹è¯•ç”¨ä¾‹2ã€‘ç½‘å®¿ç§‘æŠ€ 2026-02-13 (å·²çŸ¥éª—ç‚®)")
    print("-"*80)
    result2 = service.analyze("300017", "2026-02-13")
    
    if 'error' in result2 and result2['error']:
        print(f"âŒ é”™è¯¯: {result2['error']}")
    else:
        print(f"âœ… åˆ†æå®Œæˆ")
        print(f"   ç»´æŒèƒ½åŠ›åˆ†: {result2['sustain_score']}")
        print(f"   ç»´æŒæ—¶é•¿: {result2['sustain_duration_min']:.1f}åˆ†é’Ÿ")
        print(f"   ç¯å¢ƒåˆ†: {result2['env_score']}")
        print(f"   çœŸèµ·çˆ†é¢„æµ‹: {result2['is_true_breakout']}")
        print(f"   ç½®ä¿¡åº¦: {result2['confidence']}")
    
    # æµ‹è¯•ç”¨ä¾‹3: æ— æ•ˆæ•°æ®æµ‹è¯•
    print("\nã€æµ‹è¯•ç”¨ä¾‹3ã€‘æ— æ•ˆè‚¡ç¥¨ä»£ç æµ‹è¯•")
    print("-"*80)
    result3 = service.analyze("999999", "2026-01-26")
    if 'error' in result3 and result3['error']:
        print(f"âš ï¸ é¢„æœŸé”™è¯¯: {result3['error']}")
    else:
        print(f"   ç»“æœ: {result3}")
    
    print("\n" + "="*80)
    print("æµ‹è¯•å®Œæˆ")
    print("="*80)
