#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å®šæ—¶ä»»åŠ¡ç›‘æ§ç³»ç»Ÿ

åŠŸèƒ½ï¼š
1. æ¯å¤©9:10æ£€æŸ¥Redisæ˜¯å¦å¯åŠ¨ï¼Œæœªå¯åŠ¨åˆ™è‡ªåŠ¨å¯åŠ¨
2. æ¯å¤©9:20æ£€æŸ¥ç«ä»·å¿«ç…§æ˜¯å¦è·å–ï¼Œå¦‚æœæ²¡æœ‰æŸ¥æ˜åŸå› 
3. æ£€æŸ¥æ—©ç›˜å‰éœ€è¦è¿è¡Œçš„Pythonæ–‡ä»¶
4. æ£€æŸ¥æ”¶ç›˜åå¤ç›˜éœ€è¦è¿è¡Œçš„æ–‡ä»¶
5. æ£€æŸ¥æ¯å‘¨éœ€è¦è¿è¡Œçš„æ–‡ä»¶
6. UIæç¤ºå’Œæ§åˆ¶å°å‘Šè­¦

Author: iFlow CLI
Version: V1.1
"""

import os
import sys
import subprocess
import time
from datetime import datetime, time as dt_time
from typing import Dict, List, Optional, Any
import json
import schedule
import threading

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from logic.logger import get_logger
from logic.data_manager import DataManager

logger = get_logger(__name__)


class ScheduledTaskMonitor:
    """å®šæ—¶ä»»åŠ¡ç›‘æ§ç³»ç»Ÿ"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç›‘æ§ç³»ç»Ÿ"""
        self.dm = DataManager()
        self.alerts = []
        self.alert_file = "data/scheduled_alerts.json"
        self.running = False
        
        # å®šæ—¶ä»»åŠ¡é…ç½®
        self.tasks = {
            # æ—©ç›˜å‰æ£€æŸ¥ï¼ˆ9:10ï¼‰
            'pre_market_check': {
                'time': '09:10',
                'enabled': True,
                'description': 'æ—©ç›˜å‰ç³»ç»Ÿæ£€æŸ¥'
            },
            # ç›˜å‰é¢„è®¡ç®—ï¼ˆ9:20ï¼‰
            'pre_market_precompute': {
                'time': '09:20',
                'enabled': True,
                'description': 'ç›˜å‰MA4é¢„è®¡ç®—'
            },
            # ç«ä»·å¿«ç…§æ£€æŸ¥ï¼ˆ9:20ï¼‰
            'auction_snapshot_check': {
                'time': '09:20',
                'enabled': True,
                'description': 'æ£€æŸ¥ç«ä»·å¿«ç…§æ˜¯å¦è·å–'
            },
            # ğŸ†• V19.6 æ–°å¢ï¼šç«ä»·å¿«ç…§ä¿å­˜ï¼ˆ9:25ï¼‰
            'auction_snapshot_save': {
                'time': '09:25',
                'enabled': True,
                'description': 'ç«ä»·å¿«ç…§è‡ªåŠ¨ä¿å­˜'
            },
            # æ”¶ç›˜åå¤ç›˜ï¼ˆ15:30ï¼‰
            'post_market_review': {
                'time': '15:30',
                'enabled': True,
                'description': 'æ”¶ç›˜åå¤ç›˜'
            },
            # æ¯å‘¨æ£€æŸ¥ï¼ˆå‘¨æ—¥20:00ï¼‰
            'weekly_check': {
                'time': '20:00',
                'day': 'sunday',
                'enabled': True,
                'description': 'æ¯å‘¨ç³»ç»Ÿæ£€æŸ¥'
            }
        }
        
        # éœ€è¦è¿è¡Œçš„Pythonæ–‡ä»¶é…ç½®
        self.required_files = {
            'pre_market': [
                'main.py',  # ä¸»ç¨‹åº
            ],
            'post_market': [
                'logic/review_manager.py',  # å¤ç›˜ç®¡ç†å™¨
                'logic/auto_reviewer_v18_7.py',  # æ™ºèƒ½å¤ç›˜
            ],
            'weekly': [
                'check_system_health.py',  # ç³»ç»Ÿå¥åº·æ£€æŸ¥
            ]
        }
        
        self._init_alert_file()
    
    def _init_alert_file(self):
        """åˆå§‹åŒ–å‘Šè­¦æ–‡ä»¶"""
        os.makedirs(os.path.dirname(self.alert_file), exist_ok=True)
        if not os.path.exists(self.alert_file):
            with open(self.alert_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'alerts': [],
                    'last_check': None,
                    'created_at': datetime.now().isoformat()
                }, f, ensure_ascii=False, indent=4)
    
    def _save_alert(self, alert_type: str, severity: str, message: str, details: Dict = None):
        """ä¿å­˜å‘Šè­¦ä¿¡æ¯"""
        alert = {
            'timestamp': datetime.now().isoformat(),
            'type': alert_type,
            'severity': severity,
            'message': message,
            'details': details or {}
        }
        
        try:
            with open(self.alert_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            data['alerts'].append(alert)
            data['last_check'] = datetime.now().isoformat()
            
            # ä¿ç•™æœ€è¿‘100æ¡å‘Šè­¦
            if len(data['alerts']) > 100:
                data['alerts'] = data['alerts'][-100:]
            
            with open(self.alert_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=4)
            
            self.alerts.append(alert)
            logger.warning(f"ğŸš¨ [å‘Šè­¦] {severity}: {message}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜å‘Šè­¦å¤±è´¥: {e}")
    
    def check_redis_status(self) -> bool:
        """æ£€æŸ¥RedisæœåŠ¡çŠ¶æ€"""
        try:
            # æ£€æŸ¥Redisè¿›ç¨‹
            result = subprocess.run(['tasklist'], capture_output=True, text=True)
            redis_running = 'redis-server.exe' in result.stdout
            
            if redis_running:
                logger.info("âœ… RedisæœåŠ¡æ­£åœ¨è¿è¡Œ")
                return True
            else:
                logger.warning("âš ï¸ RedisæœåŠ¡æœªè¿è¡Œ")
                self._save_alert(
                    'redis_status',
                    'WARNING',
                    'RedisæœåŠ¡æœªè¿è¡Œ',
                    {'action': 'å°è¯•è‡ªåŠ¨å¯åŠ¨Redis'}
                )
                return False
                
        except Exception as e:
            logger.error(f"æ£€æŸ¥RedisçŠ¶æ€å¤±è´¥: {e}")
            self._save_alert(
                'redis_status',
                'ERROR',
                f'æ£€æŸ¥RedisçŠ¶æ€å¤±è´¥: {str(e)}',
                {}
            )
            return False
    
    def start_redis_service(self) -> bool:
        """å¯åŠ¨RedisæœåŠ¡"""
        try:
            logger.info("ğŸ”„ å°è¯•å¯åŠ¨RedisæœåŠ¡...")
            
            # æ£€æŸ¥RedisæœåŠ¡æ˜¯å¦å­˜åœ¨
            result = subprocess.run(['sc', 'query', 'Redis'], capture_output=True, text=True)
            
            if 'RUNNING' in result.stdout:
                logger.info("âœ… RedisæœåŠ¡å·²åœ¨è¿è¡Œ")
                return True
            
            # å°è¯•å¯åŠ¨RedisæœåŠ¡
            subprocess.run(['sc', 'start', 'Redis'], capture_output=True, timeout=10)
            time.sleep(2)
            
            # å†æ¬¡æ£€æŸ¥
            result = subprocess.run(['sc', 'query', 'Redis'], capture_output=True, text=True)
            if 'RUNNING' in result.stdout:
                logger.info("âœ… RedisæœåŠ¡å¯åŠ¨æˆåŠŸ")
                self._save_alert(
                    'redis_status',
                    'INFO',
                    'RedisæœåŠ¡å¯åŠ¨æˆåŠŸ',
                    {}
                )
                return True
            else:
                logger.error("âŒ RedisæœåŠ¡å¯åŠ¨å¤±è´¥")
                self._save_alert(
                    'redis_status',
                    'CRITICAL',
                    'RedisæœåŠ¡å¯åŠ¨å¤±è´¥',
                    {'suggestion': 'è¯·æ‰‹åŠ¨å¯åŠ¨Redisæˆ–ä½¿ç”¨start_with_redis.bat'}
                )
                return False
                
        except Exception as e:
            logger.error(f"å¯åŠ¨RedisæœåŠ¡å¤±è´¥: {e}")
            self._save_alert(
                'redis_status',
                'CRITICAL',
                f'å¯åŠ¨RedisæœåŠ¡å¤±è´¥: {str(e)}',
                {'suggestion': 'è¯·æ‰‹åŠ¨å¯åŠ¨Redisæˆ–ä½¿ç”¨start_with_redis.bat'}
            )
            return False
    
    def check_required_files(self, category: str) -> Dict[str, bool]:
        """æ£€æŸ¥å¿…éœ€çš„Pythonæ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        results = {}
        files = self.required_files.get(category, [])
        
        for file_path in files:
            full_path = os.path.join(project_root, file_path)
            exists = os.path.exists(full_path)
            results[file_path] = exists
            
            if not exists:
                self._save_alert(
                    'missing_file',
                    'CRITICAL',
                    f'ç¼ºå°‘å¿…éœ€æ–‡ä»¶: {file_path}',
                    {'category': category, 'path': full_path}
                )
        
        return results
    
    def check_auction_snapshot(self) -> bool:
        """æ£€æŸ¥ç«ä»·å¿«ç…§åŠŸèƒ½"""
        try:
            # æ£€æŸ¥AuctionSnapshotManageræ˜¯å¦å¯ç”¨
            if hasattr(self.dm, 'auction_snapshot_manager') and self.dm.auction_snapshot_manager:
                status = self.dm.auction_snapshot_manager.get_snapshot_status()
                
                if status['is_available']:
                    logger.info(f"âœ… ç«ä»·å¿«ç…§åŠŸèƒ½æ­£å¸¸ (Rediså·²è¿æ¥)")
                    return True
                else:
                    logger.warning("âš ï¸ ç«ä»·å¿«ç…§åŠŸèƒ½ä¸å¯ç”¨ (Redisæœªè¿æ¥)")
                    self._save_alert(
                        'auction_snapshot',
                        'WARNING',
                        'ç«ä»·å¿«ç…§åŠŸèƒ½ä¸å¯ç”¨',
                        {'reason': 'Redisæœªè¿æ¥'}
                    )
                    return False
            else:
                logger.warning("âš ï¸ ç«ä»·å¿«ç…§ç®¡ç†å™¨æœªåˆå§‹åŒ–")
                return False
                
        except Exception as e:
            logger.error(f"æ£€æŸ¥ç«ä»·å¿«ç…§å¤±è´¥: {e}")
            return False
    
    def run_pre_market_check(self):
        """æ—©ç›˜å‰æ£€æŸ¥ï¼ˆ9:10ï¼‰"""
        logger.info("=" * 80)
        logger.info("ğŸ• æ—©ç›˜å‰ç³»ç»Ÿæ£€æŸ¥ (9:10)")
        logger.info("=" * 80)
        
        # 1. æ£€æŸ¥Redis
        redis_ok = self.check_redis_status()
        if not redis_ok:
            logger.info("ğŸ”„ å°è¯•è‡ªåŠ¨å¯åŠ¨Redis...")
            self.start_redis_service()
        
        # 2. æ£€æŸ¥ç«ä»·å¿«ç…§
        auction_ok = self.check_auction_snapshot()
        
        # 3. æ£€æŸ¥å¿…éœ€æ–‡ä»¶
        pre_market_files = self.check_required_files('pre_market')
        files_ok = all(pre_market_files.values())
        
        # 4. ç”Ÿæˆæ£€æŸ¥æŠ¥å‘Š
        report = {
            'timestamp': datetime.now().isoformat(),
            'redis_ok': redis_ok,
            'auction_ok': auction_ok,
            'files_ok': files_ok,
            'files_status': pre_market_files,
            'overall_status': 'OK' if redis_ok and auction_ok and files_ok else 'WARNING'
        }
        
        logger.info(f"ğŸ“Š æ—©ç›˜å‰æ£€æŸ¥å®Œæˆ: {report['overall_status']}")
        
        if report['overall_status'] != 'OK':
            self._save_alert(
                'pre_market_check',
                'WARNING',
                'æ—©ç›˜å‰æ£€æŸ¥å‘ç°é—®é¢˜',
                report
            )
        
        return report
    
    def run_pre_market_precompute(self):
        """ç›˜å‰é¢„è®¡ç®—ï¼ˆ9:20ï¼‰"""
        logger.info("=" * 80)
        logger.info("ğŸ• ç›˜å‰MA4é¢„è®¡ç®— (9:20)")
        logger.info("=" * 80)
        
        try:
            from logic.pre_market_cache import get_pre_market_cache
            from logic.data_manager import DataManager
            
            logger.info("ğŸ”„ å¼€å§‹ç›˜å‰é¢„è®¡ç®—...")
            
            # è·å–ç¼“å­˜å®ä¾‹
            cache = get_pre_market_cache()
            
            # è·å–æ‰€æœ‰è‚¡ç¥¨åˆ—è¡¨
            dm = DataManager()
            stock_list_df = dm.get_market_data()
            
            # æ£€æŸ¥è¿”å›å€¼æ˜¯å¦ä¸ºç©º
            if stock_list_df is None:
                logger.warning("âš ï¸ æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
                return False
            
            # å¦‚æœæ˜¯å­—å…¸ï¼Œè½¬æ¢ä¸ºDataFrame
            if isinstance(stock_list_df, dict):
                import pandas as pd
                if not stock_list_df:
                    logger.warning("âš ï¸ è‚¡ç¥¨åˆ—è¡¨ä¸ºç©º")
                    return False
                stock_list_df = pd.DataFrame(stock_list_df)
            # å¦‚æœæ˜¯DataFrameï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºç©º
            elif hasattr(stock_list_df, 'empty') and stock_list_df.empty:
                logger.warning("âš ï¸ è‚¡ç¥¨åˆ—è¡¨ä¸ºç©º")
                return False
            
            # æå–è‚¡ç¥¨ä»£ç 
            stock_codes = stock_list_df['ä»£ç '].tolist()
            logger.info(f"ğŸ“Š å¾…é¢„è®¡ç®—è‚¡ç¥¨: {len(stock_codes)} åª")
            
            # æ‰§è¡Œé¢„è®¡ç®—
            success_count = cache.precompute_ma4(stock_codes, max_stocks=len(stock_codes))
            
            # ç”ŸæˆæŠ¥å‘Š
            report = {
                'timestamp': datetime.now().isoformat(),
                'total_stocks': len(stock_codes),
                'success_count': success_count,
                'cache_time': cache.cache_time.isoformat() if cache.cache_time else None,
                'overall_status': 'OK' if success_count > 0 else 'WARNING'
            }
            
            logger.info(f"âœ… ç›˜å‰é¢„è®¡ç®—å®Œæˆ:")
            logger.info(f"  - æ€»è‚¡ç¥¨æ•°: {report['total_stocks']}")
            logger.info(f"  - æˆåŠŸè®¡ç®—: {report['success_count']}")
            logger.info(f"  - ç¼“å­˜æ—¶é—´: {report['cache_time']}")
            logger.info(f"  - çŠ¶æ€: {report['overall_status']}")
            
            if report['overall_status'] != 'OK':
                self._save_alert(
                    'pre_market_precompute',
                    'WARNING',
                    'ç›˜å‰é¢„è®¡ç®—å¤±è´¥',
                    report
                )
            
            return report
    
    def run_auction_snapshot_save(self):
        """ç«ä»·å¿«ç…§è‡ªåŠ¨ä¿å­˜ï¼ˆ9:25ï¼‰"""
        logger.info("=" * 80)
        logger.info("ğŸ• ç«ä»·å¿«ç…§è‡ªåŠ¨ä¿å­˜ (9:25)")
        logger.info("=" * 80)
        
        try:
            from logic.auction_snapshot_saver import AuctionSnapshotSaver
            
            logger.info("ğŸ”„ å¼€å§‹ä¿å­˜ç«ä»·å¿«ç…§...")
            
            # åˆ›å»ºç«ä»·å¿«ç…§ä¿å­˜å™¨
            saver = AuctionSnapshotSaver(self.dm)
            
            # æ‰§è¡Œä¿å­˜
            result = saver.save_auction_snapshot_for_stocks()
            
            # ç”ŸæˆæŠ¥å‘Š
            report = {
                'timestamp': datetime.now().isoformat(),
                'success': result['success'],
                'saved_count': result.get('saved_count', 0),
                'failed_count': result.get('failed_count', 0),
                'total_count': result.get('total_count', 0),
                'error': result.get('error', None),
                'overall_status': 'OK' if result['success'] else 'WARNING'
            }
            
            if result['success']:
                logger.info(f"âœ… ç«ä»·å¿«ç…§ä¿å­˜å®Œæˆ:")
                logger.info(f"  - æˆåŠŸä¿å­˜: {report['saved_count']} åª")
                logger.info(f"  - å¤±è´¥: {report['failed_count']} åª")
                logger.info(f"  - æ€»è®¡: {report['total_count']} åª")
                logger.info(f"  - çŠ¶æ€: {report['overall_status']}")
            else:
                logger.warning(f"âš ï¸ ç«ä»·å¿«ç…§ä¿å­˜å¤±è´¥:")
                logger.warning(f"  - é”™è¯¯: {report['error']}")
                logger.warning(f"  - æˆåŠŸä¿å­˜: {report['saved_count']} åª")
                logger.warning(f"  - å¤±è´¥: {report['failed_count']} åª")
                
                # ä¿å­˜å‘Šè­¦
                self._save_alert(
                    'auction_snapshot_save',
                    'WARNING',
                    f'ç«ä»·å¿«ç…§ä¿å­˜å¤±è´¥: {report.get("error", "æœªçŸ¥é”™è¯¯")}',
                    report
                )
            
            return report
    
    def run_check_auction_snapshot(self):
        """æ£€æŸ¥ç«ä»·å¿«ç…§æ˜¯å¦è·å–ï¼ˆ9:20ï¼‰"""
        logger.info("=" * 80)
        logger.info("ğŸ• æ£€æŸ¥ç«ä»·å¿«ç…§æ˜¯å¦è·å– (9:20)")
        logger.info("=" * 80)
        
        try:
            # æ£€æŸ¥ Redis ä¸­æ˜¯å¦æœ‰ç«ä»·å¿«ç…§æ•°æ®
            redis_has_data = False
            snapshot_count = 0
            
            if hasattr(self.dm, 'auction_snapshot_manager') and self.dm.auction_snapshot_manager:
                # æ£€æŸ¥ Redis è¿æ¥
                status = self.dm.auction_snapshot_manager.get_snapshot_status()
                
                if not status['is_available']:
                    logger.error("âŒ Redis æœªè¿æ¥ï¼Œæ— æ³•æ£€æŸ¥ç«ä»·å¿«ç…§")
                    self._save_alert(
                        'auction_snapshot_check',
                        'ERROR',
                        'Redis æœªè¿æ¥ï¼Œæ— æ³•æ£€æŸ¥ç«ä»·å¿«ç…§',
                        {'redis_connected': False}
                    )
                    return {
                        'timestamp': datetime.now().isoformat(),
                        'success': False,
                        'snapshot_count': 0,
                        'error': 'Redis æœªè¿æ¥',
                        'overall_status': 'ERROR'
                    }
                
                # æ£€æŸ¥ Redis ä¸­ä»Šæ—¥çš„ç«ä»·å¿«ç…§æ•°é‡
                try:
                    today = self.dm.auction_snapshot_manager.get_today_str()
                    pattern = f"auction:{today}:*"
                    keys = self.dm._redis_client.keys(pattern)
                    snapshot_count = len(keys)
                    redis_has_data = snapshot_count > 0
                except Exception as e:
                    logger.error(f"âŒ æ£€æŸ¥ Redis ç«ä»·å¿«ç…§å¤±è´¥: {e}")
            
            # æ£€æŸ¥æ–‡ä»¶ç³»ç»Ÿä¸­çš„ç«ä»·å¿«ç…§
            file_has_data = False
            file_path = None
            
            try:
                import os
                from datetime import datetime as dt
                date_str = dt.now().strftime("%Y%m%d")
                file_path = f"data/auction_snapshots/auction_{date_str}.csv"
                file_has_data = os.path.exists(file_path) and os.path.getsize(file_path) > 0
            except Exception as e:
                logger.error(f"âŒ æ£€æŸ¥æ–‡ä»¶ç«ä»·å¿«ç…§å¤±è´¥: {e}")
            
            # ç”ŸæˆæŠ¥å‘Š
            report = {
                'timestamp': datetime.now().isoformat(),
                'redis_has_data': redis_has_data,
                'redis_snapshot_count': snapshot_count,
                'file_has_data': file_has_data,
                'file_path': file_path,
                'overall_status': 'OK' if (redis_has_data or file_has_data) else 'WARNING'
            }
            
            if redis_has_data or file_has_data:
                logger.info(f"âœ… ç«ä»·å¿«ç…§æ£€æŸ¥é€šè¿‡:")
                logger.info(f"  - Redis å¿«ç…§æ•°é‡: {snapshot_count}")
                logger.info(f"  - æ–‡ä»¶å¿«ç…§å­˜åœ¨: {'æ˜¯' if file_has_data else 'å¦'}")
                logger.info(f"  - çŠ¶æ€: {report['overall_status']}")
            else:
                logger.warning("âš ï¸ ç«ä»·å¿«ç…§æœªè·å–åˆ°æ•°æ®")
                logger.warning("âš ï¸ å¯èƒ½çš„åŸå› :")
                logger.warning("  1. æ•°æ®æºæœªå¯åŠ¨æˆ–è¿æ¥å¤±è´¥")
                logger.warning("  2. 9:15-9:20 æœŸé—´ç¨‹åºæœªè¿è¡Œ")
                logger.warning("  3. è‚¡ç¥¨ä»£ç åˆ—è¡¨ä¸ºç©º")
                logger.warning("  4. ç½‘ç»œé—®é¢˜å¯¼è‡´æ•°æ®è·å–å¤±è´¥")
                
                # ä¿å­˜å‘Šè­¦
                self._save_alert(
                    'auction_snapshot_check',
                    'WARNING',
                    '9:20 æœªè·å–åˆ°ç«ä»·å¿«ç…§æ•°æ®',
                    {
                        'redis_has_data': redis_has_data,
                        'redis_snapshot_count': snapshot_count,
                        'file_has_data': file_has_data,
                        'file_path': file_path,
                        'possible_reasons': [
                            'æ•°æ®æºæœªå¯åŠ¨æˆ–è¿æ¥å¤±è´¥',
                            '9:15-9:20 æœŸé—´ç¨‹åºæœªè¿è¡Œ',
                            'è‚¡ç¥¨ä»£ç åˆ—è¡¨ä¸ºç©º',
                            'ç½‘ç»œé—®é¢˜å¯¼è‡´æ•°æ®è·å–å¤±è´¥'
                        ]
                    }
                )
            
            return report
            
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥ç«ä»·å¿«ç…§å¤±è´¥: {e}")
            self._save_alert(
                'auction_snapshot_check',
                'ERROR',
                f'æ£€æŸ¥ç«ä»·å¿«ç…§å¼‚å¸¸: {str(e)}',
                {'error': str(e)}
            )
            return {
                'timestamp': datetime.now().isoformat(),
                'success': False,
                'error': str(e),
                'overall_status': 'ERROR'
            }
            
        except Exception as e:
            logger.error(f"âŒ ç«ä»·å¿«ç…§ä¿å­˜ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            
            # ä¿å­˜å‘Šè­¦
            self._save_alert(
                'auction_snapshot_save',
                'ERROR',
                f'ç«ä»·å¿«ç…§ä¿å­˜ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}',
                {'error': str(e)}
            )
            
            return {
                'timestamp': datetime.now().isoformat(),
                'success': False,
                'error': str(e),
                'overall_status': 'ERROR'
            }
            
            if report['overall_status'] != 'OK':
                self._save_alert(
                    'pre_market_precompute',
                    'WARNING',
                    f'ç›˜å‰é¢„è®¡ç®—é—®é¢˜: æˆåŠŸ{success_count}/{len(stock_codes)}',
                    report
                )
            else:
                self._save_alert(
                    'pre_market_precompute',
                    'INFO',
                    f'ç›˜å‰é¢„è®¡ç®—æˆåŠŸ: {success_count}/{len(stock_codes)}',
                    report
                )
            
            return report
            
        except Exception as e:
            logger.error(f"ç›˜å‰é¢„è®¡ç®—å¤±è´¥: {e}")
            self._save_alert(
                'pre_market_precompute',
                'ERROR',
                f'ç›˜å‰é¢„è®¡ç®—å¤±è´¥: {str(e)}',
                {}
            )
            return False
    
    def run_post_market_review(self):
        """æ”¶ç›˜åå¤ç›˜ï¼ˆ15:30ï¼‰"""
        logger.info("=" * 80)
        logger.info("ğŸ• æ”¶ç›˜åå¤ç›˜ (15:30)")
        logger.info("=" * 80)
        
        try:
            # 1. æ£€æŸ¥å¿…éœ€æ–‡ä»¶
            post_market_files = self.check_required_files('post_market')
            
            if not all(post_market_files.values()):
                logger.error("âŒ ç¼ºå°‘å¤ç›˜å¿…éœ€æ–‡ä»¶")
                return False
            
            # 2. è¿è¡Œå¤ç›˜ç®¡ç†å™¨
            from logic.review_manager import ReviewManager
            rm = ReviewManager()
            
            # è·å–ä»Šå¤©çš„æ—¥æœŸ
            today = datetime.now().strftime('%Y%m%d')
            
            logger.info(f"ğŸ”„ å¼€å§‹æ‰§è¡Œ {today} æ¯æ—¥å¤ç›˜...")
            result = rm.run_daily_review(date=today)
            
            if result:
                logger.info("âœ… æ”¶ç›˜åå¤ç›˜å®Œæˆ")
                self._save_alert(
                    'post_market_review',
                    'INFO',
                    f'æ”¶ç›˜åå¤ç›˜å®Œæˆ: {today}',
                    {}
                )
                return True
            else:
                logger.warning("âš ï¸ æ”¶ç›˜åå¤ç›˜å¤±è´¥æˆ–æ— æ•°æ®")
                self._save_alert(
                    'post_market_review',
                    'WARNING',
                    f'æ”¶ç›˜åå¤ç›˜å¤±è´¥æˆ–æ— æ•°æ®: {today}',
                    {}
                )
                return False
                
        except Exception as e:
            logger.error(f"æ”¶ç›˜åå¤ç›˜å¤±è´¥: {e}")
            self._save_alert(
                'post_market_review',
                'ERROR',
                f'æ”¶ç›˜åå¤ç›˜å¤±è´¥: {str(e)}',
                {}
            )
            return False
    
    def run_weekly_check(self):
        """æ¯å‘¨ç³»ç»Ÿæ£€æŸ¥ï¼ˆå‘¨æ—¥20:00ï¼‰"""
        logger.info("=" * 80)
        logger.info("ğŸ• æ¯å‘¨ç³»ç»Ÿæ£€æŸ¥ (å‘¨æ—¥20:00)")
        logger.info("=" * 80)
        
        try:
            # 1. è¿è¡Œç³»ç»Ÿå¥åº·æ£€æŸ¥
            logger.info("ğŸ”„ è¿è¡Œç³»ç»Ÿå¥åº·æ£€æŸ¥...")
            import subprocess
            result = subprocess.run(
                ['python', 'check_system_health.py'],
                capture_output=True,
                text=True,
                timeout=60
            )
            
            if result.returncode == 0:
                logger.info("âœ… ç³»ç»Ÿå¥åº·æ£€æŸ¥é€šè¿‡")
            else:
                logger.warning("âš ï¸ ç³»ç»Ÿå¥åº·æ£€æŸ¥å‘ç°é—®é¢˜")
                self._save_alert(
                    'weekly_check',
                    'WARNING',
                    'ç³»ç»Ÿå¥åº·æ£€æŸ¥å‘ç°é—®é¢˜',
                    {'output': result.stdout, 'error': result.stderr}
                )
            
            # 2. æ£€æŸ¥å¿…éœ€æ–‡ä»¶
            weekly_files = self.check_required_files('weekly')
            
            # 3. ç”Ÿæˆæ£€æŸ¥æŠ¥å‘Š
            report = {
                'timestamp': datetime.now().isoformat(),
                'health_check': result.returncode == 0,
                'files_ok': all(weekly_files.values()),
                'files_status': weekly_files
            }
            
            logger.info(f"ğŸ“Š æ¯å‘¨æ£€æŸ¥å®Œæˆ")
            self._save_alert(
                'weekly_check',
                'INFO',
                'æ¯å‘¨ç³»ç»Ÿæ£€æŸ¥å®Œæˆ',
                report
            )
            
            return report
            
        except Exception as e:
            logger.error(f"æ¯å‘¨ç³»ç»Ÿæ£€æŸ¥å¤±è´¥: {e}")
            self._save_alert(
                'weekly_check',
                'ERROR',
                f'æ¯å‘¨ç³»ç»Ÿæ£€æŸ¥å¤±è´¥: {str(e)}',
                {}
            )
            return False
    
    def get_alerts(self, limit: int = 10) -> List[Dict]:
        """è·å–æœ€è¿‘çš„å‘Šè­¦"""
        try:
            with open(self.alert_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            return data['alerts'][-limit:]
        except Exception as e:
            logger.error(f"è·å–å‘Šè­¦å¤±è´¥: {e}")
            return []
    
    def get_system_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        redis_ok = self.check_redis_status()
        auction_ok = self.check_auction_snapshot()
        
        return {
            'timestamp': datetime.now().isoformat(),
            'redis_ok': redis_ok,
            'auction_ok': auction_ok,
            'alerts_count': len(self.get_alerts()),
            'recent_alerts': self.get_alerts(5)
        }
    
    def start(self):
        """å¯åŠ¨å®šæ—¶ä»»åŠ¡ç›‘æ§"""
        logger.info("ğŸš€ å¯åŠ¨å®šæ—¶ä»»åŠ¡ç›‘æ§ç³»ç»Ÿ")
        
        # è®¾ç½®å®šæ—¶ä»»åŠ¡
        schedule.every().day.at(self.tasks['pre_market_check']['time']).do(self.run_pre_market_check)
        schedule.every().day.at(self.tasks['pre_market_precompute']['time']).do(self.run_pre_market_precompute)
        schedule.every().day.at(self.tasks['auction_snapshot_check']['time']).do(self.run_check_auction_snapshot)
        schedule.every().day.at(self.tasks['auction_snapshot_save']['time']).do(self.run_auction_snapshot_save)  # ğŸ†• V19.6 æ–°å¢
        schedule.every().day.at(self.tasks['post_market_review']['time']).do(self.run_post_market_review)
        schedule.every().sunday.at(self.tasks['weekly_check']['time']).do(self.run_weekly_check)
        
        self.running = True
        
        logger.info("âœ… å®šæ—¶ä»»åŠ¡å·²è®¾ç½®:")
        logger.info(f"  - æ—©ç›˜å‰æ£€æŸ¥: {self.tasks['pre_market_check']['time']}")
        logger.info(f"  - ç›˜å‰é¢„è®¡ç®—: {self.tasks['pre_market_precompute']['time']}")
        logger.info(f"  - ç«ä»·å¿«ç…§æ£€æŸ¥: {self.tasks['auction_snapshot_check']['time']}")
        logger.info(f"  - ç«ä»·å¿«ç…§ä¿å­˜: {self.tasks['auction_snapshot_save']['time']}")  # ğŸ†• V19.6 æ–°å¢
        logger.info(f"  - æ”¶ç›˜åå¤ç›˜: {self.tasks['post_market_review']['time']}")
        logger.info(f"  - æ¯å‘¨æ£€æŸ¥: å‘¨æ—¥ {self.tasks['weekly_check']['time']}")
        
        # å¯åŠ¨ç›‘æ§çº¿ç¨‹
        monitor_thread = threading.Thread(target=self._run_scheduler, daemon=True)
        monitor_thread.start()
        
        return monitor_thread
    
    def _run_scheduler(self):
        """è¿è¡Œè°ƒåº¦å™¨"""
        logger.info("ğŸ“… å®šæ—¶ä»»åŠ¡ç›‘æ§å™¨å·²å¯åŠ¨")
        
        while self.running:
            schedule.run_pending()
            time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
    
    def stop(self):
        """åœæ­¢ç›‘æ§"""
        self.running = False
        logger.info("ğŸ›‘ å®šæ—¶ä»»åŠ¡ç›‘æ§å™¨å·²åœæ­¢")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("ğŸš€ MyQuantTool å®šæ—¶ä»»åŠ¡ç›‘æ§ç³»ç»Ÿ")
    print(f"ğŸ“… å¯åŠ¨æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)
    
    monitor = ScheduledTaskMonitor()
    
    # ç«‹å³æ‰§è¡Œä¸€æ¬¡æ—©ç›˜å‰æ£€æŸ¥
    print("\nğŸ” æ‰§è¡Œæ—©ç›˜å‰æ£€æŸ¥...")
    monitor.run_pre_market_check()
    
    # å¯åŠ¨å®šæ—¶ä»»åŠ¡
    print("\nğŸ“… å¯åŠ¨å®šæ—¶ä»»åŠ¡ç›‘æ§...")
    monitor.start()
    
    print("\nâœ… ç›‘æ§ç³»ç»Ÿå·²å¯åŠ¨ï¼ŒæŒ‰ Ctrl+C åœæ­¢")
    print("\nğŸ“Š å½“å‰ç³»ç»ŸçŠ¶æ€:")
    status = monitor.get_system_status()
    print(f"  - Redis: {'âœ… æ­£å¸¸' if status['redis_ok'] else 'âŒ å¼‚å¸¸'}")
    print(f"  - ç«ä»·å¿«ç…§: {'âœ… æ­£å¸¸' if status['auction_ok'] else 'âŒ å¼‚å¸¸'}")
    print(f"  - å‘Šè­¦æ•°: {status['alerts_count']}")
    
    if status['recent_alerts']:
        print("\nğŸš¨ æœ€è¿‘å‘Šè­¦:")
        for alert in status['recent_alerts']:
            print(f"  - [{alert['severity']}] {alert['timestamp']}: {alert['message']}")
    
    # ä¿æŒè¿è¡Œ
    try:
        while True:
            time.sleep(60)
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ æ­£åœ¨åœæ­¢ç›‘æ§ç³»ç»Ÿ...")
        monitor.stop()
        print("âœ… ç›‘æ§ç³»ç»Ÿå·²åœæ­¢")


if __name__ == '__main__':
    main()