"""
æ¸¸èµ„å¸­ä½åˆ†ææ¨¡å—
åˆ†æé¾™è™æ¦œæ¸¸èµ„ã€è¿½è¸ªæ“ä½œæ¨¡å¼ã€è¯†åˆ«çŸ¥åæ¸¸èµ?"""

import pandas as pd
from logic.data_manager import DataManager


class CapitalAnalyzer:
    """æ¸¸èµ„å¸­ä½åˆ†æå™?""

    # çŸ¥åæ¸¸èµ„å¸­ä½åˆ—è¡¨ï¼ˆåŒ…å«å¸¸è§å˜ä½“ï¼‰
    FAMOUS_CAPITALISTS = {
        "ç« ç›Ÿä¸?: [
            "ä¸­ä¿¡è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸æ­å·å»¶å®‰è·¯è¯åˆ¸è¥ä¸šéƒ¨",
            "å›½æ³°å›å®‰è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸ä¸Šæµ·æ±Ÿè‹è·¯è¯åˆ¸è¥ä¸šéƒ¨",
            "å›½æ³°å›å®‰è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸ä¸Šæµ·åˆ†å…¬å?,
            "å›½æ³°å›å®‰è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸ä¸Šæµ·æ±Ÿè‹è·?,
            "ä¸­ä¿¡è¯åˆ¸æ­å·å»¶å®‰è·?,
            "å›½æ³°å›å®‰ä¸Šæµ·æ±Ÿè‹è·?
        ],
        "æ–¹æ–°ä¾?: [
            "å…´ä¸šè¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸é™•è¥¿åˆ†å…¬å?,
            "ä¸­ä¿¡è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸è¥¿å®‰æœ±é›€å¤§è¡—è¯åˆ¸è¥ä¸šéƒ?,
            "å…´ä¸šè¯åˆ¸é™•è¥¿åˆ†å…¬å?,
            "ä¸­ä¿¡è¯åˆ¸è¥¿å®‰æœ±é›€å¤§è¡—",
            "å…´ä¸šè¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸é™•è¥¿"
        ],
        "å¾ç¿”": [
            "å›½æ³°å›å®‰è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸ä¸Šæµ·ç¦å±±è·¯è¯åˆ¸è¥ä¸šéƒ¨",
            "å…‰å¤§è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸å®æ³¢è§£æ”¾å—è·¯è¯åˆ¸è¥ä¸šéƒ?,
            "å›½æ³°å›å®‰ä¸Šæµ·ç¦å±±è·?,
            "å…‰å¤§è¯åˆ¸å®æ³¢è§£æ”¾å—è·¯",
            "å›½æ³°å›å®‰ä¸Šæµ·ç¦å±±è·¯è¯åˆ?
        ],
        "èµµè€å“¥": [
            "ä¸­å›½é“¶æ²³è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸ç»å…´è¯åˆ¸è¥ä¸šéƒ?,
            "åæ³°è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸æµ™æ±Ÿåˆ†å…¬å?,
            "é“¶æ²³è¯åˆ¸ç»å…´",
            "åæ³°è¯åˆ¸æµ™æ±Ÿåˆ†å…¬å?,
            "ä¸­å›½é“¶æ²³è¯åˆ¸ç»å…´"
        ],
        "ä¹”å¸®ä¸?: [
            "ä¸­ä¿¡è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸ä¸Šæµ·æ·®æµ·ä¸­è·¯è¯åˆ¸è¥ä¸šéƒ?,
            "å›½æ³°å›å®‰è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸ä¸Šæµ·åˆ†å…¬å?,
            "ä¸­ä¿¡è¯åˆ¸ä¸Šæµ·æ·®æµ·ä¸­è·¯",
            "å›½æ³°å›å®‰ä¸Šæµ·åˆ†å…¬å?
        ],
        "æˆéƒ½å¸?: [
            "åæ³°è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸æˆéƒ½èœ€é‡‘è·¯è¯åˆ¸è¥ä¸šéƒ?,
            "å›½æ³°å›å®‰è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸æˆéƒ½åŒ—ä¸€ç¯è·¯è¯åˆ¸è¥ä¸šéƒ?,
            "åæ³°è¯åˆ¸æˆéƒ½èœ€é‡‘è·¯",
            "å›½æ³°å›å®‰æˆéƒ½åŒ—ä¸€ç¯è·¯",
            "åæ³°è¯åˆ¸æˆéƒ½"
        ],
        "ä½›å±±å¸?: [
            "å…‰å¤§è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸ä½›å±±ç»¿æ™¯è·¯è¯åˆ¸è¥ä¸šéƒ¨",
            "é•¿æ±Ÿè¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸ä½›å±±é¡ºå¾·æ–°å®è·¯è¯åˆ¸è¥ä¸šéƒ¨",
            "å…‰å¤§è¯åˆ¸ä½›å±±ç»¿æ™¯è·?,
            "é•¿æ±Ÿè¯åˆ¸ä½›å±±é¡ºå¾·æ–°å®è·?,
            "å…‰å¤§è¯åˆ¸ä½›å±±"
        ],
        "ç‘é¹¤ä»?: [
            "ä¸­å›½ä¸­é‡‘è´¢å¯Œè¯åˆ¸æœ‰é™å…¬å¸æ·±åœ³åˆ†å…¬å?,
            "åæ³°è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸æ·±åœ³ç›Šç”°è·¯è£è¶…å•†åŠ¡ä¸­å¿ƒè¯åˆ¸è¥ä¸šéƒ¨",
            "ä¸­é‡‘è´¢å¯Œæ·±åœ³",
            "åæ³°è¯åˆ¸æ·±åœ³ç›Šç”°è·?,
            "ä¸­å›½ä¸­é‡‘è´¢å¯Œæ·±åœ³"
        ],
        "ä½œæ‰‹æ–°ä¸€": [
            "å›½æ³°å›å®‰è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸å—äº¬å¤ªå¹³å—è·¯è¯åˆ¸è¥ä¸šéƒ?,
            "åæ³°è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸å—äº¬æ±Ÿä¸œä¸­è·¯è¯åˆ¸è¥ä¸šéƒ?,
            "å›½æ³°å›å®‰å—äº¬å¤ªå¹³å—è·¯",
            "åæ³°è¯åˆ¸å—äº¬æ±Ÿä¸œä¸­è·¯",
            "å›½æ³°å›å®‰å—äº¬"
        ],
        "å°é³„é±?: [
            "ä¸­å›½é“¶æ²³è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸åŒ—äº¬ä¸­å…³æ‘å¤§è¡—è¯åˆ¸è¥ä¸šéƒ¨",
            "ä¸­ä¿¡è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸åŒ—äº¬æ€»éƒ¨è¯åˆ¸è¥ä¸šéƒ?,
            "é“¶æ²³è¯åˆ¸åŒ—äº¬ä¸­å…³æ‘å¤§è¡?,
            "ä¸­ä¿¡è¯åˆ¸åŒ—äº¬æ€»éƒ¨",
            "é“¶æ²³è¯åˆ¸åŒ—äº¬"
        ]
    }

    @staticmethod
    def analyze_longhubu_capital(date=None):
        """
        åˆ†æé¾™è™æ¦œæ¸¸èµ?        è¿”å›å½“æ—¥é¾™è™æ¦œä¸­çš„æ¸¸èµ„å¸­ä½åˆ†æ?        """
        try:
            import akshare as ak
            from datetime import datetime

            # è·å–é¾™è™æ¦œæ•°æ?            try:
                if date:
                    if isinstance(date, str):
                        date_str = date
                    else:
                        date_str = date.strftime("%Y%m%d")
                    lhb_df = ak.stock_lhb_detail_em(date=date_str)
                    print(f"è·å– {date_str} çš„é¾™è™æ¦œæ•°æ®ï¼Œå…± {len(lhb_df)} æ¡è®°å½?)
                else:
                    # è·å–æœ€è¿‘å‡ å¤©çš„æ•°æ®
                    today = datetime.now()
                    lhb_df = ak.stock_lhb_detail_em(date=today.strftime("%Y%m%d"))
                    print(f"è·å–ä»Šæ—¥é¾™è™æ¦œæ•°æ®ï¼Œå…?{len(lhb_df)} æ¡è®°å½?)
                    
                    # å¦‚æœä»Šæ—¥æ— æ•°æ®ï¼Œå°è¯•è·å–æ˜¨å¤©çš?                    if lhb_df.empty:
                        yesterday = today - pd.Timedelta(days=1)
                        lhb_df = ak.stock_lhb_detail_em(date=yesterday.strftime("%Y%m%d"))
                        print(f"ä»Šæ—¥æ— æ•°æ®ï¼Œè·å–æ˜¨æ—¥é¾™è™æ¦œæ•°æ®ï¼Œå…?{len(lhb_df)} æ¡è®°å½?)
            except Exception as e:
                print(f"è·å–é¾™è™æ¦œæ•°æ®å¤±è´? {e}")
                return {
                    'æ•°æ®çŠ¶æ€?: 'è·å–é¾™è™æ¦œæ•°æ®å¤±è´?,
                    'é”™è¯¯ä¿¡æ¯': str(e),
                    'è¯´æ˜': 'å¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜æˆ–æ•°æ®æºé™åˆ¶ï¼Œè¯·ç¨åé‡è¯?
                }

            if lhb_df is None or lhb_df.empty:
                print("é¾™è™æ¦œæ•°æ®ä¸ºç©?)
                return {
                    'æ•°æ®çŠ¶æ€?: 'æ— æ•°æ?,
                    'è¯´æ˜': 'æš‚æ— é¾™è™æ¦œæ•°æ®ï¼Œå¯èƒ½ä»Šæ—¥æ— é¾™è™æ¦œæˆ–æ•°æ®æœªæ›´æ–°ã€‚å»ºè®®é€‰æ‹©å…¶ä»–æ—¥æœŸæŸ¥çœ‹ã€?
                }
            
            # æ‰“å°åˆ—åï¼Œå¸®åŠ©è°ƒè¯?            print(f"é¾™è™æ¦œæ•°æ®åˆ—å? {lhb_df.columns.tolist()}")
            print(f"å‰?æ¡æ•°æ®ç¤ºä¾?\n{lhb_df.head(3)}")

            # åˆ†ææ¸¸èµ„å¸­ä½
            capital_analysis = []
            capital_stats = {}
            matched_count = 0

            # æ‰“å°æ‰€æœ‰è¥ä¸šéƒ¨åç§°ï¼Œå¸®åŠ©è°ƒè¯?            unique_seats = lhb_df['è¥ä¸šéƒ¨åç§?].unique()
            print(f"å…±æ‰¾åˆ?{len(unique_seats)} ä¸ªä¸åŒçš„è¥ä¸šéƒ?)
            print(f"è¥ä¸šéƒ¨åˆ—è¡? {unique_seats[:10]}...")  # åªæ‰“å°å‰10ä¸?
            for _, row in lhb_df.iterrows():
                seat_name = str(row['è¥ä¸šéƒ¨åç§?])
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºçŸ¥åæ¸¸èµ„å¸­ä½ï¼ˆä½¿ç”¨æ¨¡ç³ŠåŒ¹é…ï¼‰
                for capital_name, seats in CapitalAnalyzer.FAMOUS_CAPITALISTS.items():
                    # ç²¾ç¡®åŒ¹é…
                    if seat_name in seats:
                        matched = True
                    # æ¨¡ç³ŠåŒ¹é…ï¼šæ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®è¯
                    else:
                        matched = any(keyword in seat_name for keyword in seats)
                    
                    if matched:
                        matched_count += 1
                        # ç»Ÿè®¡æ¸¸èµ„æ“ä½œ
                        if capital_name not in capital_stats:
                            capital_stats[capital_name] = {
                                'ä¹°å…¥æ¬¡æ•°': 0,
                                'å–å‡ºæ¬¡æ•°': 0,
                                'ä¹°å…¥é‡‘é¢': 0,
                                'å–å‡ºé‡‘é¢': 0,
                                'æ“ä½œè‚¡ç¥¨': []
                            }

                        # åˆ¤æ–­ä¹°å–æ–¹å‘
                        buy_amount = row.get('ä¹°å…¥é‡‘é¢', 0)
                        sell_amount = row.get('å–å‡ºé‡‘é¢', 0)
                        
                        if buy_amount > 0:
                            capital_stats[capital_name]['ä¹°å…¥æ¬¡æ•°'] += 1
                            capital_stats[capital_name]['ä¹°å…¥é‡‘é¢'] += buy_amount
                        elif row['å–å‡ºé‡‘é¢'] > 0:
                            capital_stats[capital_name]['å–å‡ºæ¬¡æ•°'] += 1
                            capital_stats[capital_name]['å–å‡ºé‡‘é¢'] += row['å–å‡ºé‡‘é¢']

                        # è®°å½•æ“ä½œè‚¡ç¥¨
                        stock_info = {
                            'ä»£ç ': row['ä»£ç '],
                            'åç§°': row['åç§°'],
                            'æ—¥æœŸ': row['ä¸Šæ¦œæ—?],
                            'ä¹°å…¥é‡‘é¢': row['ä¹°å…¥é‡‘é¢'],
                            'å–å‡ºé‡‘é¢': row['å–å‡ºé‡‘é¢'],
                            'å‡€ä¹°å…¥': row['ä¹°å…¥é‡‘é¢'] - row['å–å‡ºé‡‘é¢']
                        }
                        capital_stats[capital_name]['æ“ä½œè‚¡ç¥¨'].append(stock_info)

                        capital_analysis.append({
                            'æ¸¸èµ„åç§°': capital_name,
                            'è¥ä¸šéƒ¨åç§?: row['è¥ä¸šéƒ¨åç§?],
                            'è‚¡ç¥¨ä»£ç ': row['ä»£ç '],
                            'è‚¡ç¥¨åç§°': row['åç§°'],
                            'ä¸Šæ¦œæ—?: row['ä¸Šæ¦œæ—?],
                            'ä¹°å…¥é‡‘é¢': row['ä¹°å…¥é‡‘é¢'],
                            'å–å‡ºé‡‘é¢': row['å–å‡ºé‡‘é¢'],
                            'å‡€ä¹°å…¥': row['ä¹°å…¥é‡‘é¢'] - row['å–å‡ºé‡‘é¢']
                        })

            # è®¡ç®—æ¸¸èµ„ç»Ÿè®¡
            capital_summary = []
            for capital_name, stats in capital_stats.items():
                net_flow = stats['ä¹°å…¥é‡‘é¢'] - stats['å–å‡ºé‡‘é¢']
                total_trades = stats['ä¹°å…¥æ¬¡æ•°'] + stats['å–å‡ºæ¬¡æ•°']

                # åˆ¤æ–­æ“ä½œé£æ ¼
                if stats['ä¹°å…¥é‡‘é¢'] > stats['å–å‡ºé‡‘é¢'] * 2:
                    style = "æ¿€è¿›ä¹°å…?
                elif stats['å–å‡ºé‡‘é¢'] > stats['ä¹°å…¥é‡‘é¢'] * 2:
                    style = "æ¿€è¿›å–å‡?
                elif net_flow > 0:
                    style = "åå¤šå¤?
                else:
                    style = "åç©ºå¤?

                capital_summary.append({
                    'æ¸¸èµ„åç§°': capital_name,
                    'ä¹°å…¥æ¬¡æ•°': stats['ä¹°å…¥æ¬¡æ•°'],
                    'å–å‡ºæ¬¡æ•°': stats['å–å‡ºæ¬¡æ•°'],
                    'æ€»æ“ä½œæ¬¡æ•?: total_trades,
                    'ä¹°å…¥é‡‘é¢': stats['ä¹°å…¥é‡‘é¢'],
                    'å–å‡ºé‡‘é¢': stats['å–å‡ºé‡‘é¢'],
                    'å‡€æµå…¥': net_flow,
                    'æ“ä½œé£æ ¼': style,
                    'æ“ä½œè‚¡ç¥¨æ•?: len(stats['æ“ä½œè‚¡ç¥¨'])
                })

            # æŒ‰å‡€æµå…¥æ’åº
            capital_summary.sort(key=lambda x: x['å‡€æµå…¥'], reverse=True)

            print(f"åˆ†æå®Œæˆï¼šåŒ¹é…åˆ° {matched_count} æ¡æ¸¸èµ„æ“ä½œè®°å½•ï¼Œæ¶‰åŠ {len(capital_stats)} ä¸ªæ¸¸èµ?)

            return {
                'æ•°æ®çŠ¶æ€?: 'æ­£å¸¸',
                'æ¸¸èµ„ç»Ÿè®¡': capital_summary,
                'æ¸¸èµ„æ“ä½œè®°å½•': capital_analysis,
                'åŒ¹é…è®°å½•æ•?: matched_count,
                'æ¸¸èµ„æ•°é‡': len(capital_stats),
                'é¾™è™æ¦œæ€»è®°å½•æ•°': len(lhb_df),
                'è¯´æ˜': f'åœ?{len(lhb_df)} æ¡é¾™è™æ¦œè®°å½•ä¸­ï¼Œæ‰¾åˆ° {matched_count} æ¡æ¸¸èµ„æ“ä½œè®°å½?
            }

            return {
                'æ•°æ®çŠ¶æ€?: 'æ­£å¸¸',
                'æ¸¸èµ„åˆ†æåˆ—è¡¨': capital_analysis,
                'æ¸¸èµ„ç»Ÿè®¡æ±‡æ€?: capital_summary,
                'æ´»è·ƒæ¸¸èµ„æ•?: len(capital_stats),
                'æ€»æ“ä½œæ¬¡æ•?: len(capital_analysis)
            }

        except Exception as e:
            return {
                'æ•°æ®çŠ¶æ€?: 'è·å–å¤±è´¥',
                'é”™è¯¯ä¿¡æ¯': str(e),
                'è¯´æ˜': 'å¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜æˆ–æ•°æ®æºé™åˆ?
            }

    @staticmethod
    def track_capital_pattern(capital_name, days=30):
        """
        è¿½è¸ªæ¸¸èµ„æ“ä½œæ¨¡å¼
        åˆ†æç‰¹å®šæ¸¸èµ„åœ¨æŒ‡å®šæ—¶é—´å†…çš„æ“ä½œè§„å¾?        """
        try:
            import akshare as ak

            if capital_name not in CapitalAnalyzer.FAMOUS_CAPITALISTS:
                return {
                    'æ•°æ®çŠ¶æ€?: 'æœªçŸ¥æ¸¸èµ„',
                    'è¯´æ˜': f'æœªæ‰¾åˆ°æ¸¸èµ? {capital_name}'
                }

            # è·å–è¯¥æ¸¸èµ„çš„å¸­ä½åˆ—è¡¨
            seats = CapitalAnalyzer.FAMOUS_CAPITALISTS[capital_name]
            print(f"æ¸¸èµ„ {capital_name} çš„å¸­ä½åˆ—è¡? {seats}")

            # è·å–å†å²é¾™è™æ¦œæ•°æ?            end_date = pd.Timestamp.now()
            start_date = end_date - pd.Timedelta(days=days)

            all_operations = []
            checked_dates = 0
            matched_dates = 0

            # è·å–æ¯æ—¥é¾™è™æ¦œæ•°æ?            current_date = start_date
            while current_date <= end_date:
                date_str = current_date.strftime("%Y%m%d")
                checked_dates += 1

                try:
                    lhb_df = ak.stock_lhb_detail_em(date=date_str)

                    if not lhb_df.empty:
                        print(f"{date_str}: è·å–åˆ?{len(lhb_df)} æ¡é¾™è™æ¦œè®°å½•")
                        
                        # ç­›é€‰è¯¥æ¸¸èµ„çš„æ“ä½œï¼ˆä½¿ç”¨æ¨¡ç³ŠåŒ¹é…ï¼?                        for _, row in lhb_df.iterrows():
                            seat_name = str(row['è¥ä¸šéƒ¨åç§?])
                            
                            # ç²¾ç¡®åŒ¹é…æˆ–æ¨¡ç³ŠåŒ¹é…?                            if seat_name in seats or any(keyword in seat_name for keyword in seats):
                                matched_dates += 1
                                all_operations.append({
                                    'æ—¥æœŸ': row['ä¸Šæ¦œæ—?],
                                    'è‚¡ç¥¨ä»£ç ': row['ä»£ç '],
                                    'è‚¡ç¥¨åç§°': row['åç§°'],
                                    'ä¹°å…¥é‡‘é¢': row.get('ä¹°å…¥é‡‘é¢', 0),
                                    'å–å‡ºé‡‘é¢': row.get('å–å‡ºé‡‘é¢', 0),
                                    'å‡€ä¹°å…¥': row.get('ä¹°å…¥é‡‘é¢', 0) - row.get('å–å‡ºé‡‘é¢', 0),
                                    'è¥ä¸šéƒ¨åç§?: seat_name
                                })
                                print(f"  åŒ¹é…åˆ? {seat_name} - {row['åç§°']}({row['ä»£ç ']})")
                except Exception as e:
                    print(f"{date_str}: è·å–æ•°æ®å¤±è´¥ - {e}")
                    pass

                current_date += pd.Timedelta(days=1)

            print(f"æ£€æŸ¥äº† {checked_dates} å¤©ï¼Œåœ?{matched_dates} å¤©æ‰¾åˆ°æ“ä½œè®°å½•ï¼Œå…?{len(all_operations)} æ¡æ“ä½?)

            # å¦‚æœæ²¡æœ‰æ“ä½œè®°å½•ï¼Œæ˜¾ç¤ºæ‰€æœ‰æ‰¾åˆ°çš„è¥ä¸šéƒ¨åç§?            if not all_operations:
                # è·å–æœ€è¿‘å‡ å¤©çš„é¾™è™æ¦œæ•°æ®ï¼Œæ”¶é›†æ‰€æœ‰è¥ä¸šéƒ¨åç§°
                found_seats = []
                sample_date = start_date
                
                for _ in range(min(5, days)):  # æœ€å¤šæ£€æŸ?å¤?                    date_str = sample_date.strftime("%Y%m%d")
                    try:
                        lhb_df = ak.stock_lhb_detail_em(date=date_str)
                        if not lhb_df.empty:
                            all_seats = lhb_df['è¥ä¸šéƒ¨åç§?].unique()
                            found_seats.extend(all_seats)
                            print(f"{date_str}: æ‰¾åˆ° {len(all_seats)} ä¸ªè¥ä¸šéƒ¨")
                            if len(found_seats) >= 50:  # æ”¶é›†è¶³å¤Ÿå¤šçš„è¥ä¸šéƒ?                                break
                    except:
                        pass
                    sample_date += pd.Timedelta(days=1)
                
                # å»é‡å¹¶æ’åº?                found_seats = sorted(list(set(found_seats)))
                
                return {
                    'æ•°æ®çŠ¶æ€?: 'æ— æ“ä½œè®°å½?,
                    'è¯´æ˜': f'{capital_name} åœ¨æœ€è¿?{days} å¤©å†…æ— æ“ä½œè®°å½•ã€‚å¯èƒ½åŸå› ï¼š1) è¯¥æ¸¸èµ„è¿‘æœŸæœªä¸Šæ¦œ 2) å¸­ä½åç§°ä¸åŒ¹é…?3) æ•°æ®æºé™åˆ¶ã€‚è¯·æŸ¥çœ‹ä¸‹æ–¹è°ƒè¯•ä¿¡æ¯ä¸­çš„å®é™…è¥ä¸šéƒ¨åç§°è¿›è¡Œå¯¹æ¯”ã€?,
                    'æ£€æŸ¥å¤©æ•?: checked_dates,
                    'åŒ¹é…å¤©æ•°': matched_dates,
                    'æ¸¸èµ„å¸­ä½': seats,
                    'å®é™…è¥ä¸šéƒ?: found_seats[:30]  # åªè¿”å›å‰30ä¸?                }

            # åˆ†ææ“ä½œæ¨¡å¼
            df_ops = pd.DataFrame(all_operations)

            # 1. æ“ä½œé¢‘ç‡
            operation_frequency = len(all_operations) / days

            # 2. ä¹°å–åå¥½
            total_buy = df_ops['ä¹°å…¥é‡‘é¢'].sum()
            total_sell = df_ops['å–å‡ºé‡‘é¢'].sum()
            buy_ratio = total_buy / (total_buy + total_sell) if (total_buy + total_sell) > 0 else 0

            # 3. å•æ¬¡æ“ä½œé‡‘é¢
            avg_operation_amount = df_ops['å‡€ä¹°å…¥'].abs().mean()

            # 4. æ“ä½œæˆåŠŸç‡ï¼ˆåç»­3å¤©æ¶¨è·Œï¼‰
            success_count = 0
            total_count = 0

            db = DataManager()
            for op in all_operations:
                try:
                    symbol = op['è‚¡ç¥¨ä»£ç ']
                    op_date = op['æ—¥æœŸ']

                    # è·å–å†å²æ•°æ®
                    start_date_str = op_date
                    end_date_str = (pd.Timestamp(op_date) + pd.Timedelta(days=5)).strftime("%Y%m%d")

                    df = db.get_history_data(symbol, start_date=start_date_str, end_date=end_date_str)

                    if not df.empty and len(df) > 3:
                        # è®¡ç®—æ“ä½œå?å¤©çš„æ¶¨è·Œå¹?                        op_price = df.iloc[0]['close']
                        future_price = df.iloc[3]['close']
                        future_return = (future_price - op_price) / op_price * 100

                        if future_return > 0:
                            success_count += 1
                        total_count += 1
                except:
                    pass

            db.close()

            success_rate = (success_count / total_count * 100) if total_count > 0 else 0

            # 5. åˆ¤æ–­æ“ä½œé£æ ¼
            if buy_ratio > 0.7:
                style = "æ¿€è¿›ä¹°å…¥å‹"
            elif buy_ratio < 0.3:
                style = "æ¿€è¿›å–å‡ºå‹"
            elif avg_operation_amount > 50000000:
                style = "å¤§èµ„é‡‘æ“ä½œå‹"
            else:
                style = "å‡è¡¡æ“ä½œå?

            return {
                'æ•°æ®çŠ¶æ€?: 'æ­£å¸¸',
                'æ¸¸èµ„åç§°': capital_name,
                'åˆ†æå¤©æ•°': days,
                'æ“ä½œæ¬¡æ•°': len(all_operations),
                'æ“ä½œé¢‘ç‡': round(operation_frequency, 2),
                'æ€»ä¹°å…¥é‡‘é¢?: total_buy,
                'æ€»å–å‡ºé‡‘é¢?: total_sell,
                'ä¹°å…¥æ¯”ä¾‹': round(buy_ratio * 100, 1),
                'å¹³å‡æ“ä½œé‡‘é¢': round(avg_operation_amount, 0),
                'æ“ä½œæˆåŠŸç?: round(success_rate, 1),
                'æ“ä½œé£æ ¼': style,
                'æ“ä½œè®°å½•': all_operations
            }

        except Exception as e:
            return {
                'æ•°æ®çŠ¶æ€?: 'åˆ†æå¤±è´¥',
                'é”™è¯¯ä¿¡æ¯': str(e),
                'è¯´æ˜': 'å¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜æˆ–æ•°æ®æºé™åˆ?
            }

    @staticmethod
    def predict_capital_next_move(capital_name):
        """
        é¢„æµ‹æ¸¸èµ„ä¸‹ä¸€æ­¥æ“ä½?        åŸºäºå†å²æ“ä½œæ¨¡å¼é¢„æµ‹
        """
        try:
            # è·å–æ¸¸èµ„æ“ä½œæ¨¡å¼
            pattern_result = CapitalAnalyzer.track_capital_pattern(capital_name, days=30)

            if pattern_result['æ•°æ®çŠ¶æ€?] != 'æ­£å¸¸':
                return pattern_result

            # è·å–æœ€è¿‘æ“ä½?            recent_operations = pattern_result['æ“ä½œè®°å½•'][-5:]  # æœ€è¿?æ¬¡æ“ä½?
            # åˆ†ææœ€è¿‘æ“ä½œå€¾å‘
            recent_buy = sum(op['ä¹°å…¥é‡‘é¢'] for op in recent_operations)
            recent_sell = sum(op['å–å‡ºé‡‘é¢'] for op in recent_operations)

            # é¢„æµ‹
            predictions = []

            if recent_buy > recent_sell * 2:
                predictions.append({
                    'é¢„æµ‹ç±»å‹': 'ç»§ç»­ä¹°å…¥',
                    'æ¦‚ç‡': 'é«?,
                    'è¯´æ˜': f'{capital_name} æœ€è¿‘å¤§å¹…ä¹°å…¥ï¼Œå¯èƒ½ç»§ç»­åŠ ä»“'
                })
            elif recent_sell > recent_buy * 2:
                predictions.append({
                    'é¢„æµ‹ç±»å‹': 'ç»§ç»­å–å‡º',
                    'æ¦‚ç‡': 'é«?,
                    'è¯´æ˜': f'{capital_name} æœ€è¿‘å¤§å¹…å–å‡ºï¼Œå¯èƒ½ç»§ç»­å‡ä»“'
                })
            else:
                predictions.append({
                    'é¢„æµ‹ç±»å‹': 'è§‚æœ›æˆ–å°å¹…æ“ä½?,
                    'æ¦‚ç‡': 'ä¸?,
                    'è¯´æ˜': f'{capital_name} æœ€è¿‘æ“ä½œå‡è¡¡ï¼Œå¯èƒ½è§‚æœ›'
                })

            # æ ¹æ®æˆåŠŸç‡é¢„æµ?            if pattern_result['æ“ä½œæˆåŠŸç?] > 60:
                predictions.append({
                    'é¢„æµ‹ç±»å‹': 'å…³æ³¨å…¶æ“ä½?,
                    'æ¦‚ç‡': 'é«?,
                    'è¯´æ˜': f'{capital_name} å†å²æˆåŠŸç‡é«˜ï¼Œå»ºè®®å…³æ³¨å…¶æ“ä½œ'
                })

            return {
                'æ•°æ®çŠ¶æ€?: 'æ­£å¸¸',
                'æ¸¸èµ„åç§°': capital_name,
                'é¢„æµ‹åˆ—è¡¨': predictions
            }

        except Exception as e:
            return {
                'æ•°æ®çŠ¶æ€?: 'é¢„æµ‹å¤±è´¥',
                'é”™è¯¯ä¿¡æ¯': str(e),
                'è¯´æ˜': 'å¯èƒ½æ˜¯æ•°æ®é—®é¢?
            }