#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
iFlowçº¢çº¿å®¡è®¡è§„åˆ™è„šæœ¬ - è‡ªæ„ˆæ–­è¨€ç³»ç»Ÿ
CTOé»‘ç§‘æŠ€2: Self-Healing Assertions

èŒè´£: åœ¨ä»£ç æäº¤å‰è‡ªåŠ¨æ‰«æçº¢çº¿è¿è§„
è§¦å‘: iflow_config.yamlä¸­redline_hooks.pre_commit_checks
è¾“å‡º: è¿è§„æŠ¥å‘Šï¼Œè‡ªåŠ¨æ‰“å›è¿è§„ä»£ç 

Author: CTOæ¶æ„è§„èŒƒ
Version: V20.0
"""

import re
import sys
import ast
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import json


class RedlineAuditor:
    """çº¢çº¿å®¡è®¡å‘˜ - ä»£ç æäº¤å‰å¼ºåˆ¶æ£€æŸ¥"""
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.violations: List[Dict] = []
        self.errors = 0
        self.warnings = 0
        
    def audit_file(self, file_path: Path) -> bool:
        """å®¡è®¡å•ä¸ªæ–‡ä»¶"""
        if not file_path.exists():
            return True
            
        content = file_path.read_text(encoding='utf-8')
        
        # æ£€æŸ¥1: é­”æ³•æ•°å­—ç¡¬ç¼–ç 
        self._check_magic_numbers(file_path, content)
        
        # æ£€æŸ¥2: Tushareæ®‹ç•™
        self._check_tushare_residue(file_path, content)
        
        # æ£€æŸ¥3: ç¡¬ç¼–ç è·¯å¾„
        self._check_hardcoded_paths(file_path, content)
        
        # æ£€æŸ¥4: Forå¾ªç¯éå†Tick
        self._check_for_loop_tick_iteration(file_path, content)
        
        # æ£€æŸ¥5: ConfigManagerä½¿ç”¨
        self._check_config_manager_usage(file_path, content)
        
        return self.errors == 0
    
    def _check_magic_numbers(self, file_path: Path, content: str):
        """æ£€æŸ¥é­”æ³•æ•°å­—ç¡¬ç¼–ç """
        # æ£€æµ‹æ¨¡å¼: åœ¨ç‰¹å®šä¸Šä¸‹æ–‡ä¸­å‡ºç°çš„ç–‘ä¼¼é˜ˆå€¼æ•°å­—
        patterns = [
            (r'volume_ratio\s*[>=<]+\s*0\.[0-9]+', "é‡æ¯”é˜ˆå€¼ç¡¬ç¼–ç "),
            (r'turnover\s*[>=<]+\s*[0-9]+\.[0-9]+', "æ¢æ‰‹ç‡é˜ˆå€¼ç¡¬ç¼–ç "),
            (r'threshold\s*=\s*0\.[0-9]+', "thresholdç¡¬ç¼–ç "),
            (r'change_pct\s*[>=<]+\s*[0-9]+\.[0-9]+', "æ¶¨è·Œå¹…é˜ˆå€¼ç¡¬ç¼–ç "),
        ]
        
        for pattern, desc in patterns:
            matches = re.finditer(pattern, content, re.IGNORECASE)
            for match in matches:
                # æ’é™¤ä»configè¯»å–çš„åˆæ³•æƒ…å†µ
                line_num = content[:match.start()].count('\n') + 1
                line_content = content.split('\n')[line_num - 1].strip()
                
                if 'config' not in line_content.lower() and 'get_config' not in line_content.lower():
                    self.violations.append({
                        'file': str(file_path),
                        'line': line_num,
                        'type': 'magic_number',
                        'severity': 'error',
                        'message': f"{desc}: {match.group()}",
                        'fix': 'å¿…é¡»ä»ConfigManagerè¯»å–é…ç½®'
                    })
                    self.errors += 1
    
    def _check_tushare_residue(self, file_path: Path, content: str):
        """æ£€æŸ¥Tushareæ®‹ç•™"""
        patterns = [
            (r'import\s+tushare', "å¯¼å…¥tushareæ¨¡å—"),
            (r'from\s+tushare', "ä»tushareå¯¼å…¥"),
            (r'ts\.pro_api', "è°ƒç”¨tushare API"),
            (r'daily_basic', "tushare daily_basicæ¥å£"),
            (r'ts_code', "tushareä»£ç æ ¼å¼"),
            (r'TUSHARE_TOKEN', "tushare tokenå¼•ç”¨"),
        ]
        
        for pattern, desc in patterns:
            matches = re.finditer(pattern, content, re.IGNORECASE)
            for match in matches:
                line_num = content[:match.start()].count('\n') + 1
                self.violations.append({
                    'file': str(file_path),
                    'line': line_num,
                    'type': 'tushare_residue',
                    'severity': 'error',
                    'message': desc,
                    'fix': 'å¿…é¡»ä½¿ç”¨QMTæœ¬åœ°æ•°æ®(xtdata)'
                })
                self.errors += 1
    
    def _check_hardcoded_paths(self, file_path: Path, content: str):
        """æ£€æŸ¥ç¡¬ç¼–ç è·¯å¾„"""
        # Windowsè·¯å¾„: C:\xxx, D:\xxx
        # Linux/Macè·¯å¾„: /home/xxx, /Users/xxx
        patterns = [
            (r'[C-Z]:\\\\[^\s\'"]+', "Windowsç¡¬ç¼–ç è·¯å¾„"),
            (r'/home/[^\s\'"]+', "Linuxç¡¬ç¼–ç è·¯å¾„"),
            (r'/Users/[^\s\'"]+', "Macç¡¬ç¼–ç è·¯å¾„"),
        ]
        
        allowed_contexts = ['__file__', 'PathResolver', 'get_root', 'Path(__file__)']
        
        for pattern, desc in patterns:
            matches = re.finditer(pattern, content)
            for match in matches:
                line_num = content[:match.start()].count('\n') + 1
                line_content = content.split('\n')[line_num - 1].strip()
                
                # æ£€æŸ¥æ˜¯å¦åœ¨å…è®¸ä¸Šä¸‹æ–‡ä¸­
                if not any(ctx in line_content for ctx in allowed_contexts):
                    self.violations.append({
                        'file': str(file_path),
                        'line': line_num,
                        'type': 'hardcoded_path',
                        'severity': 'warning',
                        'message': desc,
                        'fix': 'ä½¿ç”¨PathResolveråŠ¨æ€è§£æè·¯å¾„'
                    })
                    self.warnings += 1
    
    def _check_for_loop_tick_iteration(self, file_path: Path, content: str):
        """æ£€æŸ¥Forå¾ªç¯éå†Tick"""
        # æ£€æµ‹å¯ç–‘çš„forå¾ªç¯éå†Tickæ•°æ®
        patterns = [
            (r'for\s+\w+\s+in\s+ticks', "forå¾ªç¯éå†ticks"),
            (r'for\s+\w+\s+in\s+df\.', "forå¾ªç¯éå†DataFrameè¡Œ"),
            (r'for\s+\w+\s+in\s+tick_data', "forå¾ªç¯éå†tick_data"),
        ]
        
        # å…è®¸çš„åˆæ³•ä¸Šä¸‹æ–‡ï¼ˆäº‹ä»¶é©±åŠ¨æ¨¡æ‹Ÿéƒ¨åˆ†ï¼‰
        allowed_contexts = ['event_driven', 'micro_defense', 'simulation', 'matching']
        
        for pattern, desc in patterns:
            matches = re.finditer(pattern, content, re.IGNORECASE)
            for match in matches:
                line_num = content[:match.start()].count('\n') + 1
                
                # è·å–ä¸Šä¸‹æ–‡ï¼ˆå‰å5è¡Œï¼‰
                lines = content.split('\n')
                context_start = max(0, line_num - 6)
                context_end = min(len(lines), line_num + 5)
                context = '\n'.join(lines[context_start:context_end])
                
                # æ£€æŸ¥æ˜¯å¦åœ¨å…è®¸çš„åˆæ³•ä¸Šä¸‹æ–‡ä¸­
                if not any(ctx in context.lower() for ctx in allowed_contexts):
                    self.violations.append({
                        'file': str(file_path),
                        'line': line_num,
                        'type': 'for_loop_tick',
                        'severity': 'error',
                        'message': desc,
                        'fix': 'ä½¿ç”¨Pandaså‘é‡åŒ–æ“ä½œ(df.cumsum/apply)ï¼Œä¸¥ç¦Forå¾ªç¯éå†Tick'
                    })
                    self.errors += 1
    
    def _check_config_manager_usage(self, file_path: Path, content: str):
        """æ£€æŸ¥ConfigManageræ­£ç¡®ä½¿ç”¨"""
        # æ£€æŸ¥æ˜¯å¦å¯¼å…¥äº†ConfigManager
        has_config_import = 'get_config_manager' in content or 'ConfigManager' in content
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç¡¬ç¼–ç é˜ˆå€¼ï¼ˆåœ¨åº”æœ‰ConfigManagerçš„æ–‡ä»¶ä¸­ï¼‰
        if has_config_import:
            # å¦‚æœæ–‡ä»¶ä½¿ç”¨äº†ConfigManagerï¼Œä½†ä»æœ‰ç¡¬ç¼–ç æ•°å­—
            hardcoded_patterns = [
                (r'volume_ratio\s*=\s*0\.[0-9]+', "é‡æ¯”ç¡¬ç¼–ç "),
                (r'turnover.*=\s*[0-9]+\.[0-9]+', "æ¢æ‰‹ç‡ç¡¬ç¼–ç "),
            ]
            
            for pattern, desc in hardcoded_patterns:
                matches = re.finditer(pattern, content, re.IGNORECASE)
                for match in matches:
                    line_num = content[:match.start()].count('\n') + 1
                    self.violations.append({
                        'file': str(file_path),
                        'line': line_num,
                        'type': 'config_usage',
                        'severity': 'error',
                        'message': f"{desc}ï¼ˆæ–‡ä»¶å·²å¯¼å…¥ConfigManagerï¼Œå¿…é¡»ä»é…ç½®è¯»å–ï¼‰",
                        'fix': 'ä½¿ç”¨config.get("live_sniper.volume_ratio_percentile")è¯»å–é…ç½®'
                    })
                    self.errors += 1
    
    def audit_project(self, target_paths: Optional[List[str]] = None) -> Dict:
        """å®¡è®¡æ•´ä¸ªé¡¹ç›®æˆ–æŒ‡å®šè·¯å¾„"""
        if target_paths is None:
            target_paths = ['logic/', 'tools/', 'tasks/']
        
        for target in target_paths:
            target_path = self.project_root / target
            if target_path.is_file():
                self.audit_file(target_path)
            elif target_path.is_dir():
                for py_file in target_path.rglob('*.py'):
                    # è·³è¿‡æµ‹è¯•æ–‡ä»¶å’Œç¼“å­˜
                    if 'test_' not in py_file.name and '__pycache__' not in str(py_file):
                        self.audit_file(py_file)
        
        return self.generate_report()
    
    def generate_report(self) -> Dict:
        """ç”Ÿæˆå®¡è®¡æŠ¥å‘Š"""
        report = {
            'summary': {
                'total_errors': self.errors,
                'total_warnings': self.warnings,
                'total_violations': len(self.violations),
                'pass': self.errors == 0
            },
            'violations': self.violations,
            'recommendations': []
        }
        
        if self.errors > 0:
            report['recommendations'].append("å­˜åœ¨è‡´å‘½è¿è§„ï¼Œå¿…é¡»ä¿®å¤åæ‰èƒ½æäº¤")
            report['recommendations'].append(f"å…±å‘ç°{self.errors}ä¸ªé”™è¯¯ï¼Œ{self.warnings}ä¸ªè­¦å‘Š")
            
            # æŒ‰ç±»å‹åˆ†ç»„
            by_type = {}
            for v in self.violations:
                vtype = v['type']
                by_type[vtype] = by_type.get(vtype, 0) + 1
            
            report['by_type'] = by_type
        else:
            report['recommendations'].append("âœ… ä»£ç é€šè¿‡æ‰€æœ‰çº¢çº¿å®¡è®¡")
        
        return report
    
    def print_report(self, report: Dict):
        """æ‰“å°å®¡è®¡æŠ¥å‘Š"""
        print("=" * 70)
        print("ğŸ” iFlowçº¢çº¿å®¡è®¡æŠ¥å‘Š")
        print("=" * 70)
        
        summary = report['summary']
        if summary['pass']:
            print("\nâœ… æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼ä»£ç ç¬¦åˆCTOæ¶æ„è§„èŒƒ")
        else:
            print(f"\nâŒ å®¡è®¡å¤±è´¥: {summary['total_errors']}ä¸ªé”™è¯¯, {summary['total_warnings']}ä¸ªè­¦å‘Š")
            print("\nè¿è§„è¯¦æƒ…:")
            print("-" * 70)
            
            for v in report['violations']:
                severity_emoji = "ğŸ”´" if v['severity'] == 'error' else "ğŸŸ¡"
                print(f"\n{severity_emoji} [{v['type'].upper()}] {v['file']}:{v['line']}")
                print(f"   é—®é¢˜: {v['message']}")
                print(f"   ä¿®å¤: {v['fix']}")
        
        print("\n" + "=" * 70)
        
        return summary['pass']


def main():
    """ä¸»å…¥å£ - å‘½ä»¤è¡Œè°ƒç”¨"""
    import argparse
    
    parser = argparse.ArgumentParser(description='iFlowçº¢çº¿å®¡è®¡å·¥å…·')
    parser.add_argument('--path', '-p', nargs='+', help='å®¡è®¡è·¯å¾„')
    parser.add_argument('--json', '-j', action='store_true', help='è¾“å‡ºJSONæ ¼å¼')
    args = parser.parse_args()
    
    auditor = RedlineAuditor()
    report = auditor.audit_project(args.path)
    
    if args.json:
        print(json.dumps(report, ensure_ascii=False, indent=2))
        sys.exit(0 if report['summary']['pass'] else 1)
    else:
        passed = auditor.print_report(report)
        sys.exit(0 if passed else 1)


if __name__ == '__main__':
    main()
