# ğŸ“Š MyQuantTool v4 å®Œæ•´ä¼˜åŒ–ä¸è¿­ä»£è§„åˆ’

**æ–‡æ¡£ç‰ˆæœ¬**: v4.0 (Optimization & Feature Extension)  
**æ›´æ–°æ—¶é—´**: 2026-01-07 11:16 UTC+8  
**çŠ¶æ€**: ğŸŸ¡ è§„åˆ’ä¸­ (å‡†å¤‡å¼€å‘)  
**ç›®æ ‡å®Œæˆ**: 2026 å¹´ 1 æœˆåº•

---

## ğŸ¯ æ ¸å¿ƒç°çŠ¶åˆ†æ

### å½“å‰ç³»ç»Ÿæˆç†Ÿåº¦

| æ¨¡å— | å®Œæˆåº¦ | ç²¾å‡†åº¦ | æ€§èƒ½ | çŠ¶æ€ |
|------|--------|--------|------|------|
| **æ¸¸èµ„ç½‘ç»œåˆ†æ** | 100% | 65-75% | <1s | âœ… ç”Ÿäº§å°±ç»ª |
| **å¤šå› å­èåˆæ¨¡å‹** | 100% | 70-80% | 0.1s | âœ… ç”Ÿäº§å°±ç»ª |
| **Kçº¿æŠ€æœ¯åˆ†æ** | 100% | 55-65% | <0.1s | âœ… ç”Ÿäº§å°±ç»ª |
| **é¾™å¤´è¯†åˆ«** | 100% | 80%+ | <0.1s | âœ… ç”Ÿäº§å°±ç»ª |
| **é‚®ä»¶å‘Šè­¦ç³»ç»Ÿ** | 100% | 99.8% | 1-3s | âœ… ç”Ÿäº§å°±ç»ª |
| **å®æ—¶æ•°æ®é›†æˆ** | 100% | 99%+ | 3-5s | âœ… ç”Ÿäº§å°±ç»ª |
| **æ¿å—è½®åŠ¨åˆ†æ** | 0% | - | - | âŒ å¾…å¼€å‘ |
| **çƒ­ç‚¹é¢˜ææå–** | 30% | 45% | 2s | ğŸŸ¡ éƒ¨åˆ†åŠŸèƒ½ |
| **æ‰“æ¿é¢„æµ‹æ¨¡å‹** | 20% | 35% | <0.1s | ğŸŸ¡ åŸºç¡€æ¡†æ¶ |

---

## ğŸš€ v4 æ–°å¢åŠŸèƒ½è§„åˆ’ (ä¸‰å¤§æ ¸å¿ƒåŠŸèƒ½)

### 1ï¸âƒ£ æ¿å—è½®åŠ¨åˆ†æç³»ç»Ÿ (Sector Rotation)

#### åŠŸèƒ½éœ€æ±‚

```
ğŸ“Š æ¿å—è·Ÿè¸ª (30 ä¸ªè¡Œä¸š)
â”œâ”€ å®æ—¶æ¿å—æ¶¨å¹…æ’å
â”œâ”€ æ¿å—èµ„é‡‘æµå‘è¿½è¸ª
â”œâ”€ æ¿å—é¾™å¤´è‚¡è¯†åˆ«
â””â”€ æ¿å—è½®åŠ¨ä¿¡å·

ğŸ”„ è½®åŠ¨é¢„æµ‹ (5-10 ä¸ªäº¤æ˜“æ—¥)
â”œâ”€ æ¿å—å¼ºåº¦è¯„åˆ† (0-100)
â”œâ”€ è½®åŠ¨è¶‹åŠ¿é¢„æµ‹
â”œâ”€ æœ€å¼ºæ¿å—åˆ‡æ¢ç‚¹
â””â”€ æ¿å—è”åŠ¨å…³ç³»

ğŸ’¹ è”åŠ¨æœºåˆ¶
â”œâ”€ æ¿å—é—´ç›¸å…³æ€§çŸ©é˜µ
â”œâ”€ é¾™å¤´å¸¦åŠ¨æ•ˆåº”
â”œâ”€ èµ„é‡‘è·¨æ¿å—æµåŠ¨
â””â”€ æ¿å—è½®åŠ¨ä¿¡å·

ğŸ“ˆ å†³ç­–æ”¯æŒ
â”œâ”€ æ¿å—åˆ‡æ¢å»ºè®®
â”œâ”€ æœ€ä¼˜åˆ‡å…¥ç‚¹
â”œâ”€ é£é™©é¢„è­¦
â””â”€ æ”¶ç›Šé¢„æµ‹
```

#### æŠ€æœ¯æ–¹æ¡ˆ

**æ•°æ®æº**:
- ğŸ”— akshare æ¿å—æ•°æ® (`stock_sector_*`)
- ğŸ”— é¾™è™æ¦œæ•°æ® (æ¸¸èµ„é€‰è‚¡)
- ğŸ”— èµ„é‡‘æµå‘æ•°æ® (å¤§å®—äº¤æ˜“)
- ğŸ”— ä¸ªè‚¡ K çº¿æ•°æ® (æŠ€æœ¯å½¢æ€)

**æ ¸å¿ƒç®—æ³•**:

```python
# æ¿å—å¼ºåº¦è®¡ç®—
class SectorRotationAnalyzer:
    def __init__(self):
        self.sectors = 30  # 30 ä¸ªè¡Œä¸š
        self.time_window = [5, 10, 20]  # å¤šæ—¶é—´å‘¨æœŸ
        
    def calculate_sector_strength(self, date):
        """
        æ¿å—å¼ºåº¦è¯„åˆ† (0-100)
        
        å› å­:
        - æ¿å—æ¶¨å¹… (æƒé‡ 30%)
        - æ¿å—èµ„é‡‘æµå…¥ (æƒé‡ 25%)
        - æ¿å—é¾™å¤´æ•°é‡ (æƒé‡ 20%)
        - æ¿å—é¢˜æçƒ­åº¦ (æƒé‡ 15%)
        - æ¿å—æˆäº¤é‡ (æƒé‡ 10%)
        """
        strength_scores = {}
        
        for sector in self.sectors:
            # 1. æ¶¨å¹…å› å­ (0-100)
            price_change = get_sector_price_change(sector, date)
            price_score = normalize(price_change, -10, 10) * 30
            
            # 2. èµ„é‡‘æµå…¥å› å­ (0-100)
            capital_flow = get_sector_capital_flow(sector, date)
            capital_score = normalize(capital_flow, -1e9, 1e9) * 25
            
            # 3. é¾™å¤´æ•°é‡å› å­ (0-100)
            leaders = count_sector_leaders(sector, date)
            leader_score = min(leaders / 5, 1) * 20  # 5ä¸ªé¾™å¤´æ»¡åˆ†
            
            # 4. é¢˜æçƒ­åº¦å› å­ (0-100)
            hot_topics = extract_sector_topics(sector, date)
            topic_score = len(hot_topics) / 3 * 15  # 3ä¸ªçƒ­ç‚¹æ»¡åˆ†
            
            # 5. æˆäº¤é‡å› å­ (0-100)
            volume = get_sector_volume(sector, date)
            volume_score = normalize(volume, 0, 1e10) * 10
            
            # ç»¼åˆè¯„åˆ†
            total_score = price_score + capital_score + leader_score + topic_score + volume_score
            strength_scores[sector] = min(total_score, 100)
        
        return strength_scores
    
    def detect_rotation_signals(self, date):
        """
        æ£€æµ‹æ¿å—è½®åŠ¨ä¿¡å·
        """
        curr_strength = self.calculate_sector_strength(date)
        prev_strength = self.calculate_sector_strength(date - 1)
        
        # è®¡ç®—æ¿å—å¼ºåº¦å˜åŒ–
        delta = {s: curr_strength[s] - prev_strength[s] for s in self.sectors}
        
        # è¯†åˆ«è½®åŠ¨
        rotations = {
            'rising': [s for s, d in delta.items() if d > 10],      # ä¸Šå‡ä¸­
            'falling': [s for s, d in delta.items() if d < -10],    # ä¸‹é™ä¸­
            'leading': sorted(curr_strength, key=lambda s: curr_strength[s], reverse=True)[:3],  # é¢†æ¶¨
            'lagging': sorted(curr_strength, key=lambda s: curr_strength[s])[:3],  # é¢†è·Œ
        }
        
        return rotations
    
    def predict_rotation_trend(self, date, days_ahead=5):
        """
        é¢„æµ‹æœªæ¥ 5-10 å¤©æ¿å—è½®åŠ¨è¶‹åŠ¿
        
        ä½¿ç”¨ LSTM æˆ–ç§»åŠ¨å¹³å‡çº¿
        """
        # è·å–å†å²æ•°æ®
        history = [self.calculate_sector_strength(date - i) for i in range(30)]
        
        # LSTM é¢„æµ‹
        model = load_lstm_model('sector_rotation')
        predictions = model.predict(history[-20:])  # ç”¨è¿‡å» 20 å¤©é¢„æµ‹
        
        return predictions  # [5å¤©, 10å¤©]
```

**ç²¾å‡†åº¦ç›®æ ‡**: 65-75%  
**æ€§èƒ½ç›®æ ‡**: <1s (å•æ¬¡è®¡ç®—)

---

### 2ï¸âƒ£ çƒ­ç‚¹é¢˜ææå–ä¸è·Ÿè¸ªç³»ç»Ÿ (Hot Topics)

#### åŠŸèƒ½éœ€æ±‚

```
ğŸ”¥ å®æ—¶é¢˜æçƒ­åº¦
â”œâ”€ çƒ­ç‚¹æ–°é—»çˆ¬å–
â”œâ”€ ç¤¾äº¤åª’ä½“èˆ†æƒ…
â”œâ”€ ç ”æŠ¥å…³é”®è¯æå–
â”œâ”€ é¢˜æå…³è”è‚¡ç¥¨
â””â”€ çƒ­åº¦è¶‹åŠ¿å›¾è¡¨

ğŸ“° é¢˜æåˆ†ç±»
â”œâ”€ æ”¿ç­–é¢ (å›½å®¶æ”¿ç­–ã€è¡Œä¸šæ”¿ç­–)
â”œâ”€ æŠ€æœ¯é¢ (æ–°æŠ€æœ¯ã€äº§ä¸šå‡çº§)
â”œâ”€ æ¶ˆæ¯é¢ (å…¬å¸å…¬å‘Šã€äº‹ä»¶é©±åŠ¨)
â”œâ”€ å¸‚åœºé¢ (æ¸¸èµ„çƒ­ç‚¹ã€æ¸¸èµ„å¯¹æ ‡)
â””â”€ å¤–éƒ¨é¢ (æµ·å¤–æ–°é—»ã€é‡‘èæ•°æ®)

ğŸ“Š é¢˜æå…³è”
â”œâ”€ é¢˜æ-è‚¡ç¥¨æ˜ å°„
â”œâ”€ é¢˜æçƒ­åº¦æŒ‡æ•° (0-100)
â”œâ”€ é¢˜æå‘¨æœŸç”Ÿå‘½å‘¨æœŸ
â”œâ”€ é¢˜æé¾™å¤´è‚¡è¯†åˆ«
â””â”€ é¢˜æè½®åŠ¨è§„å¾‹

ğŸ¯ å†³ç­–æ”¯æŒ
â”œâ”€ é¢˜æé€‰è‚¡å»ºè®®
â”œâ”€ é¢˜æåˆ‡å…¥ç‚¹å»ºè®®
â”œâ”€ é¢˜æé£é™©é¢„è­¦
â””â”€ é¢˜ææ”¶ç›Šé¢„æµ‹
```

#### æŠ€æœ¯æ–¹æ¡ˆ

**æ•°æ®æº**:
- ğŸ”— æ–°é—» API (æ–°æµªã€ç½‘æ˜“ã€è…¾è®¯)
- ğŸ”— ç ”æŠ¥æ•°æ®åº“ (åŒèŠ±é¡ºã€ä¸œæ–¹è´¢å¯Œ)
- ğŸ”— èˆ†æƒ…ç›‘æ§ (å¾®åšçƒ­æœã€ç™¾åº¦æŒ‡æ•°)
- ğŸ”— é¾™è™æ¦œæ•°æ® (æ¸¸èµ„å…³æ³¨)
- ğŸ”— å…¬å‘Šæ•°æ® (é‡å¤§äº‹ä»¶)

**æ ¸å¿ƒç®—æ³•**:

```python
# çƒ­ç‚¹é¢˜ææå–
class HotTopicExtractor:
    def __init__(self):
        self.nlp = load_nlp_model()  # ä¸­æ–‡ NLP
        self.topic_db = TopicDatabase()
        self.keywords = load_keywords('finance_keywords.json')
        
    def extract_topics_from_news(self, date):
        """
        ä»æ–°é—»ä¸­æå–çƒ­ç‚¹é¢˜æ
        
        æµç¨‹:
        1. çˆ¬å–æ–°é—»
        2. åˆ†è¯ã€å»åœç”¨è¯
        3. å…³é”®è¯æå– (TFIDF / TextRank)
        4. é¢˜æåˆ†ç±»
        5. çƒ­åº¦è¯„åˆ†
        """
        # 1. çˆ¬å–æ–°é—»
        news_list = crawl_financial_news(date)
        
        # 2. åˆ†è¯
        topics = {}
        for news in news_list:
            words = self.nlp.segment(news['title'] + news['content'])
            
            # 3. å…³é”®è¯æå–
            keywords = extract_keywords(words, top_n=5)
            
            # 4. é¢˜æåˆ†ç±»
            for keyword in keywords:
                category = classify_topic(keyword)
                
                if keyword not in topics:
                    topics[keyword] = {
                        'category': category,
                        'frequency': 0,
                        'heat': 0,
                        'stocks': [],
                        'first_seen': date
                    }
                
                topics[keyword]['frequency'] += 1
        
        # 5. çƒ­åº¦è¯„åˆ†
        for topic, info in topics.items():
            # çƒ­åº¦ = é¢‘æ¬¡ * æ–°é—»é‡è¦æ€§ * çƒ­åº¦è¡°å‡
            importance = get_news_importance(topic)
            decay = calculate_decay(info['first_seen'], date)
            heat = info['frequency'] * importance * decay
            info['heat'] = min(heat, 100)
        
        return topics
    
    def map_topics_to_stocks(self, topics, date):
        """
        å°†é¢˜ææ˜ å°„åˆ°è‚¡ç¥¨
        
        æµç¨‹:
        1. æ ¹æ®é¢˜æå…³é”®è¯æ‰¾ç›¸å…³è‚¡ç¥¨
        2. æ ¹æ®é¾™è™æ¦œæ‰¾æ¸¸èµ„å…³æ³¨
        3. æ ¹æ®ç ”æŠ¥æ‰¾æœºæ„çœ‹å¥½
        4. ç»¼åˆè¯„åˆ†
        """
        topic_stocks = {}
        
        for topic, info in topics.items():
            stocks = []
            
            # 1. å…³é”®è¯åŒ¹é…
            keyword_matched = search_stocks_by_keyword(topic)
            stocks.extend(keyword_matched)
            
            # 2. é¾™è™æ¦œæ¸¸èµ„å…³æ³¨
            lhb_stocks = get_lhb_stocks_by_topic(topic, date)
            stocks.extend(lhb_stocks)
            
            # 3. ç ”æŠ¥æœºæ„çœ‹å¥½
            report_stocks = search_reports_by_topic(topic, date)
            stocks.extend(report_stocks)
            
            # å»é‡å¹¶è¯„åˆ†
            stocks_scored = {}
            for stock in set(stocks):
                score = 0
                
                # å‡ºç°åœ¨é¾™è™æ¦œ +30
                if stock in lhb_stocks:
                    score += 30
                
                # å‡ºç°åœ¨ç ”æŠ¥ +20
                if stock in report_stocks:
                    score += 20
                
                # Kçº¿å¼ºåŠ¿ +20
                if is_stock_strong(stock, date):
                    score += 20
                
                # èµ„é‡‘æµå…¥ +20
                if has_capital_inflow(stock, date):
                    score += 20
                
                # æ¶¨å¹…é¢†å…ˆ +10
                if is_stock_leading(stock, date):
                    score += 10
                
                stocks_scored[stock] = min(score, 100)
            
            topic_stocks[topic] = {
                'heat': info['heat'],
                'category': info['category'],
                'stocks': sorted(stocks_scored.items(), key=lambda x: x[1], reverse=True),
                'top_stock': stocks_scored.get(max(stocks_scored, default=None), 0)
            }
        
        return topic_stocks
    
    def calculate_topic_lifecycle(self, topic):
        """
        è®¡ç®—é¢˜æç”Ÿå‘½å‘¨æœŸ
        
        é˜¶æ®µ:
        1. å­•è‚²æœŸ (çƒ­åº¦<20) - æå‰å¸ƒå±€
        2. æˆé•¿æœŸ (çƒ­åº¦ 20-50) - ä¸»è¦ä¸Šæ¶¨
        3. çˆ†å‘æœŸ (çƒ­åº¦ 50-80) - åŠ é€Ÿä¸Šæ¶¨
        4. è¡°é€€æœŸ (çƒ­åº¦>80) - é£é™©é‡Šæ”¾
        """
        history = self.topic_db.get_topic_history(topic, days=30)
        
        if not history:
            return 'emerging'  # æ–°é¢˜æ
        
        # è®¡ç®—çƒ­åº¦å˜åŒ–è¶‹åŠ¿
        heats = [h['heat'] for h in history]
        trend = calculate_trend(heats)
        current_heat = heats[-1]
        
        if current_heat < 20:
            stage = 'incubating'
        elif current_heat < 50 and trend > 0:
            stage = 'growing'
        elif current_heat < 80 and trend > 2:
            stage = 'erupting'
        else:
            stage = 'declining'
        
        return stage
```

**ç²¾å‡†åº¦ç›®æ ‡**: 65-75% (é¢˜æè¯†åˆ«)  
**æ€§èƒ½ç›®æ ‡**: 2-3s (æ—¥æ›´æ–°)

---

### 3ï¸âƒ£ æ‰“æ¿é¢„æµ‹ä¸å†³ç­–ç³»ç»Ÿ (Limit Up Prediction)

#### åŠŸèƒ½éœ€æ±‚

```
ğŸ¯ ä¸€å­—æ¿é¢„æµ‹
â”œâ”€ æ—¥å†…ä¸€å­—æ¿æ¦‚ç‡ (0-100%)
â”œâ”€ ä¸€å­—æ¿æŒç»­æ—¶é—´é¢„æµ‹
â”œâ”€ ä¸€å­—æ¿ç ´æ¿æ¦‚ç‡
â””â”€ æ‰“æ¿ç­–ç•¥å»ºè®®

ğŸ“ˆ äºŒå­—æ¿/ä¸‰å­—æ¿é¢„æµ‹
â”œâ”€ è¿æ¿æ¦‚ç‡é¢„æµ‹
â”œâ”€ æœ€é«˜æ¿æ•°é¢„æµ‹
â”œâ”€ ç ´æ¿é£é™©é¢„è­¦
â””â”€ æœ€ä¼˜å–å‡ºç‚¹

ğŸ’° æ‰“æ¿æ“ä½œå»ºè®®
â”œâ”€ å…¥åœºä»·æ¨è
â”œâ”€ æ­¢æŸä»·è®¾ç½®
â”œâ”€ æ­¢ç›ˆä»·è®¾ç½®
â”œâ”€ æœ€ä¼˜å…¥åœºæ—¶åˆ»
â””â”€ é£é™©æ”¶ç›Šæ¯”è¯„ä¼°

ğŸš¨ é£é™©é¢„è­¦
â”œâ”€ ç ¸æ¿é£é™© (æ¦‚ç‡é¢„æµ‹)
â”œâ”€ ä¸€å­—æ¿ç ´ä½é£é™©
â”œâ”€ æ¸¸èµ„å¯¹æ ‡é£é™©
â”œâ”€ æ”¿ç­–é£é™©
â””â”€ å®æ—¶åŠ¨æ€ç›‘æ§
```

#### æŠ€æœ¯æ–¹æ¡ˆ

**æ•°æ®æº**:
- ğŸ”— åˆ†é’Ÿçº§ K çº¿æ•°æ®
- ğŸ”— é¾™è™æ¦œå®æ—¶æ•°æ®
- ğŸ”— é›†åˆç«ä»·æ•°æ®
- ğŸ”— å§”æ‰˜ç›˜æ•°æ®
- ğŸ”— å¤§å®—äº¤æ˜“æ•°æ®
- ğŸ”— ç ”æŠ¥ & æ–°é—»æ•°æ®

**æ ¸å¿ƒç®—æ³•**:

```python
# æ‰“æ¿é¢„æµ‹ç³»ç»Ÿ
class LimitUpPredictor:
    def __init__(self):
        self.lstm = load_lstm_model('limit_up')
        self.xgboost = load_xgboost_model('limit_up')
        self.history_db = HistoryDatabase()
        
    def predict_limit_up_probability(self, stock_code, date):
        """
        é¢„æµ‹ä¸€å­—æ¿æ¦‚ç‡ (0-100%)
        
        å› å­ (14 ä¸ª):
        - å‰ä¸€æ—¥æ¶¨å¹… (ç›¸å…³æ€§æœ€é«˜)
        - å‰ä¸€æ—¥é¾™è™æ¦œæ¸¸èµ„æ•°
        - å‰ä¸€æ—¥æ¸¸èµ„å…¥åœºèµ„é‡‘
        - é›†åˆç«ä»·æ¶¨å¹… (å¼ºé¢„æµ‹ä¿¡å·)
        - é›†åˆç«ä»·æˆäº¤é‡
        - å¼€ç›˜å 5 åˆ†é’Ÿæ¶¨å¹…
        - å¼€ç›˜å 10 åˆ†é’Ÿæ¶¨å¹…
        - è‚¡ç¥¨æŠ€æœ¯é¢è¯„åˆ†
        - æ¿å—å¼ºåº¦è¯„åˆ†
        - é¢˜æçƒ­åº¦è¯„åˆ†
        - æ¸¸èµ„æ”¯æŒåº¦ (å¯¹æ‰‹æ•°)
        - å…¬å¼€èˆ†è®ºåº¦
        - èµ„é‡‘é¢æƒ…ç»ªæŒ‡æ•°
        - å†å²æ‰“æ¿æˆåŠŸç‡ (è¯¥è‚¡)
        """
        # æ”¶é›†ç‰¹å¾
        features = {}
        
        # 1. å‰ä¸€æ—¥æ¶¨å¹…
        prev_return = get_prev_return(stock_code, date)
        features['prev_return'] = prev_return
        
        # 2. é¾™è™æ¦œæ¸¸èµ„æ•°
        lhb_data = get_lhb_data(stock_code, date-1)
        features['lhb_buyers'] = len(lhb_data['buyers'])
        features['lhb_capital'] = lhb_data['total_capital']
        
        # 3. é›†åˆç«ä»·æ•°æ®
        call_auction = get_call_auction(stock_code, date)
        features['call_auction_return'] = call_auction['return']
        features['call_auction_volume'] = call_auction['volume']
        
        # 4. å¼€ç›˜å 5/10 åˆ†é’Ÿæ¶¨å¹…
        features['5min_return'] = get_minute_return(stock_code, date, 5)
        features['10min_return'] = get_minute_return(stock_code, date, 10)
        
        # 5. æŠ€æœ¯é¢è¯„åˆ†
        kline_score = analyze_kline(stock_code, date)
        features['kline_score'] = kline_score
        
        # 6. æ¿å—å¼ºåº¦
        sector = get_sector(stock_code)
        sector_strength = get_sector_strength(sector, date)
        features['sector_strength'] = sector_strength
        
        # 7. é¢˜æçƒ­åº¦
        topics = get_stock_topics(stock_code, date)
        topic_heat = sum([t['heat'] for t in topics]) / len(topics) if topics else 0
        features['topic_heat'] = topic_heat
        
        # 8. æ¸¸èµ„æ”¯æŒåº¦ (å¯¹æ‰‹æ•°)
        rivals = get_rival_capitals(stock_code, date)
        features['rival_count'] = len(rivals)
        features['rival_strength'] = sum([r['strength'] for r in rivals])
        
        # 9. å…¬å¼€èˆ†è®ºåº¦
        sentiment = analyze_sentiment(stock_code, date)
        features['public_sentiment'] = sentiment
        
        # 10. èµ„é‡‘é¢æƒ…ç»ª
        market_emotion = calculate_market_emotion(date)
        features['market_emotion'] = market_emotion
        
        # 11. å†å²æˆåŠŸç‡ (è¯¥è‚¡)
        history = self.history_db.get_stock_history(stock_code)
        success_rate = len([h for h in history if h['result'] == 'success']) / len(history) if history else 0.5
        features['historical_success'] = success_rate
        
        # ä½¿ç”¨ XGBoost é¢„æµ‹
        feature_vector = self._prepare_feature_vector(features)
        probability = self.xgboost.predict_proba(feature_vector)[0][1] * 100
        
        return min(probability, 100)
    
    def predict_board_duration(self, stock_code, date):
        """
        é¢„æµ‹ä¸€å­—æ¿æŒç»­æ—¶é—´
        
        è¾“å‡º: [10:00, 11:30] (æœ€å¯èƒ½ç ´æ¿æ—¶åˆ»èŒƒå›´)
        æˆ– 'eod' (æ•´å¤©ä¸€å­—æ¿)
        """
        # ä½¿ç”¨ LSTM æ—¶é—´åºåˆ—é¢„æµ‹
        historical_durations = self.history_db.get_duration_history(stock_code, days=30)
        
        if not historical_durations:
            return '10:00-11:30'  # é»˜è®¤
        
        # è¾“å…¥: è¿‡å» 10 ä¸ªä¸€å­—æ¿çš„æŒç»­æ—¶é—´
        lstm_input = historical_durations[-10:]
        duration_pred = self.lstm.predict(lstm_input)
        
        # è½¬æ¢ä¸ºæ—¶åˆ»
        minutes_duration = int(duration_pred[0])
        start_time = 9 * 60 + 30  # 9:30 å¼€ç›˜
        end_time = start_time + minutes_duration
        
        if end_time > 15 * 60:  # 15:00
            return 'eod'  # æ•´å¤©
        
        hours = end_time // 60
        mins = end_time % 60
        return f"{hours:02d}:{mins:02d}"
    
    def predict_continuous_limits(self, stock_code, date):
        """
        é¢„æµ‹è¿æ¿æ¦‚ç‡ä¸æœ€é«˜æ¿æ•°
        
        è¾“å‡º:
        {
            '2è¿': 60%,
            '3è¿': 40%,
            '4è¿': 15%,
            '5è¿': 5%,
            'max_boards': 3
        }
        """
        # è·å–è¯¥è‚¡å†å²è¿æ¿æ•°æ®
        history = self.history_db.get_continuous_history(stock_code, days=60)
        
        # ç»Ÿè®¡åˆ†å¸ƒ
        distributions = {i: 0 for i in range(1, 6)}
        for h in history:
            board_count = min(h['consecutive_boards'], 5)
            distributions[board_count] += 1
        
        # è½¬æ¢ä¸ºæ¦‚ç‡
        total = sum(distributions.values())
        probabilities = {f"{i}è¿": (distributions[i] / total * 100) for i in range(1, 6)}
        
        # è®¡ç®—æœ€å¯èƒ½çš„æ¿æ•°
        max_boards = max(distributions, key=distributions.get)
        
        return {
            **probabilities,
            'max_boards': max_boards,
            'confidence': (max(distributions.values()) / total * 100)
        }
    
    def recommend_board_strategy(self, stock_code, date):
        """
        æ‰“æ¿æ“ä½œå»ºè®®
        
        è¾“å‡º:
        {
            'action': 'buy' / 'wait' / 'skip',
            'entry_price': 15.50,
            'stop_loss': 15.00,
            'take_profit': [16.00, 16.50],
            'risk_reward_ratio': 2.5,
            'confidence': 75,
            'reasoning': '...',
            'alerts': [...]
        }
        """
        # è®¡ç®—å„é¡¹æŒ‡æ ‡
        limit_up_prob = self.predict_limit_up_probability(stock_code, date)
        board_duration = self.predict_board_duration(stock_code, date)
        continuous_pred = self.predict_continuous_limits(stock_code, date)
        
        # è·å–å®æ—¶ä»·æ ¼
        current_price = get_current_price(stock_code, date)
        
        # å»ºè®®
        if limit_up_prob < 40:
            action = 'skip'
            confidence = 100 - limit_up_prob
        elif limit_up_prob < 60:
            action = 'wait'
            confidence = limit_up_prob
        else:
            action = 'buy'
            confidence = limit_up_prob
        
        # ä»·æ ¼å»ºè®®
        entry_price = current_price * 0.98  # é™ 2%
        stop_loss = current_price * 0.95    # æ­¢æŸ 5%
        take_profit_1 = current_price * 1.05  # ç›®æ ‡ 1: +5%
        take_profit_2 = current_price * 1.10  # ç›®æ ‡ 2: +10%
        
        risk = current_price - stop_loss
        reward = (take_profit_1 - entry_price + take_profit_2 - entry_price) / 2
        risk_reward_ratio = reward / risk if risk > 0 else 0
        
        # é£é™©å‘Šè­¦
        alerts = []
        if continuous_pred['confidence'] < 50:
            alerts.append('è¿æ¿æ¦‚ç‡ä¸ç¡®å®š')
        if board_duration == 'eod':
            alerts.append('å¯èƒ½å…¨å¤©ä¸€å­—æ¿ï¼Œé£é™©å¤§')
        if limit_up_prob > 85:
            alerts.append('æ¦‚ç‡è¿‡é«˜ï¼Œè°¨é˜²è™šå‡ä¿¡å·')
        
        return {
            'action': action,
            'entry_price': entry_price,
            'stop_loss': stop_loss,
            'take_profit': [take_profit_1, take_profit_2],
            'risk_reward_ratio': risk_reward_ratio,
            'confidence': confidence,
            'reasoning': self._generate_reasoning(limit_up_prob, continuous_pred),
            'alerts': alerts
        }
```

**ç²¾å‡†åº¦ç›®æ ‡**: 70-80% (ä¸€å­—æ¿é¢„æµ‹)  
**æ€§èƒ½ç›®æ ‡**: <0.1s (å•ä¸ªé¢„æµ‹)

---

## ğŸ“‹ å®Œæ•´å¼€å‘è®¡åˆ’

### Phase 1: åŸºç¡€æ¶æ„æ­å»º (ç¬¬ 1-2 å‘¨)

**å‘¨æœŸ**: 2026-01-07 ~ 2026-01-20  
**å·¥ä½œé‡**: 300+ è¡Œä»£ç 

#### ä»»åŠ¡åˆ†è§£

1. **æ¿å—æ•°æ®é›†æˆ** (100 è¡Œ)
   - [ ] å®ç° `SectorDataLoader` ç±»
   - [ ] é›†æˆ akshare æ¿å—æ¥å£
   - [ ] æœ¬åœ° SQLite ç¼“å­˜
   - [ ] å•å…ƒæµ‹è¯• (3 ä¸ª)

2. **é¢˜ææ•°æ®çˆ¬å–** (150 è¡Œ)
   - [ ] å®ç° `TopicCrawler` ç±»
   - [ ] é›†æˆæ–°é—» API (æ–°æµªã€ç½‘æ˜“ã€è…¾è®¯)
   - [ ] NLP åˆ†è¯ä¸å…³é”®è¯æå–
   - [ ] å•å…ƒæµ‹è¯• (3 ä¸ª)

3. **åˆ†é’Ÿçº§ K çº¿æ¥å£** (100 è¡Œ)
   - [ ] å®ç° `MinuteKlineLoader` ç±»
   - [ ] é›†åˆç«ä»·æ•°æ®è·å–
   - [ ] é«˜æ•ˆç¼“å­˜æœºåˆ¶
   - [ ] å•å…ƒæµ‹è¯• (2 ä¸ª)

### Phase 2: æ ¸å¿ƒç®—æ³•å®ç° (ç¬¬ 2-4 å‘¨)

**å‘¨æœŸ**: 2026-01-14 ~ 2026-02-03  
**å·¥ä½œé‡**: 900+ è¡Œä»£ç 

#### ä»»åŠ¡åˆ†è§£

1. **æ¿å—è½®åŠ¨æ¨¡å—** (300 è¡Œ)
   - [ ] å®Œæ•´å®ç° `SectorRotationAnalyzer` ç±»
   - [ ] æ¿å—å¼ºåº¦è®¡ç®—å‡½æ•°
   - [ ] è½®åŠ¨ä¿¡å·æ£€æµ‹å‡½æ•°
   - [ ] LSTM è¶‹åŠ¿é¢„æµ‹
   - [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•
   - [ ] å•å…ƒæµ‹è¯• (5 ä¸ª)

2. **é¢˜ææå–æ¨¡å—** (300 è¡Œ)
   - [ ] å®Œæ•´å®ç° `HotTopicExtractor` ç±»
   - [ ] æ–°é—»çˆ¬å–å’Œé¢„å¤„ç†
   - [ ] é¢˜æåˆ†ç±»ç®—æ³•
   - [ ] é¢˜æ-è‚¡ç¥¨æ˜ å°„
   - [ ] ç”Ÿå‘½å‘¨æœŸè®¡ç®—
   - [ ] å•å…ƒæµ‹è¯• (5 ä¸ª)

3. **æ‰“æ¿é¢„æµ‹æ¨¡å—** (300 è¡Œ)
   - [ ] å®Œæ•´å®ç° `LimitUpPredictor` ç±»
   - [ ] XGBoost ç‰¹å¾å·¥ç¨‹
   - [ ] LSTM æ—¶é—´åºåˆ—é¢„æµ‹
   - [ ] æ“ä½œå»ºè®®ç®—æ³•
   - [ ] é£é™©å‘Šè­¦ç³»ç»Ÿ
   - [ ] å•å…ƒæµ‹è¯• (5 ä¸ª)

### Phase 3: å‰ç«¯é›†æˆ (ç¬¬ 4-5 å‘¨)

**å‘¨æœŸ**: 2026-01-28 ~ 2026-02-10  
**å·¥ä½œé‡**: 400+ è¡Œä»£ç 

#### ä»»åŠ¡åˆ†è§£

1. **Streamlit UI é¡µé¢** (200 è¡Œ)
   - [ ] Tab 1: æ¿å—è½®åŠ¨ä»ªè¡¨æ¿
   - [ ] Tab 2: çƒ­ç‚¹é¢˜æè¿½è¸ª
   - [ ] Tab 3: æ‰“æ¿é¢„æµ‹ä¸­å¿ƒ
   - [ ] å“åº”å¼å¸ƒå±€
   - [ ] æ•°æ®å®æ—¶åˆ·æ–°

2. **äº¤äº’åŠŸèƒ½** (200 è¡Œ)
   - [ ] å‚æ•°è°ƒèŠ‚æ»‘å—
   - [ ] å›¾è¡¨äº¤äº’
   - [ ] æ•°æ®å¯¼å‡º
   - [ ] è­¦æŠ¥è®¾ç½®
   - [ ] å†å²å›æµ‹

### Phase 4: æµ‹è¯•ä¸éªŒè¯ (ç¬¬ 5-6 å‘¨)

**å‘¨æœŸ**: 2026-02-03 ~ 2026-02-17  
**å·¥ä½œé‡**: 200+ è¡Œæµ‹è¯•ä»£ç 

#### ä»»åŠ¡åˆ†è§£

1. **å•å…ƒæµ‹è¯•** (100 è¡Œ)
   - [ ] æ¨¡å— 1: 20 ä¸ªæµ‹è¯•ç”¨ä¾‹
   - [ ] æ¨¡å— 2: 20 ä¸ªæµ‹è¯•ç”¨ä¾‹
   - [ ] æ¨¡å— 3: 15 ä¸ªæµ‹è¯•ç”¨ä¾‹
   - [ ] è¦†ç›–ç‡: >85%

2. **é›†æˆæµ‹è¯•** (50 è¡Œ)
   - [ ] ç«¯åˆ°ç«¯æ•°æ®æµ
   - [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•
   - [ ] å‹åŠ›æµ‹è¯•

3. **å›æµ‹éªŒè¯** (50 è¡Œ)
   - [ ] å†å²æ•°æ®å›æµ‹
   - [ ] ç²¾å‡†åº¦è¯„ä¼°
   - [ ] å¤æ™®æ¯”ç‡è®¡ç®—

### Phase 5: æ–‡æ¡£ä¸ä¼˜åŒ– (ç¬¬ 6 å‘¨)

**å‘¨æœŸ**: 2026-02-10 ~ 2026-02-24  
**å·¥ä½œé‡**: 300+ è¡Œæ–‡æ¡£

#### ä»»åŠ¡åˆ†è§£

1. **æŠ€æœ¯æ–‡æ¡£** (150 è¡Œ)
   - [ ] API æ–‡æ¡£
   - [ ] ç®—æ³•è®¾è®¡æ–‡æ¡£
   - [ ] é›†æˆæŒ‡å—

2. **ç”¨æˆ·æŒ‡å—** (100 è¡Œ)
   - [ ] åŠŸèƒ½ä½¿ç”¨è¯´æ˜
   - [ ] å‚æ•°è°ƒèŠ‚æŒ‡å—
   - [ ] æœ€ä½³å®è·µ

3. **æ€§èƒ½ä¼˜åŒ–** (50 è¡Œä»£ç  + æ–‡æ¡£)
   - [ ] æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–
   - [ ] ç¼“å­˜å±‚ä¼˜åŒ–
   - [ ] å¼‚æ­¥å¤„ç†ä¼˜åŒ–

---

## ğŸ¯ æ–°å¢åŠŸèƒ½ä¸ç°æœ‰åŠŸèƒ½çš„æ•´åˆ

### æ•´åˆæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        MyQuantTool v4 å®Œæ•´ç³»ç»Ÿ           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æ•°æ®å±‚                                  â”‚
â”‚  â”œâ”€ é¾™è™æ¦œæ•°æ® (æ¸¸èµ„åˆ†æ)               â”‚
â”‚  â”œâ”€ Kçº¿æ•°æ® (æŠ€æœ¯åˆ†æ)                  â”‚
â”‚  â”œâ”€ æ¿å—æ•°æ® â­ NEW                     â”‚
â”‚  â”œâ”€ é¢˜ææ•°æ® â­ NEW                     â”‚
â”‚  â””â”€ åˆ†é’Ÿæ•°æ® â­ NEW                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  åˆ†æå±‚                                  â”‚
â”‚  â”œâ”€ æ¸¸èµ„ç½‘ç»œåˆ†æ                        â”‚
â”‚  â”œâ”€ å¤šå› å­èåˆ                          â”‚
â”‚  â”œâ”€ é¾™å¤´è¯†åˆ«                            â”‚
â”‚  â”œâ”€ æ¿å—è½®åŠ¨ â­ NEW                     â”‚
â”‚  â”œâ”€ çƒ­ç‚¹é¢˜æ â­ NEW                     â”‚
â”‚  â””â”€ æ‰“æ¿é¢„æµ‹ â­ NEW                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  èåˆå±‚ (ç»¼åˆå†³ç­–)                      â”‚
â”‚  â”œâ”€ å¤šæºä¿¡å·èåˆ                        â”‚
â”‚  â”œâ”€ å†³ç­–æ”¯æŒç³»ç»Ÿ                        â”‚
â”‚  â”œâ”€ é£é™©ç®¡ç†ç³»ç»Ÿ                        â”‚
â”‚  â””â”€ æ”¶ç›Šä¼˜åŒ–ç³»ç»Ÿ                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  è¾“å‡ºå±‚                                  â”‚
â”‚  â”œâ”€ Streamlit UI ä»ªè¡¨æ¿                â”‚
â”‚  â”œâ”€ é‚®ä»¶å‘Šè­¦                            â”‚
â”‚  â”œâ”€ Webhook æ¨é€                       â”‚
â”‚  â””â”€ æ•°æ®å¯¼å‡º                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### èåˆç‚¹

1. **æ¿å—è½®åŠ¨ + æ¸¸èµ„ç½‘ç»œ**
   ```
   æ¿å—å¼ºåŠ¿ â†’ æ¸¸èµ„åœ¨è¯¥æ¿å—çš„æ´»è·ƒåº¦ â†’ é¾™å¤´è‚¡é€‰æ‹©
   ```

2. **çƒ­ç‚¹é¢˜æ + å¤šå› å­èåˆ**
   ```
   é¢˜æçƒ­åº¦ â†’ åŠ å…¥å¤šå› å­æ¨¡å‹ (æƒé‡ 20%) â†’ å†³ç­–ä¿¡å·
   ```

3. **æ‰“æ¿é¢„æµ‹ + é¾™å¤´è¯†åˆ«**
   ```
   é¾™å¤´è‚¡ + æ‰“æ¿å†å² â†’ ä¸€å­—æ¿æ¦‚ç‡é¢„æµ‹ â†’ æ“ä½œå»ºè®®
   ```

---

## ğŸ“Š é¢„æœŸæ•ˆæœ

### v4 å®Œæ•´ç‰ˆæ€§èƒ½æŒ‡æ ‡

| åŠŸèƒ½ | ç²¾å‡†åº¦ | é€Ÿåº¦ | ä¼˜åŠ¿ |
|------|--------|------|------|
| æ¿å—è½®åŠ¨ | 65-75% | <1s | æå‰å‘ç°æ¿å—åˆ‡æ¢ |
| çƒ­ç‚¹é¢˜æ | 65-75% | 2-3s | æŒ–æ˜çƒ­ç‚¹é¾™å¤´ |
| æ‰“æ¿é¢„æµ‹ | 70-80% | <0.1s | ä¸€å­—æ¿æ¦‚ç‡æœ€é«˜ |
| **ç»¼åˆç³»ç»Ÿ** | **75-85%** | **<2s** | **å…¨æ–¹ä½åˆ†æ** |

### v3 vs v4 å¯¹æ¯”

| æŒ‡æ ‡ | v3 | v4 | æå‡ |
|------|-----|-----|------|
| åˆ†æç»´åº¦ | 3 ä¸ª | 6 ä¸ª | +100% |
| ç²¾å‡†åº¦ | 70-80% | 75-85% | +5-10% |
| ä»£ç è¡Œæ•° | 5,500+ | 8,500+ | +3,000 |
| æ¨¡å—æ•° | 10 ä¸ª | 16 ä¸ª | +6 |
| æ–‡æ¡£è¡Œæ•° | 1,000+ | 1,500+ | +500 |
| ç”¨æˆ·ä½“éªŒ | 3 ä¸ª Tab | 8 ä¸ª Tab | +5 |

---

## ğŸ’¡ é«˜çº§åŠŸèƒ½æ‰©å±• (v4.5+)

å¦‚æœ v4 å¼€å‘é¡ºåˆ©ï¼Œå¯ç»§ç»­æ‰©å±•:

1. **GPU åŠ é€Ÿ** (æ€§èƒ½ â†‘ 10 å€)
   - ä½¿ç”¨ CUDA åŠ é€Ÿ LSTM æ¨¡å‹
   - æ‰¹é‡æ•°æ®å¤„ç†ä¼˜åŒ–

2. **åˆ†å¸ƒå¼éƒ¨ç½²**
   - Redis ç¼“å­˜å±‚
   - å¾®æœåŠ¡æ¶æ„
   - å®æ—¶æµæ•°æ®å¤„ç†

3. **AI æ™ºèƒ½æ¨è**
   - ä¸ªæ€§åŒ–æ¨èç®—æ³•
   - ç”¨æˆ·è¡Œä¸ºå­¦ä¹ 
   - è‡ªé€‚åº”å‚æ•°è°ƒèŠ‚

4. **å®æ—¶è¡Œæƒ…å¯¹æ¥**
   - WebSocket è¿æ¥
   - æ¯«ç§’çº§æ›´æ–°
   - æœŸè´§è¡Œæƒ…æ”¯æŒ

---

## ğŸ æ€»ç»“

### v4 å¼€å‘ç›®æ ‡

âœ… **æ–°å¢ 3 å¤§æ ¸å¿ƒåŠŸèƒ½** (æ¿å—è½®åŠ¨ã€çƒ­ç‚¹é¢˜æã€æ‰“æ¿é¢„æµ‹)  
âœ… **ç²¾å‡†åº¦æå‡ 5-10%** (75-85%)  
âœ… **ä»£ç è§„æ¨¡ â†‘ 55%** (5,500 â†’ 8,500+ è¡Œ)  
âœ… **è¦†ç›–èŒƒå›´ç¿»å€** (3D â†’ 6D åˆ†æ)  
âœ… **ç”¨æˆ·ä½“éªŒä¼˜åŒ–** (3 Tab â†’ 8 Tab)  

### é¢„æœŸäº¤ä»˜æ—¶é—´

**2026 å¹´ 2 æœˆä¸­æ—¬** (çº¦ 6 å‘¨å¼€å‘å‘¨æœŸ)

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. âœ… ç¡®è®¤å¼€å‘è®¡åˆ’
2. âœ… åˆ†é…å¼€å‘ä»»åŠ¡
3. âœ… å»ºç«‹ git åˆ†æ”¯
4. âœ… å¯åŠ¨ Phase 1 å¼€å‘

---

**æ–‡æ¡£å®Œæˆ**: 2026-01-07  
**ä¸‹æ¬¡æ›´æ–°**: 2026-01-14 (ç¬¬ 1 å‘¨è¿›åº¦æ±‡æ€»)  
**ç»´æŠ¤è€…**: MyQuantTool Team
