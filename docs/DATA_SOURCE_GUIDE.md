# ğŸ“Š çœŸå®é¾™è™æ¦œæ•°æ®è·å–æŒ‡å—

## ä¸€ã€akshare é¾™è™æ¦œæ•°æ®æºï¼ˆæ¨è â­â­â­â­â­ï¼‰

### 1.1 åŸºç¡€é¾™è™æ¦œæ•°æ®

```python
import akshare as ak
import pandas as pd
from datetime import datetime, timedelta

def get_lhb_data(date_str: str):
    """
    è·å–æŒ‡å®šæ—¥æœŸçš„é¾™è™æ¦œæ—¥æ•°æ®
    
    Args:
        date_str: æ—¥æœŸå­—ç¬¦ä¸²ï¼Œæ ¼å¼ 'YYYY-MM-DD'
    
    Returns:
        DataFrame: é¾™è™æ¦œæ•°æ®
        
    åˆ—å­—æ®µ:
        - æ’å: æ’åä½ç½®
        - ä»£ç : è‚¡ç¥¨ä»£ç 
        - åç§°: è‚¡ç¥¨åç§°
        - æœ€æ–°ä»·: å½“å‰è‚¡ä»·
        - æ¶¨è·Œå¹…: æ¶¨è·Œå¹…ç™¾åˆ†æ¯”
        - æˆäº¤é¢: é¾™è™æ¦œæˆäº¤é¢ï¼ˆä¸‡å…ƒï¼‰
        - æˆäº¤é‡: é¾™è™æ¦œæˆäº¤é‡ï¼ˆä¸‡è‚¡ï¼‰
        - æ¸¸èµ„åç§°: ä¸Šæ¦œæ¸¸èµ„åç§°
        - æ“ä½œæ–¹å‘: 'ä¹°' / 'å–'
    """
    try:
        df = ak.stock_lgb_daily(date=date_str)
        return df
    except Exception as e:
        print(f"è·å– {date_str} é¾™è™æ¦œå¤±è´¥: {str(e)}")
        return None


# ä½¿ç”¨ç¤ºä¾‹
today = datetime.now().strftime('%Y-%m-%d')
df_lhb = get_lhb_data(today)

if df_lhb is not None:
    print(f"è·å–äº† {len(df_lhb)} æ¡é¾™è™æ¦œè®°å½•")
    print(df_lhb.head())
```

### 1.2 æ‰¹é‡è·å–å†å²é¾™è™æ¦œæ•°æ®

```python
def get_lhb_history(
    start_date: str,
    end_date: str,
    skip_holidays: bool = True
) -> pd.DataFrame:
    """
    æ‰¹é‡è·å–é¾™è™æ¦œå†å²æ•°æ®
    
    Args:
        start_date: å¼€å§‹æ—¥æœŸ 'YYYY-MM-DD'
        end_date: ç»“æŸæ—¥æœŸ 'YYYY-MM-DD'
        skip_holidays: æ˜¯å¦è·³è¿‡èŠ‚å‡æ—¥å’Œå‘¨æœ«
    
    Returns:
        åˆå¹¶åçš„ DataFrame
    """
    from datetime import datetime, timedelta
    
    start = datetime.strptime(start_date, '%Y-%m-%d')
    end = datetime.strptime(end_date, '%Y-%m-%d')
    
    all_data = []
    current = start
    
    while current <= end:
        # è·³è¿‡å‘¨æœ«
        if skip_holidays and current.weekday() >= 5:
            current += timedelta(days=1)
            continue
        
        date_str = current.strftime('%Y-%m-%d')
        print(f"æ­£åœ¨è·å– {date_str}...")
        
        df = get_lhb_data(date_str)
        if df is not None and len(df) > 0:
            df['date'] = date_str
            all_data.append(df)
        
        current += timedelta(days=1)
    
    if all_data:
        result = pd.concat(all_data, ignore_index=True)
        return result
    else:
        return pd.DataFrame()


# ä½¿ç”¨ç¤ºä¾‹
start = '2025-12-01'
end = '2026-01-07'

df_history = get_lhb_history(start, end)
print(f"è·å–äº† {len(df_history)} æ¡å†å²è®°å½•")

# ä¿å­˜ä¸º CSVï¼ˆç¼“å­˜åŠ é€Ÿåç»­åˆ†æï¼‰
df_history.to_csv('data/lhb_history.csv', index=False, encoding='utf-8')
```

### 1.3 è·å–é¾™è™æ¦œè¯¦æƒ…ï¼ˆæ¸¸èµ„è¯¦ç»†å¯¹æ‰‹ï¼‰

```python
def get_lhb_detail(
    stock_code: str,
    date_str: str
) -> pd.DataFrame:
    """
    è·å–å•åªè‚¡ç¥¨çš„é¾™è™æ¦œè¯¦ç»†å¯¹æ‰‹ä¿¡æ¯
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç ï¼Œä¾‹å¦‚ '000001'
        date_str: æ—¥æœŸ 'YYYY-MM-DD'
    
    Returns:
        è¯¥è‚¡ç¥¨åœ¨è¯¥æ—¥æœŸçš„æ‰€æœ‰ä¸Šæ¦œæ¸¸èµ„è¯¦æƒ…
    """
    try:
        df = ak.stock_lgb_detail(code=stock_code, date=date_str)
        return df
    except Exception as e:
        print(f"è·å– {stock_code} è¯¦æƒ…å¤±è´¥: {str(e)}")
        return None


# ä½¿ç”¨ç¤ºä¾‹
df_detail = get_lhb_detail('000001', '2026-01-07')
if df_detail is not None:
    print(f"è·å–äº† {len(df_detail)} ä¸ªæ¸¸èµ„çš„è¯¦æƒ…")
```

---

## äºŒã€å…¶ä»–æ•°æ®æºå¯¹æ¯”

### 2.1 ä¸œæ–¹è´¢å¯Œ APIï¼ˆæœ‰é™åˆ¶ï¼‰

```python
# ç½‘é¡µçˆ¬è™«æ–¹å¼ï¼ˆæ˜“è¢«åçˆ¬è™«å°æ€ï¼‰
import requests
from bs4 import BeautifulSoup

def get_lhb_from_eastmoney(date_str: str):
    """
    ä»ä¸œæ–¹è´¢å¯Œçˆ¬é¾™è™æ¦œï¼ˆä¸æ¨èï¼‰
    ç¼ºç‚¹ï¼š
    - å®¹æ˜“è¢«åçˆ¬è™«å°ç¦
    - é€Ÿåº¦æ…¢
    - æ•°æ®è§£æå¤æ‚
    """
    url = f"http://vip.stock.finance.sina.com.cn/q/go.php/vInvestConsult/kind/xjl/index.phtml?symbol=sz000001&date={date_str}"
    # ... å¤æ‚çˆ¬è™«é€»è¾‘
    pass
```

### 2.2 æ–°æµªè´¢ç»é¾™è™æ¦œï¼ˆè¿‡æ—¶ï¼‰

```python
# å·²åœæ­¢æ›´æ–°ï¼Œä¸æ¨è
def get_lhb_from_sina(date_str: str):
    """
    æ–°æµªé¾™è™æ¦œæ¥å£å·²å…³é—­ï¼ˆ2023å¹´+ï¼‰
    æ”¹ç”¨ akshare
    """
    pass
```

### 2.3 Wind æ•°æ®åº“ï¼ˆå•†ä¸šç‰ˆï¼‰

```python
# éœ€è¦ä»˜è´¹è®¢é˜…
from windpy import w

def get_lhb_from_wind(date_str: str):
    """
    Wind æ•°æ®åº“ï¼ˆé‡‘èæœºæ„ä¸“ç”¨ï¼‰
    
    ä¼˜ç‚¹ï¼š
    - æ•°æ®æœ€å‡†ç¡®ã€æ›´æ–°æœ€å¿«
    - æ”¯æŒé«˜é¢‘æŸ¥è¯¢
    
    ç¼ºç‚¹ï¼š
    - éœ€è¦ä»˜è´¹ï¼ˆâ‰¥5000å…ƒ/å¹´ï¼‰
    - ä»…ä¾›æœºæ„ç”¨æˆ·
    
    æ¨èï¼šä¸ªäºº/å°è§„æ¨¡å›¢é˜Ÿä¸æ¨è
    """
    pass
```

---

## ä¸‰ã€æœ¬åœ°ç¼“å­˜ç­–ç•¥ï¼ˆåŠ é€Ÿå¼€å‘ï¼‰

### 3.1 CSV ç¼“å­˜

```python
import os
import pandas as pd
from datetime import datetime

def load_or_fetch_lhb(
    date_str: str,
    cache_dir: str = 'data/cache'
) -> pd.DataFrame:
    """
    ä¼˜å…ˆä»æœ¬åœ°ç¼“å­˜è¯»å–ï¼Œç¼“å­˜ä¸å­˜åœ¨æ—¶å®æ—¶è·å–
    """
    os.makedirs(cache_dir, exist_ok=True)
    cache_path = f"{cache_dir}/lhb_{date_str}.csv"
    
    # å…ˆæŸ¥ç¼“å­˜
    if os.path.exists(cache_path):
        print(f"âœ… ä»ç¼“å­˜è¯»å–: {cache_path}")
        return pd.read_csv(cache_path)
    
    # å®æ—¶è·å–
    print(f"ğŸ”„ å®æ—¶è·å–: {date_str}")
    df = get_lhb_data(date_str)
    
    if df is not None and len(df) > 0:
        df.to_csv(cache_path, index=False, encoding='utf-8')
        print(f"ğŸ’¾ ç¼“å­˜ä¿å­˜: {cache_path}")
    
    return df


# ä½¿ç”¨ç¤ºä¾‹
df = load_or_fetch_lhb('2026-01-07')
```

### 3.2 SQLite æœ¬åœ°æ•°æ®åº“

```python
import sqlite3
from datetime import datetime

class LHBDatabase:
    def __init__(self, db_path: str = 'data/lhb.db'):
        self.db_path = db_path
        self._init_db()
    
    def _init_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS lhb (
                    id INTEGER PRIMARY KEY,
                    date TEXT NOT NULL,
                    code TEXT NOT NULL,
                    name TEXT,
                    capital_name TEXT,
                    direction TEXT,  -- 'ä¹°' æˆ– 'å–'
                    amount REAL,  -- æˆäº¤é¢ï¼ˆä¸‡å…ƒï¼‰
                    price REAL,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(date, code, capital_name, direction)
                )
            """)
            
            conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_date_code 
                ON lhb(date, code)
            """)
            
            conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_capital 
                ON lhb(capital_name)
            """)
    
    def insert_batch(self, df: pd.DataFrame):
        """æ‰¹é‡æ’å…¥é¾™è™æ¦œæ•°æ®"""
        with sqlite3.connect(self.db_path) as conn:
            df.to_sql('lhb', conn, if_exists='append', index=False)
    
    def query_by_date(self, date_str: str) -> pd.DataFrame:
        """æŸ¥è¯¢æŒ‡å®šæ—¥æœŸçš„é¾™è™æ¦œ"""
        with sqlite3.connect(self.db_path) as conn:
            query = f"""
                SELECT * FROM lhb 
                WHERE date = '{date_str}'
                ORDER BY amount DESC
            """
            return pd.read_sql(query, conn)
    
    def query_by_capital(self, capital_name: str, days: int = 30) -> pd.DataFrame:
        """æŸ¥è¯¢æ¸¸èµ„è¿‘Nå¤©çš„æ“ä½œ"""
        with sqlite3.connect(self.db_path) as conn:
            query = f"""
                SELECT * FROM lhb 
                WHERE capital_name = '{capital_name}'
                AND date >= date('now', '-{days} days')
                ORDER BY date DESC
            """
            return pd.read_sql(query, conn)
    
    def get_capital_pairs(self, days: int = 30):
        """è·å–å¸¸è§å¯¹æ‰‹æ¸¸èµ„å¯¹"""
        with sqlite3.connect(self.db_path) as conn:
            query = f"""
                SELECT 
                    c1.capital_name as capital_a,
                    c2.capital_name as capital_b,
                    COUNT(*) as battle_count
                FROM lhb c1
                JOIN lhb c2 ON c1.code = c2.code 
                    AND c1.date = c2.date
                    AND c1.direction != c2.direction
                    AND c1.date >= date('now', '-{days} days')
                WHERE c1.capital_name < c2.capital_name
                GROUP BY c1.capital_name, c2.capital_name
                ORDER BY battle_count DESC
                LIMIT 50
            """
            return pd.read_sql(query, conn)


# ä½¿ç”¨ç¤ºä¾‹
db = LHBDatabase()

# æ’å…¥æ•°æ®
df_history = get_lhb_history('2025-12-01', '2026-01-07')
db.insert_batch(df_history)

# æŸ¥è¯¢æŒ‡å®šæ—¥æœŸ
df_today = db.query_by_date('2026-01-07')
print(f"ä»Šæ—¥ä¸Šæ¦œ {len(df_today)} æ¡")

# æŸ¥è¯¢æ¸¸èµ„è¿‘30å¤©æ“ä½œ
df_capital = db.query_by_capital('ä¸­æ³°è¯åˆ¸æ­å·åº†æ˜¥è·¯è¥ä¸šéƒ¨', days=30)
print(f"è¯¥æ¸¸èµ„è¿‘30å¤©ä¸Šæ¦œ {len(df_capital)} æ¬¡")

# è·å–å¸¸è§å¯¹æ‰‹å¯¹
df_pairs = db.get_capital_pairs(days=30)
print("å¸¸è§å¯¹æ‰‹é…å¯¹:")
print(df_pairs.head())
```

---

## å››ã€æ•°æ®é¢„å¤„ç†ï¼ˆæ¥å…¥ MyQuantToolï¼‰

### 4.1 æ ‡å‡†åŒ–æ•°æ®æ ¼å¼

```python
def preprocess_lhb_data(df_raw: pd.DataFrame) -> pd.DataFrame:
    """
    é¢„å¤„ç†é¾™è™æ¦œåŸå§‹æ•°æ®ï¼Œè½¬æ¢ä¸º MyQuantTool æ ‡å‡†æ ¼å¼
    """
    df = df_raw.copy()
    
    # åˆ—é‡å‘½å
    rename_map = {
        'ä»£ç ': 'stock_code',
        'åç§°': 'stock_name',
        'æ¸¸èµ„åç§°': 'capital_name',
        'æ“ä½œæ–¹å‘': 'direction',
        'æˆäº¤é¢': 'amount',  # å•ä½ï¼šä¸‡å…ƒ
        'æœ€æ–°ä»·': 'price',
        'date': 'trade_date'
    }
    df.rename(columns=rename_map, inplace=True)
    
    # æ•°æ®ç±»å‹è½¬æ¢
    df['amount'] = pd.to_numeric(df['amount'], errors='coerce')
    df['price'] = pd.to_numeric(df['price'], errors='coerce')
    df['trade_date'] = pd.to_datetime(df['trade_date'])
    
    # æ ‡å‡†åŒ–æ–¹å‘ï¼ˆ'ä¹°' â†’ 1, 'å–' â†’ -1ï¼‰
    df['direction_code'] = df['direction'].map({'ä¹°': 1, 'å–': -1})
    
    # ç§»é™¤ç¼ºå¤±å€¼
    df.dropna(subset=['stock_code', 'capital_name', 'amount'], inplace=True)
    
    # æŒ‰æ—¥æœŸæ’åº
    df.sort_values('trade_date', inplace=True)
    
    return df


# ä½¿ç”¨ç¤ºä¾‹
df_processed = preprocess_lhb_data(df_history)
print(df_processed.head())
```

### 4.2 ç›´æ¥é›†æˆåˆ° CapitalNetworkBuilder

```python
from logic.capital_network import CapitalNetworkBuilder

# åŠ è½½é¾™è™æ¦œæ•°æ®
db = LHBDatabase()
df_lhb = db.query_by_date('2026-01-07')
df_lhb = preprocess_lhb_data(df_lhb)

# æ„å»ºç½‘ç»œ
builder = CapitalNetworkBuilder(lookback_days=30)
G = builder.build_graph_from_lhb(df_lhb, include_competitive=True)

# åˆ†æ
node_metrics = builder.calculate_node_metrics()
competitive = builder.analyze_competitive_landscape(df_lhb)
clusters = builder.get_capital_clusters(k=3)

print(f"âœ… ç½‘ç»œæ„å»ºæˆåŠŸ: {G.number_of_nodes()} èŠ‚ç‚¹, {G.number_of_edges()} è¾¹")
```

---

## äº”ã€å®Œæ•´é›†æˆè„šæœ¬

### 5.1 æ—¥å¸¸è‡ªåŠ¨æ›´æ–°è„šæœ¬

```python
#!/usr/bin/env python3
# update_lhb_daily.py

import logging
from datetime import datetime
from data_loader import LHBDatabase, get_lhb_data, preprocess_lhb_data

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def update_daily():
    """
    æ¯æ—¥æ›´æ–°é¾™è™æ¦œæ•°æ®ï¼ˆå»ºè®®åœ¨æ”¶ç›˜å 15:30 è¿è¡Œï¼‰
    """
    db = LHBDatabase()
    
    today = datetime.now().strftime('%Y-%m-%d')
    logger.info(f"ğŸ”„ æ­£åœ¨æ›´æ–° {today} é¾™è™æ¦œ...")
    
    try:
        # è·å–ä»Šæ—¥æ•°æ®
        df_today = get_lhb_data(today)
        
        if df_today is None or len(df_today) == 0:
            logger.warning(f"âŒ {today} æ— é¾™è™æ¦œæ•°æ®ï¼ˆå¯èƒ½æ˜¯å‘¨æœ«æˆ–èŠ‚å‡æ—¥ï¼‰")
            return
        
        # é¢„å¤„ç†
        df_processed = preprocess_lhb_data(df_today)
        
        # å…¥åº“
        db.insert_batch(df_processed)
        logger.info(f"âœ… æˆåŠŸæ’å…¥ {len(df_processed)} æ¡è®°å½•")
        
        # ç»Ÿè®¡
        capitals = df_processed['capital_name'].nunique()
        stocks = df_processed['stock_code'].nunique()
        logger.info(f"ğŸ“Š ä»Šæ—¥: {stocks} åªè‚¡ç¥¨, {capitals} ä¸ªæ¸¸èµ„")
        
    except Exception as e:
        logger.error(f"âŒ æ›´æ–°å¤±è´¥: {str(e)}")


if __name__ == '__main__':
    update_daily()
```

### 5.2 å®šæ—¶ä»»åŠ¡ï¼ˆcron/Windowsä»»åŠ¡è®¡åˆ’ï¼‰

```bash
# Linux crontab -e
# æ¯å¤© 15:35 è‡ªåŠ¨æ›´æ–°ï¼ˆAè‚¡æ”¶ç›˜15:00ï¼‰
35 15 * * 1-5 /usr/bin/python3 /path/to/update_lhb_daily.py

# Windows Task Scheduler
# ä»»åŠ¡ï¼šæ¯å·¥ä½œæ—¥ 15:35 è¿è¡Œ python update_lhb_daily.py
```

---

## å…­ã€æ¨èæ•°æ®è·å–æµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  akshare å®æ—¶è·å–            â”‚
â”‚  (stock_lgb_daily)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æœ¬åœ° SQLite æ•°æ®åº“å…¥åº“       â”‚
â”‚  (ç¼“å­˜ + ç´¢å¼•ä¼˜åŒ–)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ•°æ®é¢„å¤„ç†å’Œæ ‡å‡†åŒ–           â”‚
â”‚  (åˆ—é‡å‘½å + ç±»å‹è½¬æ¢)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  è¾“å…¥ MyQuantTool å„æ¨¡å—      â”‚
â”‚  (ç½‘ç»œåˆ†æ + LSTM + èåˆ)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ä¸ƒã€å¸¸è§é—®é¢˜ (FAQ)

### Q1: akshare æ›´æ–°é¢‘ç‡æ˜¯å¤šå°‘ï¼Ÿ
**A**: æ¯å¤© 16:00 åæ›´æ–°å‰ä¸€äº¤æ˜“æ—¥æ•°æ®ï¼Œä¸å®˜æ–¹åŒæ­¥ã€‚

### Q2: å¦‚ä½•è·å–å†å²æ•°æ®ï¼ˆå¦‚2å¹´å‰ï¼‰ï¼Ÿ
**A**: `get_lhb_history()` å¯æ‰¹é‡è·å–ï¼Œä½†éœ€è¦ç­‰å¾…ç½‘ç»œè¯·æ±‚ï¼ˆå»ºè®®ç”¨ç¼“å­˜ï¼‰ã€‚

### Q3: æ•°æ®æœ‰æ—¶ç¼ºå¤±æ€ä¹ˆåŠï¼Ÿ
**A**: akshare ä¾èµ–å®˜æ–¹æ•°æ®æºï¼Œå¶å°”ä¼šæœ‰å»¶è¿Ÿã€‚å»ºè®®ç”¨ `try-except` + é‡è¯•æœºåˆ¶ã€‚

### Q4: èƒ½å¦æœ¬åœ°å­˜å‚¨æ‰€æœ‰å†å²é¾™è™æ¦œï¼Ÿ
**A**: å¯ä»¥ï¼Œç”¨ SQLite æ•°æ®åº“ï¼Œå»ºè®®æ¯å‘¨å¤‡ä»½åˆ° CSV/Parquetã€‚

### Q5: æ¸¸èµ„åç§°æœ‰æ—¶ä¸ä¸€è‡´æ€ä¹ˆåŠï¼Ÿ
**A**: å»ºè®®ç»´æŠ¤ä¸€ä¸ªã€Œæ¸¸èµ„åˆ«åæ˜ å°„è¡¨ã€ï¼Œç”¨ `replace()` ç»Ÿä¸€åç§°ã€‚
