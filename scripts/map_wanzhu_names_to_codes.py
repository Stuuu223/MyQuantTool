"""
é¡½ä¸»æ¯è‚¡ç¥¨åç§°åˆ°ä»£ç æ˜ å°„è¡¥å…¨å·¥å…·

ä½¿ç”¨akshareæ ¹æ®åç§°æ¨¡ç³ŠåŒ¹é…è‚¡ç¥¨ä»£ç 
"""
import pandas as pd
import akshare as ak
from pathlib import Path
import json
from typing import Dict, Optional

def load_unmapped_stocks(csv_path: Path) -> pd.DataFrame:
    """åŠ è½½æœªæ˜ å°„çš„è‚¡ç¥¨"""
    df = pd.read_csv(csv_path)
    # æ‰¾å‡ºcodeä¸ºç©ºçš„è®°å½•
    unmapped = df[df['code'].isna() | (df['code'] == '')]['name'].unique()
    return pd.DataFrame({'name': unmapped})

def search_stock_code(name: str) -> Optional[str]:
    """ä½¿ç”¨akshareæœç´¢è‚¡ç¥¨ä»£ç """
    try:
        # å°è¯•ç²¾ç¡®åŒ¹é…
        stock_info = ak.stock_info_a_code_name()
        match = stock_info[stock_info['name'] == name]
        if not match.empty:
            return match.iloc[0]['code']
        
        # å°è¯•æ¨¡ç³ŠåŒ¹é…ï¼ˆåç§°åŒ…å«ï¼‰
        match = stock_info[stock_info['name'].str.contains(name, na=False)]
        if not match.empty:
            return match.iloc[0]['code']
        
        # å°è¯•åå‘æ¨¡ç³ŠåŒ¹é…ï¼ˆè¢«åŒ…å«ï¼‰
        match = stock_info[stock_info['name'].apply(lambda x: name in x if pd.notna(x) else False)]
        if not match.empty:
            return match.iloc[0]['code']
        
        return None
    except Exception as e:
        print(f"æœç´¢ {name} å¤±è´¥: {e}")
        return None

def build_mapping(wanzhu_csv: Path, output_json: Path):
    """æ„å»ºåç§°åˆ°ä»£ç çš„æ˜ å°„"""
    print("=" * 60)
    print("ğŸ” é¡½ä¸»æ¯è‚¡ç¥¨ä»£ç æ˜ å°„è¡¥å…¨")
    print("=" * 60)
    
    # 1. åŠ è½½æœªæ˜ å°„è‚¡ç¥¨
    unmapped_df = load_unmapped_stocks(wanzhu_csv)
    print(f"\nå‘ç° {len(unmapped_df)} åªæœªæ˜ å°„è‚¡ç¥¨")
    
    # 2. åŠ è½½ç°æœ‰æ˜ å°„
    existing_mapping = {}
    if output_json.exists():
        with open(output_json, 'r', encoding='utf-8') as f:
            existing_mapping = json.load(f)
        print(f"å·²æœ‰æ˜ å°„: {len(existing_mapping)} æ¡")
    
    # 3. é€ä¸ªæœç´¢
    new_mappings = {}
    failed_names = []
    
    print("\nğŸŒ å¼€å§‹æœç´¢è‚¡ç¥¨ä»£ç ...")
    for idx, row in unmapped_df.iterrows():
        name = row['name']
        
        # è·³è¿‡å·²å­˜åœ¨çš„
        if name in existing_mapping:
            continue
        
        code = search_stock_code(name)
        if code:
            new_mappings[name] = code
            print(f"  âœ… {name} -> {code}")
        else:
            failed_names.append(name)
            print(f"  âŒ {name} -> æœªæ‰¾åˆ°")
    
    # 4. åˆå¹¶å¹¶ä¿å­˜
    all_mappings = {**existing_mapping, **new_mappings}
    
    with open(output_json, 'w', encoding='utf-8') as f:
        json.dump(all_mappings, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ æ˜ å°„å·²ä¿å­˜: {output_json}")
    print(f"  æ–°å¢æ˜ å°„: {len(new_mappings)} æ¡")
    print(f"  æ€»è®¡æ˜ å°„: {len(all_mappings)} æ¡")
    print(f"  æ˜ å°„å¤±è´¥: {len(failed_names)} åª")
    
    if failed_names:
        print(f"\nâš ï¸ æ˜ å°„å¤±è´¥çš„è‚¡ç¥¨ï¼ˆéœ€äººå·¥å¤„ç†ï¼‰:")
        for name in failed_names[:10]:
            print(f"  - {name}")
        if len(failed_names) > 10:
            print(f"  ... è¿˜æœ‰ {len(failed_names) - 10} åª")
    
    return all_mappings

if __name__ == '__main__':
    wanzhu_csv = Path('data/wanzhu_history_from_api.csv')
    output_json = Path('config/wanzhu_name_to_code_mapping.json')
    
    build_mapping(wanzhu_csv, output_json)
