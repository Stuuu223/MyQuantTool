#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¡½ä¸»æ¯æ•°æ®æ¸…æ´—è„šæœ¬

é—®é¢˜ï¼šAPIè¿”å›çš„æ—©æœŸæ•°æ®ï¼ˆ2025-11-17è‡³2026-02-03ï¼‰æ˜¯å¡«å……æ•°æ®ï¼Œå­—æ®µå€¼å®Œå…¨ä¸å˜
è§£å†³æ–¹æ¡ˆï¼šè¯†åˆ«å¹¶åˆ é™¤å¡«å……æ•°æ®ï¼Œåªä¿ç•™çœŸå®å˜åŒ–çš„æ•°æ®

æ¸…æ´—è§„åˆ™ï¼š
1. å¦‚æœæŸåªè‚¡ç¥¨åœ¨æŸæ—¥æœŸèŒƒå›´å†…çš„ holding_amountã€amount_changeã€holder_count è¿ç»­ä¸å˜
2. åˆ™åˆ¤å®šä¸ºå¡«å……æ•°æ®ï¼Œäºˆä»¥åˆ é™¤
"""

import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import json


def identify_filled_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    è¯†åˆ«å¡«å……æ•°æ®
    
    åˆ¤å®šæ ‡å‡†ï¼š
    - holding_amountã€amount_changeã€holder_count è¿ç»­3å¤©ä»¥ä¸Šå®Œå…¨ç›¸åŒ
    - è§†ä¸ºå¡«å……æ•°æ®
    """
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'])
    df = df.sort_values(['name', 'date'])
    
    # å¯¹æ¯åªè‚¡ç¥¨ï¼Œæ ‡è®°æ˜¯å¦ä¸ºå¡«å……æ•°æ®
    df['is_filled'] = False
    
    for name in df['name'].unique():
        mask = df['name'] == name
        stock_df = df[mask].copy()
        
        if len(stock_df) < 3:
            continue
        
        # è®¡ç®—ä¸‰ä¸ªå…³é”®å­—æ®µçš„å˜åŒ–
        stock_df['amount_diff'] = stock_df['holding_amount'].diff().abs()
        stock_df['change_diff'] = stock_df['amount_change'].diff().abs()
        stock_df['holder_diff'] = stock_df['holder_count'].diff().abs()
        
        # å¦‚æœè¿ç»­å¤šå¤©è¿™ä¸‰ä¸ªå­—æ®µéƒ½ä¸º0ï¼ˆæ— å˜åŒ–ï¼‰ï¼Œåˆ™ä¸ºå¡«å……æ•°æ®
        stock_df['no_change'] = (
            (stock_df['amount_diff'] == 0) & 
            (stock_df['change_diff'] == 0) & 
            (stock_df['holder_diff'] == 0)
        )
        
        # æ ‡è®°å¡«å……æ•°æ®ï¼šè¿ç»­æ— å˜åŒ–è¶…è¿‡3å¤©çš„è®°å½•
        consecutive_no_change = 0
        filled_indices = []
        
        for idx in stock_df.index:
            if stock_df.loc[idx, 'no_change']:
                consecutive_no_change += 1
                if consecutive_no_change >= 2:  # è¿ç»­3å¤©ï¼ˆåŒ…æ‹¬å½“å‰å¤©ï¼‰
                    filled_indices.append(idx)
            else:
                consecutive_no_change = 0
        
        df.loc[filled_indices, 'is_filled'] = True
    
    return df


def clean_data(input_path: Path, output_path: Path):
    """æ¸…æ´—æ•°æ®"""
    print("=" * 60)
    print("ğŸ§¹ é¡½ä¸»æ¯æ•°æ®æ¸…æ´—")
    print("=" * 60)
    
    # 1. åŠ è½½åŸå§‹æ•°æ®
    print(f"\nğŸ“‚ åŠ è½½æ•°æ®: {input_path}")
    df = pd.read_csv(input_path)
    print(f"   åŸå§‹è®°å½•æ•°: {len(df)}")
    print(f"   æ—¥æœŸèŒƒå›´: {df['date'].min()} è‡³ {df['date'].max()}")
    print(f"   å”¯ä¸€è‚¡ç¥¨æ•°: {df['name'].nunique()}")
    
    # 2. è¯†åˆ«å¡«å……æ•°æ®
    print("\nğŸ” è¯†åˆ«å¡«å……æ•°æ®...")
    df_marked = identify_filled_data(df)
    
    filled_count = df_marked['is_filled'].sum()
    print(f"   è¯†åˆ«åˆ°å¡«å……æ•°æ®: {filled_count} æ¡ ({filled_count/len(df)*100:.1f}%)")
    
    # 3. åˆ é™¤å¡«å……æ•°æ®
    df_clean = df_marked[~df_marked['is_filled']].copy()
    df_clean = df_clean.drop(columns=['is_filled'], errors='ignore')
    
    print(f"\nâœ… æ¸…æ´—åæ•°æ®:")
    print(f"   ä¿ç•™è®°å½•æ•°: {len(df_clean)} ({len(df_clean)/len(df)*100:.1f}%)")
    print(f"   åˆ é™¤è®°å½•æ•°: {len(df) - len(df_clean)}")
    print(f"   å”¯ä¸€è‚¡ç¥¨æ•°: {df_clean['name'].nunique()}")
    
    # 4. ç»Ÿè®¡æ¯åªè‚¡ç¥¨çš„é¦–æ¬¡ä¸Šæ¦œæ—¥æœŸï¼ˆçœŸå®ï¼‰
    print("\nğŸ“Š çœŸå®é¦–æ¬¡ä¸Šæ¦œæ—¥æœŸç»Ÿè®¡ (Top 20):")
    first_rank = df_clean.groupby('name').agg({
        'date': 'min',
        'code': 'first',
        'rank': 'first'
    }).reset_index()
    first_rank.columns = ['name', 'first_rank_date', 'code', 'first_rank']
    first_rank = first_rank.sort_values('first_rank_date')
    
    for row in first_rank.head(20).itertuples():
        print(f"   {row.first_rank_date}: {row.name} ({row.code}) - æ’å{row.first_rank}")
    
    # 5. ä¿å­˜æ¸…æ´—åçš„æ•°æ®
    output_path.parent.mkdir(parents=True, exist_ok=True)
    df_clean.to_csv(output_path, index=False, encoding='utf-8-sig')
    print(f"\nğŸ’¾ æ¸…æ´—åæ•°æ®å·²ä¿å­˜: {output_path}")
    
    # 6. ä¿å­˜é¦–æ¬¡ä¸Šæ¦œä¿¡æ¯
    first_rank_path = output_path.parent / 'wanzhu_first_rank_cleaned.json'
    first_rank_dict = {}
    for _, row in first_rank.iterrows():
        if pd.notna(row['code']) and row['code']:
            # å°†Timestampè½¬æ¢ä¸ºå­—ç¬¦ä¸²
            first_rank_date = row['first_rank_date']
            if hasattr(first_rank_date, 'strftime'):
                first_rank_date = first_rank_date.strftime('%Y-%m-%d')
            
            first_rank_dict[row['code']] = {
                'name': row['name'],
                'first_rank_date': first_rank_date,
                'first_rank': int(row['first_rank']) if pd.notna(row['first_rank']) else 0
            }
    
    with open(first_rank_path, 'w', encoding='utf-8') as f:
        json.dump(first_rank_dict, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ é¦–æ¬¡ä¸Šæ¦œä¿¡æ¯å·²ä¿å­˜: {first_rank_path}")
    print(f"   å…± {len(first_rank_dict)} åªæœ‰ä»£ç æ˜ å°„çš„è‚¡ç¥¨")
    
    return df_clean, first_rank


def analyze_cleaned_data(df_clean: pd.DataFrame):
    """åˆ†ææ¸…æ´—åçš„æ•°æ®è´¨é‡"""
    print("\n" + "=" * 60)
    print("ğŸ“ˆ æ¸…æ´—åæ•°æ®åˆ†æ")
    print("=" * 60)
    
    # 1. æ—¥æœŸåˆ†å¸ƒ
    df_clean['date'] = pd.to_datetime(df_clean['date'])
    print(f"\næ—¥æœŸåˆ†å¸ƒ:")
    print(f"   æœ€æ—©: {df_clean['date'].min()}")
    print(f"   æœ€æ™š: {df_clean['date'].max()}")
    print(f"   äº¤æ˜“æ—¥æ•°: {df_clean['date'].nunique()}")
    
    # 2. æ¯æœˆè®°å½•æ•°
    df_clean['month'] = df_clean['date'].dt.to_period('M')
    monthly_counts = df_clean.groupby('month').size()
    print(f"\næ¯æœˆè®°å½•æ•°:")
    for month, count in monthly_counts.items():
        print(f"   {month}: {count} æ¡")
    
    # 3. è‚¡ç¥¨ä¸Šæ¦œå¤©æ•°åˆ†å¸ƒ
    days_on_list = df_clean.groupby('name').size()
    print(f"\nè‚¡ç¥¨ä¸Šæ¦œå¤©æ•°åˆ†å¸ƒ:")
    print(f"   å¹³å‡: {days_on_list.mean():.1f} å¤©")
    print(f"   ä¸­ä½æ•°: {days_on_list.median():.1f} å¤©")
    print(f"   æœ€å¤š: {days_on_list.max()} å¤© ({days_on_list.idxmax()})")
    print(f"   æœ€å°‘: {days_on_list.min()} å¤©")
    
    # 4. æŒä»“é‡‘é¢å˜åŒ–ç¤ºä¾‹ï¼ˆéªŒè¯æ•°æ®çœŸå®æ€§ï¼‰
    print(f"\næŒä»“é‡‘é¢å˜åŒ–ç¤ºä¾‹ (ç½‘å®¿ç§‘æŠ€):")
    wangsu = df_clean[df_clean['name'] == 'ç½‘å®¿ç§‘æŠ€'].sort_values('date')
    if len(wangsu) > 0:
        print(f"   è®°å½•æ•°: {len(wangsu)}")
        print(f"   é‡‘é¢èŒƒå›´: {wangsu['holding_amount'].min()} ~ {wangsu['holding_amount'].max()}")
        print(f"   å˜åŠ¨èŒƒå›´: {wangsu['amount_change'].min()} ~ {wangsu['amount_change'].max()}")
        
        # æ˜¾ç¤ºå‰5æ¡å’Œå5æ¡
        print(f"\n   å‰5æ¡:")
        for _, row in wangsu.head(5).iterrows():
            print(f"     {row['date']}: é‡‘é¢={row['holding_amount']}, å˜åŠ¨={row['amount_change']}")
        print(f"\n   å5æ¡:")
        for _, row in wangsu.tail(5).iterrows():
            print(f"     {row['date']}: é‡‘é¢={row['holding_amount']}, å˜åŠ¨={row['amount_change']}")


def main():
    input_path = Path('data/wanzhu_history_mapped.csv')
    output_path = Path('data/wanzhu_history_cleaned.csv')
    
    if not input_path.exists():
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
        return
    
    # æ¸…æ´—æ•°æ®
    df_clean, first_rank = clean_data(input_path, output_path)
    
    # åˆ†ææ¸…æ´—åçš„æ•°æ®
    analyze_cleaned_data(df_clean)
    
    print("\n" + "=" * 60)
    print("âœ… æ•°æ®æ¸…æ´—å®Œæˆ")
    print("=" * 60)


if __name__ == '__main__':
    main()
